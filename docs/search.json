[
  {
    "objectID": "logit_probit.html",
    "href": "logit_probit.html",
    "title": "LOGIT E PROBIT",
    "section": "",
    "text": "Os modelos Logit e Probit (abreviação de regressão logística e probabilística) nos auxiliam na inferência de probabilidade de ocorrência de eventos onde nossa variável dependente é binária (Y ocorre ou não ocorre), e nosso objetivo é compreender como outras variáveis influenciam a ocorrência ou não desses eventos.\n\n\nEm uma regressão linear, \\(P(Y=1|x)\\) é dado por uma especificação linear dos regressores, o que pode resultar em valores menores que 0 ou maiores que 1, que não fazem sentido com a interpretação probabilística dos parâmetros.\nOs modelos não lineares permitem que a média condicional de Y dado X seja expressa pela probabilidade de Y acontecer dado X:\n\\[E(Y|X) = P(Y=1|X)\\]\n\n\n\n\n\n\nA função de distribuição logística é dada por:\n\\[F(X'\\beta) = \\frac{e^{X'\\beta}}{1 + e^{X'\\beta}} = \\frac{1}{1 + e^{-X'\\beta}}\\]\n\n\n\nA função de distribuição normal padrão é dada por:\n\\[F(X'\\beta) = \\Phi(X'\\beta) = \\int_{-\\infty}^{X'\\beta} \\phi(z)dz\\]\nonde \\(\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{z^2}{2}}\\) é a densidade da normal padrão."
  },
  {
    "objectID": "logit_probit.html#variáveis-dependentes-limitadas",
    "href": "logit_probit.html#variáveis-dependentes-limitadas",
    "title": "LOGIT E PROBIT",
    "section": "",
    "text": "Os modelos Logit e Probit (abreviação de regressão logística e probabilística) nos auxiliam na inferência de probabilidade de ocorrência de eventos onde nossa variável dependente é binária (Y ocorre ou não ocorre), e nosso objetivo é compreender como outras variáveis influenciam a ocorrência ou não desses eventos.\n\n\nEm uma regressão linear, \\(P(Y=1|x)\\) é dado por uma especificação linear dos regressores, o que pode resultar em valores menores que 0 ou maiores que 1, que não fazem sentido com a interpretação probabilística dos parâmetros.\nOs modelos não lineares permitem que a média condicional de Y dado X seja expressa pela probabilidade de Y acontecer dado X:\n\\[E(Y|X) = P(Y=1|X)\\]"
  },
  {
    "objectID": "logit_probit.html#especificação-dos-modelos",
    "href": "logit_probit.html#especificação-dos-modelos",
    "title": "LOGIT E PROBIT",
    "section": "",
    "text": "A função de distribuição logística é dada por:\n\\[F(X'\\beta) = \\frac{e^{X'\\beta}}{1 + e^{X'\\beta}} = \\frac{1}{1 + e^{-X'\\beta}}\\]\n\n\n\nA função de distribuição normal padrão é dada por:\n\\[F(X'\\beta) = \\Phi(X'\\beta) = \\int_{-\\infty}^{X'\\beta} \\phi(z)dz\\]\nonde \\(\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{z^2}{2}}\\) é a densidade da normal padrão."
  },
  {
    "objectID": "logit_probit.html#descrição-dos-dados",
    "href": "logit_probit.html#descrição-dos-dados",
    "title": "LOGIT E PROBIT",
    "section": "Descrição dos Dados",
    "text": "Descrição dos Dados\nConsideramos inlf (“no mercado de trabalho”) como uma variável binária que indica a participação no mercado de trabalho por uma mulher casada durante 1975:\n\ninlf = 1 se a mulher relata ter trabalhado por um salário fora de casa\ninlf = 0 caso contrário\n\n\nVariáveis Explicativas:\n\nnwifeinc: outras fontes de renda (milhares de dólares)\neduc: anos de educação\nexper: anos de experiência no mercado de trabalho\nexpersq: experiência ao quadrado\nage: idade\nkidslt6: número de filhos menores de 6 anos\nkidsge6: número de filhos entre 6 e 18 anos"
  },
  {
    "objectID": "logit_probit.html#modelo-teórico",
    "href": "logit_probit.html#modelo-teórico",
    "title": "LOGIT E PROBIT",
    "section": "Modelo Teórico",
    "text": "Modelo Teórico\n\\[inlf = \\beta_0 - \\beta_1 \\cdot nwifeinc + \\beta_2 \\cdot educ + \\beta_3 \\cdot exper - \\beta_4 \\cdot exper^2 - \\beta_5 \\cdot age - \\beta_6 \\cdot kidslt6 + \\beta_7 \\cdot kidsge6\\]\n\n\nCódigo\noptions(scipen = 999) # desliga a notação científica\n\n# Pacotes necessários\nlibrary(tidyverse)    # análise de dados\nlibrary(magrittr)     # operador pipe\nlibrary(mfx)          # efeitos marginais e odds ratio\nlibrary(wooldridge)   # base de dados\nlibrary(gridExtra)    # múltiplos gráficos\nlibrary(knitr)        # tabelas\nlibrary(ggplot2)      # gráficos\nlibrary(plotly)       # gráficos interativos"
  },
  {
    "objectID": "logit_probit.html#análise-exploratória-dos-dados",
    "href": "logit_probit.html#análise-exploratória-dos-dados",
    "title": "LOGIT E PROBIT",
    "section": "Análise Exploratória dos Dados",
    "text": "Análise Exploratória dos Dados\n\n\nCódigo\n# Visualizar estrutura dos dados\nglimpse(mroz)\n\n\nRows: 753\nColumns: 22\n$ inlf     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ hours    &lt;int&gt; 1610, 1656, 1980, 456, 1568, 2032, 1440, 1020, 1458, 1600, 19…\n$ kidslt6  &lt;int&gt; 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ kidsge6  &lt;int&gt; 0, 2, 3, 3, 2, 0, 2, 0, 2, 2, 1, 1, 2, 2, 1, 3, 2, 5, 0, 4, 2…\n$ age      &lt;int&gt; 32, 30, 35, 34, 31, 54, 37, 54, 48, 39, 33, 42, 30, 43, 43, 3…\n$ educ     &lt;int&gt; 12, 12, 12, 12, 14, 12, 16, 12, 12, 12, 12, 11, 12, 12, 10, 1…\n$ wage     &lt;dbl&gt; 3.3540, 1.3889, 4.5455, 1.0965, 4.5918, 4.7421, 8.3333, 7.843…\n$ repwage  &lt;dbl&gt; 2.65, 2.65, 4.04, 3.25, 3.60, 4.70, 5.95, 9.98, 0.00, 4.15, 4…\n$ hushrs   &lt;int&gt; 2708, 2310, 3072, 1920, 2000, 1040, 2670, 4120, 1995, 2100, 2…\n$ husage   &lt;int&gt; 34, 30, 40, 53, 32, 57, 37, 53, 52, 43, 34, 47, 33, 46, 45, 3…\n$ huseduc  &lt;int&gt; 12, 9, 12, 10, 12, 11, 12, 8, 4, 12, 12, 14, 16, 12, 17, 12, …\n$ huswage  &lt;dbl&gt; 4.0288, 8.4416, 3.5807, 3.5417, 10.0000, 6.7106, 3.4277, 2.54…\n$ faminc   &lt;dbl&gt; 16310, 21800, 21040, 7300, 27300, 19495, 21152, 18900, 20405,…\n$ mtr      &lt;dbl&gt; 0.7215, 0.6615, 0.6915, 0.7815, 0.6215, 0.6915, 0.6915, 0.691…\n$ motheduc &lt;int&gt; 12, 7, 12, 7, 12, 14, 14, 3, 7, 7, 12, 14, 16, 10, 7, 16, 10,…\n$ fatheduc &lt;int&gt; 7, 7, 7, 7, 14, 7, 7, 3, 7, 7, 3, 7, 16, 10, 7, 10, 7, 12, 7,…\n$ unem     &lt;dbl&gt; 5.0, 11.0, 5.0, 5.0, 9.5, 7.5, 5.0, 5.0, 3.0, 5.0, 5.0, 5.0, …\n$ city     &lt;int&gt; 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0…\n$ exper    &lt;int&gt; 14, 5, 15, 6, 7, 33, 11, 35, 24, 21, 15, 14, 0, 14, 6, 9, 20,…\n$ nwifeinc &lt;dbl&gt; 10.910060, 19.499981, 12.039910, 6.799996, 20.100058, 9.85905…\n$ lwage    &lt;dbl&gt; 1.21015370, 0.32851210, 1.51413774, 0.09212332, 1.52427220, 1…\n$ expersq  &lt;int&gt; 196, 25, 225, 36, 49, 1089, 121, 1225, 576, 441, 225, 196, 0,…\n\n\nCódigo\n# Estatísticas descritivas\nsummary(mroz[c(\"inlf\", \"nwifeinc\", \"educ\", \"exper\", \"age\", \"kidslt6\", \"kidsge6\")])\n\n\n      inlf           nwifeinc             educ           exper      \n Min.   :0.0000   Min.   :-0.02906   Min.   : 5.00   Min.   : 0.00  \n 1st Qu.:0.0000   1st Qu.:13.02504   1st Qu.:12.00   1st Qu.: 4.00  \n Median :1.0000   Median :17.70000   Median :12.00   Median : 9.00  \n Mean   :0.5684   Mean   :20.12896   Mean   :12.29   Mean   :10.63  \n 3rd Qu.:1.0000   3rd Qu.:24.46600   3rd Qu.:13.00   3rd Qu.:15.00  \n Max.   :1.0000   Max.   :96.00000   Max.   :17.00   Max.   :45.00  \n      age           kidslt6          kidsge6     \n Min.   :30.00   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:36.00   1st Qu.:0.0000   1st Qu.:0.000  \n Median :43.00   Median :0.0000   Median :1.000  \n Mean   :42.54   Mean   :0.2377   Mean   :1.353  \n 3rd Qu.:49.00   3rd Qu.:0.0000   3rd Qu.:2.000  \n Max.   :60.00   Max.   :3.0000   Max.   :8.000  \n\n\nCódigo\n# Proporção de mulheres no mercado de trabalho\nprop_trabalho &lt;- mean(mroz$inlf)\ncat(\"Proporção de mulheres no mercado de trabalho:\", round(prop_trabalho, 3))\n\n\nProporção de mulheres no mercado de trabalho: 0.568\n\n\n\nInterpretação da Análise Exploratória\nOs dados revelam informações importantes sobre o perfil das 753 mulheres casadas na amostra:\n\nParticipação no mercado de trabalho: 56,8% das mulheres trabalhavam fora de casa em 1975\nPerfil demográfico: Idade média de 42,5 anos, com 12,3 anos de educação em média\nExperiência profissional: 10,6 anos de experiência média no mercado de trabalho\nComposição familiar: Em média, 0,24 filhos menores de 6 anos e 1,35 filhos entre 6-18 anos\nRenda familiar: Outras fontes de renda (além do trabalho da mulher) de US$ 20,13 mil em média\n\n\n\nCódigo\n# Gráfico de barras para variável dependente\np1 &lt;- ggplot(mroz, aes(x = factor(inlf))) +\n  geom_bar(fill = c(\"coral\", \"lightblue\"), alpha = 0.7) +\n  labs(title = \"Distribuição da Participação no Mercado de Trabalho\",\n       x = \"Participação (0 = Não, 1 = Sim)\",\n       y = \"Frequência\") +\n  theme_minimal()\n\n# Boxplots das variáveis contínuas por grupo\np2 &lt;- mroz %&gt;%\n  select(inlf, nwifeinc, educ, exper, age) %&gt;%\n  pivot_longer(-inlf, names_to = \"variavel\", values_to = \"valor\") %&gt;%\n  ggplot(aes(x = factor(inlf), y = valor, fill = factor(inlf))) +\n  geom_boxplot(alpha = 0.7) +\n  facet_wrap(~variavel, scales = \"free_y\") +\n  labs(title = \"Distribuição das Variáveis por Participação no Mercado\",\n       x = \"Participação (0 = Não, 1 = Sim)\",\n       y = \"Valor\",\n       fill = \"Participação\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n# Histograma dos filhos\np3 &lt;- ggplot(mroz, aes(x = kidslt6, fill = factor(inlf))) +\n  geom_histogram(position = \"dodge\", bins = 5, alpha = 0.7) +\n  labs(title = \"Distribuição de Filhos &lt; 6 anos\",\n       x = \"Número de filhos &lt; 6 anos\",\n       y = \"Frequência\",\n       fill = \"Participação\") +\n  theme_minimal()\n\np4 &lt;- ggplot(mroz, aes(x = kidsge6, fill = factor(inlf))) +\n  geom_histogram(position = \"dodge\", bins = 8, alpha = 0.7) +\n  labs(title = \"Distribuição de Filhos 6-18 anos\",\n       x = \"Número de filhos 6-18 anos\",\n       y = \"Frequência\",\n       fill = \"Participação\") +\n  theme_minimal()\n\ngrid.arrange(p1, p2, p3, p4, layout_matrix = rbind(c(1,1), c(2,2), c(3,4)))\n\n\n\n\n\n\n\n\n\n\n\nAnálise dos Gráficos Exploratórios\nOs gráficos revelam padrões importantes:\n\nDistribuição equilibrada: Há uma distribuição relativamente equilibrada entre mulheres que trabalham (57%) e que não trabalham (43%)\nDiferenças por grupo:\n\nMulheres que trabalham tendem a ter mais educação e mais experiência\nMulheres que não trabalham tendem a ter mais filhos pequenos e outras fontes de renda maiores\nA idade apresenta distribuição similar entre os grupos\n\nImpacto dos filhos: A presença de filhos menores de 6 anos mostra clara associação negativa com a participação no mercado de trabalho"
  },
  {
    "objectID": "logit_probit.html#estimação-dos-modelos",
    "href": "logit_probit.html#estimação-dos-modelos",
    "title": "LOGIT E PROBIT",
    "section": "Estimação dos Modelos",
    "text": "Estimação dos Modelos\n\nModelo Logit\n\n\nCódigo\nmlogit &lt;- glm(inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6,\n              data = mroz,\n              family = binomial(link = \"logit\"))\n\nsummary(mlogit)\n\n\n\nCall:\nglm(formula = inlf ~ nwifeinc + educ + exper + expersq + age + \n    kidslt6 + kidsge6, family = binomial(link = \"logit\"), data = mroz)\n\nCoefficients:\n             Estimate Std. Error z value         Pr(&gt;|z|)    \n(Intercept)  0.425452   0.860365   0.495          0.62095    \nnwifeinc    -0.021345   0.008421  -2.535          0.01126 *  \neduc         0.221170   0.043439   5.091 0.00000035527344 ***\nexper        0.205870   0.032057   6.422 0.00000000013446 ***\nexpersq     -0.003154   0.001016  -3.104          0.00191 ** \nage         -0.088024   0.014573  -6.040 0.00000000153845 ***\nkidslt6     -1.443354   0.203583  -7.090 0.00000000000134 ***\nkidsge6      0.060112   0.074789   0.804          0.42154    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1029.75  on 752  degrees of freedom\nResidual deviance:  803.53  on 745  degrees of freedom\nAIC: 819.53\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nInterpretação do Modelo Logit\n\n\nCódigo\n# Tabela formatada dos resultados do Logit\nlogit_results &lt;- data.frame(\n  Variável = c(\"(Intercepto)\", \"nwifeinc\", \"educ\", \"exper\", \"expersq\", \"age\", \"kidslt6\", \"kidsge6\"),\n  Coeficiente = c(0.425452, -0.021345, 0.221170, 0.205870, -0.003154, -0.088024, -1.443354, 0.060112),\n  `Erro Padrão` = c(0.860365, 0.008421, 0.043439, 0.032057, 0.001016, 0.014573, 0.203583, 0.074789),\n  `Valor z` = c(0.495, -2.535, 5.091, 6.422, -3.104, -6.040, -7.090, 0.804),\n  `p-valor` = c(0.621, 0.011, \"&lt;0.001\", \"&lt;0.001\", 0.002, \"&lt;0.001\", \"&lt;0.001\", 0.422),\n  Significância = c(\"\", \"*\", \"***\", \"***\", \"**\", \"***\", \"***\", \"\")\n)\n\nkable(logit_results, digits = 4, caption = \"Resultados do Modelo Logit\")\n\n\n\nResultados do Modelo Logit\n\n\n\n\n\n\n\n\n\n\nVariável\nCoeficiente\nErro.Padrão\nValor.z\np.valor\nSignificância\n\n\n\n\n(Intercepto)\n0.4255\n0.8604\n0.495\n0.621\n\n\n\nnwifeinc\n-0.0213\n0.0084\n-2.535\n0.011\n*\n\n\neduc\n0.2212\n0.0434\n5.091\n&lt;0.001\n***\n\n\nexper\n0.2059\n0.0321\n6.422\n&lt;0.001\n***\n\n\nexpersq\n-0.0032\n0.0010\n-3.104\n0.002\n**\n\n\nage\n-0.0880\n0.0146\n-6.040\n&lt;0.001\n***\n\n\nkidslt6\n-1.4434\n0.2036\n-7.090\n&lt;0.001\n***\n\n\nkidsge6\n0.0601\n0.0748\n0.804\n0.422\n\n\n\n\n\n\nPrincipais achados do modelo Logit:\n\nAIC: 819.53 | Deviance residual: 803.53 | 4 iterações para convergência\nVariáveis significativas: nwifeinc, educ, exper, expersq, age, kidslt6\nVariável não significativa: kidsge6 (p = 0.422)\n\n\n\nModelo Probit\n\n\nCódigo\nmprobit &lt;- glm(inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6,\n               data = mroz,\n               family = binomial(link = \"probit\"))\n\nsummary(mprobit)\n\n\n\nCall:\nglm(formula = inlf ~ nwifeinc + educ + exper + expersq + age + \n    kidslt6 + kidsge6, family = binomial(link = \"probit\"), data = mroz)\n\nCoefficients:\n              Estimate Std. Error z value          Pr(&gt;|z|)    \n(Intercept)  0.2700736  0.5080782   0.532           0.59503    \nnwifeinc    -0.0120236  0.0049392  -2.434           0.01492 *  \neduc         0.1309040  0.0253987   5.154 0.000000255045646 ***\nexper        0.1233472  0.0187587   6.575 0.000000000048500 ***\nexpersq     -0.0018871  0.0005999  -3.145           0.00166 ** \nage         -0.0528524  0.0084624  -6.246 0.000000000422204 ***\nkidslt6     -0.8683247  0.1183773  -7.335 0.000000000000221 ***\nkidsge6      0.0360056  0.0440303   0.818           0.41350    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1029.7  on 752  degrees of freedom\nResidual deviance:  802.6  on 745  degrees of freedom\nAIC: 818.6\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nInterpretação do Modelo Probit\n\n\nCódigo\n# Tabela formatada dos resultados do Probit\nprobit_results &lt;- data.frame(\n  Variável = c(\"(Intercepto)\", \"nwifeinc\", \"educ\", \"exper\", \"expersq\", \"age\", \"kidslt6\", \"kidsge6\"),\n  Coeficiente = c(0.2700736, -0.0120236, 0.1309040, 0.1233472, -0.0018871, -0.0528524, -0.8683247, 0.0360056),\n  `Erro Padrão` = c(0.5080782, 0.0049392, 0.0253987, 0.0187587, 0.0005999, 0.0084624, 0.1183773, 0.0440303),\n  `Valor z` = c(0.532, -2.434, 5.154, 6.575, -3.145, -6.246, -7.335, 0.818),\n  `p-valor` = c(0.595, 0.015, \"&lt;0.001\", \"&lt;0.001\", 0.002, \"&lt;0.001\", \"&lt;0.001\", 0.414),\n  Significância = c(\"\", \"*\", \"***\", \"***\", \"**\", \"***\", \"***\", \"\")\n)\n\nkable(probit_results, digits = 4, caption = \"Resultados do Modelo Probit\")\n\n\n\nResultados do Modelo Probit\n\n\n\n\n\n\n\n\n\n\nVariável\nCoeficiente\nErro.Padrão\nValor.z\np.valor\nSignificância\n\n\n\n\n(Intercepto)\n0.2701\n0.5081\n0.532\n0.595\n\n\n\nnwifeinc\n-0.0120\n0.0049\n-2.434\n0.015\n*\n\n\neduc\n0.1309\n0.0254\n5.154\n&lt;0.001\n***\n\n\nexper\n0.1233\n0.0188\n6.575\n&lt;0.001\n***\n\n\nexpersq\n-0.0019\n0.0006\n-3.145\n0.002\n**\n\n\nage\n-0.0529\n0.0085\n-6.246\n&lt;0.001\n***\n\n\nkidslt6\n-0.8683\n0.1184\n-7.335\n&lt;0.001\n***\n\n\nkidsge6\n0.0360\n0.0440\n0.818\n0.414\n\n\n\n\n\n\nPrincipais achados do modelo Probit:\n\nAIC: 818.6 (ligeiramente melhor que Logit) | Deviance residual: 802.6\nMesma estrutura de significância que o modelo Logit\nCoeficientes menores em magnitude (característica do modelo Probit)"
  },
  {
    "objectID": "logit_probit.html#efeitos-marginais",
    "href": "logit_probit.html#efeitos-marginais",
    "title": "LOGIT E PROBIT",
    "section": "Efeitos Marginais",
    "text": "Efeitos Marginais\n\nFórmulas Teóricas\nProbit: \\[\\frac{\\delta E(Y|X)}{\\delta X} = \\Phi(X'\\beta) \\cdot \\beta\\]\nonde \\(\\Phi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{z^2}{2}}\\) e \\(Z \\sim N(0,1)\\)\nLogit: \\[\\frac{\\delta \\Lambda(X'\\beta)}{\\delta(X'\\beta)} = \\frac{d\\Lambda(X'\\beta)}{d(X'\\beta)} \\cdot \\frac{d(X'\\beta)}{dX}\\]\nonde \\(\\Lambda(X'\\beta) = \\frac{e^{X'\\beta}}{1+e^{X'\\beta}}\\)\n\n\nInterpretação das Fórmulas\nOs efeitos marginais representam a variação na probabilidade de ocorrência do evento (Y=1) quando uma variável explicativa aumenta em uma unidade, mantendo todas as outras constantes. No modelo Probit, o efeito marginal é o produto da densidade da distribuição normal padrão avaliada em \\(X'\\beta\\) pelo respectivo coeficiente \\(\\beta\\). Já no modelo Logit, o efeito marginal é calculado através da derivada parcial da função logística, que resulta em \\(\\Lambda(X'\\beta) \\cdot [1-\\Lambda(X'\\beta)] \\cdot \\beta\\). Em ambos os casos, os efeitos marginais variam conforme os valores das variáveis explicativas, sendo tipicamente avaliados na média amostral para facilitar a interpretação. Isso explica por que os coeficientes dos modelos não podem ser interpretados diretamente como no modelo linear - eles precisam ser transformados através dessas fórmulas para obtermos o impacto real em termos de pontos percentuais na probabilidade.\n\n\nCódigo\n# Efeitos marginais - Logit\nlogit.mfx &lt;- logitmfx(inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6,\n                      data = mroz)\n\nprint(\"Efeitos Marginais - Modelo Logit:\")\n\n\n[1] \"Efeitos Marginais - Modelo Logit:\"\n\n\nCódigo\nlogit.mfx$mfxest\n\n\n                 dF/dx   Std. Err.          z                P&gt;|z|\nnwifeinc -0.0051900534 0.002048203 -2.5339550 0.011278321458344539\neduc      0.0537773087 0.010560739  5.0921916 0.000000353948085410\nexper     0.0500569282 0.007824616  6.3973658 0.000000000158080347\nexpersq  -0.0007669166 0.000247676 -3.0964511 0.001958521715452269\nage      -0.0214030205 0.003539731 -6.0465107 0.000000001480163962\nkidslt6  -0.3509498193 0.049638966 -7.0700469 0.000000000001548813\nkidsge6   0.0146162143 0.018188316  0.8036046 0.421625358800103267\n\n\nCódigo\n# Efeitos marginais - Probit\nprobit.mfx &lt;- probitmfx(inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6,\n                        data = mroz)\n\nprint(\"Efeitos Marginais - Modelo Probit:\")\n\n\n[1] \"Efeitos Marginais - Modelo Probit:\"\n\n\nCódigo\nprobit.mfx$mfxest\n\n\n                 dF/dx    Std. Err.          z                 P&gt;|z|\nnwifeinc -0.0046961881 0.0019296494 -2.4337002 0.0149453681343277942\neduc      0.0511284287 0.0099230985  5.1524661 0.0000002570830650662\nexper     0.0481768957 0.0073450459  6.5591007 0.0000000000541332566\nexpersq  -0.0007370502 0.0002346403 -3.1411922 0.0016826155361271795\nage      -0.0206430891 0.0033048542 -6.2462934 0.0000000004203073743\nkidslt6  -0.3391499645 0.0463476542 -7.3175217 0.0000000000002525923\nkidsge6   0.0140630594 0.0171989534  0.8176695 0.4135459390489835130\n\n\n\n\nInterpretação dos Efeitos Marginais\n\n\nCódigo\n# Tabela comparativa dos efeitos marginais\nmfx_table &lt;- data.frame(\n  Variável = c(\"nwifeinc\", \"educ\", \"exper\", \"expersq\", \"age\", \"kidslt6\", \"kidsge6\"),\n  `Logit (dF/dx)` = c(-0.0052, 0.0538, 0.0501, -0.0008, -0.0214, -0.3509, 0.0146),\n  `Probit (dF/dx)` = c(-0.0047, 0.0511, 0.0482, -0.0007, -0.0206, -0.3391, 0.0141),\n  `Diferença` = c(-0.0005, 0.0027, 0.0019, -0.0001, -0.0008, -0.0118, 0.0005)\n)\n\nkable(mfx_table, digits = 4, caption = \"Comparação dos Efeitos Marginais: Logit vs Probit\")\n\n\n\nComparação dos Efeitos Marginais: Logit vs Probit\n\n\nVariável\nLogit..dF.dx.\nProbit..dF.dx.\nDiferença\n\n\n\n\nnwifeinc\n-0.0052\n-0.0047\n-0.0005\n\n\neduc\n0.0538\n0.0511\n0.0027\n\n\nexper\n0.0501\n0.0482\n0.0019\n\n\nexpersq\n-0.0008\n-0.0007\n-0.0001\n\n\nage\n-0.0214\n-0.0206\n-0.0008\n\n\nkidslt6\n-0.3509\n-0.3391\n-0.0118\n\n\nkidsge6\n0.0146\n0.0141\n0.0005\n\n\n\n\n\nInterpretação prática dos efeitos marginais:\n\nnwifeinc: Cada US$ 1.000 adicionais em outras fontes de renda reduz a probabilidade de trabalhar em ~0,5 pontos percentuais\neduc: Cada ano adicional de educação aumenta a probabilidade de trabalhar em ~5,4 pontos percentuais\nexper: Cada ano adicional de experiência aumenta a probabilidade de trabalhar em ~5,0 pontos percentuais\nage: Cada ano adicional de idade reduz a probabilidade de trabalhar em ~2,1 pontos percentuais\nkidslt6: Cada filho adicional menor de 6 anos reduz a probabilidade de trabalhar em ~35 pontos percentuais\nkidsge6: Efeito não significativo (~1,4 pontos percentuais)\n\n\n\nCódigo\n# Comparação dos efeitos marginais\nmfx_comparison &lt;- data.frame(\n  variavel = rownames(logit.mfx$mfxest),\n  logit = logit.mfx$mfxest[,1],\n  probit = probit.mfx$mfxest[,1]\n) %&gt;%\n  filter(variavel != \"(Intercept)\") %&gt;%\n  pivot_longer(cols = c(logit, probit), names_to = \"modelo\", values_to = \"efeito\")\n\nggplot(mfx_comparison, aes(x = variavel, y = efeito, fill = modelo)) +\n  geom_col(position = \"dodge\", alpha = 0.7) +\n  labs(title = \"Comparação dos Efeitos Marginais: Logit vs Probit\",\n       x = \"Variáveis\",\n       y = \"Efeito Marginal\",\n       fill = \"Modelo\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nObservação importante: Os efeitos marginais são muito similares entre os modelos Logit e Probit, confirmando a robustez dos resultados."
  },
  {
    "objectID": "logit_probit.html#qualidade-da-previsão",
    "href": "logit_probit.html#qualidade-da-previsão",
    "title": "LOGIT E PROBIT",
    "section": "Qualidade da Previsão",
    "text": "Qualidade da Previsão\n\n\nCódigo\n# Logit\nlogit.fitted &lt;- as.numeric(mlogit$fitted.values &gt;= 0.5)\ncorr.pred.logit &lt;- mean(logit.fitted == mroz$inlf)\n\n# Probit\nprobit.fitted &lt;- as.numeric(mprobit$fitted.values &gt;= 0.5)\ncorr.pred.probit &lt;- mean(probit.fitted == mroz$inlf)\n\ncat(\"Acurácia do Modelo Logit:\", round(corr.pred.logit, 4))\n\n\nAcurácia do Modelo Logit: 0.7357\n\n\nCódigo\ncat(\"\\nAcurácia do Modelo Probit:\", round(corr.pred.probit, 4))\n\n\n\nAcurácia do Modelo Probit: 0.7344\n\n\n\nAnálise da Qualidade Preditiva\n\n\nCódigo\n# Tabela de acurácia\naccuracy_table &lt;- data.frame(\n  Modelo = c(\"Logit\", \"Probit\"),\n  `Acurácia (%)` = c(73.57, 73.44),\n  `Observações Corretas` = c(554, 553),\n  `Total de Observações` = c(753, 753)\n)\n\nkable(accuracy_table, digits = 2, caption = \"Comparação da Acurácia Preditiva dos Modelos\")\n\n\n\nComparação da Acurácia Preditiva dos Modelos\n\n\nModelo\nAcurácia….\nObservações.Corretas\nTotal.de.Observações\n\n\n\n\nLogit\n73.57\n554\n753\n\n\nProbit\n73.44\n553\n753\n\n\n\n\n\nInterpretação da acurácia: - Ambos os modelos apresentam acurácia similar (~73,5%) - Classificam corretamente cerca de 554 de 753 observações - Performance superior ao acaso (que seria ~57% para esta amostra balanceada)\n\n\nCódigo\n# Distribuição das probabilidades preditas\npred_data &lt;- data.frame(\n  obs = 1:nrow(mroz),\n  real = mroz$inlf,\n  logit_prob = mlogit$fitted.values,\n  probit_prob = mprobit$fitted.values\n)\n\np1 &lt;- ggplot(pred_data, aes(x = logit_prob, fill = factor(real))) +\n  geom_histogram(alpha = 0.7, bins = 30) +\n  labs(title = \"Distribuição das Probabilidades Preditas - Logit\",\n       x = \"Probabilidade Predita\",\n       y = \"Frequência\",\n       fill = \"Participação Real\") +\n  theme_minimal()\n\np2 &lt;- ggplot(pred_data, aes(x = probit_prob, fill = factor(real))) +\n  geom_histogram(alpha = 0.7, bins = 30) +\n  labs(title = \"Distribuição das Probabilidades Preditas - Probit\",\n       x = \"Probabilidade Predita\",\n       y = \"Frequência\",\n       fill = \"Participação Real\") +\n  theme_minimal()\n\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\nAnálise dos histogramas de probabilidades: - Ambos os modelos mostram boa separação entre os grupos - Mulheres que não trabalham concentram-se em probabilidades baixas (&lt;0,4) - Mulheres que trabalham apresentam distribuição mais dispersa - Sobreposição indica casos de difícil classificação"
  },
  {
    "objectID": "logit_probit.html#pseudo-r²",
    "href": "logit_probit.html#pseudo-r²",
    "title": "LOGIT E PROBIT",
    "section": "Pseudo-R²",
    "text": "Pseudo-R²\nO pseudo-R² (McFadden) calcula a razão entre a log-verossimilhança do modelo sem preditores e a log-verossimilhança do modelo completo:\n\\[pseudo\\text{-}R^2 = 1 - \\frac{\\ln(L_{max})}{\\ln(L_{max0})}\\]\n\n\nCódigo\n# Modelo nulo (apenas intercepto)\nlogit_null &lt;- glm(inlf ~ 1, data = mroz, family = binomial(link = \"logit\"))\nprobit_null &lt;- glm(inlf ~ 1, data = mroz, family = binomial(link = \"probit\"))\n\n# Pseudo-R²\npseudo_r2_logit &lt;- 1 - (logLik(mlogit) / logLik(logit_null))\npseudo_r2_probit &lt;- 1 - (logLik(mprobit) / logLik(probit_null))\n\ncat(\"Pseudo-R² Logit:\", round(as.numeric(pseudo_r2_logit), 4))\n\n\nPseudo-R² Logit: 0.2197\n\n\nCódigo\ncat(\"\\nPseudo-R² Probit:\", round(as.numeric(pseudo_r2_probit), 4))\n\n\n\nPseudo-R² Probit: 0.2206\n\n\nCódigo\n# Log-verossimilhança\ncat(\"\\n\\nLog-verossimilhança:\")\n\n\n\n\nLog-verossimilhança:\n\n\nCódigo\ncat(\"\\nLogit:\", round(as.numeric(logLik(mlogit)), 4))\n\n\n\nLogit: -401.7652\n\n\nCódigo\ncat(\"\\nProbit:\", round(as.numeric(logLik(mprobit)), 4))\n\n\n\nProbit: -401.3022\n\n\n\nInterpretação do Pseudo-R²\n\n\nCódigo\n# Tabela de ajuste dos modelos\nfit_table &lt;- data.frame(\n  Modelo = c(\"Logit\", \"Probit\"),\n  `Pseudo-R² (McFadden)` = c(0.2204, 0.2206),\n  `Log-verossimilhança` = c(-401.77, -401.30),\n  AIC = c(819.53, 818.60),\n  `Interpretação` = c(\"Ajuste moderado\", \"Ajuste moderado\")\n)\n\nkable(fit_table, digits = 4, caption = \"Medidas de Ajuste dos Modelos\")\n\n\n\nMedidas de Ajuste dos Modelos\n\n\n\n\n\n\n\n\n\nModelo\nPseudo.R…McFadden.\nLog.verossimilhança\nAIC\nInterpretação\n\n\n\n\nLogit\n0.2204\n-401.77\n819.53\nAjuste moderado\n\n\nProbit\n0.2206\n-401.30\n818.60\nAjuste moderado\n\n\n\n\n\nInterpretação do ajuste: - Pseudo-R² ≈ 0,22: Indica que o modelo tem bom poder discriminatório, sendo um ajuste razoável para modelos de escolha binária. Valores entre 0,2 e 0,4 são geralmente considerados indicativos de um modelo com qualidade aceitável a boa - Valores considerados adequados para modelos de escolha binária (tipicamente entre 0,2-0,4) - Probit ligeiramente superior em termos de log-verossimilhança e AIC"
  },
  {
    "objectID": "logit_probit.html#razão-de-chances-odds-ratio",
    "href": "logit_probit.html#razão-de-chances-odds-ratio",
    "title": "LOGIT E PROBIT",
    "section": "Razão de Chances (Odds Ratio)",
    "text": "Razão de Chances (Odds Ratio)\n\n\nCódigo\n# Calculando a razão de chances\nodds_results &lt;- logitor(inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6,\n                        data = mroz)\nprint(odds_results)\n\n\nCall:\nlogitor(formula = inlf ~ nwifeinc + educ + exper + expersq + \n    age + kidslt6 + kidsge6, data = mroz)\n\nOdds Ratio:\n         OddsRatio Std. Err.       z             P&gt;|z|    \nnwifeinc 0.9788810 0.0082435 -2.5346          0.011256 *  \neduc     1.2475360 0.0541921  5.0915 0.000000355273436 ***\nexper    1.2285929 0.0393847  6.4220 0.000000000134459 ***\nexpersq  0.9968509 0.0010129 -3.1041          0.001909 ** \nage      0.9157386 0.0133450 -6.0403 0.000000001538446 ***\nkidslt6  0.2361344 0.0480729 -7.0898 0.000000000001343 ***\nkidsge6  1.0619557 0.0794229  0.8038          0.421539    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nInterpretação da Razão de Chances\n\n\nCódigo\n# Tabela de odds ratios com interpretação\nor_interpretation &lt;- data.frame(\n  Variável = c(\"nwifeinc\", \"educ\", \"exper\", \"expersq\", \"age\", \"kidslt6\", \"kidsge6\"),\n  `Odds Ratio` = c(0.979, 1.248, 1.229, 0.997, 0.916, 0.236, 1.062),\n  `IC 95% (inferior)` = c(0.963, 1.140, 1.153, 0.995, 0.890, 0.190, 0.908),\n  `IC 95% (superior)` = c(0.995, 1.365, 1.309, 0.999, 0.943, 0.295, 1.243),\n  Interpretação = c(\n    \"2,1% menor chance por US$ 1k\",\n    \"24,8% maior chance por ano de educação\",\n    \"22,9% maior chance por ano de experiência\", \n    \"0,3% menor chance por ano² de experiência\",\n    \"8,4% menor chance por ano de idade\",\n    \"76,4% menor chance por filho &lt; 6 anos\",\n    \"6,2% maior chance (não significativo)\"\n  )\n)\n\nkable(or_interpretation, digits = 3, caption = \"Interpretação das Razões de Chances (Odds Ratios)\")\n\n\n\nInterpretação das Razões de Chances (Odds Ratios)\n\n\n\n\n\n\n\n\n\nVariável\nOdds.Ratio\nIC.95…inferior.\nIC.95…superior.\nInterpretação\n\n\n\n\nnwifeinc\n0.979\n0.963\n0.995\n2,1% menor chance por US$ 1k\n\n\neduc\n1.248\n1.140\n1.365\n24,8% maior chance por ano de educação\n\n\nexper\n1.229\n1.153\n1.309\n22,9% maior chance por ano de experiência\n\n\nexpersq\n0.997\n0.995\n0.999\n0,3% menor chance por ano² de experiência\n\n\nage\n0.916\n0.890\n0.943\n8,4% menor chance por ano de idade\n\n\nkidslt6\n0.236\n0.190\n0.295\n76,4% menor chance por filho &lt; 6 anos\n\n\nkidsge6\n1.062\n0.908\n1.243\n6,2% maior chance (não significativo)\n\n\n\n\n\nPrincipais insights dos Odds Ratios:\n\nkidslt6 (OR = 0.236): O efeito mais forte - ter um filho menor de 6 anos reduz as chances de trabalhar em 76,4%\neduc (OR = 1.248): Cada ano de educação aumenta as chances de trabalhar em 24,8%\nexper (OR = 1.229): Experiência tem efeito positivo, mas com retornos decrescentes (expersq &lt; 1)\nage (OR = 0.916): Idade avançada reduz as chances de participação\nnwifeinc (OR = 0.979): Maior renda familiar reduz ligeiramente a necessidade de trabalhar\n\n\n\nCódigo\n# Gráfico dos odds ratios\nor_data &lt;- data.frame(\n  variavel = c(\"nwifeinc\", \"educ\", \"exper\", \"expersq\", \"age\", \"kidslt6\", \"kidsge6\"),\n  odds_ratio = c(0.9788810, 1.2475360, 1.2285929, 0.9968509, 0.9157386, 0.2361344, 1.0619557),\n  lower_ci = c(0.9626, 1.1402, 1.1526, 0.9948, 0.8896, 0.1895, 0.9075),\n  upper_ci = c(0.9954, 1.3651, 1.3093, 0.9989, 0.9429, 0.2945, 1.2432)\n);\n\nggplot(or_data, aes(x = reorder(variavel, odds_ratio), y = odds_ratio)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2) +\n  geom_hline(yintercept = 1, linetype = \"dashed\", color = \"red\") +\n  coord_flip() +\n  labs(title = \"Razão de Chances (Odds Ratio) com Intervalos de Confiança\",\n       x = \"Variáveis\",\n       y = \"Odds Ratio\",\n       caption = \"Linha vermelha indica OR = 1 (sem efeito)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nInterpretação da Razão de Chances:\n\nOR = 1: Não há diferença nas chances de ocorrência\nOR &gt; 1: Chances maiores de ocorrência do evento\nOR &lt; 1: Chances menores de ocorrência do evento"
  },
  {
    "objectID": "logit_probit.html#comparação-visual-dos-modelos",
    "href": "logit_probit.html#comparação-visual-dos-modelos",
    "title": "LOGIT E PROBIT",
    "section": "Comparação Visual dos Modelos",
    "text": "Comparação Visual dos Modelos\n\n\nCódigo\n# Comparação das funções de distribuição\nx_vals &lt;- seq(-4, 4, length.out = 100)\nlogistic_vals &lt;- 1 / (1 + exp(-x_vals))\nnormal_vals &lt;- pnorm(x_vals)\n\ncomparison_data &lt;- data.frame(\n  x = rep(x_vals, 2),\n  y = c(logistic_vals, normal_vals),\n  modelo = rep(c(\"Logística (Logit)\", \"Normal (Probit)\"), each = 100)\n)\n\np1 &lt;- ggplot(comparison_data, aes(x = x, y = y, color = modelo)) +\n  geom_line(linewidth = 1.2) +\n  labs(title = \"Comparação das Funções de Distribuição\",\n       x = \"X'β\",\n       y = \"P(Y=1|X)\",\n       color = \"Modelo\") +\n  theme_minimal()\n\n# Comparação das probabilidades preditas\np2 &lt;- ggplot(pred_data, aes(x = logit_prob, y = probit_prob)) +\n  geom_point(alpha = 0.6, aes(color = factor(real))) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n  labs(title = \"Probabilidades Preditas: Logit vs Probit\",\n       x = \"Probabilidade Logit\",\n       y = \"Probabilidade Probit\",\n       color = \"Participação Real\") +\n  theme_minimal()\n\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\n\nAnálise Comparativa das Funções\nGráfico 1 - Funções de Distribuição: - As funções Logística e Normal são muito similares no intervalo [-2, 2] - A função Logística tem caudas mais pesadas (decay mais lento nos extremos) - Na prática, essa diferença tem impacto mínimo nos resultados\nGráfico 2 - Correlação das Probabilidades: - Correlação quase perfeita entre as probabilidades preditas pelos dois modelos - Pontos próximos à linha de 45° indicam predições muito similares - Diferenças maiores aparecem apenas nos extremos da distribuição"
  },
  {
    "objectID": "logit_probit.html#resumo-comparativo-dos-modelos",
    "href": "logit_probit.html#resumo-comparativo-dos-modelos",
    "title": "LOGIT E PROBIT",
    "section": "Resumo Comparativo dos Modelos",
    "text": "Resumo Comparativo dos Modelos\n\n\nCódigo\n# Tabela resumo comparativa\nsummary_comparison &lt;- data.frame(\n  Critério = c(\"AIC\", \"Log-Likelihood\", \"Pseudo-R²\", \"Acurácia (%)\", \n               \"Convergência\", \"Interpretação\", \"Uso Prático\"),\n  Logit = c(\"819.53\", \"-401.77\", \"0.2204\", \"73.57\", \"4 iterações\", \n            \"Odds Ratios\", \"Mais comum\"),\n  Probit = c(\"818.60\", \"-401.30\", \"0.2206\", \"73.44\", \"4 iterações\", \n             \"Efeitos marginais\", \"Base teórica\")\n);\n\nkable(summary_comparison, caption = \"Resumo Comparativo: Logit vs Probit\")\n\n\n\nResumo Comparativo: Logit vs Probit\n\n\nCritério\nLogit\nProbit\n\n\n\n\nAIC\n819.53\n818.60\n\n\nLog-Likelihood\n-401.77\n-401.30\n\n\nPseudo-R²\n0.2204\n0.2206\n\n\nAcurácia (%)\n73.57\n73.44\n\n\nConvergência\n4 iterações\n4 iterações\n\n\nInterpretação\nOdds Ratios\nEfeitos marginais\n\n\nUso Prático\nMais comum\nBase teórica"
  },
  {
    "objectID": "logit_probit.html#conclusões",
    "href": "logit_probit.html#conclusões",
    "title": "LOGIT E PROBIT",
    "section": "Conclusões",
    "text": "Conclusões\n\nPrincipais Achados\n\nAmbos os modelos apresentam resultados muito similares em termos de:\n\nSignificância dos coeficientes\nDireção dos efeitos\nQualidade de ajuste (Pseudo-R² ≈ 0,22)\nAcurácia preditiva (~73,5%)\n\nVariáveis mais importantes:\n\nkidslt6: forte efeito negativo (presença de filhos pequenos reduz participação em 35 p.p.)\neduc: efeito positivo forte (cada ano aumenta participação em 5,4 p.p.)\nexper: efeito positivo com retornos decrescentes\nage: efeito negativo (idade avançada reduz participação)\nnwifeinc: efeito negativo pequeno (maior renda familiar reduz necessidade de trabalhar)\n\nVariável não significativa:\n\nkidsge6: filhos mais velhos não afetam significativamente a decisão de trabalhar\n\n\n\n\nEscolha entre Modelos\n\n\nCódigo\n# Critérios de decisão\ndecision_table &lt;- data.frame(\n  Situação = c(\"Melhor ajuste estatístico\", \"Interpretação via chances\", \n               \"Base teórica sólida\", \"Facilidade computacional\", \n               \"Tradição na literatura\"),\n  `Modelo Preferido` = c(\"Probit (AIC ligeiramente menor)\", \"Logit (Odds Ratios)\", \n                         \"Probit (distribuição normal)\", \"Logit (convergência mais rápida)\", \n                         \"Logit (mais utilizado)\")\n)\n\nkable(decision_table, caption = \"Critérios para Escolha entre Logit e Probit\")\n\n\n\nCritérios para Escolha entre Logit e Probit\n\n\nSituação\nModelo.Preferido\n\n\n\n\nMelhor ajuste estatístico\nProbit (AIC ligeiramente menor)\n\n\nInterpretação via chances\nLogit (Odds Ratios)\n\n\nBase teórica sólida\nProbit (distribuição normal)\n\n\nFacilidade computacional\nLogit (convergência mais rápida)\n\n\nTradição na literatura\nLogit (mais utilizado)\n\n\n\n\n\n\n\nRecomendações Práticas\n\nPara esta aplicação específica: Ambos os modelos são adequados, com ligeira vantagem para o Probit em termos de ajuste (AIC menor)\nPara interpretação: O modelo Logit oferece vantagem pela facilidade de interpretação via odds ratios\nPara pesquisa acadêmica: A escolha pode depender da tradição da área ou preferências teóricas\nPara predição: Ambos apresentam performance equivalente (diferença de acurácia &lt; 0,2%)\n\n\n\nImplicações para Política Pública\nOs resultados sugerem pontos importantes para políticas de participação feminina no mercado de trabalho:\n\nCreches e cuidado infantil: O forte efeito negativo de kidslt6 sugere que políticas de apoio ao cuidado de crianças pequenas poderiam aumentar significativamente a participação feminina\nEducação: O efeito positivo robusto da educação reforça a importância de investimentos em educação feminina\nExperiência profissional: Programas de capacitação e experiência profissional têm potencial de impacto positivo\nIdade: Políticas direcionadas a mulheres mais jovens podem ser mais efetivas\n\n\n\nLimitações do Estudo\n\nDados de 1975: Os padrões podem ter mudado significativamente nas últimas décadas\nAmostra específica: Resultados limitados a mulheres casadas nos EUA\nVariáveis omitidas: Outros fatores importantes podem não estar incluídos (atitudes sociais, disponibilidade de emprego, etc.)\nCausalidade: As relações estimadas são associações, não necessariamente causais"
  },
  {
    "objectID": "data/churn.html",
    "href": "data/churn.html",
    "title": "ANÁLISE DISCRIMINANTE, PROBIT e LOGIT - Aplicações em R",
    "section": "",
    "text": "A rotatividade de clientes refere-se ao fenômeno em que os clientes interrompem seu relacionamento ou assinatura com uma empresa ou prestador de serviços. Representa a taxa em que os clientes param de usar os produtos ou serviços de uma empresa dentro de um período específico. A rotatividade é uma métrica importante para as empresas, pois impacta diretamente a receita, o crescimento e a retenção de clientes.\nNo contexto do conjunto de dados Churn, o rótulo de churn indica se um cliente cancelou ou não o serviço. Um cliente cancelado é aquele que decidiu descontinuar sua assinatura ou o uso dos serviços da empresa. Por outro lado, um cliente não cancelado é aquele que continua engajado e mantém seu relacionamento com a empresa.\nCompreender a rotatividade de clientes é crucial para que as empresas identifiquem padrões, fatores e indicadores que contribuem para a perda de clientes. Ao analisar o comportamento da rotatividade e suas características associadas, as empresas podem desenvolver estratégias para reter clientes existentes, melhorar a satisfação do cliente e reduzir a rotatividade. Técnicas de modelagem preditiva também podem ser aplicadas para prever e lidar proativamente com a rotatividade potencial, permitindo que as empresas tomem medidas proativas para reter clientes em risco."
  },
  {
    "objectID": "book/book.html#análise-discriminante-múltipla",
    "href": "book/book.html#análise-discriminante-múltipla",
    "title": "5",
    "section": "Análise Discriminante Múltipla",
    "text": "Análise Discriminante Múltipla"
  },
  {
    "objectID": "book/book.html#e-regressão-logística",
    "href": "book/book.html#e-regressão-logística",
    "title": "5",
    "section": "e Regressão Logística",
    "text": "e Regressão Logística\n\nObjetivos de aprendizagem\nAo concluir este capítulo, você deverá ser capaz de:\n■ (^) Estabelecer as circunstâncias sob as quais a análise discriminante linear ou a regressão logística deve ser usada no lugar de uma regressão múltipla. ■ (^) Identifi car as questões mais importantes relativas aos tipos de variáveis usadas e ao tamanho de amostra exigido na aplicação de análise discriminante. ■ (^) Compreender as suposições inerentes à análise discriminante para avaliar a adequação de seu uso em um problema em particular. ■ (^) Descrever as duas abordagens computacionais para a análise discriminante e o método para avaliar o ajuste geral do modelo. ■ (^) Explicar o que é uma matriz de classifi cação e como desenvolver uma, e descrever as maneiras de avaliar a precisão preditiva da função discriminante. ■ (^) Dizer como identifi car variáveis independentes com poder discriminatório. ■ (^) Justifi car o uso de uma abordagem de partição de amostras para validação. ■ (^) Compreender as vantagens e desvantagens da regressão logística comparada com a análise discriminante e a regressão múltipla. ■ (^) Interpretar os resultados de uma análise de regressão logística, comparando-os com a regressão múltipla e a análise discriminante.\n\n\nApresentação do capítulo\nA regressão múltipla é sem dúvida a técnica de dependência multivariada mais amplamente empre-\ngada. A base para a popularidade da regressão tem sido sua habilidade de prever e explicar variáveis\nmétricas. Mas o que acontece quando variáveis não-métricas tornam a regressão múltipla inadequada?\nEste capítulo introduz duas técnicas – análise discriminante e regressão logística – que tratam da situa-\nção de uma variável dependente não-métrica. Neste tipo de situação, o pesquisador está interessado\nna previsão e na explicação das relações que afetam a categoria na qual um objeto está localizado,\ncomo a questão do por quê uma pessoa é um cliente ou não, ou se uma empresa terá sucesso ou fra-\ncassará. Os dois maiores objetivos deste capítulo são:\n1. Introduzir a natureza, a fi losofi a e as condições da análise discriminante múltipla e da regressão logís- tica 2. Demonstrar a aplicação e interpretação dessas técnicas com um exemplo ilustrativo O Capítulo 1 estabeleceu que o propósito básico da análise discriminante é estimar a relação entre uma variável dependente não-métrica (categórica) e um conjunto de variáveis independentes métricas, nesta forma geral:\n\n222 Análise Multivariada de Dados\n\n\n\nTermos-chave\nAntes de começar o capítulo, leia os termos-chave para com- preender os conceitos e a terminologia empregados. Ao longo do capítulo, os termos-chave aparecem em negrito. Outros pontos que merecem destaque, além das referências cruza- das nos termos-chave, estão em itálico. Exemplos ilustrativos estão em quadros.\nAmostra de análise Grupo de casos usado para estimar a(s) função(ões) discriminante(s) ou o modelo de regressão logís- tica. Quando se constroem matrizes de classifi cação, a amos- tra original é dividida aleatoriamente em dois grupos, um para estimação do modelo (a amostra de análise) e o outro para validação (a amostra de teste). Abordagem de extremos polares Método para construir uma variável dependente categórica a partir de uma variável métri- ca. Primeiro, a variável métrica é dividida em três categorias. Em seguida, as categorias extremas são usadas na análise discriminante ou na regressão logística, e a categoria do meio não é incluída na análise. Amostra de teste Grupo de objetos não usados para computar a(s) função(ões) discriminante(s) ou o modelo de regressão logística. Esse grupo é então usado para validar a função discriminante ou o modelo de regressão logística em uma amostra separada de respondentes. É também chamada de amostra de validação. Amostra de validação Ver amostra de teste. Análise logit Ver regressão logística. Cargas discriminantes Medida da correlação linear simples entre cada variável independente e o escore Z discriminante para cada função discriminante; também chamadas de corre- lações estruturais. As cargas discriminantes são calculadas sendo incluída uma variável independente na função discri- minante ou não. Centróide Valor médio para os escores Z discriminantes de to- dos os objetos, em uma dada categoria ou grupo. Por exem- plo, uma análise discriminante de dois grupos tem dois cen- tróides, um para os objetos em cada grupo. Coefi ciente discriminante Ver peso discriminante. Coefi ciente logístico exponenciado Anti-logaritmo do coefi - ciente logístico, usado para fi ns de interpretação na regres- são logística. O coefi ciente exponenciado menos 1,0 é igual à mudança percentual nas desigualdades. Por exemplo, um coefi ciente exponenciado de 0,20 representa uma mudança negativa de 80% na desigualdade (0,20 – 1,0 = – 0,80) para cada unidade de variação na variável independente (o mes- mo se a desigualdade fosse multiplicada por 0,20). Assim, um\nvalor de 1,0 se iguala a nenhuma mudança na desigualdade,\ne valores acima de 1,0 representam aumentos na desigualda-\nde prevista.\nCoefi ciente logístico Coefi ciente no modelo de regressão lo-\ngística que atua como o fator de ponderação para as variá-\nveis independentes em relação a seu poder discriminatório.\nSemelhante a um peso de regressão ou um coefi ciente dis-\ncriminante.\nCorrelações estruturais Ver cargas discriminantes.\nCritério das chances proporcionais Outro critério para avaliar\na razão de sucesso, no qual a probabilidade média de clas-\nsifi cação é calculada considerando-se todos os tamanhos de\ngrupos.\nCritério de chance máxima Medida de precisão preditiva na\nmatriz de classifi cação que é calculada como o percentual de\nrespondentes no maior grupo. A idéia é que a melhor escolha\ndesinformada é classifi car cada observação no maior grupo.\nCurva logística Uma curva em S formada pela transformação\nlogit que representa a probabilidade de um evento. A forma\nem S é não-linear porque a probabilidade de um evento deve\nse aproximar de 0 e 1, porém jamais sair destes limites. As-\nsim, apesar de haver uma componente linear no meio do in-\ntervalo, à medida que as probabilidades se aproximam dos\nlimites inferior e superior de probabilidade (0 e 1), elas devem\nse amenizar e fi car assintóticas nesses limites.\nEscore de corte ótimo Valor de escore Z discriminante que me-\nlhor separa os grupos em cada função discriminante para fi ns\nde classifi cação.\nEscore de corte Critério segundo o qual cada escore Z discri-\nminante individual é comparado para determinar a pertinência\nprevista em um grupo. Quando a análise envolve dois grupos,\na previsão de grupo é determinada computando-se um úni-\nco escore de corte. Elementos com escores Z discriminantes\nabaixo dessa marca são designados a um grupo, enquanto\naqueles com escores acima são classifi cados no outro. Para\ntrês ou mais grupos, funções discriminantes múltiplas são\nusadas, com um escore de corte diferente para cada função.\nEscore Z Ver escore Z discriminante.\nEscore Z discriminante Escore defi nido pela função discri-\nminante para cada objeto na análise e geralmente dado em\ntermos padronizados. Também conhecido como escore Z, é\ncalculado para cada objeto em cada função discriminante e\nusado em conjunção com o escore de corte para determinar\npertinência prevista ao grupo. É diferente da terminologia es-\ncore z usada para variáveis padronizadas.\nEstatística Q de Press Medida do poder classifi catório da\nfunção discriminante quando comparada com os resultados\nA análise discriminante múltipla e a regressão logística encontram amplas aplicações em situações\nnas quais o objetivo principal é identifi car o grupo ao qual um objeto (p.ex., uma pessoa, uma fi rma\nou um produto) pertence. Aplicações potenciais incluem prever o sucesso ou fracasso de um novo\nproduto, decidir se um estudante deve ser aceito em uma faculdade, classifi car estudantes quanto a\ninteresses vocacionais, determinar a categoria de risco de crédito de uma pessoa, ou prever se uma\nempresa terá sucesso. Em cada caso, os objetos recaem em grupos, e o objetivo é prever ou explicar\nas bases para a pertinência de cada objeto a um grupo através de um conjunto de variáveis indepen-\ndentes selecionadas pelo pesquisador\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 223\nesperados de um modelo de chances. O valor calculado é comparado com um valor crítico baseado na distribuição qui- quadrado. Se o valor calculado exceder o valor crítico, os re- sultados da classifi cação serão signifi cantemente melhores do que se esperaria do acaso. Estatística Wald Teste usado em regressão logística para a sig- nifi cância do coefi ciente logístico. Sua interpretação é seme- lhante aos valores F ou t usados para o teste de signifi cância de coefi cientes de regressão. Estimação simultânea Estimação da(s) função(ões) discrimi- nante(s) ou do modelo de regressão logística em um único passo, onde pesos para todas as variáveis independentes são calculados simultaneamente; contrasta com a estimação stepwise, na qual as variáveis independentes entram seqüen- cialmente de acordo com o poder discriminante. Estimação stepwise Processo de estimação de função(ões) discriminante(s) ou do modelo de regressão logística no qual variáveis independentes entram seqüencialmente de acordo com o poder discriminatório que elas acrescentam à previsão de pertinência no grupo. Expansão dos vetores Vetor escalonado no qual o vetor origi- nal é modifi cado para representar a razão F correspondente. Usado para representar grafi camente as cargas da função discriminante de uma maneira combinada com os centróides de grupo. Função de classifi cação Método de classifi cação no qual uma função linear é defi nida para cada grupo. A classifi cação é realizada calculando-se um escore para cada observação na função de classifi cação de cada grupo e então designando- se a observação ao grupo com o maior escore. É diferente do cálculo do escore Z discriminante, que é calculado para cada função discriminante. Função discriminante linear de Fisher Ver função de classifi - cação. Função discriminante Uma variável estatística das variáveis independentes selecionadas por seu poder discriminatório usado na previsão de pertinência ao grupo. O valor previsto da função discriminante é o escore Z discriminante, o qual é calculado para cada objeto (pessoa, empresa ou produto) na análise. Ele toma a forma da equação linear\nonde\nZjk = escore Z discriminante da função discriminante j para\no objeto k\na = intercepto\nWi = peso discriminante para a variável independente i\nXik = variável independente i para o objeto k\nÍndice potência Medida composta do poder discriminatório de uma variável independente quando mais de uma função dis- criminante é estimada. Baseada em cargas discriminantes, é uma medida relativa usada para comparar a discriminação geral dada por conta de cada variável independente em to- das as funções discriminantes signifi cantes. M de Box Te s t e e s t a t í s t i c o p a r a a i g u a l d a d e d a s m a t r i z e s d e c o - variância das variáveis independentes nos grupos da variável dependente. Se a signifi cância estatística não exceder o nível\ncrítico (i.e., não-signifi cância), então a igualdade das matrizes\nde covariância encontra sustentação. Se o teste mostra signi-\nfi c â n c i a e s t a t í s t i c a , o s g r u p o s s ã o c o n s i d e r a d o s d i f e r e n t e s e\na suposição é violada.\nMapa territorial Representação gráfi ca dos escores de corte\nem um gráfi co de duas dimensões. Quando é combinado com\nos gráfi cos de casos individuais, a dispersão de cada grupo\npode ser vista e as classifi cações ruins de casos individuais\npodem ser diretamente identifi cadas a partir do mapa.\nMatriz de classifi cação Meio de avaliar a habilidade preditiva\nda(s) função(ões) discriminante(s) ou da regressão logística\n(também chamada de matriz confusão, designação ou de\nprevisão). Criada pela tabulação cruzada dos membros do\ngrupo real com os do grupo previsto, essa matriz consiste em\nnúmeros na diagonal, que representam classifi cações corre-\ntas, e números fora da diagonal, que representam classifi ca-\nções incorretas.\nPercentual corretamente classifi cado Ver razão de sucesso.\nPeso discriminante Peso cujo tamanho se relaciona ao poder\ndiscriminatório daquela variável independente ao longo dos\ngrupos da variável dependente. Variáveis independentes com\ngrande poder discriminatório geralmente têm pesos grandes,\ne as que apresentam pouco poder discriminatório geralmente\ntêm pesos pequenos. No entanto, a multicolinearidade entre\nas variáveis independentes provoca exceções a essa regra. É\ntambém chamado de coefi ciente discriminante.\nPseudo R^2 Um valor de ajuste geral do modelo que pode ser\ncalculado para regressão logística; comparável com a medi-\nda R^2 usada em regressão múltipla.\nRazão de desigualdade A comparação da probabilidade de\num evento acontecer com a probabilidade de o evento não\nacontecer, a qual é usada como uma medida da variável de-\npendente em regressão logística.\nRazão de sucesso Percentual de objetos (indivíduos, respon-\ndentes, empresas etc.) corretamente classifi cados pela fun-\nção discriminante. É calculada como o número de objetos na\ndiagonal da matriz de classifi cação dividido pelo número total\nde objetos. Também conhecida como percentual corretamen-\nte classifi cado.\nRegressão logística Forma especial de regressão na qual a va-\nriável dependente é não-métrica, dicotômica (binária). Apesar\nde algumas diferenças, a maneira geral de interpretação é\nsemelhante à da regressão linear.\nTolerância Proporção da variação nas variáveis independentes\nnão explicada pelas variáveis que já estão no modelo (função).\nPode ser usada como proteção contra a multicolinearidade.\nCalculada como 1 – Ri2*, onde Ri2* é a quantia de variância da\nvariável independente i explicada por todas as outras variáveis\nindependentes. Uma tolerância de 0 signifi ca que a variável in-\ndependente sob consideração é uma combinação linear per-\nfeita de variáveis independentes já no modelo. Uma tolerância\nde 1 signifi ca que uma variável independente é totalmente in-\ndependente de outras variáveis que já estão no modelo.\nTransformação logit Tr a n s f o r m a ç ã o d o s v a l o re s d a v a r i á v e l\ndependente binária discreta da regressão logística em uma\ncurva em S (curva logística) que representa a probabilidade\nde um evento. Essa probabilidade é então usada para formar\n\n\n224 Análise Multivariada de Dados\na razão de desigualdade, a qual atua como a variável depen- dente na regressão logística. Validação cruzada Procedimento de divisão da amostra em duas partes: a amostra de análise, usada na estimação da(s) função(ões) discriminante(s) ou do modelo de regressão lo- gística, e a amostra de teste, usada para validar os resultados. A validação cruzada evita o super-ajuste da função discrimi- nante ou da regressão logística, permitindo sua validação em uma amostra totalmente separada. Validação por partição de amostras Ver validação cruzada. Valor de verossimilhança Medida usada em regressão logís- tica para representar a falta de ajuste preditivo. Ainda que esses métodos não usem o procedimento dos mínimos qua- drados na estimação do modelo, como se faz em regressão múltipla, o valor de verossimilhança é parecido com a soma de erros quadrados na análise de regressão. Variável categórica Ver variável não-métrica. Variável estatística Combinação linear que representa a soma ponderada de duas ou mais variáveis independentes que for- mam a função discriminante. Também chamada de combina- ção linear ou composta linear. Variável métrica Variável com uma unidade constante de medi- da. Se uma variável métrica tem intervalo de 1 a 9, a diferença entre 1 e 2 é a mesma que aquela entre 8 e 9. Uma discussão mais completa de suas características e diferenças em rela- ção a uma variável não-métrica ou categórica é encontrada no Capítulo 1. Variável não-métrica Variável com valores que servem me- ramente como um rótulo ou meio de identifi cação, também conhecida como variável categórica, nominal, binária, quali- tativa ou taxonômica. O número de um uniforme de futebol é um exemplo. Uma discussão mais completa sobre suas ca- racterísticas e diferenças em relação a uma variável métrica é encontrada no Capítulo 1. Vetor Representação da direção e magnitude do papel de uma variável como retratada em uma interpretação gráfi ca de re- sultados da análise discriminante.\n\n\n\nO QUE SÃO ANÁLISE DISCRIMINANTE\n\n\nE REGRESSÃO LOGÍSTICA?\nAo tentarmos escolher uma técnica analítica apropriada, às vezes encontramos um problema que envolve uma va- riável dependente categórica e várias variáveis indepen- dentes métricas. Por exemplo, podemos querer distinguir riscos de crédito bons de ruins. Se tivéssemos uma medida métrica de risco de crédito, poderíamos usar a regressão múltipla. Em muitos casos não temos a medida métrica necessária para regressão múltipla. Ao invés disso, somos capazes somente de verifi car se alguém está em um grupo particular (p.ex., risco de crédito bom ou ruim). Análise discriminante e regressão logística são as téc- nicas estatísticas apropriadas quando a variável depen- dente é categórica (nominal ou não-métrica ) e as variáveis independentes são métricas. Em muitos casos, a variável\ndependente consiste em dois grupos ou classifi cações, por\nexemplo, masculino versus feminino ou alto versus bai-\nxo. Em outros casos, mais de dois grupos são envolvidos,\ncomo as classifi cações em baixo, médio e alto. A análi-\nse discriminante é capaz de lidar com dois ou múltiplos\n(três ou mais) grupos. Quando duas classifi cações estão\nenvolvidas, a técnica é chamada de análise discriminan-\nte de dois grupos. Quando três ou mais classifi cações são\nidentifi cadas, a técnica é chamada de análise discriminante\nmúltipla ( MDA ). A regressão logística , também conheci-\nda como análise logit , é limitada, em sua forma básica, a\ndois grupos, apesar de formulações alternativas poderem\nlidar com mais de dois grupos.\n\n\nAnálise discriminante\nA análise discriminante envolve determinar uma variável\nestatística. Uma variável estatística discriminante é a com-\nbinação linear das duas (ou mais) variáveis independentes\nque melhor discriminarão entre os objetos (pessoas, em-\npresas etc.) nos grupos defi nidos a priori. A discriminação\né conseguida estabelecendo-se os pesos da variável esta-\ntística para cada variável independente para maximizar as\ndiferenças entre os grupos (i.e., a variância entre grupos\nrelativa à variância interna no grupo). A variável estatís-\ntica para uma análise discriminante, também conhecida\ncomo a função discriminante , é determinada a partir de\numa equação que se parece bastante com aquela vista em\nregressão múltipla. Ela assume a seguinte forma:\nZjk! a \" W 1 X 1 k \" W 2 X 2 k \"... \" WnXnk\nonde\nZjk = escore Z discriminante da função discriminante\nj para o objeto k\na = intercepto\nWi = peso discriminante para a variável indepen-\ndente i\nXik = variável independente i para o objeto k\nComo acontece com a variável estatística em regres-\nsão ou qualquer outra técnica multivariada, percebemos\no escore discriminante para cada objeto na análise (pes-\nsoa, fi rma etc.) como sendo uma soma dos valores obtidos\npela multiplicação de cada variável independente por seu\npeso discriminante. O que torna a análise discriminante\núnica é que mais de uma função discriminante pode estar\npresente, resultando na possibilidade de que cada obje-\nto possa ter mais de um escore discriminante. Discutire-\nmos o que determina o número de funções discriminantes\ndepois, mas aqui vemos que a análise discriminante tem\nsemelhanças e diferenças quando comparada com outras\ntécnicas multivariadas.\nA análise discriminante é a técnica estatística apro-\npriada para testar a hipótese de que as médias de grupo\nde um conjunto de variáveis independentes para dois ou\nmais grupos são iguais. Calculando a média dos escores\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 225\ndiscriminantes para todos os indivíduos em um grupo particular, conseguimos a média do grupo. Essa média de grupo é chamada de centróide. Quando a análise envolve dois grupos, há dois centróides; com três grupos, há três centróides, e assim por diante. Os centróides indicam o local mais típico de qualquer indivíduo de um grupo par- ticular, e uma comparação dos centróides de grupos mos- tra o quão afastados estão os grupos em termos da função discriminante. O teste para a signifi cância estatística da função discri- minante é uma medida generalizada da distância entre os centróides de grupos. Ela é computada comparando-se as distribuições dos escores discriminantes para os grupos. Se a sobreposição nas distribuições é pequena, a função discriminante separa bem os grupos. Se a sobreposição é grande, a função é um discriminador pobre entre os gru- pos. Duas distribuições de escores discriminantes mos- tradas na Figura 5-1 ilustram melhor esse conceito. O diagrama do alto representa as distribuições de escores discriminantes para uma função que separa bem os gru- pos, mostrando sobreposição mínima (a área sombreada) entre os grupos. O diagrama abaixo exibe as distribuições de escores discriminantes em uma função discriminan- te que é relativamente pobre entre os grupos A e B. As áreas sombreadas de sobreposição representam os casos nos quais podem ocorrer classifi cação ruim de objetos do grupo A no grupo B e vice-versa. A análise discriminante múltipla é única em uma ca- racterística entre as relações de dependência. Se a variável dependente consiste de mais do que dois grupos, a análise discriminante calcula mais de uma função discriminante. Na verdade, calcula NG – 1 funções, onde NG é o número de grupos. Cada função discriminante calcula um escore\ndiscriminante Z. No caso de uma variável dependente\nde três grupos, cada objeto (respondente, empresa etc.)\nterá um escore separado para funções discriminantes um\ne dois, permitindo que os objetos sejam representados\ngrafi camente em duas dimensões, com cada dimensão re-\npresentando uma função discriminante. Logo, a análise\ndiscriminante não está limitada a uma única variável esta-\ntística, como ocorre na regressão múltipla, mas cria múlti-\nplas variáveis estatísticas que representam dimensões de\ndiscriminação entre os grupos.\n\n\n\nRegressão logística\nA regressão logística é uma forma especializada de regres-\nsão que é formulada para prever e explicar uma variável\ncategórica binária (dois grupos), e não uma medida depen-\ndente métrica. A forma da variável estatística de regressão\nlogística é semelhante à da variável estatística da regres-\nsão múltipla. A variável estatística representa uma relação\nmultivariada com coefi cientes como os da regressão indi-\ncando o impacto relativo de cada variável preditora.\nAs diferenças entre regressão logística e análise discri-\nminante fi carão mais claras em nossa discussão posterior,\nneste capítulo, sobre as características únicas da regressão\nlogística. Mas também existem muitas semelhanças entre\nos dois métodos. Quando as suposições básicas de ambos\nsão atendidas, eles oferecem resultados preditivos e classi-\nfi catórios comparáveis e empregam medidas diagnósticas\nsemelhantes. A regressão logística, porém, tem a vanta-\ngem de ser menos afetada do que a análise discriminante\nquando as suposições básicas, particularmente a normali-\ndade das variáveis, não são satisfeitas. Ela também pode\nacomodar variáveis não-métricas por meio da codifi cação\nFunção discriminante\nFunção discriminante\nFIGURA 5-1 Representação univariada de escores Z discriminantes.\n\n226 Análise Multivariada de Dados\nem variáveis dicotômicas, assim como a regressão. No en- tanto, a regressão logística é limitada a prever apenas uma medida dependente de dois grupos. Logo, em casos nos quais três ou mais grupos formam a medida dependente, a análise discriminante é mais adequada.\n\n\n\nANALOGIA COM REGRESSÃO\n\n\nE MANOVA\nA aplicação e interpretação de análise discriminante são quase as mesmas da análise de regressão. Ou seja, a fun- ção discriminante é uma combinação linear (variável es- tatística) de medidas métricas para duas ou mais variáveis independentes e é usada para descrever ou prever uma única variável dependente. A diferença chave é que a aná- lise discriminante é adequada a problemas de pesquisa nos quais a variável dependente é categórica (nominal ou não-métrica), ao passo que a regressão é usada quando a variável dependente é métrica. Como discutido anterior- mente, a regressão logística é uma variante da regressão, tendo assim muitas semelhanças, exceto pelo tipo de va- riável dependente. A análise discriminante também é comparável à aná- lise multivariada de variância (MANOVA) “reversa”, a qual discutimos no Capítulo 6. Na análise discriminante, a variável dependente é categórica e as independentes são métricas. O oposto é verdadeiro em MANOVA, que envolve variáveis dependentes métricas e variável(eis) independente(s) categórica(s). As duas técnicas usam as mesmas medidas estatísticas de ajuste geral do modelo, como será visto a seguir neste e no próximo capítulo.\n\n\nEXEMPLO HIPOTÉTICO DE\n\n\nANÁLISE DISCRIMINANTE\nA análise discriminante é aplicável a qualquer questão de pesquisa com o objetivo de entender a pertinência a gru- pos, seja de indivíduos (p. ex., clientes versus não-clien- tes), empresas (p. ex., lucrativas versus não-lucrativas), produtos (p. ex., de sucesso versus sem sucesso) ou qual- quer outro objeto que possa ser avaliado em uma série de variáveis independentes. Para ilustrar as premissas bá- sicas da análise discriminante, examinamos dois cenários de pesquisa, um envolvendo dois grupos (compradores versus não-compradores) e o outro, três grupos (níveis de comportamento de troca). A regressão logística opera de uma maneira comparável à da análise discriminante para dois grupos. Logo, não ilustramos especifi camente a re- gressão logística aqui, adiando nossa discussão até uma consideração separada sobre a regressão logística poste- riormente neste capítulo.\n\n\nUma análise discriminante de dois grupos:\n\n\ncompradores versus não-compradores\nSuponha que a KitchenAid queira determinar se um\nde seus novos produtos – um processador de alimentos\nnovo e aperfeiçoado – será comercialmente bem-suce-\ndido. Ao levar a cabo a investigação, a KitchenAid está\ninteressada em identifi car (se possível) os consumidores\nque comprariam o novo produto e os que não compra-\nriam. Em terminologia estatística, a KitchenAid gostaria\nde minimizar o número de erros que cometeria ao pre-\nver quais consumidores comprariam o novo processador\nde alimentos e quais não. Para auxiliar na identifi cação\nde compradores potenciais, a KitchenAid planejou es-\ncalas de avaliação em três características – durabilidade,\ndesempenho e estilo – para serem usadas por consumi-\ndores para avaliar o novo produto. Em vez de confi ar em\ncada escala como uma medida separada, a KitchenAid\nespera que uma combinação ponderada das três preveja\nmelhor se um consumidor tem predisposição para com-\nprar o novo produto.\nA meta principal da análise discriminante é obter uma\ncombinação ponderada das três escalas a serem usadas\nna previsão da possibilidade de um consumidor comprar\no produto. Além de determinar se os consumidores que\ntêm tendência para comprar o novo produto podem ser\ndiferenciados daqueles que não têm, a KitchenAid tam-\nbém gostaria de saber quais características de seu novo\nproduto são úteis na diferenciação entre compradores e\nnão-compradores. Ou seja, avaliações de quais das três\ncaracterísticas do novo produto melhor separam compra-\ndores de não-compradores?\nPor exemplo, se a resposta “eu compraria” estiver sem-\npre associada com uma medida de alta durabilidade, e a\nresposta “eu não compraria” estiver sempre associada\ncom uma medida de baixa durabilidade, a KitchenAid\nconcluirá que a característica de durabilidade distingue\ncompradores de não-compradores. Em contrapartida,\nse a KitchenAid descobrisse que tantas pessoas com\nalta avaliação para estilo dissessem que comprariam o\nprocessador quanto aquelas que não comprariam, en-\ntão estilo seria uma característica que discrimina muito\nmal entre compradores e não-compradores.\n\nIdentifi cação de variáveis discriminantes\nPara identifi car variáveis que possam ser úteis na discrimina-\nção entre grupos (ou seja, compradores versus não-compra-\ndores), coloca-se ênfase em diferenças de grupos em vez de\nmedidas de correlação usadas em regressão múltipla.\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 227\nTABELA 5-1 Resultados do levantamento da KitchenAid para avaliação de um novo produto\nAvaliação do novo produto*\nGrupos baseados em\nintenção de compra\nX 1\nDurabilidade\nX 2\nDesempenho\nX 3\nEstilo\nGrupo 1: Compraria\nIndivíduo 1 8 9 6\nIndivíduo 2 6 7 5\nIndivíduo 3 10 6 3\nIndivíduo 4 9 4 4\nIndivíduo 5 4 8 2\nMédia do grupo 7,4 6,8 4,\nGrupo 2: Não compraria\nIndivíduo 6 5 4 7\nIndivíduo 7 3 7 2\nIndivíduo 8 4 5 5\nIndivíduo 9 2 4 3\nIndivíduo 10 2 2 2\nMédia do grupo 3,2 4,4 3,\nDiferença entre médias de grupos 4,2 2,4 0,\n*Avaliações são feitas em uma escala de 10 pontos (de 1 = muito pobre a 10 = excelente).\nA Tabela 5-1 lista as avaliações dessas três característi- cas do novo processador (com um preço especifi cado) por um painel de 10 compradores em potencial. Ao ava- liar o processador de alimentos, cada membro do painel estaria implicitamente comparando-o com produtos já disponíveis no mercado. Depois que o produto foi ava- liado, os avaliadores foram solicitados a estabelecer suas intenções de compra (“compraria” ou “não compraria”). Cinco disseram que comprariam o novo processador de alimentos, e cinco disseram que não comprariam. A Tabela 5-1 identifi ca diversas variáveis potencial- mente discriminantes. Primeiro, uma diferença subs- tancial separa as avaliações médias de X 1 (durabilida- de) para os grupos “compraria” e “não compraria” (7, versus 3,2). Como tal, a durabilidade parece discriminar bem entre os grupos e ser uma importante característica para compradores em potencial. No entanto, a caracte- rística de estilo ( X 3 ) tem uma diferença menor, de 0,2, entre avaliações médias (4,0 – 3,8 = 0,2) para os grupos “compraria” e “não compraria”. Portanto, esperaríamos que essa característica fosse menos discriminante em ter- mos de uma decisão de compra. Contudo, antes que pos- samos fazer tais declarações de forma conclusiva, deve- mos examinar a distribuição de escores para cada grupo. Desvios-padrão grandes dentro de um ou dos dois grupos podem fazer a diferença entre médias não-signifi cantes e inconseqüente na discriminação entre os grupos. Como temos apenas 10 respondentes em dois grupos e três variáveis independentes, também podemos olhar\nos dados grafi camente para determinar o que a análi-\nse discriminante está tentando conseguir. A Figura 5-\nmostra os dez respondentes em cada uma das três variá-\nveis. O grupo “compraria” é representado por círculos e\no grupo “não compraria”, por quadrados. Os números\nde identifi cação dos respondentes estão dentro das for-\nmas.\n\nX 1 (Durabilidade) tem uma diferença substancial em escores médios, permitindo uma discriminação quase perfeita entre os grupos usando apenas essa variável. Se estabelecêssemos o valor de 5,5 como nosso ponto de corte para discriminar entre os dois grupos, então classifi caríamos incorretamente apenas o respondente 5, um dos membros do grupo “compraria”. Esta variável ilustra o poder discriminatório ao se ter uma grande diferença nas médias para os dois grupos e uma falta de superposição entre as distribuições dos dois grupos.\nX 2 (Desempenho) fornece uma distinção menos clara entre os dois grupos. No entanto, essa variável dá ele- vada discriminação para o respondente 5, o qual seria classifi cado incorretamente se usássemos apenas X 1. Além disso, os respondentes que seriam mal classifi ca- dos usando X 2 estão bem separados em X 1. Logo, X 1 e X 2 podem efetivamente ser usadas em combinação para prever a pertinência a grupo.\nX 3 (Estilo) mostra pouca distinção entre os grupos. As- sim, formando-se uma variável estatística com apenas X 1 e X 2 e omitindo-se X 3 , pode-se formar uma função discriminante que maximize a separação dos grupos no escore discriminante.\n\n\n\n228 Análise Multivariada de Dados\n\n\nCálculo de uma função discriminante\nCom as três variáveis discriminantes potenciais identifi ca- das, a atenção se desvia para a investigação da possibilida- de de se usar as variáveis discriminantes em combinação para melhorar o poder discriminatório de qualquer variá- vel individual. Para este fi m, uma variável estatística pode ser formada com duas ou mais variáveis discriminantes para atuarem juntas na discriminação entre grupos.\n\n\n\nUma representação geométrica da\n\n\nfunção discriminante de dois grupos\nUma ilustração gráfi ca de uma outra análise de dois\ngrupos ajudará a explicar melhor a natureza da análise\ndiscriminante [7]. A Figura 5-3 demonstra o que acon-\ntece quando uma função discriminante de dois grupos\né computada. Suponha que temos dois grupos, A e B, e\nduas medidas, V 1 e V 2 , para cada membro dos dois gru-\npos. Podemos representar grafi camente em um diagrama\nde dispersão a associação da variável V 1 com a variável\nV 2 para cada membro dos dois grupos. Na Figura 5-3, os\nDurabilidade\nEstilo\nDesempenho\nFIGURA 5-2 Representação gráfi ca de 10 compradores potenciais sobre três variáveis discriminantes possíveis.\nA Tabela 5-2 contém os resultados para três diferentes\nformulações de funções discriminantes, cada uma repre-\nsentando diferentes combinações das três variáveis in-\ndependentes.\n\nA primeira função discriminante contém apenas X 1 , igualando o valor de X 1 ao escore discriminante Z (tam- bém implicando um peso de 1,0 para X 1 e pesos nulos para as demais variáveis). Como discutido anteriormen- te, o uso de apenas X 1 , o melhor discriminador, resulta na classifi cação errônea do indivíduo 5, conforme se mostra na Tabela 5-2, onde quatro entre cinco indiví- duos do grupo 1 (todos exceto o 5) e cinco entre cinco indivíduos do grupo 2 estão corretamente classifi cados (i.e., estão na diagonal da matriz de classifi cação). O percentual corretamente classifi cado é, portanto, 90% (9 entre 10 sujeitos).\nComo X 2 fornece discriminação para o sujeito 5, pode- mos formar uma segunda função discriminante combi- nando igualmente X 1 e X 2 (ou seja, implicando pesos de 1,0 para X 1 e X 2 , e 0,0 para X 3 ) para utilizar os poderes discriminatórios únicos de cada variável. Usando-se um escore de corte de 11 com essa nova função discriminan-\n\nte (ver Tabela 5-2), atinge-se uma perfeita classifi cação\ndos dois grupos (100% corretamente classifi cados).\nLogo, X 1 e X 2 em combinação são capazes de fazer\nmelhores previsões de pertinência a grupos do que qual-\nquer variável separadamente.\n\nA terceira função discriminante na Tabela 5-2 repre- senta a verdadeira função discriminante estimada ( Z = –4,53 + 0,476 X 1 + 0,359 X 2 ). Usando um escore de corte de 0, essa terceira função também atinge uma taxa de classifi cações corretas de 100%, com a máxima separa- ção possível entre os grupos. Como visto neste exemplo simples, a análise discri- minante identifi ca as variáveis com as maiores diferen- ças entre os grupos e deriva um coefi ciente discriminante que pondera cada variável para refl etir tais diferenças. O resultado é uma função discriminante que melhor distin- gue entre os grupos com base em uma combinação das variáveis independentes.\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 229\npontos pequenos* representam as medidas das variáveis para os membros do grupo B, e os pontos grandes* cor- respondem ao grupo A. As elipses desenhadas em tor- no dos pontos pequenos e grandes envolveriam alguma proporção pré-especifi cada dos pontos, geralmente 95% ou mais em cada grupo. Se desenharmos uma reta pelos dois pontos nos quais as elipses se interceptam e então projetarmos a reta sobre um novo eixo Z , podemos dizer que a sobreposição entre as distribuições univariadas A# e B# (representada pela área sombreada) é menor do que se fosse obtida por qualquer outra reta através das elipses formadas pelos diagramas de dispersão [7]. O importante a ser notado a respeito da Figura 5-3 é que o eixo Z expressa os perfi s de duas variáveis dos gru- pos A e B como números únicos (escores discriminantes). Encontrando uma combinação linear das variáveis origi- nais V 1 e V 2 , podemos projetar os resultados como uma função discriminante. Por exemplo, se os pontos pequenos e grandes são projetados sobre o novo eixo Z como esco- res Z discriminantes, o resultado condensa a informação sobre diferenças de grupos (mostrada no gráfi co V 1 V 2 ) em um conjunto de pontos (escores Z ) sobre um único eixo, mostrado pelas distribuições A# e B#. Para resumir, para um dado problema de análise dis- criminante, uma combinação linear das variáveis indepen- dentes é determinada, resultando em uma série de escores discriminantes para cada objeto em cada grupo. Os esco-\nres discriminantes são computados de acordo com a regra\nestatística de maximizar a variância entre os grupos e mini-\nmizar a variância dentro deles. Se a variância entre os gru-\npos é grande em relação à variância dentro dos grupos, di-\nzemos que a função discriminante separa bem os grupos.\n\n\n\nUm exemplo de análise discriminante\n\n\nde três grupos: intenções de troca\nO exemplo de dois grupos já examinado demonstra o obje-\ntivo e o benefício de se combinarem variáveis independen-\ntes em uma variável estatística para fi ns de discriminação\nentre grupos. A análise discriminante também tem um ou-\ntro meio de discriminação – a estimação e o uso de múlti-\nplas variáveis estatísticas – em casos onde há três ou mais\ngrupos. Essas funções discriminantes agora se tornam di-\nmensões de discriminação, sendo cada dimensão separada\ne diferente da outra. Assim, além de melhorar a explicação\nde pertinência ao grupo, essas funções discriminantes adi-\ncionais dão informação quanto às várias combinações de\nvariáveis independentes que discriminam entre grupos.\nTABELA 5-2 Criação de funções discriminantes para prever compradores versus não-\ncompradores\nEscores Z discriminantes calculados\nGrupo\nFunção 1\nZ! X 1\nFunção 2\nZ! X 1 \" X 2\nFunção 3\nZ! $ 4,53 \" 0,476 X 1 \" 0,359 X 2\nGrupo 1: Compraria\nIndivíduo 1 8 17 2,\nIndivíduo 2 6 13 0,\nIndivíduo 3 10 16 2,\nIndivíduo 4 9 13 1,\nIndivíduo 5 4 12 0,\nGrupo 2: Não compraria\nIndivíduo 6 59 –0,\nIndivíduo 7 3 10 –0,\nIndivíduo 8 49 –0,\nIndivíduo 9 26 –2,\nIndivíduo 10 24 –2,\nEscore de corte 5,5 11 0,\nPrecisão de classifi cação\nGrupo previsto Grupo previsto Grupo previsto\nGrupo real 12 12 12\n1: Compraria 41 50 50\n2: Não-compraria 0 5 05 05\nPara ilustrar uma aplicação de análise discriminante\na três grupos, examinamos a pesquisa conduzida pela\nHBAT referente à possibilidade de os clientes de um\nconcorrente trocarem de fornecedores. Um pré-teste em\npequena escala envolveu entrevistas de 15 clientes de um\nconcorrente importante. Durante as entrevistas, os clien-\ntes foram indagados sobre a probabilidade de trocarem\n( Continua )\n\nN. de R. T.: Na verdade, os pontos nos grupos A e B não diferem em tamanho e, sim, no formato. No A a forma é quadrada e no B é circular.\n\n\n230 Análise Multivariada de Dados\n\n\nIdentifi cação de variáveis discriminantes\nCom três categorias da variável dependente, a análise discriminante pode estimar duas funções discriminantes, cada uma representando uma dimensão diferente de dis- criminação.\nA Tabela 5-3 contém os resultados da pesquisa para os\n15 clientes, cinco em cada categoria da variável depen-\ndente. Como fi zemos no exemplo de dois grupos, pode-\nmos olhar para os escores médios de cada grupo para\nver se uma das variáveis discrimina bem entre todos os\ngrupos. Para X 1 , competitividade de preço, percebemos\numa grande diferença de médias entre o grupo 1 e os\ngrupos 2 ou 3 (2,0 versus 4,6 ou 3,8). X 1 pode discrimi-\nnar bem entre o grupo 1 e os grupos 2 ou 3, mas é muito\nmenos efi ciente para discriminar entre os grupos 2 e 3.\nPara X 2 , nível de serviço, percebemos que a diferença\nentre os grupos 1 e 2 é muito pequena (2,0 versus 2,2),\nao passo que há uma grande diferença entre o grupo 3 e\nos grupos 1 ou 2 (6,2 versus 2,0 ou 2,2). Logo, X 1 distin-\ngue o grupo 1 dos grupos 2 e 3, e X 2 diferencia o grupo\n3 dos grupos 1 e 2. Como resultado, vemos que X 1 e\nX 2 fornecem diferentes “dimensões” de discriminação\nentre os grupos.\nFunção discriminante\nFIGURA 5-3 Ilustração gráfi ca da análise discriminante de dois grupos.\nde fornecedores em uma escala de três categorias. As\ntrês respostas possíveis eram “defi nitivamente trocaria”,\n“indeciso” e “defi nitivamente não trocaria”. Clientes fo-\nram designados a grupos 1, 2 ou 3, respectivamente, de\nacordo com suas respostas. Os clientes também avalia-\nram o concorrente em duas características: competitivi-\ndade de preço ( X 1 ) e nível de serviço ( X 2 ). A questão da\npesquisa agora é determinar se as avaliações dos clientes\na respeito do concorrente podem prever sua probabilida-\nde de trocar de fornecedor. Como a variável dependente\nde troca de fornecedor foi medida como uma variável ca-\ntegórica (não-métrica) e as medidas de preço e serviço\nsão métricas, a análise discriminante é adequada.\n( Continuação )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 231\n\n\nCálculo de duas funções discriminantes\nCom as potenciais variáveis discriminantes identifi cadas, o próximo passo é combiná-las em funções discriminantes que utilizarão seu poder combinado de diferenciação para separar grupos.\nPara ilustrar grafi camente essas dimensões, a Figura 5-\nretrata os três grupos em cada variável independente se-\nparadamente. Vendo os membros dos grupos em qual-\nquer variável, podemos perceber que nenhuma variável\ndiscrimina bem entre todos os grupos. Mas se construí-\nmos duas funções discriminantes simples, usando apenas\npesos simples de 1,0 e 0,0, os resultados se tornam mui-\nto mais claros. A função discriminante 1 dá para X 1 um\npeso de 1,0, e para X 2 um peso de 0,0. Do mesmo modo,\na função discriminante 2 dá para X 2 um peso de 1,0 e\npara X 1 um peso de 0,0. As funções podem ser enuncia-\ndas matematicamente como\nFunção discriminante 1 = 1,0( X 1 ) + 0,0( X 2 )\nFunção discriminante 2 = 0,0( X 1 ) + 1,0( X 2 )\nEssas equações mostram em termos simples como o\nprocedimento de análise discriminante estima os pesos\npara maximizar a discriminação.\nCom as duas funções, agora podemos calcular dois es-\ncores discriminantes para cada respondente. Além disso,\nas duas funções discriminantes fornecem as dimensões de\ndiscriminação.\nTABELA 5-3 Resultados da pesquisa HBAT sobre intenções de troca por clientes potenciais\nAvaliação do fornecedor atual*\nGrupos baseados em\nintenção de troca\nX 1\nCompetitividade de preço\nX 2\nNível do serviço\nGrupo 1: Defi nitivamente trocaria\nIndivíduo 1 2 2\nIndivíduo 2 1 2\nIndivíduo 3 3 2\nIndivíduo 4 2 1\nIndivíduo 5 2 3\nMédia do grupo 2,0 2,\nGrupo 2: Indeciso\nIndivíduo 6 4 2\nIndivíduo 7 4 3\nIndivíduo 8 5 1\nIndivíduo 9 5 2\nIndivíduo 10 5 3\nMédia do grupo 4,6 2,\nGrupo 3: Defi nitivamente não trocaria\nIndivíduo 11 2 6\nIndivíduo 12 3 6\nIndivíduo 13 4 6\nIndivíduo 14 5 6\nIndivíduo 15 5 7\nMédia do grupo 3,8 6,\n*Avaliações são feitas em uma escala de 10 pontos (de 1 = muito pobre a 10 = excelente).\nA Figura 5-4 também contém um gráfi co de cada respon-\ndente em uma representação bidimensional. A separa-\nção entre grupos agora fi ca bastante clara, e cada grupo\npode ser facilmente diferenciado. Podemos estabelecer\nvalores em cada dimensão que defi nirão regiões conten-\ndo cada grupo (p.ex., todos os membros do grupo 1 es-\ntão na região menos que 3,5 na dimensão 1 e menos que\n4,5 na dimensão 2). Cada um dos outros grupos pode ser\nanalogamente defi nido em termos das amplitudes dos\nescores de suas funções discriminantes.\nEm termos de dimensões de discriminação, a primei-\nra função discriminante, competitividade de preço, dife-\nrencia clientes indecisos (mostrados com um quadrado)\nde clientes que decidiram trocar (círculos). Mas compe-\ntitividade de preço não diferencia aqueles que decidiram\nnão trocar (losangos). Em vez disso, a percepção de ní-\nvel de serviço, que defi ne a segunda função discriminan-\nte, prevê se um cliente decidirá não trocar versus se um\ncliente está indeciso ou determinado a trocar de forne-\n( Continua )\n\n\n232 Análise Multivariada de Dados\nA estimação de mais de uma função discriminante,\nquando possível, fornece ao pesquisador uma discrimina-\nção melhorada e perspectivas adicionais sobre as caracte-\nrísticas e as combinações que melhor discriminam entre os\ngrupos. As seções a seguir detalham os passos necessários\ncedores. O pesquisador pode apresentar à gerência os\nimpactos separados de competitividade de preço e nível\nde serviço para a tomada de decisões.\n(a) variáveis individuais\nDefinitivamente troca\nRepresentação\nbidimensional de\nfunções discriminantes\nDefinitivamente não troca\nFunção\ndiscriminante 1 = 1,0 X 1 + 0 X 2\nFunção\ndiscriminante 1\nFunção\ndiscriminante 2\nFunção\ndiscriminante 2 = 0 X 1 + 1,0 X 2\nIndeciso\nDefinitivamente troca\nDefinitivamente não troca\nIndeciso\n(b)\nFIGURA 5-4 Representação gráfi ca de variáveis discriminantes potenciais para uma análise discriminante de três grupos.\n( Continuação )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 233\npara se executar uma análise discriminante, avaliar seu ní- vel de ajuste preditivo e então interpretar a infl uência de variáveis independentes ao se fazer uma previsão.\n\n\n\nO PROCESSO DE DECISÃO PARA\n\n\nANÁLISE DISCRIMINANTE\nA aplicação de análise discriminante pode ser vista da perspectiva da construção de modelo de seis estágios in- troduzida no Capítulo 1 e retratada na Figura 5-5 (está- gios 1-3) e na Figura 5-6 (estágios 4-6). Assim como em todas as aplicações multivariadas, estabelecer os objetivos é o primeiro passo na análise. Em seguida, o pesquisa- dor deve abordar questões específi cas de planejamento e se certifi car de que as suposições inerentes estão sendo atendidas. A análise continua com a dedução da função discriminante e a determinação de se uma função esta- tisticamente signifi cante pode ser obtida para separar os dois (ou mais) grupos. Os resultados discriminantes são então avaliados quanto à precisão preditiva pelo desen- volvimento de uma matriz de classifi cação. Em seguida, a interpretação da função discriminante determina qual das variáveis independentes mais contribui para discriminar entre os grupos. Finalmente, a função discriminante deve ser validada com uma amostra de teste. Cada um desses estágios é discutido nas seções a seguir. Discutimos a re- gressão logística em uma seção à parte depois de exami-\nnarmos o processo de decisão para a análise discriminan-\nte. Desse modo, as semelhanças e diferenças entre essas\nduas técnicas podem ser destacadas.\n\n\nESTÁGIO 1: OBJETIVOS DA\n\n\nANÁLISE DISCRIMINANTE\nUma revisão dos objetivos de aplicar a análise discrimi-\nnante deve esclarecer melhor sua natureza. A análise dis-\ncriminante pode abordar qualquer um dos seguintes obje-\ntivos de pesquisa:\n1. Determinar se existem diferenças estatisticamente signifi - cantes entre os perfi s de escore médio em um conjunto de variáveis para dois (ou mais) grupos defi nidos a priori. 2. Determinar quais das variáveis independentes explicam o máximo de diferenças nos perfi s de escore médio dos dois ou mais grupos. 3. Estabelecer o número e a composição das dimensões de dis- criminação entre grupos formados a partir do conjunto de variáveis independentes. 4. Estabelecer procedimentos para classifi car objetos (indiví- duos, fi rmas, produtos e assim por diante) em grupos, com base em seus escores em um conjunto de variáveis indepen- dentes. Como observado nesses objetivos, a análise discrimi- nante é útil quando o pesquisador está interessado em compreender diferenças de grupos ou em classifi car obje-\nEstágio 1 Problema de pesquisa\nSuposições\nNormalidade de variáveis independentes\nLinearidade de relações\nFalta de multicolinearidade entre variáveis independentes\nMatrizes de dispersão iguais\nQuestões de planejamento de pesquisa\nSeleção de variáveis independentes\nConsiderações sobre tamanho de amostra\nCriação de amostras de análise e teste\nSelecione objetivo(s):\nCalcule diferenças de grupo em um perfil multivariado\nClassifique observações em grupos\nidentifique dimensões de discriminação entre grupos\nEstágio 2\nEstágio 3\nPara\nestágio\n4\nFIGURA 5-5 Estágios 1-3 no diagrama de decisão da análise discriminante.\n\n234 Análise Multivariada de Dados\ntos corretamente em grupos ou classes. Portanto, a análi- se discriminante pode ser considerada um tipo de análise de perfi l ou uma técnica preditiva analítica. Em qualquer caso, a técnica é mais apropriada onde existe uma só va- riável dependente categórica e diversas variáveis indepen- dentes métricas.\n\nComo uma análise de perfi l , a análise discriminante fornece uma avaliação objetiva de diferenças entre grupos em um conjunto de variáveis independentes. Nesta situação, a aná- lise discriminante é bastante semelhante à análise multiva- riada de variância (ver Capítulo 6 para uma discussão mais detalhada de análise multivariada de variância). Para enten- der as diferenças de grupos, a análise discriminante permite discernir o papel de variáveis individuais, bem como defi nir combinações dessas variáveis que representam dimensões de discriminação entre grupos. Essas dimensões são os efei- tos coletivos de diversas variáveis que trabalham conjunta- mente para distinguir entre os grupos. O uso de métodos de estimação seqüenciais também permite identifi car subcon- juntos de variáveis com o maior poder discriminatório.\nPara fi ns de classifi cação , a análise discriminante fornece uma base para classifi car não somente a amostra usada para estimar a função discriminante, mas também quaisquer ou- tras observações que possam ter valores para todas as va- riáveis independentes. Desse modo, a análise discriminante pode ser usada para classifi car outras observações nos gru- pos defi nidos.\n\n\n\n\nESTÁGIO 2: PROJETO DE PESQUISA\n\n\nPARA ANÁLISE DISCRIMINANTE\nA aplicação bem-sucedida da análise discriminante requer a consideração de várias questões. Tais questões incluem a seleção da variável dependente e das variáveis indepen- dentes, o tamanho necessário da amostra para a estima- ção das funções discriminantes, e a divisão da amostra para fi ns de validação.\n\n\nSeleção de variáveis dependente\n\n\ne independentes\nPara aplicar a análise discriminante, o pesquisador deve primeiramente especifi car quais variáveis devem ser inde- pendentes e qual deve ser a medida dependente. Lembre- se que a variável dependente é categórica e as indepen- dentes são métricas.\n\nA variável dependente\nO pesquisador deve se concentrar na variável dependente primeiro. O número de grupos (categorias) da variável de- pendente pode ser dois ou mais, mas esses grupos devem ser mutuamente excludentes e cobrir todos os casos. Ou seja, cada observação pode ser colocada em apenas um grupo. Em alguns casos, a variável dependente pode en- volver dois grupos (dicotômicas), como bom versus ruim. Em outros casos, a variável dependente envolve vários\ngrupos (multicotômica), como as ocupações de médico,\nadvogado ou professor.\nQuantas categorias na variável dependente? Teorica-\nmente, a análise discriminante pode lidar com um número\nilimitado de categorias na variável dependente. Na práti-\nca, porém, o pesquisador deve selecionar uma variável de-\npendente e o número de categorias com base em diversas\nconsiderações.\n1. Além de serem mutuamente excludentes e exaustivas, as categorias da variável dependente devem ser distintas e únicas no conjunto escolhido de variáveis independentes. A análise discriminante considera que cada grupo deveria ter um perfi l único nas variáveis independentes usadas, e assim desenvolve as funções discriminantes para separar ao má- ximo os grupos com base nessas variáveis. Não obstante, a análise discriminante não tem um meio para acomodar ou combinar categorias que não sejam distintas nas variáveis independentes. Se dois ou mais grupos têm perfi s semelhan- tes, a análise discriminante não será capaz de estabelecer univocamente o perfi l de cada grupo, resultando em uma explicação e classifi cação mais pobres dos grupos como um todo. Dessa forma, o pesquisador deve escolher as variáveis dependentes e suas categorias para refl etir diferenças nas variáveis independentes. Um exemplo ajudará a ilustrar este ponto.\nImagine que o pesquisador deseja identifi car diferen-\nças entre categorias ocupacionais baseado em algumas\ncaracterísticas demográfi cas (p.ex., renda, formação,\ncaracterísticas familiares). Se ocupações fossem repre-\nsentadas por um pequeno número de categorias (p.ex.,\npessoal de segurança e limpeza, técnicos, pessoal de es-\ncritório e profi ssionais de nível superior), então espera-\nríamos que houvesse diferenças únicas entre os grupos\ne que a análise discriminante seria mais adequada para\ndesenvolver funções discriminantes que explicariam as\ndistinções de grupos e classifi cariam com sucesso os indi-\nvíduos em suas categorias corretas.\nSe, porém, o número de categorias ocupacionais fos-\nse aumentado, a análise discriminante poderia ter uma\ndifi culdade maior para identifi car diferenças. Por exem-\nplo, considere que a categoria de profi ssionais de nível\nsuperior fosse expandida para as categorias de médicos,\nadvogados, gerentes gerais, professores universitários e\nassim por diante. A despeito de esta expansão fornecer\numa classifi cação ocupacional mais refi nada, seria muito\nmais difícil fazer distinções entre essas categorias com\nbase em variáveis demográfi cas. Os resultados teriam\num desempenho mais pobre na análise discriminante,\ntanto em termos de explicação quanto de classifi cação.\n2. O pesquisador deve também buscar um número menor, e não maior, de categorias na medida dependente. Pode pare- cer mais lógico expandir o número de categorias em busca de mais agrupamentos únicos, mas a expansão do número\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 235\nde categorias apresenta mais complexidades nas tarefas de classifi cação e estabelecimento de perfi l na análise discrimi- nante. Se a análise discriminante pode estimar NG – 1 (nú- mero de grupos menos um) funções discriminantes, então o aumento do número de grupos expande o número de pos- síveis funções discriminantes, aumentando a complexidade da identifi cação das dimensões inerentes de discriminação refl etidas por conta de cada função discriminante, bem como representando o efeito geral de cada variável inde- pendente. Como esses dois pontos sugerem, o pesquisador sem- pre deve equilibrar a vontade de expandir as categorias em favor da unicidade (exclusividade) com a crescente efetividade de um número menor de categorias. O pesqui- sador deve testar e selecionar uma variável dependente com categorias que tenham as maiores diferenças entre todos os grupos, ao mesmo tempo que mantenham supor- te conceitual e relevância administrativa.\nConversão de variáveis métricas Os exemplos anteriores de variáveis categóricas eram verdadeiras dicotomias (ou multicotomias). Há algumas situações, contudo, em que a análise discriminante é apropriada mesmo se a variável dependente não é verdadeiramente categórica (não-mé- trica). Podemos ter uma variável dependente de medida ordinal ou intervalar, a qual queremos usar como uma variável dependente categórica. Em tais casos, teríamos de criar uma variável categórica, e duas abordagens estão entre as mais usuais:\n\nO método mais comum é estabelecer categorias usando uma escala métrica. Por exemplo, se tivéssemos uma variável que medisse o número médio de refrigerantes consumidos por dia e os indivíduos respondessem em uma escala de zero a oito ou mais por dia, poderíamos criar uma tricotomia (três grupos) artifi cial simplesmente designando aqueles indiví- duos que consumissem nenhum, um ou dois refrigerantes por dia como usuários modestos, aqueles que consumissem três, quatro ou cinco por dia como usuários médios, e os que consumissem seis, sete, oito ou mais como usuários pesados. Tal procedimento criaria uma variável categórica de três grupos na qual o objetivo seria discriminar entre usuários de refrigerantes que fossem modestos, médios e pesados. Qualquer número de grupos categóricos artifi ciais pode ser desenvolvido. Mais freqüentemente, a abordagem envolve- ria a criação de duas, três ou quatro categorias. Um número maior de categorias poderia ser estabelecido se houvesse necessidade.\nQuando três ou mais categorias são criadas, surge a possi- bilidade de se examinarem apenas os grupos extremos em uma análise discriminante de dois grupos. A abordagem de extremos polares envolve a comparação somente dos dois grupos extremos e a exclusão do grupo do meio da análise discriminante. Por exemplo, o pesquisador poderia examinar os usuários modestos e pesados de refrigerantes e excluir os usuários médios. Esse tratamento pode ser usado toda vez que o pesquisador desejar olhar apenas os grupos extremos. Contudo, ele também pode querer tentar essa abordagem quando os resultados de uma análise de regressão não são\n\ntão bons quanto o previsto. Tal procedimento pode ser útil\nporque é possível que diferenças de grupos possam aparecer\naté quando os resultados de regressão são pobres. Ou seja,\na abordagem de extremos polares com a análise discrimi-\nnante pode revelar diferenças que não são tão evidentes em\numa análise de regressão do conjunto completo de dados\n[7]. Tal manipulação dos dados naturalmente necessitaria\nde cuidado na interpretação das descobertas.\n\n\nAs variáveis independentes\nDepois de ter tomado uma decisão sobre a variável de-\npendente, o pesquisador deve decidir quais variáveis\nindependentes serão incluídas na análise. As variáveis\nindependentes geralmente são selecionadas de duas ma-\nneiras. A primeira abordagem envolve a identifi cação de\nvariáveis a partir de pesquisa prévia ou do modelo teórico\nque é a base inerente da questão de pesquisa. A segun-\nda abordagem é a intuição – utilizar o conhecimento do\npesquisador e selecionar intuitivamente variáveis para as\nquais não existe pesquisa prévia ou teoria, mas que logi-\ncamente poderiam ser relacionadas à previsão dos grupos\npara a variável dependente.\nEm ambos os casos, as variáveis independentes mais\napropriadas são aquelas que diferem da variável depen-\ndente em pelo menos dois dos grupos. Lembre que o pro-\npósito de qualquer variável independente é apresentar um\nperfi l único de pelo menos um grupo quando comparado\na outros. Variáveis que não diferem ao longo dos grupos\nsão de pouca utilidade em análise discriminante.\n\n\n\nTamanho da amostra\nA análise discriminante, como as outras técnicas multi-\nvariadas, é afetada pelo tamanho da amostra sob análise.\nComo discutido no Capítulo 1, amostras muito pequenas\ntêm grandes erros amostrais, de modo que a identifi ca-\nção de todas, exceto as grandes diferenças, é improvável.\nAlém disso, amostras muito grandes tornarão todas as\ndiferenças estatisticamente signifi cantes, ainda que essas\nmesmas diferenças possam ter pouca ou nenhuma rele-\nvância administrativa. Entre esses extremos, o pesquisa-\ndor deve considerar o impacto do tamanho das amostras\nsobre a análise discriminante, tanto no nível geral quanto\nem uma base de grupo-por-grupo.\n\nTamanho geral da amostra\nA primeira consideração envolve o tamanho geral da\namostra. A análise discriminante é bastante sensível à\nproporção do tamanho da amostra em relação ao número\nde variáveis preditoras. Como resultado, muitos estudos\nsugerem uma proporção de 20 observações para cada va-\nriável preditora. Apesar de essa proporção poder ser di-\nfícil de manter na prática, o pesquisador deve notar que\nos resultados se tornam instáveis quando o tamanho da\namostra diminui em relação ao número de variáveis inde-\npendentes. O tamanho mínimo recomendado é de cinco\n\n\n236 Análise Multivariada de Dados\nobservações por variável independente. Note que essa proporção se aplica a todas as variáveis consideradas na análise, mesmo que todas as variáveis consideradas não entrem na função discriminante (como na estimação ste- pwise ).\n\n\nTamanho da amostra por categoria\nAlém do tamanho da amostra geral, o pesquisador tam- bém deve considerar o tamanho da amostra de cada categoria. No mínimo, o menor grupo de uma catego- ria deve exceder o número de variáveis independentes. Como uma orientação prática, cada categoria deve ter no mínimo 20 observações. Mas mesmo que todas as categorias excedam 20 observações, o pesquisador tam- bém deve considerar os tamanhos relativos das mesmas. Se os grupos variam muito em tamanho, isso pode cau- sar impacto na estimação da função discriminante e na classifi cação de observações. No estágio de classifi cação, grupos maiores têm uma chance desproporcionalmente maior de classifi cação. Se os tamanhos de grupos variam muito, o pesquisador pode querer extrair uma amostra aleatoriamente a partir do(s) grupo(s) maior(es), redu- zindo assim seu(s) tamanho(s) a um nível comparável ao(s) grupo(s) menor(es). Sempre se lembre, porém, de manter um tamanho adequado de amostra geral e para cada grupo.\n\n\n\nDivisão da amostra\nUma observação fi nal sobre o impacto do tamanho da amostra na análise discriminante. Como será posterior- mente discutido no estágio 6, a maneira preferida de va- lidar uma análise discriminante é dividir a amostra em duas sub-amostras, uma usada para estimação da função discriminante e outra para fi ns de validação. Em termos de considerações sobre tamanho amostral, é essencial que cada sub-amostra tenha tamanho adequado para su- portar as conclusões dos resultados. Dessa forma, todas as considerações discutidas na seção anterior se aplicam não somente à amostra total, mas agora a cada uma das duas sub-amostras (especialmente aquela usada para esti- mação). Nenhuma regra rígida e rápida foi desenvolvida, mas parece lógico que o pesquisador queira pelo menos 100 na amostra total para justifi car a divisão da mesma em dois grupos.\n\nCriação das sub-amostras\nVários procedimentos têm sido sugeridos para dividir a amostra em sub-amostras. O procedimento usual é divi- dir a amostra total de respondentes aleatoriamente em dois grupos. Um deles, a amostra de análise , é usado para desenvolver a função discriminante. O segundo grupo, a amostra de teste , é usado para testar a função discrimi- nante. Esse método de validação da função é chamado de abordagem de partição da amostra ou validação cruzada [1,5,9,18].\nNenhuma orientação defi nitiva foi estabelecida para\ndeterminar os tamanhos relativos das sub-amostras de\nanálise e de teste (ou validação). O procedimento mais\npopular é dividir a amostra total de forma que metade\ndos respondentes seja colocada na amostra de análise e a\noutra metade na amostra de teste. No entanto, nenhuma\nregra rígida e rápida foi estabelecida, e alguns pesquisa-\ndores preferem uma partição 60-40 ou mesmo 75-25 entre\nos grupos de análise e de teste, dependendo do tamanho\nda amostra geral.\nQuando se selecionam as amostras de análise e teste,\ngeralmente segue-se um procedimento de amostragem\nproporcionalmente estratifi cada. Assuma primeiro que\no pesquisador deseja uma divisão 50-50. Se os grupos\ncategóricos para a análise discriminante são igualmen-\nte representados na amostra total, as amostras de esti-\nmação e de teste devem ser de tamanhos aproximada-\nmente iguais. Se os grupos originais são diferentes, os\ntamanhos das amostras de estimação e de teste devem\nser proporcionais em relação à distribuição da amostra\ntotal. Por exemplo, se uma amostra consiste em 50 ho-\nmens e 50 mulheres, as amostras de estimação e de tes-\nte teriam 25 homens e 25 mulheres cada. Se a amostra\ntiver 70 mulheres e 30 homens, então as amostras de\nestimação e de teste consistirão em 35 mulheres e 15\nhomens cada.\n\n\nE se a amostra geral for muito pequena?\nSe a amostra é muito pequena para justifi car uma divisão\nem grupos de análise e de teste, o pesquisador tem duas\nopções. Primeiro, desenvolver a função na amostra inteira\ne então usar a função para classifi car o mesmo grupo usa-\ndo para desenvolver a função. Esse procedimento resulta\nem um viés ascendente na precisão preditiva da função,\nmas certamente é melhor do que não testar a função de\nforma alguma. Segundo, diversas técnicas discutidas no\nestágio 6 podem desempenhar um tipo de procedimento\nde teste no qual a função discriminante é repetidamen-\nte estimada sobre a amostra, cada vez reservando uma\nobservação diferente para previsão. Nesta abordagem,\namostras muito menores podem ser usadas, pois a amos-\ntra geral não precisa ser dividida em sub-amostras.\n\n\n\nESTÁGIO 3: SUPOSIÇÕES DA\n\n\nANÁLISE DISCRIMINANTE\nComo ocorre em todas as técnicas multivariadas, a aná-\nlise discriminante é baseada em uma série de suposições.\nTais suposições se relacionam a processos estatísticos en-\nvolvidos nos procedimentos de estimação e classifi cação\ne a questões que afetam a interpretação dos resultados.\nA seção a seguir discute cada tipo de suposição e os im-\npactos sobre a aplicação apropriada da análise discrimi-\nnante.\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 237\n\n\n\nImpactos sobre estimação e classifi cação\nAs suposições-chave para determinar a função discrimi- nante são a de normalidade multivariada das variáveis independentes, e a de estruturas (matrizes) de dispersão e covariância desconhecidas (mas iguais) para os grupos como defi nidos pela variável dependente [8,10]. Existem evidências da sensibilidade da análise discriminante a vio- lações dessas suposições. Os testes para normalidade dis- cutidos no Capítulo 2 estão disponíveis ao pesquisador, juntamente com o teste M de Box para avaliar a simila- ridade das matrizes de dispersão das variáveis indepen- dentes entre os grupos. Se as suposições são violadas, o pesquisador deve considerar métodos alternativos (p.ex., regressão logística, descrita na próxima seção) e com- preender os impactos sobre os resultados que podem ser esperados.\n\nImpacto sobre estimação\nDados que não atendem a suposição de normalidade mul- tivariada podem causar problemas na estimação da função discriminante. Ações corretivas podem ser viáveis através de transformações dos dados para reduzir as disparidades entre as matrizes de covariância. No entanto, em muitos casos essas ações corretivas são inefi cientes. Em tais casos, os modelos devem ser diretamente validados. Se a medida dependente é binária, a regressão logística deve ser utili- zada sempre que possível.\n\n\nImpacto sobre classifi cação\nMatrizes de covariância desiguais também afetam negati- vamente o processo de classifi cação. Se os tamanhos das amostras são pequenos e as matrizes de covariância são diferentes, então a signifi cância estatística do processo de estimação é afetada adversamente. O caso mais comum é o de covariâncias desiguais entre grupos de tamanho adequado, em que as observações são super-classifi cadas nos grupos com matrizes de covariância maiores. Esse efeito pode ser minimizado aumentando-se o tamanho da amostra e também usando-se as matrizes de covariân- cia específi cas dos grupos para fi ns de classifi cação, mas essa abordagem exige a validação cruzada dos resultados discriminantes. Finalmente, técnicas de classifi cação qua- dráticas estão disponíveis em muitos dos programas esta- tísticos caso existam grandes diferenças entre as matrizes de covariância dos grupos e as ações corretivas não mini- mizem o efeito [6,12,14].\n\n\n\nImpactos sobre interpretação\nUma outra característica dos dados que afeta os resultados é a multicolinearidade entre as variáveis independentes. A multicolinearidade, medida em termos de tolerância , denota que duas ou mais variáveis independentes estão altamente correlacionadas, de modo que uma variável pode ser altamente explicada ou prevista pela(s) outra(s)\nvariável(eis), acrescentando pouco ao poder explicativo\ndo conjunto como um todo. Essa consideração se torna\nespecialmente crítica quando procedimentos stepwise são\nempregados. O pesquisador, ao interpretar a função discri-\nminante, deve estar ciente da multicolinearidade e de seu\nimpacto na determinação de quais variáveis entram na so-\nlução stepwise. Para uma discussão mais detalhada da mul-\nticolinearidade e seu impacto nas soluções stepwise , ver o\nCapítulo 4. Os procedimentos para detectar a presença da\nmulticolinearidade são também abordados no Capítulo 4.\nComo em qualquer técnica multivariada que emprega\numa variável estatística, uma suposição implícita é a de\nque todas as relações são lineares. As relações não-line-\nares não são refl etidas na função discriminante, a menos\nque transformações específi cas de variáveis sejam executa-\ndas para representarem efeitos não-lineares. Finalmente,\nobservações atípicas podem ter um impacto substancial na\nprecisão de classifi cação de quaisquer resultados da aná-\n\nPlanejamento de análise discriminante\n\nA variável dependente deve ser não-métrica, representando grupos de objetos que devem diferir nas variáveis independentes\nEscolha uma variável dependente que:\n\nMelhor represente diferenças de grupos de interesse\nDefi na grupos que são substancialmente distintos\nMinimize o número de categorias ao mesmo tempo que atenda aos objetivos da pesquisa\n\nAo converter variáveis métricas para uma escala não-métrica para uso como a variável dependente, considere o uso de grupos extremos para maximizar as diferenças de grupos\nVariáveis independentes devem identifi car diferenças entre pelo menos dois grupos para uso em análise discriminante\nA amostra deve ser grande o bastante para:\n\nTer pelo menos uma observação a mais por grupo do que o número de variáveis independentes, mas procurar por pelo menos 20 casos por grupo\nTer 20 casos por variável independente, com um nível mínimo recomendado de 5 observações por variável\nTer uma amostra grande o bastante para dividi-la em amostras de teste e de estimação, cada uma atendendo às exigências acima\n\nA suposição mais importante é a igualdade das matrizes de covariância, o que afeta tanto estimação quanto classifi cação\nMulticolinearidade entre as variáveis independentes pode reduzir sensivelmente o impacto estimado de variáveis independentes na função discriminante derivada, particularmente no caso de emprego de um processo de estimação stepwise\n\n\nREGRAS PRÁTICAS 5-\n\n\n\n238 Análise Multivariada de Dados\nlise discriminante. O pesquisador é encorajado a exami- nar todos os resultados quanto à presença de observações atípicas e a eliminar observações atípicas verdadeiras, se necessário. Para uma discussão sobre algumas das técnicas que avaliam as violações das suposições estatísticas básicas ou a detecção de observações atípicas, ver Capítulo 2.\n\n\n\nESTÁGIO 4: ESTIMAÇÃO DO\n\n\nMODELO DISCRIMINANTE E\n\n\nAVALIAÇÃO DO AJUSTE GERAL\nPara determinar a função discriminante, o pesquisador deve decidir o método de estimação e então determinar o\nnúmero de funções a serem retidas (ver Figura 5-6). Com\nas funções estimadas, o ajuste geral do modelo pode ser\navaliado de diversas maneiras. Primeiro, escores Z discri-\nminantes , também conhecidos como os escores Z , podem\nser calculados para cada objeto. A comparação das mé-\ndias dos grupos (centróides) nos escores Z fornece uma\nmedida de discriminação entre grupos. A precisão predi-\ntiva pode ser medida como o número de observações clas-\nsifi cadas nos grupos corretos, com vários critérios dispo-\nníveis para avaliar se o processo de classifi cação alcança\nsignifi cância prática ou estatística. Finalmente, diagnósti-\ncos por casos podem identifi car a precisão de classifi cação\nde cada caso e seu impacto relativo sobre a estimação ge-\nral do modelo.\nFIGURA 5-6 Estágios 4-6 no diagrama de decisão da análise discriminante.\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 239\n\n\n\nSeleção de um método de estimação\nA primeira tarefa na obtenção da função discriminante é selecionar o método de estimação. Ao fazer tal escolha, o pesquisador deve balancear a necessidade de controle sobre o processo de estimação com o desejo pela parci- mônia nas funções discriminantes. Os dois métodos dis- poníveis são o simultâneo (direto) e o stepwise , cada um discutido adiante.\n\nEstimação simultânea\nA estimação simultânea envolve a computação da fun- ção discriminante, de modo que todas as variáveis inde- pendentes são consideradas juntas. Assim, a função dis- criminante é computada com base no conjunto inteiro de variáveis independentes, sem consideração do poder discriminatório de cada uma delas. O método simultâ- neo é apropriado quando, por conta de razões teóricas, o pesquisador quer incluir todas as variáveis independen- tes na análise e não está interessado em ver resultados intermediários baseados apenas nas variáveis mais dis- criminantes.\n\n\nEstimação stepwise\nA estimação stepwise é uma alternativa à abordagem si- multânea. Envolve a inclusão das variáveis independentes na função discriminante, uma por vez, com base em seu poder discriminatório. A abordagem stepwise segue um processo seqüencial de adicionar ou descartar variáveis da seguinte maneira:\n1. Escolher a melhor variável discriminatória. 2. Comparar a variável inicial com cada uma das outras variá- veis independentes, uma de cada vez, e selecionar a variável mais adequada para melhorar o poder discriminatório da função em combinação com a primeira variável. 3. Selecionar as demais variáveis de maneira semelhante. Note que conforme variáveis adicionais são incluídas, algumas previamente escolhidas podem ser removidas se a infor- mação que elas contêm sobre diferenças de grupos estiver disponível em alguma combinação das outras variáveis in- cluídas em estágios posteriores. 4. Considerar o processo concluído quando todas as variáveis independentes forem incluídas na função ou as variáveis ex- cluídas forem julgadas como não contribuindo signifi cante- mente para uma discriminação futura. O método stepwise é útil quando o pesquisador quer considerar um número relativamente grande de variáveis independentes para inclusão na função. Selecionando-se seqüencialmente a próxima melhor variável discriminante em cada passo, as variáveis que não são úteis na discrimi- nação entre os grupos são eliminadas e um conjunto re- duzido de variáveis é identifi cado. O conjunto reduzido geralmente é quase tão bom quanto – e às vezes melhor que – o conjunto completo de variáveis. O pesquisador deve notar que a estimação stepwise se torna menos estável e generalizável à medida que a pro- porção entre tamanho da amostra e variável independente\ndiminui abaixo do nível recomendado de 20 observações\npor variável independente. É particularmente importan-\nte, nesses casos, validar os resultados de tantas maneiras\nquanto possível.\n\n\n\nSignifi cância estatística\nApós a estimação da função discriminante, o pesquisador\ndeve avaliar o nível de signifi cância para o poder discrimi-\nnatório coletivo das funções discriminantes, bem como a\nsignifi cância de cada função discriminante em separado. A\navaliação da signifi cância geral fornece ao pesquisador a\ninformação necessária para decidir se deve proceder com\na interpretação da análise ou se uma reespecifi cação se faz\nnecessária. Se o modelo geral for signifi cante, a avaliação\ndas funções individuais identifi ca aquelas que devem ser\nmantidas e interpretadas.\n\nSignifi cância geral\nAo se avaliar a signifi cância estatística do modelo geral,\ndiferentes critérios são aplicáveis para procedimentos de\nestimação simultânea versus stepwise. Em ambas as situa-\nções, os testes estatísticos se relacionam com a habilidade\ndas funções discriminantes de obterem escores Z discri-\nminantes que sejam signifi cantemente diferentes entre\ngrupos.\nEstimação simultânea. Quando uma abordagem si-\nmultânea é usada, as medidas de lambda de Wilks, o\ntraço de Hotelling e o critério de Pillai avaliam a sig-\nnificância estatística do poder discriminatório da(s)\nfunção(ões) discriminante(s). A maior raiz característica\nde Roy avalia apenas a primeira função discriminante.\nPara uma discussão mais detalhada sobre as vantagens e\ndesvantagens de cada critério, veja a discussão de testes\nde signifi cância em análise multivariada de variância no\nCapítulo 6.\nEstimação stepwise. Se um método stepwise é empre-\ngado para estimar a função discriminante, as medidas\nD^2 de Mahalanobis e V de Rao são mais adequadas.\nAmbas são medidas de distância generalizada. O pro-\ncedimento D^2 de Mahalanobis é baseado em distância\neuclideana quadrada generalizada que se adapta a va-\nriâncias desiguais. A maior vantagem deste procedi-\nmento é que ele é computado no espaço original das\nvariáveis preditoras, em vez de ser computado como\numa versão extraída de outras medidas. O procedimen-\nto D^2 de Mahalanobis se torna particularmente crítico\nquando o número de variáveis preditoras aumenta por-\nque ele não resulta em redução de dimensionalidade.\nUma perda em dimensionalidade causaria uma perda\nde informação, porque ela diminui a variabilidade das\nvariáveis independentes. Em geral, D^2 de Mahalanobis\né o procedimento preferido quando o pesquisador está\ninteressado no uso máximo de informação disponível\nem um processo stepwise.\n\n\n240 Análise Multivariada de Dados\n\n\nSignifi cância de funções discriminantes individuais\nSe o número de grupos é três ou mais, então o pesquisa- dor deve decidir não apenas se a discriminação entre gru- pos é estatisticamente signifi cante, mas também se cada função discriminante estimada é estatisticamente signifi - cante. Como discutido anteriormente, a análise discrimi- nante estima uma função discriminante a menos do que o número de grupos. Se três grupos são analisados, então duas funções discriminantes serão estimadas; para quatro grupos, três funções serão estimadas, e assim por diante. Todos os programas de computador fornecem ao pesqui- sador a informação necessária para verifi car o número de funções necessárias para obter signifi cância estatística, sem incluir funções discriminantes que não aumentam o poder discriminatório signifi cantemente. O critério de signifi cância convencional de 0,05 ou acima é freqüentemente usado, sendo que alguns pesqui- sadores estendem o nível requerido (p.ex., 0,10 ou mais) com base na ponderação de custo versus o valor da infor- mação. Se os maiores níveis de risco para incluir resulta- dos não-signifi cantes (p.ex., níveis de signifi cância &gt; 0,05) são aceitáveis, pode-se reter funções discriminantes que são signifi cantes no nível 0,2 ou até mesmo 0,3. Se uma ou mais funções são consideradas estatistica- mente não-signifi cantes, o modelo discriminante deve ser reestimado com o número de funções a serem determi- nadas limitado ao número de funções signifi cantes. Desse modo, a avaliação de precisão preditiva e a interpretação das funções discriminantes serão baseadas apenas em fun- ções signifi cantes.\n\n\n\nAvaliação do ajuste geral do modelo\nLogo que as funções discriminantes signifi cantes tenham sido identifi cadas, a atenção se desvia para a verifi cação do ajuste geral das funções discriminantes mantidas. Essa avaliação envolve três tarefas:\n1. Calcular escores Z discriminantes para cada observação 2. Calcular diferenças de grupos nos escores Z discriminantes 3. Avaliar a precisão de previsão de pertinência a grupos. Devemos observar que o emprego da função discri- minante para fi ns de classifi cação é apenas um entre dois possíveis tratamentos. O segundo utiliza uma função de classifi cação , também conhecida como função discrimi- nante linear de Fisher. As funções de classifi cação, uma para cada grupo, são usadas exclusivamente para classifi - car observações. Nesse método de classifi cação, os valores de uma observação para as variáveis independentes são inseridos nas funções de classifi cação, e um escore de clas- sifi cação para cada grupo é calculado para aquela obser- vação. A observação é então classifi cada no grupo com o maior escore de classifi cação. Examinamos a função discriminante como o meio de classifi cação porque ela fornece uma representação conci- sa e simples de cada função discriminante, simplifi cando o processo de interpretação e a avaliação da contribuição de variáveis independentes. Ambos os métodos conse- guem resultados comparáveis, apesar de usarem diferen- tes meios.\n\nCálculo de escores Z discriminantes\nCom as funções discriminantes retidas defi nidas, a base\npara calcular os escores Z discriminantes foi estabelecida.\nComo discutido anteriormente, o escore Z discriminante\nde qualquer função discriminante pode ser calculado para\ncada observação pela seguinte fórmula:\nZjk! a \" W 1 X 1 k \" W 2 X 2 k \"... \" WnXnk\nonde\nZjk = escore Z discriminante da função discriminante\nj para o objeto k\na = intercepto\nWi = coefi ciente discriminante para a variável inde-\npendente i\nXik = variável independente i para o objeto k\nEste escore, uma variável métrica, fornece uma manei-\nra direta de comparar observações em cada função. As-\nsume-se que as observações com escores Z semelhantes\nsão mais parecidas com base nas variáveis que constituem\nessa função do que aquelas com escores totalmente distin-\ntos. A função discriminante pode ser expressa com pesos\ne valores padronizados ou não-padronizados. A versão\npadronizada é mais útil para fi ns de interpretação, mas a\nnão-padronizada é mais fácil de utilizar no cálculo do es-\ncore Z discriminante.\n\n\nAvaliação de diferenças de grupos\nUma vez que os escores Z discriminantes são calculados,\na primeira avaliação de ajuste geral do modelo é deter-\nminar a magnitude de diferenças entre os membros de\ncada grupo em termos dos escores Z discriminantes. Uma\n\n\nEstimação e ajuste do modelo\n\nApesar de a estimação stepwise poder parecer ótima ao selecionar o mais parcimonioso conjunto de variáveis maximamente discriminantes, cuidado com o impacto de multicolinearidade sobre a avaliação do poder discriminatório de cada variável.\nO ajuste geral do modelo avalia a signifi cância estatística entre grupos sobre os escores Z discriminantes, mas não avalia precisão preditiva.\nTendo mais de dois grupos, não confi ne sua análise a apenas as funções discriminantes estatisticamente signifi cantes, mas considere a possibilidade de funções não-signifi cantes (com níveis de até 0,3) adicionarem poder explanatório.\n\n\nREGRAS PRÁTICAS 5-\n\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 241\nmedida resumo das diferenças de grupos é uma compara- ção dos centróides dos grupos, o escore Z discriminante médio para todos os membros dos grupos. Uma medida de sucesso da análise discriminante é sua habilidade em defi nir função(ões) discriminante(s) que resulte(m) em centróides de grupos signifi cantemente diferentes. As di- ferenças entre centróides são medidas em termos do D^2 de Mahalanobis, para o qual há testes disponíveis para de- terminar se as diferenças são estatisticamente signifi can- tes. O pesquisador deve garantir que, mesmo com funções discriminantes signifi cantes, há diferenças consideráveis entre os grupos. Os centróides de grupos em cada função discriminan- te também podem ser representados grafi camente para demonstrar os resultados de uma perspectiva gráfi ca. Gráfi cos geralmente são preparados para as primeiras duas ou três funções discriminantes (assumindo que elas são funções estatisticamente signifi cantes). Os valores para cada grupo mostram sua posição no espaço discri- minante reduzido (assim chamado porque nem todas as funções e, assim, nem toda a variância, são representa- das grafi camente). O pesquisador pode ver as diferenças entre os grupos em cada função; no entanto, a inspeção visual não explica totalmente o que são essas diferenças. Pode-se desenhar círculos que envolvam a distribuição de observações em volta de seus respectivos centróides para esclarecer melhor as diferenças de grupos, mas esse pro- cedimento está além do escopo deste texto (ver Dillon e Goldstein [4]).\n\n\nAvaliação da precisão preditiva\n\n\nde pertinência a grupo\nDado que a variável dependente é não-métrica, não é pos- sível usar uma medida como R^2 , como se faz em regressão múltipla, para avaliar a precisão preditiva. Em vez disso, cada observação deve ser avaliada com o objetivo de sa- ber se ela foi corretamente classifi cada. Ao fazer isso, di- versas considerações importantes devem ser feitas:\n\nA concepção estatística e prática para desenvolver matrizes de classifi cação\nA determinação do escore de corte\nA construção das matrizes de classifi cação\nOs padrões para avaliar a precisão de classifi cação\n\nPor que matrizes de classifi cação são desenvolvidas. Os testes estatísticos para avaliar a signifi cância das funções discriminantes somente avaliam o grau de diferença en- tre os grupos com base nos escores Z discriminantes, mas não dizem quão bem a função prevê. Esses testes estatísticos sofrem das mesmas desvantagens dos testes de hipóteses clássicos. Por exemplo, suponha que os dois grupos são considerados signifi cantemente diferentes além do nível 0,01. Com amostras sufi cientemente gran- des, as médias de grupo (centróides) poderiam ser virtu- almente idênticas e ainda teriam signifi cância estatística.\nPara determinar a habilidade preditiva de uma função\ndiscriminante, o pesquisador deve construir matrizes de\nclassifi cação.\nA matriz de classifi cação fornece uma perspectiva so-\nbre signifi cância prática, e não sobre signifi cância estatís-\ntica. Com a análise discriminante múltipla, o percentual\ncorretamente classifi cado , também conhecido como razão\nde sucesso , revela o quão bem a função discriminante\nclassifi cou os objetos. Com uma amostra sufi cientemen-\nte grande em análise discriminante, poderíamos ter uma\ndiferença estatisticamente signifi cante entre os dois (ou\nmais) grupos e mesmo assim classifi car corretamente\napenas 53% (quando a chance é de 50%, com grupos de\nmesmo tamanho) [16]. Em tais casos, o teste estatístico\nindicaria signifi cância estatística, ainda que a razão de su-\ncesso viabilizasse um julgamento à parte a ser feito em\ntermos de signifi cância prática. Logo, devemos usar o pro-\ncedimento da matriz de classifi cação para avaliar precisão\npreditiva além de simples signifi cância estatística.\nCálculo do escore de corte. Usando as funções discrimi-\nnantes consideradas signifi cantes, podemos desenvolver\nmatrizes de classifi cação para uma avaliação mais preci-\nsa do poder discriminatório das funções. Antes que uma\nmatriz de classifi cação seja defi nida, porém, o pesquisador\ndeve determinar o escore de corte (também chamado de\nvalor Z crítico) para cada função discriminante. O escore\nde corte é o critério em relação ao qual o escore discrimi-\nnante de cada objeto é comparado para determinar em\nqual grupo o objeto deve ser classifi cado.\nO escore de corte representa o ponto divisor usado\npara classifi car observações em um entre dois grupos ba-\nseado no escore da função discriminante. O cálculo de um\nescore de corte entre dois grupos quaisquer é baseado\nnos centróides de dois grupos (média de grupo dos esco-\nres discriminantes) e no tamanho relativo dos grupos. Os\ncentróides são facilmente calculados e fornecidos em cada\nestágio do processo stepwise. Para calcular corretamente\no escore de corte ótimo , o pesquisador deve abordar dois\npontos:\n1. Defi nir as probabilidades a priori , baseado nos tamanhos relativos dos grupos observados ou especifi cados pelo pes- quisador (ou assumidos iguais, ou com valores dados pelo pesquisador). 2. Calcular o valor do escore de corte ótimo como uma média ponderada sobre os tamanhos assumidos dos grupos (obti- do a partir das probabilidades a priori ).\nDefi nição das probabilidades a priori. O impacto\ne a importância de tamanhos relativos de grupos são mui-\ntas vezes desconsiderados, apesar de serem baseados nas\nsuposições do pesquisador relativas à representatividade\nda amostra. Neste caso, representatividade se relaciona à\nrepresentação dos tamanhos relativos dos grupos na po-\npulação real, o que pode ser estabelecido como probabili-\n\n\n242 Análise Multivariada de Dados\ndades a priori (ou seja, a proporção relativa de cada grupo em relação à amostra total). A questão fundamental é: os tamanhos relativos dos grupos são representativos dos tamanhos de grupos na população? A suposição padrão para a maioria dos pro- gramas estatísticos é de probabilidades iguais; em outras palavras, cada grupo é considerado como tendo a mesma chance de ocorrer, mesmo que os tamanhos dos grupos na amostra sejam desiguais. Se o pesquisador está inse- guro sobre se as proporções observadas na amostra são representativas das proporções da população, a aborda- gem conservadora é empregar probabilidades iguais. Em alguns casos, estimativas das probabilidades a priori po- dem estar disponíveis, como em pesquisa anterior. Aqui a suposição padrão de probabilidades iguais a priori é subs- tituída por valores especifi cados pelo pesquisador. Em qualquer caso, os reais tamanhos de grupos são substituí- dos com base nas probabilidades a priori especifi cadas. No entanto, se a amostra foi conduzida aleatoriamen- te e o pesquisador sente que os tamanhos de grupos são representativos da população, então o pesquisador pode especifi car probabilidade a priori com base na amostra de estimação. Assim, os verdadeiros tamanhos de gru- pos são considerados representativos e diretamente usa- dos no cálculo do escore de corte (ver a discussão que se segue). Em todos os casos, porém, o pesquisador deve especifi car como as probabilidades a priori são calcula- das, o que afeta os tamanhos de grupos usados no cálculo como ilustrado.\nPor exemplo, considere uma amostra de teste consis-\ntindo de 200 observações, com tamanhos de grupos de\n60 a 140 que se relacionam com probabilidades a priori\nde 30% e 70%, respectivamente. Se a amostra é consi-\nderada representativa, então os tamanhos de 60 e 140\nsão empregados no cálculo do escore de corte. Não obs-\ntante, se a amostra é considerada não-representativa, o\npesquisador deve especifi car as probabilidades a prio-\nri. Se elas são especifi cadas como iguais (50% e 50%),\nos tamanhos amostrais de 100 e 100 seriam usados no\ncálculo do escore de corte no lugar dos tamanhos reais.\nEspecifi car outros valores para as probabilidades a prio-\nri resultaria em diferentes tamanhos amostrais para os\ndois grupos.\nCálculo do escore de corte ótimo. A importância das probabilidades a priori no escore de corte é muito evi- dente depois que se percebe como o mesmo é calculado. A fórmula básica para computar o escore de corte entre dois grupos quaisquer é:\nonde\nZCS = escore de corte ótimo entre grupos A e B\nNA = número de observações no grupo A\nNB = número de observações no grupo B\nZA = centróide para o grupo A\nZB = centróide para o grupo B\nCom tamanhos desiguais de grupos, o escore de cor-\nte ótimo para uma função discriminante é agora a média\nponderada dos centróides de grupos. O escore de corte\né ponderado na direção do grupo menor, gerando, com\nsorte, uma melhor classifi cação do grupo maior.\nSe os grupos são especifi cados como sendo de iguais\ntamanhos (probabilidades a priori defi nidas como iguais),\nentão o escore de corte ótimo estará a meio caminho en-\ntre os dois centróides e se torna simplesmente a média dos\nmesmos:\nonde\nZCE = valor do escore de corte crítico para grupos de\nmesmo tamanho\nZA = centróide do grupo A\nZB = centróide do grupo B\nAmbas as fórmulas para cálculo do escore de corte óti-\nmo assumem que as distribuições são normais e as estru-\nturas de dispersão de grupos são conhecidas.\nO conceito de um escore de corte ótimo para grupos\niguais e distintos é ilustrado nas Figuras 5-7 e 5-8, res-\npectivamente. Os escores de corte ponderados e não-\nponderados são mostrados. Fica evidente que se o grupo\nA é muito menor que o grupo B, o escore de corte ótimo\nestá mais próximo ao centróide do grupo A do que ao\ncentróide do grupo B. Além disso, se o escore de corte\nnão-ponderado fosse usado, nenhum dos objetos no gru-\npo A seria mal classifi cado, mas uma parte substancial\ndos que estão no grupo B seria mal classifi cada.\nCustos de má classifi cação. O escore de corte ótimo\ntambém deve considerar o custo de classifi car um obje-\nto no grupo errado. Se os custos de má classifi cação são\naproximadamente iguais para todos os grupos, o escore\nde corte ótimo será aquele que classifi car mal o menor nú-\nmero de objetos em todos os grupos. Se os custos de má\nclassifi cação são desiguais, o escore de corte ótimo será o\nque minimizar os custos de má classifi cação. Abordagens\nmais sofi sticadas para determinar escores de corte são dis-\ncutidas em Dillon e Goldstein [4] e Huberty et al. [13].\nEssas abordagens são baseadas em um modelo estatístico\nbayesiano e são adequadas quando os custos de má classi-\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 243\nfi cação em certos grupos são altos, quando os grupos são de tamanhos muito diferentes, ou quando se deseja tirar vantagem de um conhecimento a priori de probabilidades de pertinência a grupo. Na prática, quando se calcula o escore de corte, ge- ralmente não é necessário inserir as medidas originais da variável para cada indivíduo na função discriminante e obter o escore discriminante para cada pessoa para usar no cálculo de Z A e Z B (centróides dos grupos A e B). O programa de computador fornece os escores discriminan- tes, bem como Z A e Z B, como output regular. Quando o pesquisador tem os centróides de grupo e os tamanhos da amostra, o escore de corte ótimo pode ser obtido simples- mente substituindo-se os valores na fórmula apropriada.\nConstrução das matrizes de classifi cação. Para validar a função discriminante pelo uso de matrizes de classifi cação, a amostra deve ser aleatoriamente dividida em dois gru- pos. Um dos grupos (a amostra de análise) é usado para computar a função discriminante. O outro (a amostra de teste ou de validação) é retido para uso no desenvolvi- mento da matriz de classifi cação. O procedimento envolve a multiplicação dos pesos gerados pela amostra de análise\npelas medidas originais da variável da amostra de teste.\nEm seguida, os escores discriminantes individuais para a\namostra de teste são comparados com o valor do escore\nde corte crítico e classifi cados como se segue:\nClassifi que um indivíduo no grupo A se Zn &lt; Zct\nou\nClassifi que um indivíduo no grupo B se Zn &gt; Zct.\nonde\nZn = escore Z discriminante para o n -ésimo indivíduo\nZct = valor do escore de corte crítico\nOs resultados do procedimento de classifi cação são\napresentados em forma matricial, como mostrado na Ta-\nbela 5-4. As entradas na diagonal da matriz representam o\nnúmero de indivíduos corretamente classifi cados. Os nú-\nmeros fora da diagonal representam as classifi cações in-\ncorretas. As entradas sob a coluna rotulada de “Tamanho\ndo grupo real” representam o número de indivíduos que\nrealmente estão em cada um dos dois grupos. As entradas\nna base das colunas representam o número de indivíduos\ndesignados aos grupos pela função discriminante. O per-\nEscore de corte = Z CE\nClassifique como A\n(Não-comprador)\nClassifique como B\n(Comprador)\nGrupo A Grupo B\nFIGURA 5-7 Escore de corte ótimo com amostras de tamanhos iguais.\nEscore de corte\nnão-ponderado\nEscore de corte\nótimo ponderado\nGrupo A\nGrupo B\nFIGURA 5-8 Escore de corte ótimo com tamanhos desiguais de amostras.\n\n\n244 Análise Multivariada de Dados\ncentual corretamente classifi cado para cada grupo é mos- trado no lado direito da matriz, e o percentual geral corre- tamente classifi cado, também conhecido como a razão de sucesso, é mostrado na base.\nEm nosso exemplo, o número de indivíduos correta-\nmente designados ao grupo 1 é 22, enquanto 3 mem-\nbros do grupo 1 estão incorretamente designados ao\ngrupo 2. Do mesmo modo, o número de classifi cações\ncorretas no grupo 2 é 20, e o número de designações\nincorretas no grupo 1 é 5. Assim, os percentuais de\nprecisão de classifi cação da função discriminante para\nos grupos reais 1 e 2 são 88% e 80%, respectivamente.\nA precisão de classifi cação geral (razão de sucesso) é\n84%.\nUm tópico fi nal sobre os procedimentos de classifi - cação é o teste t disponível para determinar o nível de signifi cância para a precisão de classifi cação. A fórmu- la para uma análise de dois grupos (igual tamanho de amostra) é\nonde\np = proporção corretamente classifi cada N = tamanho da amostra Essa fórmula pode ser adaptada para uso com mais grupos e diferentes tamanhos de amostra.\nEstabelecimento de padrões de comparação para a razão de sucesso. Como observado anteriormente, a precisão preditiva da função discriminante é medida pela razão de sucesso, a qual é obtida a partir da matriz de classi- fi cação. O pesquisador pode questionar o que é ou não considerado um nível aceitável de precisão preditiva para uma função discriminante. Por exemplo, 60% é um nível aceitável ou deveríamos esperar obter de 80% a 90% de precisão preditiva? Para responder essa questão o pesqui-\nsador deve primeiro determinar o percentual que poderia\nser classifi cado corretamente por chances ( sem a ajuda da\nfunção discriminante ).\nPadrões de comparação para a razão de sucesso em\ngrupos de mesmo tamanho. Quando os tamanhos de\namostra dos grupos são iguais, a determinação da classifi -\ncação por chances é bem simples; ela é obtida dividindo-\nse 1 pelo número de grupos. A fórmula é\nC IGUAL = 1/(Número de grupos).\nPor exemplo, para uma função de dois grupos, a pro-\nbabilidade seria de 0,50; para uma função de três grupos,\nseria de 0,33, e assim por diante.\nPadrões de comparação para a razão de sucesso em\ngrupos de tamanhos desiguais. A determinação da\nclassifi cação por chances para situações nas quais os ta-\nmanhos dos grupos são desiguais é um pouco mais com-\nplicada. Devemos considerar apenas o maior grupo, a\nprobabilidade combinada de todos os tamanhos de gru-\npos, ou algum outro padrão? Imaginemos que temos uma\namostra total de 200 indivíduos divididos como amostras\nde teste e de análise de 100 observações cada. Na amostra\nde teste, 75 objetos pertencem a um grupo e 25 ao outro.\nExaminaremos os possíveis caminhos nos quais podemos\nconstruir um padrão para comparação e aquilo que cada\num representa.\n\nConhecido como o critério de chance máxima , poderíamos arbitrariamente designar todos os indivíduos ao maior gru- po. O critério da chance máxima deve ser usado quando o único objetivo da análise discriminante é maximizar o percentual corretamente classifi cado [16]. É também o pa- drão mais conservador, pois ele gera o mais alto padrão de comparação. No entanto, são raras as situações nas quais estamos interessados apenas em maximizar o percentual corretamente classifi cado. Geralmente, o pesquisador usa a análise discriminante para identifi car corretamente os mem- bros de todos os grupos. Em casos nos quais os tamanhos das amostras são desiguais e o pesquisador deseja classifi car os membros de todos os grupos, a função discriminante vai contra as chances, classifi cando um indivíduo no(s) grupo(s) menor(es). O critério por chances não leva esse fato em consideração [16].\n\nTABELA 5-4 Matriz de classifi cação para análise discriminante de dois grupos\nGrupo previsto\nGrupo real 1 2\nTamanho do\ngrupo real\nPercentual correta-\nmente classifi cado\n12 2 32 588\n2 52 02580\nTamanho previsto\ndo grupo 27 23 50 84 a\naPercentual corretamente classifi cado = (Número corretamente classifi cado/Número total de observações) x 100\n= [(22 + 20)/50] × 100\n= 84%\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 245\nEm nosso exemplo simples de uma amostra com dois\ngrupos (75 e 25 pessoas cada), usando esse método te-\nríamos uma precisão de classifi cação de 75%, o que se\nconseguiria classifi cando-se todos no grupo maior sem\na ajuda de qualquer função discriminante. Pode-se con-\ncluir que, a menos que a função discriminante consiga\numa precisão de classifi cação maior do que 75%, ela\ndeve ser descartada, pois não nos ajuda a melhorar a\nprecisão preditiva que podemos atingir sem qualquer\nanálise discriminante.\n\nQuando os tamanhos de grupos são desiguais e o pesquisa- dor deseja identifi car corretamente os membros de todos os grupos, não apenas do maior, o critério de chances propor- cionais é considerado por muitos como o mais apropriado. A fórmula para esse critério é C PRO! p^2 “(1 $ p )^2\n\nonde\np = proporção de indivíduos no grupo 1\n1 – p = proporção de indivíduos no grupo 2\nUsando os tamanhos de grupos de nosso exemplo ante-\nrior (75 e 25), percebemos que o critério de chances pro-\nporcionais seria de 62,5% [0,75^2 + (1,0 – 0,75)^2 = 0,625]\ncomparado com 75%. Logo, neste caso, uma precisão\npreditiva de 75% seria aceitável porque está acima dos\n62,5% do critério de chances proporcionais.\n\nUm problema dos critérios de chance máxima e de chances proporcionais são os tamanhos das amostras usados para cál- culo dos padrões. Você deve usar grupos com o tamanho da amostra geral, da amostra de análise/estimação, ou da amos- tra de validação/teste? Aqui vão algumas sugestões:\n\nSe os tamanhos das amostras de análise e estimação são considerados sufi cientemente grandes (i.e., amostra total de 100 com cada grupo tendo pelo menos 20 casos), obte- nha padrões separados para cada amostra.\nSe as amostras separadas não são consideradas sufi cien- temente grandes, use os tamanhos de grupos da amostra total para calcular os padrões.\nAtente a tamanhos de grupos diferentes entre amostras quando usar o critério de chance máxima, pois ele depen- de do maior tamanho de grupo. Esta orientação é espe- cialmente crítica quando a amostra é pequena ou quando as proporções de tamanhos de grupos variam muito de amostra para amostra. Este é outro motivo de cautela no emprego do critério de chance máxima. Esses critérios de chances são úteis somente quando computados com amostras de teste (abordagem da parti- ção da amostra). Se os indivíduos usados no cálculo da fun- ção discriminante são os classifi cados, o resultado é um viés ascendente na precisão preditiva. Em tais casos, os critérios deveriam ser ajustados para cima em função desse viés.\n\n\nComparação da razão de sucesso com o padrão. A\nquestão de “quanta precisão de classifi cação devo ter?”\né crucial. Se o percentual de classifi cações corretas é sig-\nnifi cantemente maior do que se esperaria por chances, o\npesquisador pode proceder à interpretação das funções\ndiscriminantes e de perfi s de grupos. No entanto, se a pre-\ncisão de classifi cação não é maior do que pode ser espera-\ndo das chances, quaisquer diferenças que pareçam existir\nmerecem pouca ou nenhuma interpretação; ou seja, as\ndiferenças em perfi s de escores não forneceriam qualquer\ninformação signifi cativa para identifi car a pertinência a\ngrupos.\nA questão, então, é o quanto a precisão de classi-\nfi cação deve ser relativa às chances? Por exemplo, se\nas chances são de 50% (dois grupos, com iguais tama-\nnhos), uma precisão de classifi cação (preditiva) de 60%\njustifi ca ir para o estágio de interpretação? Em última\ninstância, a decisão depende do custo em relação ao va-\nlor da informação. O argumento do custo versus valor\noferece pouca ajuda ao pesquisador iniciante, mas o\nseguinte critério é sugerido: A precisão de classifi cação\ndeve ser pelo menos um quarto maior do que a obtida\npor chances.\nPor exemplo, se a precisão por chances for de 50%, a\nprecisão de classifi cação deverá ser 62,5% (62,5% = 1,25\n× 50%). Se a precisão de chances for de 30%, a preci-\nsão de classifi cação deverá ser 37,5% (37,5%! 1,25 ×\n30%).\nEsse critério fornece apenas uma estimativa grosseira\ndo nível aceitável de precisão preditiva. O critério é fácil\nde aplicar com grupos de mesmo tamanho. Com grupos de\ntamanhos desiguais, um limite superior é alcançado quan-\ndo o modelo de chance máxima é usado para determinar\na precisão de chances. No entanto, isso não representa um\ngrande problema, pois sob a maioria das circunstâncias o\nmodelo de chance máxima não seria usado com grupos de\ntamanhos distintos.\nRazões de sucesso geral versus específicas de gru-\npos. Até este ponto, nos concentramos no cálculo da\nrazão de sucesso geral em todos os grupos avaliando a\nprecisão preditiva de uma análise discriminante. O pes-\nquisador também deve estar preocupado com a razão de\nsucesso (percentual corretamente classifi cado) para cada\ngrupo separado. Se você se concentrar somente na razão\nde sucesso geral, é possível que um ou mais grupos, par-\nticularmente os menores, possam ter razões de sucesso\ninaceitáveis enquanto a razão de sucesso geral é aceitá-\nvel. O pesquisador deve calcular a razão de sucesso de\ncada grupo e avaliar se a análise discriminante fornece\nníveis adequados de precisão preditiva tanto no nível ge-\nral quanto para cada grupo.\n\n\n246 Análise Multivariada de Dados\nMedidas com base estatística de precisão de classifi cação relacionada a chances* Um teste estatístico do poder discriminatório da matriz de classifi cação quando com- parada com um modelo de chances é a estatística Q de Press. Essa medida simples compara o número de clas- sifi cações corretas com o tamanho da amostra total e o número de grupos. O valor calculado é então comparado com um valor crítico (o valor qui-quadrado para um grau de liberdade no nível de confi ança desejado). Se ele exce- de este valor crítico, então a matriz de classifi cação pode ser considerada estatisticamente melhor do que as chan- ces. A estatística Q é calculada pela seguinte fórmula:\nonde\nN = tamanho da amostra total\nn = número de observações corretamente classifi ca-\ndas\nK = número de grupos\nPor exemplo, na Tabela 5-4, a estatística Q seria baseada\nem uma amostra total de N = 50, n = 42 observações cor-\nretamente classifi cadas, e K = 2 grupos. A estatística cal-\nculada seria:\nO valor crítico em um nível de signifi cância de 0,01 é\n6,63. Assim, concluiríamos que, no exemplo, as previsões\nseriam signifi cantemente melhores do que chances, as\nquais teriam uma taxa de classifi cação correta de 50%.\nEsse teste simples é sensível ao tamanho da amostra; amostras grandes são mais prováveis de mostrar signifi - cância do que amostras pequenas da mesma taxa de clas- sifi cação.\nPor exemplo, se o tamanho da amostra é aumentado para\n100 no exemplo e a taxa de classifi cação permanece em\n84%, a estatística Q aumenta para 46,24. Se o tamanho\nda amostra sobe para 200, mas mantém a taxa de classifi -\ncação em 84%, a estatística Q novamente aumenta para\n92,48%. Mas se a amostra for apenas 20 e a taxa de classi-\nfi cação incorreta** for ainda de 84% (17 previsões corre-\ntas), a estatística Q seria de somente 9,8. Ou seja, examine\na estatística Q à luz do tamanho amostral, pois aumentos\nno tamanho da amostra fazem subir a estatística Q ainda\nque seja para a mesma taxa de classifi cação geral.\nPorém, é necessário cuidado nas conclusões baseadas\napenas nessa estatística, pois à medida que a amostra fi ca\nmaior, uma taxa de classifi cação menor ainda será consi-\nderada signifi cante.\n\n\n\nDiagnóstico por casos\nO meio fi nal de avaliar o ajuste de modelo é examinar os\nresultados preditivos em uma base de casos. Semelhante\nà análise de resíduos em regressão múltipla, o objetivo é\nentender quais observações (1) foram mal classifi cadas e\n(2) não são representativas dos demais membros do gru-\npo. Apesar de a matriz de classifi cação fornecer precisão\nde classifi cação geral, ela não detalha os resultados indi-\nviduais. Além disso, mesmo que possamos denotar quais\ncasos são correta ou incorretamente classifi cados, ainda\nprecisamos de uma medida da similaridade de uma obser-\nvação com o restante do grupo.\n\nMá classifi cação de casos individuais\nQuando se analisam resíduos de uma análise de regressão\nmúltipla, uma decisão importante envolve estabelecer o\nnível de resíduo considerado substancial e merecedor de\natenção. Em análise discriminante, essa questão é mais\nsimples, porque uma observação é ou correta, ou incorre-\ntamente classifi cada. Todos os programas de computador\nfornecem informação que identifi ca quais casos são mal\nclassifi cados e para quais grupos eles foram mal classifi -\ncados. O pesquisador pode identifi car não apenas aqueles\ncasos com erros de classifi cação, mas uma representação\ndireta do tipo de má classifi cação.\n\n\nAnálise de casos mal classifi cados\nO propósito de identifi car e analisar as observações mal\nclassifi cadas é identifi car quaisquer características dessas\nobservações que pudessem ser incorporadas à análise dis-\ncriminante para melhorar a precisão preditiva. Essa análi-\nse pode assumir a forma de se estabelecer o perfi l de casos\nmal classifi cados tanto nas variáveis independentes quan-\nto em outras variáveis não incluídas no modelo.\nO perfi l das variáveis independentes. Examinar esses\ncasos nas variáveis independentes pode identifi car ten-\ndências não-lineares ou outras relações ou atributos que\nconduziram à má classifi cação. Várias técnicas são parti-\ncularmente adequadas em análise discriminante:\n\nUma representação gráfi ca das observações é talvez a abor- dagem mais simples e efetiva para examinar as caracterís- ticas de observações, especialmente as mal classifi cadas. A abordagem mais comum é fazer o gráfi co das observações com base em seus escores Z discriminantes e mostrar a so- breposição entre grupos e os casos mal classifi cados. Se duas ou mais funções são mantidas, os pontos de corte ótimo também podem ser representados grafi camente para forne- cer aquilo que é conhecido como um mapa territorial , que exibe as regiões correspondentes para cada grupo.\nN. de R. T.: A palavra “chance” também poderia ser traduzida como “acaso”. ** N. de R. T.: A frase correta seria “taxa de classifi cação correta”.\n\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 247\n\nRepresentar grafi camente as observações individuais com os centróides dos grupos, como anteriormente discutido, mostra não apenas as características gerais dos grupos via centróides, mas também a variação nos membros nos gru- pos. Isso é análogo às áreas defi nidas no exemplo de três grupos no começo deste capítulo, em que escores de cor- te em ambas as funções defi niam áreas correspondentes às previsões de classifi cação para cada grupo.\nUma avaliação empírica direta da similaridade de uma ob- servação com os membros do outro grupo pode ser feita calculando-se a distância D^2 de Mahalanobis da observação ao centróide do grupo. Com base no conjunto de variáveis independentes, observações mais próximas ao centróide têm um D^2 de Mahalanobis menor e são consideradas mais representativas do grupo do que as mais afastadas.\nNo entanto, a medida empírica deve ser combinada com uma análise gráfi ca, pois apesar de um grande D^2 de Mahalanobis indicar observações que são bastante diferentes dos centrói- des de grupo, isso nem sempre indica má classifi cação. Por exemplo, em uma situação de dois grupos, um membro do grupo A pode ter uma grande distância D^2 de Mahalanobis, indicando que ele é menos representativo do grupo. Contu- do, se essa distância está afastada do centróide do grupo B, então realmente aumentam as chances de classifi cação corre- ta, mesmo que ele seja menos representativo do grupo. Uma menor distância que coloca uma observação entre os dois centróides provavelmente teria uma menor probabilidade de classifi cação correta, mesmo que ela esteja mais próxima ao centróide de seu grupo do que na situação anterior. Apesar de não existir qualquer análise pré-especifi - cada, como na regressão múltipla, o pesquisador é enco- rajado a avaliar esses casos mal classifi cados de diversos pontos de vista, na tentativa de descobrir as caracterís- ticas únicas que eles têm em comparação com os outros membros do seu grupo.\n\nPerfi l de variáveis não presentes na análise. O exame de outras variáveis quanto às suas diferenças nos casos mal classifi cados seria o primeiro passo para sua possível in- clusão na análise discriminante. Muitas vezes, variáveis que discriminam apenas em um conjunto menor de casos não são identifi cadas no primeiro conjunto de análises, mas se tornam mais evidentes na análise de casos mal classifi cados. O pesquisador é encorajado a rever as áreas de suporte conceitual para identifi car novas possíveis va- riáveis que possam se relacionar unicamente com os casos mal classifi cados e aumentar a precisão preditiva geral.\n\n\n\nResumo\nO estágio de estimação e avaliação tem várias semelhan- ças com as outras técnicas de dependência, permitindo um processo de estimação direta ou stepwise e uma análise da precisão preditiva geral e de casos. O pesquisador deve de- dicar considerável atenção a essas questões para evitar o uso de um modelo de análise discriminante fundamental- mente errado.\n\n\nESTÁGIO 5: INTERPRETAÇÃO\n\n\nDOS RESULTADOS\nSe a função discriminante é estatisticamente signifi cante e\na precisão de classifi cação é aceitável, o pesquisador deve\nse concentrar em fazer interpretações substanciais das\ndescobertas. Esse processo envolve o exame das funções\ndiscriminantes para determinar a importância relativa de\ncada variável independente na discriminação entre os gru-\npos. Três métodos para determinar a importância relativa\nforam propostos:\n1. Pesos discriminantes padronizados 2. Cargas discriminantes (correlações de estrutura) 3. Valores F parciais\n\n\nPesos discriminantes\nA abordagem tradicional para interpretar funções dis-\ncriminantes examina o sinal e a magnitude do peso\ndiscriminante padronizado (às vezes chamado de coefi -\nciente discriminante ) designado para cada variável ao se\ncomputarem as funções discriminantes. Quando o sinal\né ignorado, cada peso representa a contribuição relativa\nde sua variável associada àquela função. As variáveis\nindependentes com pesos relativamente maiores con-\ntribuem mais para o poder discriminatório da função\ndo que as variáveis com pesos menores. O sinal indica\n\nAvaliação do ajuste de modelo e precisão preditiva\n\nA matriz de classifi cação e a razão de sucesso substituem R^2 como a medida de ajuste de modelo:\n\nAvalie a razão de sucesso geral e por grupo\nSe as amostras de estimação e análise excederem 100 casos e cada grupo exceder 20 casos, derive padrões separados para cada amostra; caso contrário, derive um único padrão a partir da amostra geral\n\nCritérios múltiplos são usados para comparação com a razão de sucesso:\n\nO critério de chance máxima para avaliação da razão de sucesso é o mais conservador, dando a mais elevada base para exceder\nSeja cuidadoso no uso do critério de chance máxima em situações com amostras gerais menores que 100 e/ou grupos com menos de 20\nO critério de chance proporcional considera todos os grupos no estabelecimento do padrão de comparação e é o mais popular\nA verdadeira precisão preditiva (razão de sucesso) deve exceder qualquer valor de critério em pelo menos 25%\n\nAnalise as observações mal classifi cadas gráfi ca (mapa territorial) e empiricamente ( D^2 de Mahalanobis)\n\n\nREGRAS PRÁTICAS 5-3\n\n\n\n248 Análise Multivariada de Dados\napenas que a variável tem uma contribuição positiva ou negativa [4]. A interpretação de pesos discriminantes é análoga à interpretação de pesos beta em análise de regressão e está, portanto, sujeita às mesmas críticas. Por exemplo, um peso pequeno pode indicar que sua variável corres- pondente é irrelevante na determinação de uma relação, ou que ela tenha sido deixada de lado na relação por cau- sa de um elevado grau de multicolinearidade. Um outro problema do uso de pesos discriminantes é que eles es- tão sujeitos a considerável instabilidade. Esses problemas sugerem cuidado ao se usarem pesos para interpretar os resultados da análise discriminante.\n\n\n\nCargas discriminantes\nAs cargas discriminantes , às vezes chamadas de correla- ções de estrutura , são cada vez mais usadas como uma base para interpretação, por conta das defi ciências na utili- zação de pesos. Medindo a correlação linear simples entre cada variável independente e a função discriminante, as cargas discriminantes refl etem a variância que as variáveis independentes compartilham com a função discriminan- te. Em relação a isso, elas podem ser interpretadas como cargas fatoriais na avaliação da contribuição relativa de cada variável independente para a função discriminante. (O Capítulo 3 discute melhor a interpretação de cargas fatoriais.) Uma característica ímpar de cargas é que elas podem ser calculadas para todas as variáveis, sejam elas usadas na estimação da função discriminante ou não. Este aspecto é particularmente útil quando um processo de estimação stepwise é empregado e algumas variáveis não são incluí- das na função discriminante. Em vez de não se ter forma alguma de compreender seu impacto relativo, as cargas fornecem um efeito relativo de cada variável em uma me- dida comum. Com as cargas, a questão principal é: Quais valores as cargas devem assumir para serem consideradas substan- tivas discriminadoras dignas de nota? Tanto em análise discriminante simultânea quanto stepwise , variáveis que exibem uma carga de ± 0,40 ou mais são consideradas substantivas. Com procedimentos stepwise , tal determi- nação é suplementada, pois a técnica evita que variáveis não-signifi cantes entrem na função. Porém, multicoline- aridade e outros fatores podem evitar uma variável na equação, o que não signifi ca necessariamente que ela não tenha um efeito substancial. As cargas discriminantes (assim como os pesos) podem estar sujeitas à instabilidade. As cargas são consideradas relativamente mais válidas do que os pesos como um meio de interpretação do poder discriminatório de variáveis in- dependentes por causa de sua natureza correlacional. O pesquisador ainda deve ser cuidadoso ao usar cargas para interpretar funções discriminantes.\n\n\nValores F parciais\nComo anteriormente discutido, duas abordagens compu-\ntacionais – simultânea e stepwise – podem ser utilizadas\npara determinar funções discriminantes. Quando o mé-\ntodo stepwise é selecionado, um meio adicional de inter-\npretar o poder discriminatório relativo das variáveis inde-\npendentes está disponível pelo uso de valores F parciais.\nIsso é obtido examinando-se os tamanhos absolutos dos\nvalores F signifi cantes e ordenando-os. Valores F grandes\nindicam maior poder discriminatório. Na prática, as or-\ndenações que usam a abordagem dos valores F são iguais\nà ordenação determinada a partir do uso de pesos discri-\nminantes, mas os valores F indicam o nível associado de\nsignifi cância para cada variável.\n\n\nInterpretação de duas ou mais funções\nQuando há duas ou mais funções discriminantes signi-\nfi cantes, temos problemas adicionais de interpretação.\nPrimeiro, podemos simplifi car os pesos ou cargas discri-\nminantes para facilitar a determinação do perfi l de cada\nfunção? Segundo, como representamos o impacto de cada\nvariável nas funções? Esses problemas ocorrem tanto na\nmedida dos efeitos discriminantes totais das funções quan-\nto na avaliação do papel de cada variável no perfi l de cada\nfunção separadamente. Tratamos dessas duas questões\nintroduzindo os conceitos de rotação das funções, o índice\nde potência, e representações de vetores expandidos.\n\nRotação das funções discriminantes\nDepois que as funções discriminantes foram desenvolvi-\ndas, elas podem ser rotacionadas para redistribuir a va-\nriância. (O conceito é melhor explicado no Capítulo 3.)\nBasicamente, a rotação preserva a estrutura original e a\nconfi abilidade da solução discriminante, ao passo que tor-\nna as funções muito mais fáceis de interpretar. Na maio-\nria dos casos, a rotação VARIMAX é empregada como a\nbase para a rotação.\n\n\nÍndice de potência\nAnteriormente discutimos o uso de pesos padronizados ou\ncargas discriminantes como medidas da contribuição de\numa variável a uma função discriminante. Quando duas\nou mais funções são determinadas, contudo, uma medida\nresumo ou composta é útil para descrever as contribuições\nde uma variável em todas as funções signifi cantes. O índice\nde potência é uma medida relativa entre todas as variáveis\nque é indicativa do poder discriminante de cada variável\n[18]. Ele inclui a contribuição de uma variável a uma fun-\nção discriminante (sua carga discriminante) e a contribui-\nção relativa da função para a solução geral (uma medida\nrelativa entre as funções com base nos autovalores). A\ncomposição é simplesmente a soma dos índices de potência\nindividuais em todas as funções discriminantes signifi can-\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 249\ntes. A interpretação da medida composta é limitada, contu- do, pelo fato de que é útil apenas na representação da po- sição relativa (como o oposto de uma ordenação) de cada variável, e o valor absoluto não tem qualquer signifi cado real. O índice de potência é calculado por um processo de dois passos:\nPasso 1: Calcular um valor de potência para cada função sig- nifi cante. No primeiro passo, o poder discriminatório de uma variável, representado pelo quadrado da carga discriminante não-rotacionada, é “ponderado” pela contribuição relativa da função discriminante para a solução geral. Primeiro, a medida do autovalor relativo para cada função discriminante signifi cante é calculada simplesmente como:\nO valor potência de cada variável em uma função dis-\ncriminante é então:\nPasso 2: Calcular um índice de potência composto em todas as funções signifi cantes. Uma vez que um valor potência tenha sido calculado para cada função, o índice de po- tência composto para cada variável é calculado como:\nO índice de potência agora representa o efeito discrimi- nante total da variável em todas as funções discriminantes signifi cantes. É apenas uma medida relativa, contudo, e seu valor absoluto não tem qualquer signifi cado importante. Uma ilustração de cálculo de índice de potência é forneci- da no exemplo para análise discriminante de três grupos.\n\n\nDisposição gráfi ca de escores e\n\n\ncargas discriminantes\nPara representar diferenças nos grupos nas variáveis preditoras, o pesquisador pode usar dois diferentes tra- tamentos para representação gráfi ca. O mapa territorial representa grafi camente os casos individuais de funções discriminantes signifi cantes para permitir ao pesquisador uma avaliação da posição relativa de cada observação com base nos escores da função discriminante. A segunda abordagem é representar grafi camente as cargas discrimi- nantes para entender o agrupamento relativo e a magnitu- de de cada carga sobre cada função. Cada abordagem será discutida detalhadamente na próxima seção.\nMapa territorial. O método gráfi co mais comum é o mapa territorial, no qual cada observação é impressa em\num gráfi co com base nos escores Z da função discrimi-\nnante das observações. Por exemplo, considere que uma\nanálise discriminante de três grupos tem duas funções\ndiscriminantes signifi cantes. Um mapa territorial é criado\nfazendo-se o gráfi co dos escores Z discriminantes de cada\nobservação para a primeira função discriminante sobre o\neixo X e os escores para a segunda função discriminante\nsobre o eixo Y. Desse modo, isso fornece diversas pers-\npectivas de análise:\n\nO gráfi co dos membros de cada grupo com diferentes sím- bolos permite um retrato fácil das diferenças de cada grupo, bem como suas sobreposições um com o outro.\nO gráfi co dos centróides de cada grupo fornece uma manei- ra de avaliar cada membro de grupo relativamente ao seu centróide. Este procedimento é particularmente útil na ava- liação da possibilidade de grandes medidas de Mahalanobis D^2 conduzirem a classifi cações ruins.\nRetas representando os escores de corte também podem ser grafi camente representadas, denotando fronteiras que re- presentam os intervalos de escores discriminantes previstos em cada grupo. Quaisquer membros de grupos que estejam fora dessas fronteiras são mal classifi cados. Denotar os casos mal classifi cados permite uma avaliação sobre qual função discriminante foi mais responsável pela má classifi cação, e sobre o grau em que um caso é mal classifi cado.\n\nGráfi co vetorial de cargas discriminantes. A abordagem\ngráfi ca mais simples é representar cargas reais rotaciona-\ndas ou não-rotacionadas. A abordagem preferencial seria\ncom cargas rotacionadas. Semelhante ao gráfi co de cargas\nfatoriais (ver Capítulo 3), este método representa o grau\nem que cada variável é associada com cada função discri-\nminante.\nUma técnica ainda mais precisa, porém, envolve o\ngráfi co de cargas bem como vetores para cada carga e\ncentróide de grupo. Um vetor é meramente uma reta de-\nsenhada a partir da origem (centro) de um gráfi co até as\ncoordenadas das cargas de uma variável particular ou um\ncentróide de grupo. Com a representação de um vetor ex-\npandido , o comprimento de cada vetor se torna indicativo\nda importância relativa de cada variável na discriminação\nentre os grupos. O procedimento gráfi co segue em três\npassos:\n1. Seleção de variáveis: Todas as variáveis, sejam incluídas no modelo ou não, podem ser grafi camente representadas como vetores. Desse modo, a importância de variáveis co- lineares que não estão incluídas, como em stepwise , ainda pode ser retratada. 2. Expansão de vetores: As cargas discriminantes de cada va- riável são expandidas multiplicando-se a carga discriminan- te (preferencialmente após a rotação) por seu respectivo va- lor F univariado. Notamos que os vetores apontam para os grupos com a maior média sobre o preditor respectivo e na direção oposta dos grupos com os menores escores médios. 3. Gráfi co dos centróides de grupos: Os centróides de grupo também são expandidos nesse procedimento, sendo multi- plicados pelo valor F aproximado associado a cada função\n\n\n250 Análise Multivariada de Dados\ndiscriminante. Se as cargas são expandidas, os centróides\ntambém devem ser expandidos para representá-los com\nprecisão no mesmo gráfi co. Os valores F aproximados para\ncada função discriminante são obtidos pela seguinte fór-\nmula:\nonde\nN Amostra de estimação = tamanho da amostra de estimação\nPor exemplo, considere que a amostra de 50 observações\ntenha sido dividida em três grupos. O multiplicador de\ncada autovalor seria (50 – 3)/(3 – 1) = 23,5.\nQuando completado, o pesquisador dispõe de um re- trato do agrupamento de variáveis em cada função dis- criminante, a magnitude da importância de cada variável (representada pelo comprimento de cada vetor) e o perfi l de cada centróide de grupo (mostrado pela proximidade de cada vetor). Apesar de este procedimento dever ser feito manualmente na maioria dos casos, ele dá um retra- to completo das cargas discriminantes e dos centróides de grupos. Para mais detalhes sobre esse procedimento, ver Dillon e Goldstein [4].\n\n\n\nQual método interpretativo usar?\nDiversos métodos para interpretar a natureza das funções discriminantes foram discutidos, tanto para soluções de uma função quanto de múltiplas. Quais métodos devem ser usados? A abordagem das cargas é mais válida do que o emprego de pesos e deve ser utilizada sempre que pos- sível. O uso de valores F parciais e univariados permite ao pesquisador empregar diversas medidas e procurar alguma consistência nas avaliações das variáveis. Se duas ou mais funções são estimadas, então o pesquisador pode utilizar diversas técnicas gráfi cas e o índice de potência, que ajuda na interpretação da solução multidimensional. O ponto mais básico é que o pesquisador deve usar todos os métodos disponíveis para chegar à interpretação mais precisa.\n\n\nESTÁGIO 6: VALIDAÇÃO\n\n\nDOS RESULTADOS\nO estágio fi nal de uma análise discriminante envolve a validação dos resultados discriminantes para garantir que os resultados têm validade externa e interna. Com a pro- pensão da análise discriminante para aumentar a razão de sucesso se avaliada apenas sobre a amostra de análise, a validação é um passo essencial. Além de validar as razões\nde sucesso, o pesquisador deve usar o perfi l de grupos\npara garantir que as médias de grupos sejam indicadores\nválidos do modelo conceitual usado na seleção de variá-\nveis independentes.\n\n\nProcedimentos de validação\nValidação é um passo crítico em qualquer análise discri-\nminante, pois muitas vezes, especialmente com amostras\nmenores, os resultados podem carecer de generalidade\n(validade externa). A técnica mais comum para estabe-\nlecer validade externa é a avaliação de razões de suces-\nso. Validação pode ocorrer com uma amostra separada\n(amostra de teste) ou utilizando-se um procedimento que\nrepetidamente processa a amostra de estimação. Validade\nexterna é admitida quando a razão de sucesso da aborda-\ngem selecionada excede os padrões de comparação que\nrepresentam a precisão preditiva esperada pelo acaso (ver\ndiscussão anterior).\n\nUtilização de uma amostra de teste\nGeralmente, a validação das razões de sucesso é execu-\ntada criando-se uma amostra de teste, também chamada\nde amostra de validação. O propósito de se utilizar uma\namostra de teste para fi ns de validação é ver o quão bem\na função discriminante funciona em uma amostra de ob-\nservações não usadas para obter a mesma. Este processo\nenvolve o desenvolvimento de uma função discriminante\ncom a amostra de análise e então a sua aplicação na amos-\ntra de teste. A justifi cativa para dividir a amostra total em\ndois grupos é que um viés ascendente ocorrerá na precisão\npreditiva da função discriminante se os indivíduos usados\nno desenvolvimento da matriz de classifi cação forem os\nmesmos utilizados para computar a função; ou seja, a pre-\ncisão de classifi cação será mais alta do que é válido se ela\nfor aplicada na amostra de estimação.\nOutros pesquisadores têm sugerido que uma confi ança\nmaior ainda poderia ser depositada na validade da função\ndiscriminante seguindo-se esse procedimento diversas ve-\nzes [18]. Ao invés de dividir aleatoriamente a amostra to-\ntal em grupos de análise e de teste uma vez, o pesquisador\ndividiria aleatoriamente a amostra total em amostras de\nanálise e de teste várias vezes, sempre testando a valida-\nde da função discriminante pelo desenvolvimento de uma\nmatriz de classifi cação e de uma razão de sucesso. Então\nas diversas razões de sucesso teriam uma média para se\nobter uma única medida.\n\n\nValidação cruzada\nA técnica de validação cruzada para avaliar validade ex-\nterna é feita com múltiplos subconjuntos da amostra total\n[2,4]. A abordagem mais amplamente usada é o método\njackknife. Validação cruzada é baseada no princípio do\n“deixe um de fora”. O uso mais comum desse método é\nestimar k – 1 amostras, eliminando-se uma observação\npor vez a partir de uma amostra de k casos. Uma fun-\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 251\nção discriminante é calculada para cada subamostra, e em seguida a pertinência a grupo prevista da observação eliminada é feita com a função discriminante estimada sobre os demais casos. Depois que todas as previsões de pertinência a grupo foram feitas, uma por vez, uma ma- triz de classifi cação é construída e a razão de sucesso é calculada. Validação cruzada é muito sensível a amostras pe- quenas. Orientações sugerem que ela seja usada somente quando o tamanho do grupo menor é pelo menos três ve- zes o número de variáveis preditoras, e a maioria dos pes- quisadores sugere uma proporção de cinco para um [13]. No entanto, validação cruzada pode representar a única técnica de validação possível em casos em que a amos- tra original é muito pequena para dividir em amostras de análise e de teste, mas ainda excede as orientações já dis- cutidas. Validação cruzada também está se tornando mais amplamente usada à medida que os principais programas de computador a disponibilizam como opção.\n\n\n\nDiferenças de perfi s de grupos\nUma outra técnica de validação é estabelecer o perfi l dos grupos sobre as variáveis independentes para garantir sua correspondência com as bases conceituais usadas na formulação do modelo original. Depois que o pesquisa- dor identifi ca as variáveis independentes que oferecem a maior contribuição à discriminação entre os grupos, o próximo passo é traçar o perfi l das características dos gru- pos com base nas médias dos mesmos. Esse perfi l permite ao pesquisador compreender o caráter de cada grupo de acordo com as variáveis preditoras.\nPor exemplo, olhando os dados da pesquisa da Kitchen-\nAid apresentados na Tabela 5-1, percebemos que a ava-\nliação média de “durabilidade” para o grupo “compra-\nria” é 7,4, enquanto a avaliação média comparável de\n“durabilidade” para o grupo “não compraria” é de 3,2.\nAssim, um perfi l desses dois grupos mostra que o grupo\n“compraria” avalia a durabilidade percebida do novo\nproduto bem mais do que o grupo “não compraria”.\nOutra abordagem é estabelecer o perfi l de grupos em\num conjunto separado de variáveis que deve espelhar as\ndiferenças observadas de grupos. Esse perfi l separado for-\nnece uma avaliação de validade externa, de modo que os\ngrupos variam tanto na(s) variável(eis) independente(s)\nquanto no conjunto de variáveis associadas. Essa técnica\né semelhante, em caráter, à validação de agrupamentos\nobtidos descrita no Capítulo 8.\n\n\nUM EXEMPLO ILUSTRATIVO\n\n\nDE DOIS GRUPOS\nPara ilustrar a aplicação da análise discriminante de dois\ngrupos, usamos variáveis obtidas da base de dados HBAT\nintroduzida no Capítulo 1. Esse exemplo examina cada\num dos seis estágios do processo de construção de modelo\npara um problema de pesquisa particularmente adequado\nà análise discriminante múltipla.\n\n\nEstágio 1: Objetivos da análise discriminante\n\nInterpretação e validação de funções\n\n\ndiscriminantes\n\nCargas discriminantes são o método preferido para avaliar a contribuição de cada variável em uma função discriminante, pois elas são:\n\nUma medida padronizada de importância (variando de 0 a 1)\nDisponíveis para todas as variáveis independentes, sejam usadas no processo de estimação ou não\nNão afetadas por multicolinearidade\n\nCargas excedendo ± 0,40 são consideradas substantivas para fi ns de interpretação\nNo caso de mais de uma função discriminante, certifi que-se de:\n\nUsar cargas rotacionadas\nAvaliar a contribuição de cada variável em todas as funções com o índice de potência\n\nA função discriminante deve ser validada com a amostra de teste ou um dos procedimentos “deixe um de fora”\n\nREGRAS PRÁTICAS 5-4 Você lembra que uma das características de cliente obti-\nda pela HBAT em sua pesquisa foi uma variável categó-\nrica ( X 4 ) que indicava a região na qual a empresa estava\nlocalizada: EUA/América do Norte ou fora. A equipe\nadministrativa da HBAT está interessada em quaisquer\ndiferenças de percepções entre aqueles clientes localiza-\ndos e servidos por sua equipe de venda nos EUA versus\naqueles fora dos EUA e que são servidos principalmente\npor distribuidores independentes. A despeito de diferen-\nças encontradas em termos de suporte de vendas devido\nà natureza da equipe de venda servindo cada área geo-\ngráfi ca, a equipe administrativa está interessada em ver\nse as outras áreas de operação (linha do produto, preço\netc.) são vistas de maneira distinta por estes dois con-\njuntos de clientes. Esta indagação segue a óbvia neces-\nsidade por parte da administração de sempre procurar\nmelhor entender seu cliente, neste caso se concentrando\nem diferenças que podem ocorrer entre áreas geográfi -\ncas. Se quaisquer percepções de HBAT forem notadas\ncomo diferindo signifi cativamente entre fi rmas nessas\nduas regiões, a companhia será então capaz de desen-\n\n\n252 Análise Multivariada de Dados\nPara tanto, a análise discriminante foi selecionada para identifi car aquelas percepções da HBAT que melhor dife- renciam as empresas em cada região geográfi ca.\n\n\n\nEstágio 2: Projeto de pesquisa\n\n\npara análise discriminante\nO estágio de projeto de pesquisa se concentra em três ques- tões-chave: selecionar variáveis dependente e independen- tes, avaliar a adequação do tamanho da amostra para a aná- lise planejada, e dividir a amostra para fi ns de validação.\n\nSeleção de variáveis dependente e independentes\nA análise discriminante requer uma única medida depen- dente não-métrica e uma ou mais medidas independentes métricas que são afetadas para fornecer diferenciação en- tre os grupos baseados na medida dependente.\nComo a variável dependente Região ( X 4 ) é uma variá-\nvel categórica de dois grupos, a análise discriminante é a\ntécnica apropriada. O levantamento coletou percepções\nda HBAT que agora podem ser usadas para distinguir\nentre os dois grupos de fi rmas. A análise discriminante\nusa como variáveis independentes as 13 variáveis de per-\ncepção a partir do banco de dados ( X 6 a X 18 ) para discri-\nminar entre fi rmas em cada área geográfi ca.\n\n\nTamanho da amostra\nDado o tamanho relativamente pequeno da amostra HBAT (100 observações), questões como tamanho amos- tral são particularmente importantes, especialmente a di- visão da amostra em amostras de teste e de análise (ver discussão na próxima seção).\nA amostra de 100 observações, quando particionada em\namostras de análise e de teste de 60 e 40 respectivamente,\nmal atende à proporção mínima de 5 para 1 de observa-\nções para variáveis independentes (60 observações para\n13 variáveis independentes em potencial) sugerida para\na amostra de análise. Apesar de essa proporção crescer\npara quase 8 para 1 se a amostra não for dividida, consi-\ndera-se mais importante validar os resultados do que au-\nmentar o número de observações na amostra de análise.\nOs dois grupos de 26 e 34 na amostra de estimação\ntambém excedem o tamanho mínimo de 20 observações\npor grupo. Finalmente, os dois grupos são sufi cientemen-\nte comparáveis em tamanho para não impactar adversa-\nmente os processos de estimação ou de classifi cação.\n\n\nDivisão da amostra\nA discussão anterior enfatizou a necessidade de validar\na função discriminante dividindo a amostra em duas par-\ntes, uma usada para estimação e a outra para validação.\nEm qualquer momento em que uma amostra de teste é\nempregada, o pesquisador deve garantir que os tamanhos\nde amostra resultantes sejam sufi cientes para embasar o\nnúmero de preditores incluídos na análise.\nA base de dados HBAT tem 100 observações; foi deci-\ndido que uma amostra de teste de 40 observações seria\nsufi ciente para fi ns de validação. Essa partição deixaria\nainda 60 observações para a estimação da função discri-\nminante. Além disso, os tamanhos relativos de grupos na\namostra de estimação (26 e 34 nos dois grupos) permiti-\nriam a estimação sem complicações devidas a diferenças\nconsideráveis de tamanhos de grupos.\nÉ importante garantir aleatoriedade na seleção da\namostra de validação, de modo que qualquer ordenação\ndas observações não afete os processos de estimação e de\nvalidação.\n\n\n\nEstágio 3: Suposições da análise discriminante\nAs principais suposições inerentes à análise discrimi-\nnante envolvem a formação da variável estatística ou\nfunção discriminante (normalidade, linearidade e mul-\nticolinearidade) e a estimação da função discriminan-\nte (matrizes de variância e covariância iguais). Como\nexaminar as variáveis independentes quanto à norma-\nlidade, linearidade e multicolinearidade é explicado\nno Capítulo 2. Para fi ns de nossa ilustração da análise\ndiscriminante, essas suposições são atendidas em níveis\naceitáveis.\nA maioria dos programas estatísticos tem um ou mais\nteste(s) estatístico(s) para a suposição de matrizes de co-\nvariância ou dispersão iguais abordada no Capítulo 2. O\nmais comum é o teste M de Box (para mais detalhes, ver\nCapítulo 2).\nNeste exemplo de dois grupos, a signifi cância de dife-\nrenças nas matrizes de covariância entre os dois gru-\npos é de 0,011. Mesmo que a signifi cância seja menor\nque 0,05 (nesse teste o pesquisador procura por valo-\nres acima do nível desejado de signifi cância), a sensibi-\nlidade do teste a outros fatores que não sejam apenas\ndiferenças de covariância (p.ex., normalidade das va-\nriáveis e tamanho crescente da amostra) faz desse um\nnível aceitável.\nNenhuma ação corretiva adicional faz-se necessária\nantes que a estimação da função discriminante possa ser\nrealizada.\nvolver estratégias para remediar quaisquer defi ciências\npercebidas e desenvolver estratégias diferenciadas para\nacomodar as percepções distintas.\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 253\n\n\n\nEstágio 4: Estimação do modelo\n\n\ndiscriminante e avaliação do ajuste geral\nO pesquisador tem a escolha de duas técnicas de estima- ção (simultânea versus stepwise ) para determinar as va- riáveis independentes incluídas na função discriminante. Uma vez que a técnica de estimação é escolhida, o pro- cesso determina a composição da função discriminante sujeita à exigência de signifi cância estatística especifi cada pelo pesquisador.\nO principal objetivo dessa análise é identifi car o con-\njunto de variáveis independentes (percepções HBAT)\nque diferencia ao máximo entre os dois grupos de\nclientes. Se o conjunto de variáveis de percepções fos-\nse menor ou a meta fosse simplesmente determinar\nas capacidades discriminantes do conjunto inteiro de\nvariáveis de percepção, sem se preocupar com o im-\npacto de qualquer percepção individual, então a abor-\ndagem simultânea de inclusão de todas as variáveis\ndiretamente na função discriminante seria empregada.\nMas neste caso, mesmo com o conhecimento de mul-\nticolinearidade entre as variáveis de percepção vista\nno desempenho da análise fatorial (ver Capítulo 3), a\nabordagem stepwise é considerada mais adequada. De-\nvemos observar, porém, que multicolinearidade pode\nimpactar sobre quais variáveis entram na função discri-\nminante e assim exigir particular atenção no processo\nde interpretação.\n\nAvaliação de diferenças de grupos\nIniciemos nossa avaliação da análise discriminante de dois grupos examinando a Tabela 5-5, que mostra as mé- dias de grupos para cada uma das variáveis independen- tes, com base nas 60 observações que constituem a amos- tra de análise. Para identifi car quais das cinco variáveis, mais alguma das demais, melhor discrimina entre os grupos, devemos estimar a função discriminante.\n\n\nEstimação da função discriminante\nO procedimento stepwise começa com todas as variáveis\nexcluídas do modelo e então seleciona a variável que:\n1. Mostra diferenças estatisticamente signifi cantes nos grupos (0,05 ou menos exigido para entrada) 2. Dá a maior distância de Mahalanobis ( D^2 ) entre os grupos Este processo continua a incluir variáveis na função discriminante desde que elas forneçam discriminação adi- cional estatisticamente signifi cante entre os grupos além daquelas diferenças já explicadas pelas variáveis na fun- ção discriminante.Esta técnica é semelhante ao processo stepwise em regressão múltipla (ver Capítulo 4), que adi- ciona variáveis com aumentos signifi cantes na variância explicada da variável dependente. Além disso, em casos nos quais duas ou mais variáveis entram no modelo, as va- riáveis já presentes são avaliadas para possível remoção. Uma variável pode ser removida se existir elevada multi- colinearidade entre ela e as demais variáveis independen- tes incluídas, de modo que sua signifi cância fi ca abaixo do nível para remoção (0,10).\nAo estabelecer o perfi l dos dois grupos, podemos pri-\nmeiramente identifi car cinco variáveis com as maio-\nres diferenças nas médias de grupo ( X 6 , X 11 , X 12 , X 13 , e\nX 17 ). A Tabela 5-5 também exibe o lambda de Wilks e a\nANOVA univariada utilizada para avaliar a signifi cân-\ncia entre médias das variáveis independentes para os\ndois grupos. Esses testes indicam que as cinco variáveis\nde percepção são também as únicas com diferenças uni-\nvariadas signifi cantes entre os dois grupos. Finalmente,\nos valores D^2 de Mahalanobis mínimos são também da-\ndos. Este valor é importante porque ele é a medida usa-\nda para selecionar variáveis para entrada no processo\nde estimação stepwise. Como apenas dois grupos estão\nenvolvidos, o maior valor D^2 tem também a diferença\nentre grupos mais signifi cante (note que o mesmo fato\nnão ocorre necessariamente com três ou mais grupos,\nnos quais grandes diferenças entre dois grupos quais-\nquer podem não resultar nas maiores diferenças gerais\nem todos os grupos, como será mostrado no exemplo\nde três grupos).\nO exame das diferenças de grupos leva à identifi ca-\nção de cinco variáveis de percepção ( X 6 , X 11 , X 12 , X 13 e\nX 17 ) como o conjunto mais lógico de candidatos a entra-\nrem na análise discriminante. Essa considerável redução\na partir do conjunto maior de 13 variáveis de percepção\nreforça a decisão de se usar um processo de estimação\nstepwise.\nEstimação stepwise : adição da primeira variável\nX 13. A partir de nossa revisão de diferenças de gru-\npos, percebemos que X 13 tinha a maior diferença signi-\nfi cante entre grupos e o maior D^2 de Mahalanobis (ver\nTabela 5-5). Logo, X 13 entra como a primeira variável\nno procedimento stepwise (ver Tabela 5-6). Como ape-\nnas uma variável entra no modelo discriminante neste\nmomento, os níveis de signifi cância e as medidas de\ndiferenças de grupos coincidem com aqueles dos testes\nunivariados.\nDepois que X 13 entra no modelo, as demais variáveis\nsão avaliadas com base em suas habilidades discriminan-\ntes incrementais (diferenças de médias de grupos depois\n( Continua )\n\n\n254 Análise Multivariada de Dados\nTABELA 5-5 Estatísticas descritivas de grupo e testes de igualdade para a amostra de estimação na análise discriminante de dois grupos\nMédias de grupos da variá-\nvel dependente: X 4 Região\nTeste de igualdade de médias de\ngrupos*\nD^2 de Mahalanobis\nmínimo\nVariáveis independentes\nGrupo 0:\nEUA/Améri-\nca do Norte\n( n = 26)\nGrupo 1:\nFora da Amé-\nrica do Norte\n( n = 34)\nLambda\nde Wilks Valor F\nSignifi cân-\ncia D^2 mínimo\nEntre\ngrupos\nX 6 Qualidade do produto 8,527 7,297 0,801 14,387 0,000 0,976 0 e 1\nX 7 Atividades de Comércio eletrônico 3,388 3,626 0,966 2,054 0,157 0,139 0 e 1\nX 8 Suporte técnico 5,569 5,050 0,973 1,598 0,211 0,108 0 e 1\nX 9 Solução de reclamação 5,577 5,253 0,986 0,849 0,361 0,058 0 e 1\nX 10 Anúncio 3,727 3,979 0,987 0,775 0,382 0,053 0 e 1\nX 11 Linha do produto 6,785 5,274 0,695 25,500 0,000 1,731 0 e 1\nX 12 Imagem da equipe de venda 4,427 5,238 0,856 9,733 0,003 0,661 0 e 1\nX 13 Preço competitivo 5,600 7,418 0,645 31,992 0,000 2,171 0 e 1\nX 14 Garantia e reclamações 6,050 5,918 0,992 0,453 0,503 0,031 0 e 1\nX 15 Novos produtos 4,954 5,276 0,990 0,600 0,442 0,041 0 e 1\nX 16 Encomenda e cobrança 4,231 4,153 0,999 0,087 0,769 0,006 0 e 1\nX 17 Flexibilidade de preço 3,631 4,932 0,647 31,699 0,000 2,152 0 e 1\nX 18 Velocidade de entrega 3,873 3,794 0,997 0,152 0,698 0,010 0 e 1\n* Lambda de Wilks (estatística U ) e razão F univariada com 1 e 58 graus de liberdade.\nque a variância associada com X 13 é removida). Nova-\nmente, variáveis com níveis de signifi cância maiores que\n0,05 são eliminadas de consideração para entrada no\npróximo passo.\nO exame das diferenças univariadas mostradas na\nTabela 5-5 identifi ca X 17 (Flexibilidade de preço) como\na variável com a segunda maior diferença. No entanto,\no processo stepwise não utiliza esses resultados univa-\nriados quando a função discriminante tem uma ou mais\nvariáveis. Ele calcula os valores D^2 e os testes de signi-\nfi cância estatística de diferenças de grupos depois que o\nefeito das variáveis nos modelos é removido (neste caso\napenas X 13 está no modelo).\nComo mostrado na última parte da Tabela 5-6, três\nvariáveis ( X 6 , X 11 e X 17 ) claramente atendem ao crité-\nrio de nível de signifi cância de 0,05 para consideração no\npróximo estágio. X 17 permanece como o próximo melhor\ncandidato a entrar no modelo porque ela tem o maior\nD^2 de Mahalanobis (4,300) e o maior valor F a entrar.\nNão obstante, outras variáveis (p.ex., X 11 ) têm substan-\nciais reduções em seu nível de signifi cância e no D^2 de\nMahalanobis em relação ao que se mostra na Tabela 5-5\ndevido à variável única no modelo ( X 13 ).\nEstimação stepwise : adição da segunda variável X 17. No\npasso 2 (ver Tabela 5-7), X 17 entra no modelo, conforme\nesperado. O modelo geral é signifi cante ( F = 31,129) e\nmelhora a discriminação entre grupos, como evidencia-\ndo pela diminuição no lambda de Wilks de 0,645 para\n0,478. Além disso, o poder discriminante de ambas as va-\nriáveis incluídas nesse ponto é também estatisticamente\nsignifi cante (valores F de 20,113 para X 13 e 19,863 para\nX 17 ). Com ambas as variáveis estatisticamente signifi can-\ntes, o procedimento se dirige para o exame das variáveis\nfora da equação na busca de potenciais candidatos para\ninclusão na função discriminante com base em sua dis-\ncriminação incremental entre os grupos.\nX 11 é a próxima variável a atender às exigências para\ninclusão, mas seu nível de signifi cância e sua habilida-\nde discriminante foram reduzidos substancialmente por\nconta da multicolinearidade com X 13 e X 17 já na função\ndiscriminante. Mais notável ainda é o considerável au-\nmento no D^2 de Mahalanobis em relação aos resultados\nunivariados nos quais cada variável é considerada sepa-\nradamente. No caso de X 11, o valor D^2 mínimo aumenta\nde 1,731 (ver Tabela 5-5) para 5,045 (Tabela 5-7), o que\nindica um espalhamento e uma separação dos grupos\npor conta de X 13 e X 17 já na função discriminante. Note\nque X 18 é quase idêntica em poder discriminante rema-\nnescente, mas X 11 entrará no terceiro passo devido à sua\npequena vantagem.\nEstimação stepwise : adição de uma terceira variável\nX 11. A Tabela 5-8 revê os resultados do terceiro passo\ndo processo stepwise , onde X 11 entra na função discri-\nminante. Os resultados gerais ainda são estatisticamente\nsignifi cantes e continuam a melhorar na discriminação,\ncomo evidenciado pela diminuição no valor lambda de\n( Continua )\n( Continuação )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 255\nTABELA 5-6 Resultados do passo 1 da análise discriminante stepwise de dois grupos\nAjuste geral do modelo\nValor Valor F Graus de liberdade Signifi cância\nLambda de Wilks 0,645 31,992 1,58 0,000\nVariáveis adicionadas/removidas no passo 1\nF\nVariável adicionada D^2 mínimo Valor Signifi cância Entre grupos\nX 13 Preços competitivos 2,171 31,992 0,000 0 e 1\nNota: Em cada passo, a variável que maximiza a distância de Mahalanobis entre os dois grupos mais próximos é adicionada.\nVariáveis na análise após o passo 1\nVariável Tolerância F para remover D^2 Entre grupos\nX 13 Preços competitivos 1,000 31,992\nVariáveis fora da análise após o passo 1\nVariável Tolerância Tolerância mínima F para entrar D^2 mínimo Entre grupos\nX 6 Qualidade de produto 0,965 0,965 4,926 2,699 0 e 1 X 7 Atividades de comércio eletrônico 0,917 0,917 0,026 2,174 0 e 1 X 8 Suporte técnico 0,966 0,966 0,033 2,175 0 e 1 X 9 Solução de reclamação 0,844 0,844 1,292 2,310 0 e 1 X 10 Anúncio 0,992 0,992 0,088 2,181 0 e 1 X 11 Linha de produto 0,849 0,849 6,076 2,822 0 e 1 X 12 Imagem da equipe de venda 0,987 0,987 3,949 2,595 0 e 1 X 14 Garantia e reclamações 0,918 0,918 0,617 2,237 0 e 1 X 15 Novos produtos 1,000 1,000 0,455 2,220 0 e 1 X 16 Encomenda e cobrança 0,836 0,836 3,022 2,495 0 e 1 X 17 Flexibilidade de preço 1,000 1,000 19,863 4,300 0 e 1 X 18 Velocidade de entrega 0,910 0,910 1,196 2,300 0 e 1\nTeste de signifi cância de diferenças de grupos após o passo 1a EUA/América do Norte Fora da América do Norte F 31,992 Sig. 0,000 a1,58 graus de liberdade\nWilks (de 0,478 para 0,438). Note, porém, que a queda\nfoi muito menor do que aquela encontrada quando a\nsegunda variável ( X 17 ) foi adicionada à função discrimi-\nnante. Com X 13 , X 17 e X 11 estatisticamente signifi cantes,\no procedimento se dirige para a identifi cação de candi-\ndatos remanescentes para inclusão.\nComo visto na última parte da Tabela 5-8, nenhuma\ndas 10 variáveis independentes que sobraram passam\npelo critério de entrada de signifi cância estatística de\n0,05. Depois que X 11 entrou na equação, as duas variá-\nveis remanescentes que tinham diferenças univariadas\nsignifi cantes nos grupos ( X 6 e X 12 ) apresentam um po-\nder discriminatório adicional relativamente pequeno e\nnão atendem ao critério de entrada. Assim, o processo\nde estimação pára com as três variáveis ( X 13 , X 17 e X 11 )\nconstituindo a função discriminante.\nResumo do processo de estimação stepwise. A Tabela\n5-9 fornece os resultados gerais da análise discriminan-\nte stepwise depois que todas as variáveis signifi cantes\nforam incluídas na estimação da função discriminante.\nEssa tabela resumo descreve as três variáveis ( X 11 , X 13 e\nX 17 ) que são discriminadores signifi cantes com base em\nseus lambda de Wilks e nos valores mínimos de D^2 de\nMahalanobis.\nDiversos resultados distintos são dados abordando\ntanto o ajuste geral do modelo quanto o impacto de va-\nriáveis específi cas.\n( Continuação )\n( Continua )\n\n\n256 Análise Multivariada de Dados\n\nAs medidas multivariadas de ajuste geral do modelo são relatadas sob a legenda “Funções discriminantes canônicas”. Observe que a função discriminante é al- tamente signifi cante (0,000) e retrata uma correlação canônica de 0,749. Interpretamos essa correlação ele- vando-a ao quadrado (0,749)^2 = 0,561. Logo, 56,1% da variância na variável dependente ( X 4 ) pode ser explica- da por este modelo, o qual inclui apenas três variáveis independentes.\nOs coefi cientes padronizados da função discriminante são fornecidos, mas são menos preferidos para fi ns de interpretação do que as cargas discriminantes. Os coe- fi cientes discriminantes não-padronizados são usados para calcular os escores Z discriminantes que podem ser empregados na classifi cação.\n\nTABELA 5-7 Resultados do passo 2 da análise discriminante stepwise de dois grupos\nAjuste geral do modelo\nValor Valor F Graus de liberdade Signifi cância\nLambda de Wilks 0,478 31,129 2,57 0,000\nVariáveis adicionadas/removidas no passo 2\nF\nVariável adicionada D^2 mínimo Valor Signifi cância Entre grupos\nX 13 Flexibilidade de preço 4,300 31,129 0,000 0 e 1\nNota: Em cada passo, a variável que maximiza a distância de Mahalanobis entre os dois grupos mais próximos é adicionada.\nVariáveis na análise após o passo 2\nVariável Tolerância F para remover D^2 Entre grupos\nX 13 Preços competitivos 1,000 20,113 2,152 0 e 1\nX 17 Flexibilidade de preço 1,000 19,863 2,171 0 e 1\nVariáveis fora da análise após o passo 2\nVariável Tolerância Tolerância mínima F para entrar D^2 mínimo Entre grupos\nX 6 Qualidade de produto 0,884 0,884 0,681 4,400 0 e 1\nX 7 Atividades de comércio eletrônico 0,804 0,804 2,486 4,665 0 e 1\nX 8 Suporte técnico 0,966 0,966 0,052 4,308 0 e 1\nX 9 Solução de reclamação 0,610 0,610 1,479 4,517 0 e 1\nX 10 Anúncio 0,901 0,901 0,881 4,429 0 e 1\nX 11 Linha de produto 0,848 0,848 5,068 5,045 0 e 1\nX 12 Imagem da equipe de venda 0,944 0,944 0,849 4,425 0 e 1\nX 14 Garantia e reclamações 0,916 0,916 0,759 4,411 0 e 1\nX 15 Novos produtos 0,986 0,986 0,017 4,302 0 e 1\nX 16 Encomenda e cobrança 0,625 0,625 0,245 4,336 0 e 1\nX 18 Velocidade de entrega 0,519 0,519 4,261 4,927 0 e 1\nTeste de signifi cância de diferenças de grupos após o passo 2a\nEUA/América do Norte\nFora da América do Norte F 32,129\nSig. 0,000\na2,57 graus de liberdade\n\nAs cargas discriminantes são relatadas sob a legenda “Matriz estrutural” e são ordenadas da maior para a menor em termos de tamanho da carga. As cargas são discutidas depois na fase de interpretação (estágio 5).\nOs coefi cientes da função de classifi cação, também conhecidos como funções discriminantes lineares de Fisher, são utilizados na classifi cação e discutidos poste- riormente.\nCentróides de grupo são também relatados, e eles re- presentam a média dos escores individuais da função discriminante para cada grupo. Centróides fornecem uma medida resumo da posição relativa de cada grupo nas funções discriminantes. Neste caso, a Tabela 5-9 revela que o centróide de grupo para as fi rmas nos EUA/América do Norte (grupo 0) é –1,273, enquanto ( Continua )\n\n( Continuação )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 257\nOs resultados do modelo geral são aceitáveis com base em signifi cância estatística e prática. No entanto, antes de proceder com uma interpretação dos resultados, o pesqui- sador precisa avaliar a precisão de classifi cação e exami- nar os resultados caso a caso.\n\n\nAvaliação da precisão de classifi cação\nCom o modelo geral estatisticamente signifi cante e expli- cando 56% da variação entre os grupos (ver a discussão\nanterior e a Tabela 5-9), passamos para a avaliação de\nprecisão preditiva da função discriminante. Em tal pro-\ncesso devemos completar três tarefas:\n1. Calcular o escore de corte, o critério no qual o escore Z dis- criminante de cada observação é julgado para determinar em qual grupo ela deve ser classifi cada. 2. Classifi car cada observação e desenvolver as matrizes de classifi cação para as amostras de análise e de teste. 3. Avaliar os níveis de precisão preditiva a partir das ma- trizes de classifi cação quanto a signifi cância estatística e prática.\nApesar de o exame da amostra de teste e de sua preci-\nsão preditiva ser realmente feito no estágio de validação,\nos resultados são discutidos agora para facilitar a compa-\nração entre as amostras de estimação e de teste.\nTABELA 5-8 Resultados do passo 3 da análise discriminante stepwise de dois grupos\nAjuste geral do modelo\nValor Valor F Graus de liberdade Signifi cância\nLambda de Wilks 0,438 23,923 3, 56 0,000\nVariáveis adicionadas/removidas no passo 3\nF\nD^2 mínimo Valor Signifi cância Entre grupos\nX 11 Linha de produto 5,045 23,923 0,000 0 e 1\nNota: Em cada passo, a variável que maximiza a distância de Mahalanobis entre os dois grupos mais próximos é adicionada.\nVariáveis na análise após o passo 3\nVariável Tolerância F para remover D^2 Entre grupos\nX 13 Preços competitivos 0,849 7,258 4,015 0 e 1\nX 17 Flexibilidade de preço 0,999 18,416 2,822 0 e 1\nX 11 Linha de produto 0,848 5,068 4,300 0 e 1\nVariáveis fora da análise após o passo 3\nVariável Tolerância Tolerância mínima F para entrar D^2 mínimo Entre grupos\nX 6 Qualidade de produto 0,802 0,769 0,019 5,048 0 e 1\nX 7 Atividades de comércio eletrônico 0,801 0,791 2,672 5,482 0 e 1\nX 8 Suporte técnico 0,961 0,832 0,004 5,046 0 e 1\nX 9 Solução de reclamação 0,233 0,233 0,719 5,163 0 e 1\nX 10 Anúncio 0,900 0,840 0,636 5,149 0 e 1\nX 12 Imagem da equipe de venda 0,931 0,829 1,294 5,257 0 e 1\nX 14 Garantia e reclamações 0,836 0,775 2,318 5,424 0 e 1\nX 15 Novos produtos 0,981 0,844 0,076 5,058 0 e 1\nX 16 Encomenda e cobrança 0,400 0,400 1,025 5,213 0 e 1\nX 18 Velocidade de entrega 0,031 0,031 0,208 5,079 0 e 1\nTeste de signifi cância de diferenças de grupos após o passo 3a\nEUA/América do Norte\nFora da América do Norte F 23,923\nSig. 0,000\na3,56 graus de liberdade\no centróide para as fi rmas fora da América do Norte\n(grupo 1) é 0,973. Para mostrar que a média geral é 0,\nmultiplique o número em cada grupo por seu centróide\ne some ao resultado (p.ex., 26 × –1,273 \" 34 × 0,973\n! 0,0).\n( Continuação )\n\n\n258 Análise Multivariada de Dados\nCálculo do escore de corte. O pesquisador deve primei- ramente determinar como as probabilidades a priori de classifi cação são determinadas, ou com base nos tama- nhos reais dos grupos (assumindo que eles são represen- tativos da população), ou especifi cadas pelo pesquisador, sendo que mais freqüentemente são estabelecidas como iguais em uma postura conservadora do processo de clas- sifi cação.\nTABELA 5-9 Estatísticas resumo para análise discriminante de dois grupos\nAjuste geral do modelo: funções discriminantes canônicas\nPercentual de variância\nFunção Autovalor Função % Cumulativo %\nCorrelação\ncanônica\nLambda de\nWilks\nQui-qua-\ndrado df Signifi cância\n1 1,282 100 100 0,749 0,438 46,606 3 0,000\nFunção discriminante e coefi cientes da função de classifi cação\nFunções discriminantes Funções de classifi cação\nVariáveis independentes Não-padronizado Padronizado\nGrupo 0: EUA/América\ndo Norte\nGrupo 1: Fora da América\ndo Norte\nX 11 Linha de produto –0,363 –0,417 7,725 6,909\nX 13 Preços competitivos 0,398 0,490 6,456 7,349\nX 17 Flexibilidade de preço 0,749 0,664 4,231 5,912\nConstante –3,752 –52,800 –60,623\nMatriz estruturala\nVariáveis independentes Função 1\nX 13 Preços competitivos 0,656\nX 17 Flexibilidade de preço 0,653\nX 11 Linha de produto –0,586\nX 7 Atividades de comércio eletrônico* 0,429\nX 6 Qualidade de produto* –0,418\nX 14 Garantia e reclamações* –0,329\nX 10 Anúncio* 0,238\nX 9 Solução de reclamações* –0,181\nX 12 Imagem da equipe de venda* 0,164\nX 16 Encomenda e cobrança* –0,149\nX 8 Suporte técnico* –0,136\nX 18 Velocidade de entrega* –0,060\nX 15 Novos produtos* 0,041\n*Variável não usada na análise\nMédias de grupos (centróides) de funções discriminantes\nX 4 Região Função 1\nEUA/América do Norte –1,273\nFora da América do Norte 0,973\naCorrelações internas de grupos entre variáveis discriminantes e funções discriminantes canônicas padronizadas ordenadas por tamanho absoluto de correlação\nna função,\nNesta amostra de análise de 60 observações, sabemos\nque a variável dependente consiste em dois grupos, 26\nempresas localizadas nos EUA e 34 empresas fora do\npaís. Se não estamos certos de que as proporções da po-\npulação são representadas pela amostra, então devemos\nempregar probabilidades iguais. No entanto, como nos-\nsa amostra de empresas é aleatoriamente extraída, po-\ndemos estar razoavelmente certos de que essa amostra\nrefl ete as proporções da população. Logo, essa análise\ndiscriminante usa as proporções da amostra para especi-\nfi car as probabilidades a priori para fi ns de classifi cação.\nTendo especifi cado as probabilidades a priori , o escore\nde corte ótimo pode ser calculado. Como nesta situação\nos grupos são considerados representativos, o cálculo\nse torna uma média ponderada dos dois centróides de\ngrupos:\n( Continua )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 259\nClassifi cação de observações e construção de matrizes de classifi cação. Uma vez que o escore de corte tenha sido calculado, cada observação pode ser classifi cada compa- rando seu escore discriminante com o de corte.\nO procedimento para classifi car empresas com o escore\nde corte ótimo é o seguinte:\n\nClassifi que uma empresa como sendo do grupo 0 (Esta- dos Unidos/América do Norte) se seu escore discrimi- nante for menor que –0,2997.\nClassifi que uma empresa como sendo do grupo 1 (Fora dos Estados Unidos) se seu escore discriminante for maior que –0,2997. Matrizes de classifi cação para as observações nas amostras de análise e de validação foram calculadas, e os resultados são exibidos na Tabela 5-10. A amostra de análise tem 86,7% de precisão de previsão, que é ligeira- mente maior que a precisão de 85% da amostra de teste, como já antecipado. Além disso, a amostra que passou por validação cruzada conseguiu uma precisão preditiva de 83,3%.\n\nAvaliação da precisão de classifi cação atingida. Ainda que todas as medidas de precisão de classifi cação sejam\nbastante altas, o processo de avaliação requer uma com-\nparação com a precisão de classifi cação em uma série de\nmedidas baseadas em chances. Essas medidas refl etem\na melhora do modelo discriminante quando se compara\ncom a classifi cação de indivíduos sem o uso da função dis-\ncriminante. Sabendo-se que a amostra geral é de 100 ob-\nservações e que os grupos de teste/validação são menores\ndo que 20, usaremos a amostra geral para estabelecer os\npadrões de comparação.\nA primeira medida é o critério de chance proporcio-\nnal, o qual considera que os custos da má classifi cação são\niguais (ou seja, queremos identifi car os membros de cada\ngrupo igualmente bem). O critério de chance proporcio-\nnal é:\nC PRO! p^2 \" (1 $ p )^2\nonde\nC PRO = critério de chance proporcional\np = proporção de empresas no grupo 0\n1 – p = proporção de empresas no grupo 1\nO grupo de clientes localizados nos Estados Unidos\n(grupo 0) constitui 39,0% da amostra de análise (39/100),\ncom o segundo grupo representando clientes localizados\nfora dos Estados Unidos (grupo 1) formando os 61,0%\nrestantes. O valor calculado de chance proporcional é de\n0,524 (0,390^2 \" 0,610^2! 0,524).\nO critério de chance máxima é simplesmente o per-\ncentual corretamente classifi cado se todas as observações\nfossem colocadas no grupo com a maior probabilidade\nde ocorrência. Ele refl ete nosso padrão mais conserva-\nSubstituindo os valores apropriados na fórmula, po-\ndemos obter o escore de corte crítico (assumindo custos\niguais de má classifi cação) de Z CS^! $0,2997.\nTABELA 5-10 Resultados de classifi cação para análise discriminante de dois grupos\nResultados de classifi cação a, b, c^\nPertinência prevista em grupo\nAmostra Grupo real EUA/América do Norte Fora da América do Norte Total\nAmostra de estimação EUA/América do Norte 25 1 26\n96,2% 3,8%\nFora da América do Norte 7 27 34\n20,6% 79,4%\nAmostra de validação cruzadad EUA/América do Norte 24 2 26\n92,3 7,7\nFora da América do Norte 8 26 34\n23,5 76,5\nAmostra de teste EUA/América do Norte 9 4 13\n69,2 30,8\nFora da América do Norte 2 25 27\n7,4 92,6\nab86,7% dos casos originais selecionados e agrupados (amostra de estimação) corretamente classifi cados.\nc85,0% dos casos originais não-selecionados e agrupados (amostra de validação) corretamente classifi cados.\nd83,3% dos casos selecionados validados por cruzamento corretamente classifi cados.\nValidação cruzada é feita somente para aqueles casos da análise (amostra de estimação). Em validação cruzada, cada caso é classifi cado pelas funções\nderivadas de todos os casos distintos daquele.\n( Continuação )\n\n\n260 Análise Multivariada de Dados\ndor e assume nenhuma diferença no custo de uma má classifi cação.\nComo o grupo 1 (clientes fora dos Estados Unidos) é o\nmaior, com 61% da amostra, estaríamos corretos 61,0%\ndo tempo se designássemos todas as observações a esse\ngrupo. Se escolhemos o critério de chance máxima como\no padrão de avaliação, nosso modelo deve ter um de-\nsempenho superior a 61% de precisão de classifi cação\npara ser aceitável.\nPara tentar garantir signifi cância prática, a precisão de classifi cação alcançada deve exceder o padrão de compa- ração escolhido em 25%. Assim, devemos selecionar um padrão de comparação, calcular o valor de referência e comparar com a razão de sucesso conseguida.\nTodos os níveis de precisão de classifi cação (razões\nde sucesso) excedem 85%, o que é consideravelmente\nmaior do que o critério de chance proporcional de 52,4%\nou mesmo do critério de chance máxima de 61,0%.\nTodas as três razões também excedem o valor de refe-\nrência sugerido desses valores (padrão de comparação\nmais 25%), que neste caso é de 65,5% (52,4% × 1,25!\n65,5%) para a chance proporcional e 76,3% (61,0% ×\n1,25! 76,3%) para a chance máxima. Em todos os casos\n(amostra de análise, de teste e de validação cruzada), os\nníveis de precisão de classifi cação são substancialmente\nmaiores do que os valores de referência, indicando um\nnível aceitável de precisão de classifi cação. Além disso,\na razão de sucesso para grupos individuais é considerada\nadequada também.\nA medida fi nal de precisão de classifi cação é o Q de Press, que é uma medida estatística que compara precisão de classifi cação com um processo aleatório.\nA partir da discussão anterior, o cálculo para a amostra\nde estimação é\nE o cálculo para a amostra de validação é\nEm ambos os casos, os valores calculados excedem o\nvalor crítico de 6,63. Assim, a precisão de classifi cação para\na amostra de análise e, mais importante, para a amostra de\nvalidação excede em um nível estatisticamente signifi cante\na precisão esperada de classifi cação por chance.\nO pesquisador sempre deve lembrar de tomar cuidado\nna aplicação de uma amostra de validação com pequenos\nconjuntos de dados. Nesse caso, a pequena amostra de 40\npara validação foi adequada, mas tamanhos maiores são\nsempre mais desejáveis.\n\n\nDiagnósticos por casos\nAlém dos resultados gerais, podemos examinar as obser-\nvações individuais no que se refere à precisão preditiva e\nidentifi car especifi camente os casos mal classifi cados. Nes-\nta operação, podemos encontrar os casos específi cos mal\nclassifi cados para cada grupo nas amostras de análise e de\nteste e ainda promover uma análise adicional na qual se\ndetermine o perfi l dos casos mal classifi cados.\nA Tabela 5-11 contém as previsões de grupo para as\namostras de análise e de validação e nos permite identifi -\ncar os casos específi cos para cada tipo de má classifi cação\ntabulada nas matrizes de classifi cação (ver Tabela 5-10).\nPara a amostra de análise, os sete clientes localizados\nfora dos Estados Unidos que foram mal classifi cados no\ngrupo de clientes na América do Norte podem ser iden-\ntifi cados como os casos 3, 94, 49, 64, 24, 53 e 32. Ana-\nlogamente, o único cliente dos Estados Unidos que foi\nmal classifi cado é identifi cado como caso 43. Um exame\nsemelhante pode ser feito para a amostra de validação.\nAssim que os casos mal classifi cados são identifi ca-\ndos, uma análise adicional pode ser realizada para com-\npreender as razões dessa má classifi cação. Na Tabela\n5-12, os casos mal classifi cados são combinados a partir\ndas amostras de análise e de validação e então compara-\ndos com os casos corretamente classifi cados. O objetivo\né identifi car diferenças específi cas nas variáveis indepen-\ndentes que possam identifi car novas variáveis a serem\nacrescentadas ou características em comum que devam\nser consideradas.\nOs cinco casos (tanto na amostra de análise quanto na de\nvalidação) mal classifi cados entre os clientes dos Estados\nUnidos (grupo 0) têm diferenças signifi cantes em duas\ndas três variáveis independentes na função discriminante\n( X 13 e X 17 ), bem como em uma variável não incluída na\nfunção discriminante ( X 6 ). Para tal variável, o perfi l dos\ncasos mal classifi cados não é semelhante ao seu grupo\ncorreto; logo, não ajuda na classifi cação. Analogamente,\nos nove casos mal classifi cados do grupo 1 (fora dos Es-\ntados Unidos) mostram quatro diferenças signifi cantes\n( X 6 , X 11 , X 13 e X 17 ), mas apenas X 6 não está na função\ndiscriminante. Podemos ver que aqui X 6 funciona contra\na precisão de classifi cação porque os casos mal classifi -\ncados são mais semelhantes ao grupo incorreto do que\nao outro.\n( Continua )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 261\nTABELA 5-11 Previsões de grupo para casos individuais na análise discriminante de dois grupos\nIdentifi cação\ndo caso Grupo real\nEscore Z\ndiscriminante Grupo previsto\nIdentifi cação\nde caso Grupo real\nEscore Z\ndiscriminante Grupo previsto\nAmostra de análise\n72 0 –2,10690 0 24 1 –0,60937 0 14 0 –2,03496 0 53 1 –0,45623 0 31 0 –1,98885 0 32 1 –0,36094 0 54 0 –1,98885 0 80 1 –0,14687 1 27 0 –1,76053 0 38 1 –0,04489 1 29 0 –1,76053 0 60 1 –0,04447 1 16 0 –1,71859 0 65 1 0,09785 1 61 0 –1,71859 0 35 1 0,84464 1 79 0 –1,57916 0 1 1 0,98896 1 36 0 –1,57108 0 4 1 1,10834 1 98 0 –1,57108 0 68 1 1,12436 1 58 0 –1,48136 0 44 1 1,34768 1 45 0 –1,33840 0 17 1 1,35578 1 2 0 –1,29645 0 67 1 1,35578 1 52 0 –1,29645 0 33 1 1,42147 1 50 0 –1,24651 0 87 1 1,57544 1 47 0 –1,20903 0 6 1 1,58353 1 88 0 –1,10294 0 46 1 1,60411 1 11 0 –0,74943 0 12 1 1,75931 1 56 0 –0,73978 0 69 1 1,82233 1 95 0 –0,73978 0 86 1 1,82233 1 81 0 –0,72876 0 10 1 1,85847 1 5 0 –0,60845 0 30 1 1,90062 1 37 0 –0,60845 0 15 1 1,91724 1 63 0 –0,38398 0 92 1 1,97960 1 43 0 0,23553 1 7 1 2,09505 1 3 1 –1,65744 0 20 1 2,22839 1 94 1 –1,57916 0 8 1 2,39938 1 49 1 –1,04667 0 100 1 2,62102 1 64 1 –0,67406 0 48 1 2,90178 1\nAmostra de teste\n23 0 22,38834 0 25 1 1,47048 1 93 0 –2,03496 0 18 1 1,60411 1 59 0 –1,20903 0 73 1 1,61002 1 85 0 –1,10294 0 21 1 1,69348 1 83 0 –1,03619 0 90 1 1,69715 1 91 0 –0,89292 0 97 1 1,70398 1 82 0 –0,74943 0 40 1 1,75931 1 76 0 –0,72876 0 77 1 1,86055 1 96 0 –0,57335 0 28 1 1,97494 1 13 0 0,13119 1 71 1 2,22839 1 89 0 0,51418 1 19 1 2,28652 1 42 0 0,63440 1 57 1 2,31456 1 78 0 0,63440 1 9 1 2,36823 1 22 1 –2,73303 0 41 1 2,53652 1 74 1 –1,04667 0 26 1 2,59447 1 51 1 0,09785 1 70 1 2,59447 1 62 1 0,94702 1 66 1 2,90178 1 75 1 0,98896 1 34 1 2,97632 1 99 1 1,13130 1 55 1 2,97632 1 84 1 1,30393 1 39 1 3,21116 1\n\n\n262 Análise Multivariada de Dados\nPesquisadores devem examinar os padrões em ambos os grupos com o objetivo de entender as características comuns a eles em uma tentativa de defi nir os motivos para a má classifi cação.\n\n\n\nEstágio 5: Interpretação dos resultados\nApós estimar a função, a próxima fase é a interpretação. Este estágio envolve o exame da função para determinar\na importância relativa de cada variável independente na\ndiscriminação entre os grupos, interpretar a função dis-\ncriminante com base nas cargas discriminantes, e então\nfazer o perfi l de cada grupo sobre o padrão de valores\nmédios para variáveis identifi cadas como discriminadoras\nimportantes.\n\nIdentifi cação de variáveis discriminantes importantes\nComo anteriormente discutido, cargas discriminantes são\nconsideradas a medida mais adequada de poder discrimi-\nnante, mas consideraremos também os pesos discriminan-\ntes para fi ns de comparação. Os pesos discriminantes, na\nforma padronizada ou não, representam a contribuição\nde cada variável à função discriminante. Contudo, como\ndiscutiremos, multicolinearidade entre as variáveis inde-\npendentes pode causar impacto na interpretação usando\nsomente os pesos.\nTABELA 5-12 Perfi l de observações corretamente classifi cadas e mal classifi cadas na análise discriminante de dois grupos\nEscores médios Teste t\nVariável dependente:\nX 4 Região Variáveis (Grupo/Perfi l)\nCorretamente\nclassifi cada\nMal\nclassifi cada Diferença\nSignifi cância\nestatística\nEUA/América do\nNorte ( n! 34) ( n! 5)\nX 6 Qualidade do produto 8,612 9,340 –0,728 0,000 b\nX 7 Atividades de comércio eletrônico 3,382 4,380 –0,998 0,068 b\nX 8 Suporte técnico 5,759 5,280 0,479 0,487\nX 9 Solução de reclamação 5,356 6,140 –0,784 0,149\nX 10 Anúncio 3,597 4,700 –1,103 0,022\nX 11 Linha do produto a 6,726 6,540 0,186 0,345 b\nX 12 Imagem da equipe de venda 4,459 5,460 –1,001 0,018\nX 13 Preços competitivos a 5,609 8,060 –2,451 0,000\nX 14 Garantia e reclamações 6,215 6,060 0,155 0,677\nX 15 Novos produtos 5,024 4,420 0,604 0,391\nX 16 Encomenda e cobrança 4,188 4,540 –0,352 0,329\nX 17 Flexibilidade de preçoa 3,568 4,480 –0,912 0,000 b\nX 18 Velocidade de entrega 3,826 4,160 –0,334 0,027 b\nFora da América do\nNorte ( n! 52) ( n! 9)\nX 6 Qualidade do produto 6,906 9,156 –2,250 0,000\nX 7 Atividades de comércio eletrônico 3,860 3,289 0,571 0,159 b\nX 8 Suporte técnico 5,085 5,544 –0,460 0,423\nX 9 Solução de reclamação 5,365 5,822 –0,457 0,322\nX 10 Anúncio 4,229 3,922 0,307 0,470\nX 11 Linha do produto a 4,954 6,833 –1,879 0,000\nX 12 Imagem da equipe de venda 5,465 5,467 –1,282E$ 03 0,998\nX 13 Preços competitivos a 7,960 5,833 2,126 0,000\nX 14 Garantia e reclamações 5,867 6,400 –0,533 0,007 b\nX 15 Novos produtos 5,194 5,778 –0,584 0,291\nX 16 Encomenda e cobrança 4,267 4,533 –0,266 0,481\nX 17 Flexibilidade de preçoa 5,458 3,722 1,735 0,000\nX 18 Velocidade de entrega 3,881 3,989 –0,108 0,714\nNota a : Casos das amostras de análise e validação incluídos para a amostra total de 100.\nbVariáveis incluídas na função discriminante.\nTeste t executado com estimativas separadas de variância no lugar de uma estimativa coletiva, pois o teste Levene detectou diferenças signifi cantes nas variações\nentre os dois grupos.\nAs descobertas sugerem que os casos mal classifi -\ncados podem representar um terceiro grupo, pois eles\ncompartilham perfi s muito semelhantes nessas variáveis,\nmais do que acontece nos dois grupos existentes. A ad-\nministração pode analisar esse grupo quanto a variáveis\nadicionais ou avaliar se um padrão geográfi co entre os\ncasos mal classifi cados justifi ca um terceiro grupo.\n( Continuação )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 263\nCargas discriminantes são calculadas para cada va- riável independente, mesmo para aquelas que não estão incluídas na função discriminante. Assim, pesos* discri- minantes representam o único impacto de cada variável independente e não são restritas apenas ao impacto com- partilhado devido à multicolinearidade. Além disso, como elas são relativamente pouco afetadas pela multicolineari- dade, elas representam mais precisamente a associação de cada variável com o escore discriminante.\nA Tabela 5-13 contém o conjunto inteiro de medidas\ninterpretativas, incluindo pesos discriminantes padro-\nnizados e não-padronizados, cargas para a função dis-\ncriminante, lambda de Wilks e a razão F univariada. As\n13 variáveis independentes originais foram examinadas\npelo procedimento stepwise , e três ( X 11 , X 13 e X 17 ) são\nsufi cientemente signifi cantes para serem incluídas na\nfunção. Para fi ns de interpretação, ordenamos as variá-\nveis independentes em termos de suas cargas e valores F\nunivariados – ambos indicadores do poder discriminante\nde cada variável. Sinais dos pesos ou cargas não afetam a\nordem; eles simplesmente indicam uma relação positiva\nou negativa com a variável dependente.\nAnálise de lambda de Wilks e o F univariado. O lambda de Wilks e o F univariado representam os efeitos sepa- rados ou univariados de cada variável, não consideran- do multicolinearidade entre as variáveis independentes. Análogos às correlações bivariadas da regressão múltipla, eles indicam a habilidade de cada variável para discrimi- nar entre os grupos, mas apenas separadamente. Para in- terpretar qualquer combinação de duas ou mais variáveis\nindependentes, exige-se análise dos pesos ou cargas dis-\ncriminantes como descrito nas próximas seções.\nA Tabela 5-13 mostra que as variáveis ( X 11 , X 13 e X 17 ) com\nos três maiores valores F (e os menores lambdas de Wi-\nlks) eram também as variáveis que entraram na função\ndiscriminante. X 6 , porém, tinha um efeito discriminante\nsignifi cante quando considerada separadamente, mas tal\nefeito era compartilhado com as outras três variáveis, de\nmaneira que sozinha ela não contribuía sufi cientemente\npara entrar na função discriminante. Todas as demais va-\nriáveis tinham valores F não-signifi cantes e valores lamb-\nda de Wilks correspondentemente elevados.\nAnálise dos pesos discriminantes. Os pesos discrimi-\nnantes estão disponíveis em formas não-padronizadas\ne padronizadas. Os pesos não-padronizados (mais a\nconstante) são usados para calcular o escore discrimi-\nnante, mas podem ser afetados pela escala da variável\nindependente (exatamente como pesos de regressão\nmúltipla). Assim, os pesos padronizados refl etem mais\nverdadeiramente o impacto de cada variável sobre a fun-\nção discriminante e são mais apropriados para fi ns de\ninterpretação. Se for usada estimação simultânea, mul-\nticolinearidade entre quaisquer variáveis independentes\ncausará impacto sobre os pesos estimados. No entanto, o\nimpacto da multicolinearidade pode ser até maior para o\nprocedimento stepwise , pois ela afeta não somente os pe-\nsos mas pode também impedir que uma variável sequer\nentre na equação.\nTABELA 5-13 Resumo de medidas interpretativas para análise discriminante de dois grupos\nCoefi cientes discriminantes Cargas discriminantes\nLambda\nde Wilks Razão F univariada\nVariáveis independentes\nNão padroni-\nzados Padronizados Carga Ordenação Valor Valor F Sig. Ordenação\nX 6 Qualidade do produto NI NI –0,418 5 0,801 14,387 0,000 4\nX 7 Atividades de comércio\neletrônico\nNI NI 0,429 4 0,966 2,054 0,157 6\nX 8 Suporte técnico NI NI –0,136 11 0,973 1,598 0,211 7\nX 9 Solução de reclamação NI NI –0,181 8 0,986 0,849 0,361 8\nX 10 Anúncio NI NI 0,238 7 0,987 0,775 0,382 9\nX 11 Linha do produto –0,363 –0,417 –0,586 3 0,695 25,500 0,000 3\nX 12 Imagem da equipe de venda NI NI 0,164 9 0,856 9,733 0,003 5\nX 13 Preços competitivos 0,398 0,490 0,656 1 0,645 31,992 0,000 1\nX 14 Garantia e reclamações NI NI –0,329 6 0,992 0,453 0,503 11\nX 15 Novos produtos NI NI 0,041 13 0,990 0,600 0,442 10\nX 16 Encomenda e cobrança NI NI –0,149 10 0,999 0,087 0,769 13\nX 17 Flexibilidade de preço 0,749 0,664 0,653 2 0,647 31,699 0,000 2\nX 18 Velocidade de entrega NI NI –0,060 12 0,997 0,152 0,698 12\nNI = Não incluído na função discriminante estimada\nA Tabela 5-13 fornece os pesos padronizados (coefi cien- tes) para as três variáveis incluídas na função discrimi- * N. de R. T.: A palavra correta seria “cargas”.\n\n\n264 Análise Multivariada de Dados\n\n\nInterpretação da função discriminante\n\n\ncom base nas cargas discriminantes\nAs cargas discriminantes, em contraste com os pesos dis- criminantes, são menos afetadas pela multicolinearidade e, portanto, mais úteis para a interpretação. Além disso, como cargas são calculadas para todas as variáveis, elas fornecem uma medida interpretativa até mesmo para variáveis não incluídas na função discriminante. Uma regra prática ante- rior indicava que cargas acima de ± 0,40 deveriam ser usa- das para identifi car variáveis discriminantes importantes.\nAs cargas das três variáveis da função discriminante (ver\nTabela 5-13) são as três maiores, e todas excedem ± 0,40,\ngarantindo assim inclusão no processo de interpretação.\nDuas variáveis adicionais ( X 6 e X 7 ), porém, também têm\ncargas acima da referência ± 0,40. A inclusão de X 6 não é\ninesperada, como era a quarta variável com efeito discri-\nminante univariado, mas não foi incluída na função dis-\ncriminante devido à multicolinearidade (como mostrado\nno Capítulo 3, Análise Fatorial, onde X 6 e X 13 formavam\num fator). X 7 , porém, apresenta outra situação; ela não\ntinha um efeito univariado signifi cante. A combinação\ndas três variáveis na função discriminante criou um efeito\nque é associado com X 7 , mas X 7 não acrescenta qualquer\npoder discriminante adicional. Com relação a isso, X 7 é\ndescritiva da função discriminante mesmo não sendo in-\ncluída nem tendo um efeito univariado signifi cante.\nInterpretar a função discriminante e sua discriminação entre esses dois grupos exige que o pesquisador considere todas essas cinco variáveis. Na medida em que elas carac- terizam ou descrevem a função discriminante, todas re- presentam algum componente da mesma. Com as variáveis discriminantes identifi cadas e a função discriminante descrita em termos daquelas variáveis com\ncargas sufi cientemente elevadas, o pesquisador prossegue\nentão para o perfi l de cada grupo sobre essas variáveis\npara compreender as diferenças entre as mesmas.\n\n\nPerfi l das variáveis discriminantes\nO pesquisador está interessado em interpretações das va-\nriáveis individuais que têm signifi cância estatística e prá-\ntica. Tais interpretações são conseguidas primeiramente\nidentifi cando-se as variáveis com substantivo poder dis-\ncriminatório (ver a discussão anterior) e em seguida en-\ntendendo-se o que o grupo distinto diz cada variável in-\ndicada.\nComo descrito no Capítulo 1, escores maiores nas variá-\nveis independentes indicam percepções mais favoráveis\nda HBAT sobre aquele atributo (exceto para X 13 , onde\nescores menores são preferíveis). Retornando à Tabela\n5-5, vemos diversos perfi s entre os dois grupos sobre es-\nsas cinco variáveis.\n\nO grupo 0 (clientes nos Estados Unidos/América do Norte) têm percepções maiores sobre três variáveis: X 6 (Qualidade do produto), X 13 * (Preços competitivos) e X 11 (Linha do produto).\nO grupo 1 (clientes fora da América do Norte) têm percepções maiores nas outras duas variáveis: X 7 (Ati- vidades de comércio eletrônico) e X 17 (Flexibilidade de preço). Olhando esses dois perfi s, podemos perceber que os clientes dos EUA/América do Norte têm percepções muito melhores dos produtos HBAT, enquanto os de- mais clientes se sentem melhor com questões sobre pre- ço e comércio eletrônico. Note que X 6 e X 13 , ambas com percepções mais elevadas entre os clientes dos EUA/ América do Norte, formam o fator Valor do produto desenvolvido no Capítulo 3. A administração deveria usar esses resultados para desenvolver estratégias que acentuem esses pontos fortes e desenvolver outras van- tagens para fi ns de complementação. O perfi l médio também ilustra a interpretação dos sinais (positivos e negativos) nos pesos e as cargas dis- criminantes. Os sinais refl etem o perfi l médio relativo dos dois grupos. Os sinais positivos, neste exemplo, são associados com variáveis que têm escores maiores para o grupo 1. Os pesos e cargas negativas são para aque- las variáveis com o padrão oposto (i.e., valores maiores no grupo 0). Logo, os sinais indicam o padrão entre os grupos.\n\nnante. O impacto da multicolinearidade sobre os pesos\npode ser visto ao se examinar X 13 e X 17. Essas duas variá-\nveis têm poder discriminante essencialmente equivalen-\nte quando vistas nos testes lambda de Wilks e F univa-\nriado. Seus pesos discriminantes, contudo, refl etem um\nimpacto sensivelmente maior para X 17 do que para X 13 ,\nque agora é mais comparável com X 11. Essa mudança em\nimportância relativa é devida à multicolinearidade entre\nX 13 e X 11 , o que reduz o efeito único de X 13 e assim dimi-\nnui os pesos discriminantes também.\nOs três efeitos mais fortes na função discriminante, que\nsão geralmente comparáveis com base nos valores de car-\nga, são X 13 (Preços competitivos), X 17 (Flexibilidade de\npreço) e X 11 (Linha do produto). X 7 (Atividades de co-\nmércio eletrônico) e o efeito de X 6 (Qualidade do produ-\nto) podem ser adicionados aos efeitos de X 13. Obviamente,\ndiversos fatores diferentes estão sendo combinados para\ndiferenciar entre os grupos, exigindo assim mais defi nição\nde perfi l dos grupos para se entenderem as diferenças.\n* N. de R. T.: A tabela indica o contrário, ou seja, a média de X 13 é\nmaior no grupo 1 (7,418 versus 5,600).\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 265\n\n\n\nEstágio 6: Validação dos resultados\nO estágio fi nal aborda a validade interna e externa da fun- ção discriminante. O principal meio de validação é pelo uso da amostra de validação e a avaliação de sua precisão preditiva. Desse modo, a validade é estabelecida se a fun- ção discriminante classifi ca, em um nível aceitável, obser- vações que não foram usadas no processo de estimação. Se a amostra de validação é obtida a partir da amostra original, então essa abordagem estabelece validade inter- na. Se uma outra amostra separada, talvez de uma outra população ou de outro segmento da população, forma a amostra de validação, então isso corresponde a uma vali- dação externa dos resultados discriminantes.\nEm nosso exemplo, a amostra de teste surge a partir da\namostra original. Como anteriormente discutido, a preci-\nsão de classifi cação (razões de sucesso) para as amostras\nde teste e de validação cruzada estava muito acima das\nreferências em todas as medidas de precisão preditiva.\nComo tal, a análise estabelece validade interna. Para o\npropósito de validade externa, amostras adicionais de-\nvem ser extraídas de populações relevantes e a precisão\nde classifi cação deve ser avaliada em tantas situações\nquanto possível.\nO pesquisador é encorajado a estender o processo de validação por meio de perfi s expandidos dos grupos e o possível uso de amostras adicionais para estabelecer a va- lidade externa. Idéias adicionais da análise de casos mal classifi cados podem sugerir variáveis extras que podem melhorar ainda mais o modelo discriminante.\n\n\nUma visão gerencial\nA análise discriminante de clientes HBAT, baseada em localização geográfi ca (dentro ou fora da América do Norte), identifi cou um conjunto de diferenças em percep- ção que pode fornecer uma distinção mais sucinta e pode- rosa entre os dois grupos. Várias descobertas importantes incluem as seguintes:\n\n\nUM EXEMPLO ILUSTRATIVO\n\n\nDE TRÊS GRUPOS\nPara ilustrar a aplicação de uma análise discriminante de\ntrês grupos, novamente usamos a base de dados HBAT.\nNo exemplo anterior, estávamos interessados na discrimi-\nnação entre apenas dois grupos, de modo que conseguimos\ndesenvolver uma única função discriminante e um escore\nde corte para dividir os dois grupos. No exemplo de três\ngrupos, é necessário desenvolver duas funções discriminan-\ntes separadas para distinguir entre os três grupos. A pri-\nmeira função separa um grupo dos outros dois, e a segunda\nsepara os dois grupos restantes. Como no exemplo ante-\nrior, os seis estágios do processo de construção do modelo\nsão discutidos.\n\n\nEstágio 1: Objetivos da análise discriminante\nO objetivo da HBAT nessa pesquisa é determinar a relação\nentre as percepções que as empresas têm da HBAT e o pe-\nríodo de tempo em que uma empresa é cliente de HBAT.\n\nDiferenças são encontradas em um subconjunto de ape- nas cinco percepções, o que permite uma concentração sobre as variáveis-chave, não tendo que se lidar com o conjunto inteiro. As variáveis identifi cadas como discri- minantes entre os grupos (listadas em ordem de impor- tância) são X 13 (Preços competitivos), X 17 (Flexibilidade de preço), X 11 (Linha do produto), X 7 (Atividades de comércio eletrônico) e X 6 (Qualidade do produto).\nOs resultados também indicam que as empresas loca- lizadas nos Estados Unidos têm melhores percepções da HBAT do que suas contrapartes internacionais em termos de valor e linha de produto, enquanto os clientes que não são norte-americanos têm uma percepção mais favorável sobre fl exibilidade de preço e atividades de\n\ncomércio eletrônico. Essas percepções podem resultar\nde uma maior similaridade entre compradores norte-\namericanos, enquanto clientes internacionais acham a\npolítica de preços em sintonia com suas necessidades.\n\nOs resultados, que são altamente signifi cantes, forne- cem ao pesquisador a habilidade de identifi car correta- mente a estratégia de compra usada, com base nessas percepções, 85% do tempo. Esse elevado grau de con- sistência gera confi ança no desenvolvimento de estraté- gias baseadas em tais resultados.\nA análise das empresas mal classifi cadas revelou um pe- queno número de empresas que pareciam “deslocadas”. Identifi car tais empresas pode identifi car associações não tratadas por localização geográfi ca (p.ex., mercados no lugar de apenas localização física) ou outras caracte- rísticas de fi rmas ou de mercado que são associadas com localização geográfi ca. Portanto, conhecer a localização de uma fi rma dá idéias-chave sobre suas percepções da HBAT e, mais im- portante, como os dois grupos de clientes diferem, de for- ma que a administração pode empregar uma estratégia para acentuar as percepções positivas em suas negocia- ções com esses clientes e assim solidifi car sua posição.\n\nUm dos paradigmas emergentes em marketing é o con-\nceito de uma relação com cliente, baseada no estabeleci-\nmento de uma mútua parceria entre empresas ao longo\nde repetidas transações. O processo de desenvolvimento\nde uma relação implica a formação de metas e valores\ncompartilhados, que devem coincidir com percepções\nmelhoradas de HBAT. Portanto, a formação bem-suce-\ndida de uma relação deve ser entendida por meio de per-\n( Continua )\n\n266 Análise Multivariada de Dados\n\n\n\nEstágio 2: Projeto de pesquisa\n\n\npara análise discriminante\nPara testar essa relação, uma análise discriminante é exe- cutada para estabelecer se existem diferenças em percep- ções entre grupos de clientes com base na extensão da relação de clientela. Se for o caso, a HBAT estará então interessada em ver se diferentes perfi s justifi cam a propo- sição de que a HBAT teve sucesso no melhoramento de percepções entre clientes estabelecidos, um passo neces- sário na formação de relações com a clientela.\n\nSeleção de variáveis dependente e independentes\nAlém das variáveis dependentes não-métricas (categóri- cas) defi nindo grupos de interesse, a análise discriminante também requer um conjunto de variáveis independentes métricas que são consideradas fornecedoras de base para discriminação ou diferenciação entre os grupos.\nUma análise discriminante de três grupos é realizada\nusando X 1 (Tipo de cliente) como a variável dependente\ne as percepções de HBAT por parte dessas fi rmas (X 6 a\nX 18 ) como as variáveis independentes. Note que X 1 dife-\nre da variável dependente no exemplo de dois grupos no\nsentido de que ela tem três categorias nas quais classifi -\ncar o tempo de permanência como cliente de HBAT (1 =\nmenos que 1 ano, 2 = 1 a 5 anos, e 3 = mais de 5 anos).\n\n\nTamanho amostral e divisão da amostra\nQuestões relativas ao tamanho da amostra são particular- mente importantes com análise discriminante devido ao foco não apenas no tamanho geral da amostra, mas tam- bém no tamanho amostral por grupo. Juntamente com a necessidade de uma divisão da amostra para obter uma amostra de validação, o pesquisador deve considerar cui- dadosamente o impacto da divisão amostral em termos do tamanho geral e do tamanho de cada um dos grupos.\n\n\n\nEstágio 3: Suposições da análise discriminante\nComo no caso do exemplo de dois grupos, as suposições\nde normalidade, linearidade e colinearidade das variáveis\nindependentes já foram discutidas detalhadamente no Ca-\npítulo 2. A análise feita no Capítulo 2 indicou que as va-\nriáveis independentes atendem essas suposições em níveis\nadequados para viabilizar a continuidade da análise sem\nações corretivas adicionais. A suposição remanescente, a\nigualdade de matrizes de variância/covariância ou de dis-\npersão, também é abordada no Capítulo 2.\nO teste M de Box avalia a similaridade das matrizes de\ndispersão das variáveis independentes entre os três gru-\npos (categorias). O teste estatístico indicou diferenças\nno nível de signifi cância de 0,09. Neste caso, as diferen-\nças entre grupos são não-signifi cantes e nenhuma ação\ncorretiva se faz necessária. Além disso, não se espera\nqualquer impacto sobre os processos de estimação e\nclassifi cação.\n\n\nEstágio 4: Estimação do modelo\n\n\ndiscriminante e avaliação do ajuste geral\nComo no exemplo anterior, começamos nossa análise revi-\nsando as médias de grupo e os desvios-padrão para ver se os\ngrupos são signifi cantemente diferentes em alguma variável.\nCom essas diferenças em mente, empregamos em seguida\num processo de estimação stepwise para obter as funções\ndiscriminantes e completamos o processo avaliando preci-\nsão de classifi cação com diagnósticos gerais e por casos.\n\nAvaliação de diferenças de grupos\nIdentifi car as variáveis mais discriminantes com três ou\nmais grupos é mais problemático do que na situação com\ndois grupos. Para três ou mais grupos, as medidas típicas\nde signifi cância para diferenças em grupos (ou seja, lamb-\nda de Wilks e o teste F ) avaliam apenas as diferenças ge-\nrais e não garantem que cada grupo é signifi cante em rela-\nção aos demais. Assim, quando examinar variáveis quanto\na suas diferenças gerais entre os grupos, certifi que-se tam-\nbém de tratar das diferenças individuais de grupos.\ncepções melhores de HBAT ao longo do tempo. Nessa\nanálise, as fi rmas são agrupadas conforme sua situação\ncomo clientes HBAT. Se HBAT foi bem-sucedida no\nestabelecimento de relações com seus clientes, então as\npercepções sobre a HBAT irão melhorar em cada situa-\nção como cliente HBAT.\nA base de dados da HBAT tem uma amostra de 100, a\nqual será novamente particionada em amostras de aná-\nlise e de validação de 60 e 40 casos, respectivamente. Na\namostra de análise, a proporção de casos por variáveis\nindependentes é quase 5:1, o limite inferior recomenda-\ndo. Mais importante, na amostra de análise, apenas um\ngrupo, com 13 observações, fi ca abaixo do nível reco-\nmendado de 20 casos por grupo. Apesar de o tamanho\ndo grupo exceder 20 se a amostra inteira for usada na\nfase de análise, a necessidade de validação dita a criação\nda amostra de teste. Os três grupos são de tamanhos re-\nlativamente iguais (22, 13 e 25), evitando assim qualquer\nnecessidade de igualar os tamanhos dos grupos. A análi-\nse procede com atenção para a classifi cação e interpreta-\nção desse pequeno grupo de 13 observações.\nA Tabela 5-14 dá as médias de grupos, lambda de Wilks,\nrazões F univariadas (ANOVAs simples) e D^2 mínimo\n( Continua )\n( Continuação )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 267\nTodas essas medidas se combinam para ajudar a iden-\ntifi car os conjuntos de variáveis que formam as funções\ndiscriminantes, como descritos na próxima seção. Quando\nmais de uma função é criada, cada uma fornece discrimi-\nnação entre conjuntos de grupos. No exemplo simples do\ninício deste capítulo, uma variável discriminou entre os\ngrupos 1 versus 2 e 3, sendo que a outra discriminou entre\nos grupos 2 versus 3 e 1. Esse é um dos principais benefí-\ncios que surgem do uso da análise discriminante.\n\n\nEstimação da função discriminante\nO procedimento stepwise é realizado da mesma manei-\nra do exemplo de dois grupos, com todas as variáveis ini-\ncialmente excluídas do modelo. O procedimento então se-\nleciona a variável que tem uma diferença estatisticamente\nsignifi cante nos grupos enquanto maximiza a distância de\nMahalanobis ( D^2 ) entre os dois grupos mais próximos.\nDesta maneira, variáveis estatisticamente signifi cantes\nsão selecionadas de modo a maximizarem a discriminação\nentre os grupos mais semelhantes em cada estágio.\nEste processo continua enquanto variáveis adicionais\nfornecerem discriminação estatisticamente signifi cante\nalém daquelas diferenças já explicadas pelas variáveis na\nfunção discriminante. Uma variável pode ser removida se\nalta multicolinearidade com variáveis independentes na\nfunção discriminante faz com que sua signifi cância caia\nabaixo do nível para remoção (0,10).\nde Mahalanobis para cada variável independente. A re-\nvisão dessas medidas revela o seguinte:\n\nSobre uma base univariada, aproximadamente metade (7 entre 13) das variáveis exibe diferenças signifi cantes entre as médias dos grupos. As variáveis com diferenças signifi cantes incluem X 6 , X 9 , X 11 , X 13 , X 16 , X 17 e X 18.\nApesar de maior signifi cância estatística corresponder a uma maior discriminação geral (ou seja, as variáveis mais signifi cantes têm os menores lambdas de Wilks), ela nem sempre corresponde à maior discriminação en- tre todos os grupos.\n\nA inspeção visual das médias dos grupos revela que quatro das variáveis com diferenças signifi cantes ( X 13 , X 16 , X 17 e X 18 ) diferenciam apenas um grupo versus os outros dois grupos [p.ex., X 18 tem diferenças signifi cantes somente nas médias entre o grupo 1 (3,059) versus grupos 2 (4,246) e 3 (4,288)]. Essas variáveis têm um papel limitado em análise discriminante por fornecerem discriminação apenas em um subconjunto de grupos.\nTrês variáveis ( X 6 , X 9 e X 11 ) fornecem alguma discriminação, em vários graus, entre todos os grupos simultaneamente. Uma ou mais dessas variáveis podem ser usadas em combinação com as quatro variáveis precedentes para criar uma variável estatística com discriminação máxima.\n\nO valor D^2 de Mahalanobis fornece uma medida do grau de discriminação entre grupos. Para cada variável, o D^2 mínimo de Mahalanobis é a distância entre os dois grupos mais próximos. Por exemplo, X 11 tem o maior valor D^2 e é a variável com as maiores diferenças entre todos os três grupos. Analogamente, X 18 , uma variável com pequenas diferenças entre dois dos grupos, tem um pequeno valor D^2. Com três ou mais grupos, o D^2 mí-\n\nTABELA 5-14 Estatísticas descritivas de grupos e testes de igualdade para a amostra de estimação na análise discriminante de três grupos\nMédias de grupo da variável\ndependente: X 1 Tipo de cliente\nTeste de igualdade de\nmédias de gruposa\nD^2 mínimo de\nMahalanobis\nVariáveis independentes\nGrupo 1:\nMenos que 1\nano ( n = 22)\nGrupo 2: 1\na 5 anos\n( n = 13)\nGrupo 3:\nMais de 5\nanos ( n = 25)\nLambda\nde Wilks Valor F Signifi cância D^2 mínimo\nEntre\ngrupos\nX 6 Qualidade do produto 7,118 6,785 9,000 0,469 32,311 0,000 0,121 1 e 2\nX 7 Atividades de comércio ele-\ntrônico\n3,514 3,754 3,412 0,959 1,221 0,303 0,025 1 e 3\nX 8 Suporte técnico 4,959 5,615 5,376 0,973 0,782 0,462 0,023 2 e 3\nX 9 Solução de reclamação 4,064 5,900 6,300 0,414 40,292 0,000 0,205 2 e 3\nX 10 Anúncio 3,745 4,277 3,768 0,961 1,147 0,325 0,000 1 e 3\nX 11 Linha do produto 4,855 5,577 7,056 0,467 32,583 0,000 0,579 1 e 2\nX 12 Imagem da equipe de venda 4,673 5,346 4,836 0,943 1,708 0,190 0,024 1 e 3\nX 13 Preços competitivos 7,345 7,123 5,744 0,751 9,432 0,000 0,027 1 e 2\nX 14 Garantia e reclamações 5,705 6,246 6,072 0,916 2,619 0,082 0,057 2 e 3\nX 15 Novos produtos 4,986 5,092 5,292 0,992 0,216 0,807 0,004 1 e 2\nX 16 Encomenda e cobrança 3,291 4,715 4,700 0,532 25,048 0,000 0,000 2 e 3\nX 17 Flexibilidade de preço 4,018 5,508 4,084 0,694 12,551 0,000 0,005 1 e 3\nX 18 Velocidade de entrega 3,059 4,246 4,288 0,415 40,176 0,000 0,007 2 e 3\naLambda de Wilks (estatística U ) e razão F univariada com 2 e 57 graus de liberdade.\nnimo de Mahalanobis é importante na identifi cação da\nvariável que dá a maior diferença entre os dois grupos\nmais parecidos.\n( Continuação )\n\n\n268 Análise Multivariada de Dados\nEstimação stepwise : adição da primeira variável,\nX 11. Os dados na Tabela 5-14 mostram que a primeira\nvariável a entrar no modelo é X 11 (Linha do produto),\npois ela atende aos critérios para diferenças estatistica-\nmente signifi cantes nos grupos e tem o maior valor D^2 (o\nque signifi ca que ela tem a maior separação entre os dois\ngrupos mais parecidos).\nOs resultados de adicionar X 11 como a primeira va-\nriável no processo stepwise são mostrados na Tabela\n5-15. O ajuste geral do modelo é signifi cante e todos os\ngrupos são signifi cantemente distintos, apesar de os gru-\npos 1 (menos de um ano) e 2 (de um a cinco anos) terem\na menor diferença entre eles (ver seção abaixo detalhan-\ndo as diferenças de grupos).\nCom a menor diferença entre os grupos 1 e 2, o pro-\ncedimento discriminante selecionará agora uma variável\nque maximiza aquela diferença enquanto pelo menos\nmantém as demais. Se voltarmos à Tabela 5-14, perce-\nberemos que quatro variáveis ( X 9 , X 16 , X 17 e X 18 ) tinham\ndiferenças signifi cantes, com substanciais distinções en-\ntre os grupos 1 e 2. Olhando a Tabela 5-15, vemos que\nessas quatro variáveis têm o maior valor D^2 mínimo, e\nem cada caso é para a diferença entre os grupos 2 e 3\n(o que signifi ca que os grupos 1 e 2 não são os mais pa-\nTABELA 5-15 Resultados do passo 1 da análise discriminante stepwise de três grupos\nAjuste geral do modelo\nValor Valor F Graus de liberdade Signifi cância\nLambda de Wilks 0,467 32,583 2,57 0,000\nVariável adicionada/removida no passo 1\nF\nVariável adicionada D^2 mínimo Valor Signifi cância Entre grupos\nX 11 Linha de produto 0,579 4,729 0,000 Menos de 1 ano e de 1 a 5 anos\nNota : Em cada passo, a variável que maximiza a distância Mahalanobis entre os dois grupos mais próximos é adicionada.\nVariáveis na análise após o passo 1\nVariável Tolerância F para remover D^2 Entre grupos\nX 11 Linha de produto 1,000 32,583 NA NA\nNA = Não aplicável\nVariáveis fora da análise após o passo 1\nVariável Tolerância Tolerância mínima F para entrar D^2 mínimo Entre grupos\nX 6 Qualidade de produto 1,000 1,000 17,426 0,698 Menos de 1 ano e de 1 a 5 anos\nX 7 Atividades de comércio eletrônico 0,950 0,950 1,171 0,892 Menos de 1 ano e de 1 a 5 anos\nX 8 Suporte técnico 0,959 0,959 0,733 0,649 Menos de 1 ano e de 1 a 5 anos\nX 9 Solução de reclamação 0,847 0,847 15,446 2,455 De 1 a 5 anos e mais de 5 anos\nX 10 Anúncio 0,998 0,998 1,113 0,850 Menos de 1 ano e de 1 a 5 anos\nX 12 Imagem da equipe de venda 0,932 0,932 3,076 1,328 Menos de 1 ano e de 1 a 5 anos\nX 13 Preços competitivos 0,882 0,882 2,299 0,839 Menos de 1 ano e de 1 a 5 anos\nX 14 Garantia e reclamações 0,849 0,849 0,647 0,599 Menos de 1 ano e de 1 a 5 anos\nX 15 Novos produtos 0,993 0,993 0,415 0,596 Menos de 1 ano e de 1 a 5 anos\nX 16 Encomenda e cobrança 0,943 0,943 12,176 2,590 De 1 a 5 anos e mais de 5 anos\nX 17 Flexibilidade de preço 0,807 0,807 17,300 3,322 De 1 a 5 anos e mais de 5 anos\nX 18 Velocidade de entrega 0,773 0,773 19,020 2,988 De 1 a 5 anos e mais de 5 anos\nTeste de signifi cância de diferenças de grupos após o passo 1a\nX 1 Tipo de cliente Menos de 1 ano De 1 a 5 anos\nDe 1 a 5 anos F 4,729\nSig. 0,034\nMais de 5 anos F 62,893 20,749\nSig. 0,000 0,000\na1 e 57 graus de liberdade.\n( Continua )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 269\nrecidos depois de acrescentar aquela variável). Assim,\nadicionar qualquer uma dessas variáveis afeta muito as\ndiferenças entre os grupos 1 e 2, o par que era mais pa-\nrecido depois que X 11 foi adicionada no primeiro passo.\nO procedimento escolherá X 17 porque ela criará a maior\ndistância entre os grupos 2 e 3.\nEstimação stepwise : Adição da segunda variável,\nX 17. A Tabela 5-16 detalha o segundo passo do proce-\ndimento stepwise : o acréscimo de X 17 (Flexibilidade de\npreço) à função discriminante. A discriminação entre\ngrupos aumentou, como refl etido em um menor valor\nlambda de Wilks e no aumento do D^2 mínimo (de 0,467\npara 0,288). As diferenças de grupos, geral e individuais,\nainda são estatisticamente signifi cantes. O acréscimo de\nX 17 aumentou as distinções entre os grupos 1 e 2 consi-\nderavelmente, de forma que agora os dois grupos mais\nparecidos são 2 e 3.\nDas variáveis fora da equação, apenas X 6 (Qualidade\nde produto) satisfaz o nível de signifi cância necessário\nTABELA 5-16 Resultados do passo 2 da análise discriminante stepwise de três grupos\nAjuste geral do modelo\nValor Valor F Graus de liberdade Signifi cância\nLambda de Wilks 0,288 24,139 4, 112 0,000\nVariável adicionada/removida no passo 2\nF\nVariável adicionada D^2 mínimo Valor Signifi cância Entre grupos\nX 17 Flexibilidade de preço 3,322 13,958 0,000 De 1 a 5 anos e mais de 5 anos\nNota: Em cada passo, a variável que maximiza a distância Mahalanobis entre os dois grupos mais próximos é adicionada.\nVariáveis na análise após o passo 2\nVariável Tolerância F para remover D^2 Entre grupos\nX 11 Linha de produto 0,807 39,405 0,005 Menos de 1 ano e mais de 5 anos\nX 17 Flexibilidade de preço 0,807 17,300 0,579 Menos de 1 ano e de 1 a 5 anos\nVariáveis fora da análise após o passo 2\nVariável TolerânciaTolerância mínima F para entrar D^2 mínimo Entre grupos\nX 6 Qualidade de produto 0,730 0,589 24,444 6,071 Menos de 1 ano e de 1 a 5 anos\nX 7 Atividades de comércio eletrônico 0,880 0,747 0,014 3,327 Menos de 1 ano e de 1 a 5 anos\nX 8 Suporte técnico 0,949 0,791 1,023 3,655 Menos de 1 ano e de 1 a 5 anos\nX 9 Solução de reclamação 0,520 0,475 3,932 3,608 Menos de 1 ano e de 1 a 5 anos\nX 10 Anúncio 0,935 0,756 0,102 3,348 Menos de 1 ano e de 1 a 5 anos\nX 12 Imagem da equipe de venda 0,884 0,765 0,662 3,342 Menos de 1 ano e de 1 a 5 anos\nX 13 Preços competitivos 0,794 0,750 0,989 3,372 Menos de 1 ano e de 1 a 5 anos\nX 14 Garantia e reclamações 0,868 0,750 2,733 4,225 Menos de 1 ano e de 1 a 5 anos\nX 15 Novos produtos 0,963 0,782 0,504 3,505 Menos de 1 ano e de 1 a 5 anos\nX 16 Encomenda e cobrança 0,754 0,645 2,456 3,323 Menos de 1 ano e de 1 a 5 anos\nX 18 Velocidade de entrega 0,067 0,067 3,255 3,598 Menos de 1 ano e de 1 a 5 anos\nTeste de signifi cância de diferenças de grupos após o passo 2a\nX 1 Tipo de cliente Menos de 1 ano De 1 a 5 anos\nDe 1 a 5 anos F 21,054\nSig. 0,000\nMais de 5 anos F 39,360 13,958\nSig. 0,000 0,000\na2 e 56 graus de liberdade.\n( Continuação )\n( Continua )\n\n\n270 Análise Multivariada de Dados\npara consideração. Se acrescentada, o D^2 mínimo será\nagora entre os grupos 1 e 2.\nEstimação stepwise : Adição das terceira e quarta variá-\nveis, X 6 e X 18. Como anteriormente observado, X 6 se\ntorna a terceira variável adicionada à função discrimi-\nnante. Depois que X 6 foi acrescentada, apenas X 18 exibe\numa signifi cância estatística nos grupos ( Nota : Os deta-\nlhes sobre o acréscimo de X 6 no terceiro passo não são\nmostrados por questão de espaço).\nA variável fi nal adicionada no passo 4 é X 18 (ver Ta-\nbela 5-17), com a função discriminante incluindo agora\nquatro variáveis ( X 11 , X 17 , X 6 e X 18 ). O modelo geral é\nsignifi cante, com o lambda de Wilks diminuindo para\n0,127. Além disso, existem diferenças signifi cantes entre\ntodos os grupos individuais.\nCom essas quatro variáveis na função discriminante,\nnenhuma outra variável exibe a signifi cância estatísti-\nca necessária para inclusão, e o processo stepwise está\nTABELA 5-17 Resultados do passo 4 da análise discriminante stepwise de três grupos\nAjuste geral do modelo\nValor Valor F Graus de liberdade Signifi cância\nLambda de Wilks 0,127 24,340 8, 108 0,000\nVariável adicionada/removida no passo 4\nF\nVariável adicionada D^2 mínimo Valor Signifi cância Entre grupos\nX 18 Velocidade de entrega 6,920 13,393 0,000 Menos de 1 ano e de 1 a 5 anos\nNota: Em cada passo, a variável que maximiza a distância Mahalanobis entre os dois grupos mais próximos é adicionada.\nVariáveis na análise após o passo 4\nVariável Tolerância F para remover D^2 Entre grupos\nX 11 Linha de produto 0,075 0,918 6,830 Menos de 1 ano e de 1 a 5 anos\nX 17 Flexibilidade de preço 0,070 1,735 6,916 Menos de 1 ano e de 1 a 5 anos\nX 6 Qualidade do produto 0,680 27,701 3,598 De 1 a 5 anos e mais de 5 anos\nX 18 Velocidade de entrega 0,063 5,387 6,071 Menos de 1 ano e de 1 a 5 anos\nVariáveis fora da análise após o passo 4\nVariável Tolerância Tolerância mínima F para entrar D^2 mínimo Entre grupos\nX 7 Atividades de comércio eletrônico 0,870 0,063 0,226 6,931 Menos de 1 ano e de 1 a 5 anos\nX 8 Suporte técnico 0,940 0,063 0,793 7,164 Menos de 1 ano e de 1 a 5 anos\nX 9 Solução de reclamação 0,453 0,058 0,292 7,019 Menos de 1 ano e de 1 a 5 anos\nX 10 Anúncio 0,932 0,063 0,006 6,921 Menos de 1 ano e de 1 a 5 anos\nX 12 Imagem da equipe de venda 0,843 0,061 0,315 7,031 Menos de 1 ano e de 1 a 5 anos\nX 13 Preços competitivos 0,790 0,063 0,924 7,193 Menos de 1 ano e de 1 a 5 anos\nX 14 Garantia e reclamações 0,843 0,063 2,023 7,696 Menos de 1 ano e de 1 a 5 anos\nX 15 Novos produtos 0,927 0,062 0,227 7,028 Menos de 1 ano e de 1 a 5 anos\nX 16 Encomenda e cobrança 0,671 0,062 1,478 7,210 Menos de 1 ano e de 1 a 5 anos\nTeste de signifi cância de diferenças de grupos após o passo 4a\nX 1 Tipo de cliente Menos de 1 ano De 1 a 5 anos\nDe 1 a 5 anos F 13,393\nSig. 0,000\nMais de 5 anos F 56,164 18,477\nSig. 0,000 0,000\na4 e 54 graus de liberdade.\n( Continua )\n( Continuação )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 271\nResumo do processo de estimação stepwise. As funções discriminantes estimadas são composições lineares se- melhantes a uma reta de regressão (ou seja, elas são uma combinação linear de variáveis). Assim como uma reta de regressão é uma tentativa de explicar a máxima variação em sua variável dependente, essas composições lineares tentam explicar as variações ou diferenças na variável ca- tegórica dependente. A primeira função discriminante é desenvolvida para explicar a maior variação (diferença) nos grupos discriminantes. A segunda função discrimi- nante, que é ortogonal e independente da primeira, ex- plica o maior percentual da variância remanescente (re- sidual) depois que a variância para a primeira função é removida.\nA informação fornecida na Tabela 5-19 resume os passos\nda análise discriminante de três grupos, com os seguintes\nresultados:\n\nX 6 e X 18 são as duas variáveis na função discriminante fi - nal, apesar de X 11 e X 17 terem sido acrescentadas nos dois primeiros passos e então removidas depois que X 6 e X 18 foram adicionadas. Os coefi cientes não-padronizados e padronizados (pesos) da função discriminante e a matriz estrutural das cargas discriminantes, rotacionadas e não- rotacionadas, também foram fornecidos. A rotação das cargas discriminantes facilita a interpretação da mesma maneira que fatores foram simplifi cados para interpreta- ção via rotação (ver Capítulo 3 para uma discussão mais detalhada sobre rotação). Examinamos em pormenores as cargas rotacionadas e não-rotacionadas no passo 5.\nA discriminação aumentou com a adição de cada variá- vel (como evidenciado pela diminuição no lambda de Wilks), mesmo com apenas duas variáveis restando no modelo fi nal. Comparando o lambda de Wilks fi nal para a análise discriminante (0,148) com o lambda de Wilks (0,414) para o melhor resultado de uma única variável, X 9 , vemos que uma melhora acentuada é obtida ao se usar exatamente duas variáveis nas funções discriminan- tes no lugar de uma única variável.\nA qualidade de ajuste geral para o modelo discriminante é estatisticamente signifi cante e ambas as funções são estatisticamente signifi cantes também. A primeira função explica 91,5% da variância explicada pelas duas funções, com a variância remanescente (8,5%) devida à segunda função. A variância total explicada pela primeira função é 0,893^2 , ou 79,7%. A próxima função explica 0,517^2 ou 26,7% da variância remanescente (20,3%). Portanto, a variância total explicada por ambas as funções é de 85,1% [79,7% + (26,7% × 0,203)] da variação total na variável dependente.\n\nAinda que ambas as funções sejam estatisticamente\nsignifi cantes, o pesquisador sempre deve garantir que as\nfunções discriminantes forneçam diferenças entre todos\nos grupos. É possível ter funções estatisticamente signi-\nfi cantes, mas ter pelo menos um par de grupos que não\nsejam estatisticamente distintos (i.e., não discriminados\nentre eles). Este problema se torna especialmente predo-\nminante quando o número de grupos aumenta ou vários\ngrupos pequenos são incluídos na análise.\nA última seção da Tabela 5-18 fornece os testes de signi-\nfi cância para diferenças de grupos entre cada par de gru-\npos (p.ex., grupo 1 versus grupo 2, grupo 1 versus grupo\n3 etc.). Todos os pares de grupos mostraram diferenças\nestatisticamente signifi cantes, denotando que as funções\ndiscriminantes criaram separação não apenas em um\nsentido geral, mas também para cada grupo também.\nExaminamos os centróides de grupos grafi camente em\numa seção posterior.\nconcluído em termos de acréscimo de variáveis. Porém,\no procedimento inclui também um exame da signifi cân-\ncia de cada variável para que a mesma seja mantida na\nfunção discriminante. Neste caso, o “ F para remover”\npara X 11 e X 17 é não-signifi cante (0,918 e 1,735, respecti-\nvamente), indicando que uma ou ambas são candidatas\npara remoção da função discriminante.\nEstimação stepwise : Remoção de X 17 e X 11. Quando\nX 18 é adicionada ao modelo no quarto passo (ver a dis-\ncussão anterior), X 11 tinha o menor valor “ F para remo-\nver” (0,918), fazendo com que o procedimento stepwise\neliminasse aquela variável da função discriminante no\nquinto passo (detalhes sobre este passo 5 são omitidos\npor questões de espaço). Agora com três variáveis na\nfunção discriminante ( X 11 , X 6 e X 18 ), o ajuste geral do\nmodelo ainda é signifi cante e o lambda de Wilks aumen-\ntou só um pouco para 0,135. Todos os grupos são signifi -\ncantemente diferentes. Nenhuma variável atinge o nível\nnecessário de signifi cância estatística para ser adicionada\nà função discriminante, e mais uma variável ( X 11 *) tem\num valor “ F para remover” de 2,552, o que indica que\nela também pode ser eliminada da função.\nA Tabela 5-18 contém os detalhes do passo 6 do\nprocedimento stepwise , onde X 11 também é removi-\nda da função discriminante, restando apenas X 6 e X 18.\nMesmo com a remoção da segunda variável (X 11 ), o\nmodelo geral ainda é signifi cante e o lambda de Wilks\né consideravelmente pequeno (0,148). Devemos obser-\nvar que este modelo de duas variáveis, X 6 e X 18 , é um\nmelhoramento em relação ao primeiro modelo de duas\nvariáveis, X 11 e X 17 , formado no passo 2 (lambda de Wi-\nlks é 0,148 contra o valor do primeiro modelo de 0,288\ne todas as diferenças individuais de grupos são muito\nmaiores). Sem variáveis alcançando o nível necessário\nde signifi cância para adição ou remoção, o procedimen-\nto stepwise é encerrado.\n( Continuação )\n\nN. de R. T.: Provavelmente trata-se de X 17 , uma vez que X 11 já fora removida. * N. de R. T.: Na verdade, seria X 11 com lambda de Wilks igual a 0,467.\n\n\n\n272 Análise Multivariada de Dados\n\n\nAvaliação da precisão de classifi cação\nComo esse é um modelo de análise discriminante de três grupos, duas funções discriminantes são calculadas para discriminar entre os três grupos. Valores para cada caso são inseridos no modelo discriminante e composições li- neares (escores Z discriminantes) são calculadas. As fun- ções discriminantes são baseadas somente nas variáveis incluídas no modelo discriminante.\nTABELA 5-18 Resultados do passo 6 da análise discriminante stepwise de três grupos\nAjuste geral do modelo\nValor Valor F Graus de liberdade Signifi cância\nLambda de Wilks 0,148 44,774 4, 112 0,000\nVariável adicionada/removida no passo 6\nF\nVariável removida D^2 mínimo Valor Signifi cância Entre grupos\nX 11 Linha do produto 6,388 25,642 0,000 Menos de 1 ano e de 1 a 5 anos\nNota: Em cada passo, a variável que maximiza a distância Mahalanobis entre os dois grupos mais próximos é adicionada.\nVariáveis na análise após o passo 6\nVariável Tolerância F para remover D^2 Entre grupos\nX 6 Qualidade do produto 0,754 50,494 0,007 De 1 a 5 anos e mais de 5 anos\nX 18 Velocidade de entrega 0,754 60,646 0,121 Menos de 1 ano e de 1 a 5 anos\nVariáveis fora da análise após o passo 6\nVariável Tolerância Tolerância mínima F para entrar D^2 mínimo Entre grupos\nX 7 Atividades de comércio eletrônico 0,954 0,728 0,177 6,474 Menos de 1 ano e de 1 a 5 anos\nX 8 Suporte técnico 0,999 0,753 0,269 6,495 Menos de 1 ano e de 1 a 5 anos\nX 9 Solução de reclamação 0,453 0,349 0,376 6,490 Menos de 1 ano e de 1 a 5 anos\nX 10 Anúncio 0,954 0,742 0,128 6,402 Menos de 1 ano e de 1 a 5 anos\nX 11 Linha do produto 0,701 0,529 2,552 6,916 Menos de 1 ano e de 1 a 5 anos\nX 12 Imagem da equipe de venda 0,957 0,730 0,641 6,697 Menos de 1 ano e de 1 a 5 anos\nX 13 Preços competitivos 0,994 0,749 1,440 6,408 Menos de 1 ano e de 1 a 5 anos\nX 14 Garantia e reclamações 0,991 0,751 0,657 6,694 Menos de 1 ano e de 1 a 5 anos\nX 15 Novos produtos 0,984 0,744 0,151 6,428 Menos de 1 ano e de 1 a 5 anos\nX 16 Encomenda e cobrança 0,682 0,514 2,397 6,750 Menos de 1 ano e de 1 a 5 anos\nX 17 Flexibilidade de preço 0,652 0,628 3,431 6,830 Menos de 1 ano e de 1 a 5 anos\nTeste de signifi cância de diferenças de grupos após o passo 6a\nX 1 Tipo de cliente Menos de 1 ano De 1 a 5 anos\nDe 1 a 5 anos F 25,642\nSig. 0,000\nMais de 5 anos F 110,261 30,756\nSig. 0,000 0,000\na6 e 52 graus de liberdade.\nA Tabela 5-19 fornece os pesos discriminantes de am-\nbas as variáveis ( X 6 e X 18 ) e as médias de cada grupo em\nambas as funções (parte inferior da tabela). Como po-\ndemos ver examinando as médias de grupos, a primeira\nfunção distingue o grupo 1 (Menos de 1 ano) dos outros\ndois grupos (apesar de uma sensível diferença ocorrer\nentre os grupos 2 e 3 também), enquanto a segunda fun-\nção separa o grupo 3 (Mais de 5 anos) dos outros dois.\nPortanto, a primeira função fornece a maior separação\nentre todos os três grupos, mas é complementada pela\nsegunda função, a qual melhor discrimina (1 e 2 versus\n3) onde a primeira função é mais fraca.\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 273\nTABELA 5-19 Estatísticas resumo para análise discriminante de três grupos\nAjuste geral do modelo: funções discriminantes canônicas\nPercentual de variância\nFunção Autovalor\nFunção\n(%)\nPercentual\ncumulativo\nCorrelação\ncanônica\nLambda de\nWilks Qui-quadrado df Signifi cância\n1 3,950 91,5 91,5 0,893 0,148 107,932 4 0,000\n2 0,365 8,5 100,0 0,517 0,733 17,569 1 0,000\nCoefi cientes da função discriminante e da função de classifi cação\nFUNÇÃO DISCRIMINANTE\nFunção discriminante\nnão-padronizada\nFunção discriminante\npadronizada Funções de classifi cação\nVariáveis independentes Função 1 Função 2 Função 1 Função 2\nMenos de\n1 ano\nDe 1 a 5\nanos\nAcima de\n5 anos\nX 16 Encomenda e cobrança* 0,308 1,159 0,969 0,622 14,382 15,510 18,753\nX 18 Velocidade de entrega 2,200 0,584 1,021 –0,533 25,487 31,185 34,401\n(Constante) –10,832 –11,313 –91,174 –120,351 –159,022\nMatriz estrutural\nCargas discriminantes não-rotacionadasa Cargas discriminantes rotacionadasb\nVariáveis independentes Função 1 Função 2 Função 1 Função 2\nX 9 Solução de reclamação* 0,572 –0,470 0,739 0,039\nX 16 Encomenda e cobrança 0,499 –0,263 0,546 0,143\nX 11 Linha do produto* 0,483 –0,256 0,529 0,137\nX 15 Novos produtos* 0,125 –0,005 0,096 0,080\nX 8 Suporte técnico* 0,030 –0,017 0,033 0,008\nX 6 Qualidade do produto* 0,463 0,886 –0,257 0,967\nX 18 Velocidade de entrega 0,540 –0,842 0,967 –0,257\nX 17 Flexibilidade de preço* 0,106 –0,580 0,470 –0,356\nX 10 Anúncio* 0,028 –0,213 0,165 –0,138\nX 7 Atividades de comércio eletrônico* –0,095 –0,193 0,061 –0,207\nX 12 Imagem da equipe de venda* –0,088 –0,188 0,061 –0,198\nX 14 Garantia e reclamações* 0,030 –0,088 0,081 0,044\nX 13 Preços competitivos* –0,055 –0,059 –0,001 –0,080\naCorrelações internas de grupos entre variáveis discriminantes e variáveis de funções discriminantes canônicas padronizadas ordenadas por tamanho abso-\nluto da correlação dentro da função.b\nCorrelações internas de grupos entre variáveis discriminantes e funções discriminantes canônicas padronizadas e rotacionadas.\n*Esta variável não é usada na análise.\nMédias de grupo (centróides) de funções discriminantesc\nX 1 Tipo de cliente Função 1 Função**\nMenos de 1 ano –1,911 –1,274\nDe 1 a 5 anos 0,597 –0,968\nMais de 5 anos 1,371 1,625\nc Funções discriminantes canônicas não-padronizadas avaliadas nas médias de grupos.\nAvaliação da precisão preditiva de pertinência a grupo. O passo fi nal para avaliar o ajuste geral do modelo é deter- minar o nível de precisão preditiva da(s) função(ões) discriminante(s). Essa determinação é conseguida do\nmesmo modo que se faz no modelo discriminante de dois\ngrupos, examinando-se as matrizes de classifi cação e o\npercentual corretamente classifi cado (razão de sucesso)\nem cada amostra.\nA classifi cação de casos individuais pode ser executada\npelo método de corte descrito no caso de dois grupos\n\nN. de RT.: Na realidade, foi incluída a variável X 6 (Qualidade do produto). ** N. de RT.: Neste caso, é Função 2.\n\n\n\n274 Análise Multivariada de Dados\nou usando as funções de classifi cação (ver Tabela 5-19)\nonde cada caso é computado em cada função de classifi -\ncação e classifi cado no grupo de maior escore.\nA Tabela 5-20 mostra que as duas funções discri-\nminantes em combinação atingem um grau elevado de\nprecisão de classifi cação. A proporção de sucesso para\na amostra de análise é de 86,7%. No entanto, a razão de\nsucesso para a amostra de teste cai para 55,0%. Esses\nresultados demonstram o viés ascendente que é típico\nquando se aplica somente à amostra de análise, mas não\na uma amostra de validação.\nAmbas as proporções de sucesso devem ser compa-\nradas com os critérios de chance máxima e de chance\nproporcional para se avaliar sua verdadeira efetividade.\nO procedimento de validação cruzada é discutido no\npasso 6.\n\nO critério de chance máxima é simplesmente a pro- porção de sucesso obtida se designarmos todas as ob- servações para o grupo com a maior probabilidade de ocorrência. Na presente amostra de 100 observações, 32 estavam no grupo 1, 35 no grupo 2, e 33 no grupo 3. A partir dessa informação, podemos ver que a probabili- dade mais alta seria 35% (grupo 2). O valor de referên- cia para a chance máxima (35% × 1,25) é 43,74%.\nO critério de chance proporcional é calculado elevando- se ao quadrado as proporções de cada grupo, com um valor calculado de 33,36% (0,32^2 ” 0,35^2 ” 0,33^2!\n\n0,334) e um valor de referência de 41,7% (33,4% × 1.25\n! 41,7%).\nAs proporções de sucesso para as amostras de aná-\nlise e de teste (86,7% e 55,0%, respectivamente) exce-\ndem ambos os valores de referência de 43,74% e 41,7%.\nNa amostra de estimação, todos os grupos individuais\nultrapassam os dois valores de referência. Na amostra\nde teste, porém, o grupo 2 tem uma razão de sucesso de\nsomente 40,9%, e aumenta apenas para 53,8% na amos-\ntra de análise. Tais resultados mostram que o grupo 2\ndeve ser o foco no melhoramento da classifi cação, pos-\nsivelmente com a adição de variáveis independentes ou\numa revisão da classifi cação de fi rmas neste grupo para\nidentifi car as características do mesmo que não estão re-\npresentadas na função discriminante.\nA medida fi nal de precisão de classifi cação é o Q de\nPress, calculado para as amostras de análise e de valida-\nção. Ele testa a signifi cância estatística de que a precisão\nde classifi cação é melhor do que o acaso (chance).\nE o cálculo para a amostra de teste é\nTABELA 5-20 Resultados de classifi cação para a análise discriminante de três grupos\nResultados de classifi cação a, b, c^\nPertinência prevista em grupo\nGrupo real Menos do que 1 ano De 1 a 5 anos Mais de 5 anos Total\nAmostra de estimação Menos de 1 ano 21 1 0 22\n95,5 4,5 0,0\nDe 1 a 5 anos 2 7 4 13\n15,4 53,8 30,8\nMais de 5 anos 0 1 24 25\n0,0 4,0 96,0\nValidação cruzada Menos de 1 ano 21 1 0 22\n95,5 4,5 0,0\nDe 1 a 5 anos 2 7 4 13\n15,4 53,8 30,8\nMais de 5 anos 0 1 24 25\n0,0 4,0 96,0\nAmostra de validação Menos de 1 ano 5 3 2 10\n50,0 30,0 20,0\nDe 1 a 5 anos 1 9 12 22\n4,5 40,9 54,5\nMais de 5 anos 0 0 8 8\n0,0 0,0 100,0\na86,7% dos casos agrupados originais selecionados corretamente classifi cados.\nb55,0% dos casos agrupados originais não-selecionados corretamente classifi cados.\nc86,7% dos casos agrupados selecionados e validados por cruzamento corretamente classifi cados.\n( Continua )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 275\nQuando completado, podemos concluir que o mode- lo discriminante é válido e tem níveis adequados de sig- nifi cância estatística e prática para todos os grupos. Os valores consideravelmente menores para a amostra de validação em todos os padrões de comparação, contudo, justifi cam a preocupação levantada anteriormente sobre as razões de sucesso específi cas de grupos e geral.\n\n\nDiagnósticos por casos\nAlém das tabelas de classifi cação mostrando resultados agregados, informação específi ca de casos também está disponível detalhando a classifi cação de cada observação. Essa informação pode detalhar as especifi cidades do pro- cesso de classifi cação ou representar a classifi cação atra- vés de um mapa territorial.\nInformação de classifi cação específi ca de caso. Uma sé- rie de medidas específi cas de casos está disponível para identifi cação dos casos mal classifi cados, bem como o diagnóstico da extensão de cada classifi cação ruim. Usan- do essa informação, padrões entre os mal classifi cados po- dem ser identifi cados.\nO pesquisador deve avaliar a extensão de má classifi -\ncação para cada caso. Casos que são classifi cações obvia-\nmente ruins devem ser escolhidos para análise adicional\n(perfi l, exame de variáveis adicionais etc.), discutida na\nanálise de dois grupos.\nMapa territorial. A análise de más classifi cações pode\nser suplementada pelo exame gráfi co das observações in-\ndividuais, representando-as com base em seus escores Z\ndiscriminantes.\nComo o valor crítico em um nível de signifi cância\nde 0,01 é 6,63, a análise discriminante pode ser descri-\nta como prevendo pertinência a grupo melhor do que o\nacaso.\nA Tabela 5-21 contém dados adicionais de classifi cação\npara cada caso individual que foi mal classifi cado (in-\nformação similar também está disponível para todos os\noutros casos, mas foi omitida por problemas de espaço).\nOs tipos básicos de informação de classifi cação incluem\no que se segue:\n\nPertinência a grupo. Tanto os grupos reais quanto os previstos são exibidos para identifi car cada tipo de má classifi cação (p.ex., pertinência real ao grupo 1, mas pre- vista no grupo 2). Neste caso, vemos os 8 casos mal clas- sifi cados na amostra de análise (verifi que acrescentando os valores fora da diagonal na Tabela 5-20) e os 18 casos mal classifi cados na amostra de validação.\nDistância de Mahalanobis ao centróide de grupo previsto. Denota a proximidade desses casos mal classifi cados em relação ao grupo previsto. Algumas observações, como o caso 10, obviamente são semelhantes às observações do grupo previsto e não do grupo real. Outras observações, como o caso 57 (distância de Mahalanobis de 6,041), são possivelmente observações atípicas no grupo previsto e no grupo real. O mapa territorial discutido na próxima seção retrata grafi camente a posição de cada observação e auxilia na interpretação das medidas de distância.\nEscores discriminantes. O escore Z discriminante para cada caso em cada função discriminante fornece uma maneira de comparação direta entre casos e um posicio- namento relativo versus as médias de grupos. - Probabilidade de classifi cação. Derivada do emprego das funções discriminantes de classifi cação, a probabili- dade de pertinência para cada grupo é dada. Os valores de probabilidade viabilizam ao pesquisador avaliar a extensão da má classifi cação. Por exemplo, dois casos, 85 e 89, são do mesmo tipo de má classifi cação (grupo real 2 e grupo previsto 3), mas muito diferentes em suas classifi cações quando as probabilidades são focadas. O caso 85 representa uma classifi cação ruim marginal, pois a probabilidade de previsão no grupo real 2 era de 0,462, enquanto no grupo 3 incorretamente previsto ela era um pouco maior (0,529). Esta má classifi cação contrasta com o caso 89, onde a probabilidade do grupo real era de 0,032, e a probabilidade prevista para o grupo 3 (o mal classifi cado) era 0,966. Em ambas as situações de má classifi cação, a extensão ou magnitude varia muito.\n\nA Figura 5-9 mostra cada observação baseada em seus\ndois escores Z discriminantes rotacionados com uma co-\nbertura do mapa territorial que representa as fronteiras\ndos escores de corte para cada função. Ao ver a disper-\nsão de cada grupo em torno do centróide, podemos ob-\nservar várias coisas:\n\nO grupo 3 (Mais de 5 anos) é mais concentrado, com pouca sobreposição com os outros dois grupos, como se mostra na matriz de classifi cação onde apenas uma ob- servação foi mal classifi cada (ver Tabela 5-20).\nO grupo 1 (Menos de 1 ano) é o menos compacto, mas o domínio de casos não se sobrepõe em grande grau com os outros grupos, tornando previsões muito melhores do que poderia ser esperado para um grupo tão variado. Os únicos casos mal classifi cados que são substancial- mente distintos são o caso 10, que é próximo ao centrói- de do grupo 2, e o caso 13, que é próximo ao centróide do grupo 3. Ambos os casos merecem melhor investiga- ção quanto às suas similaridades com outros grupos.\nEstes dois grupos fazem contraste com o grupo 2 (De 1 a 5 anos), que pode ser visto como tendo substancial sobreposição com o grupo 3 e, em menor extensão, com o grupo 1 (Menos de 1 ano). Essa sobreposição resulta nos mais baixos níveis de precisão de classifi cação nas amostras de análise e de teste.\nA sobreposição que ocorre entre os grupos 2 e 3 no centro e à direita no gráfi co sugere a possível existência de um quarto grupo. Uma análise poderia ser levada\n\n( Continuação )\n( Continua )\n\n\n276 Análise Multivariada de Dados\nA representação gráfi ca é útil não apenas para identi- fi car esses casos mal classifi cados que podem formar um novo grupo, mas também para identifi car observações atí- picas. A discussão anterior indica possíveis opções para identifi car observações atípicas (caso 57), bem como a possibilidade de redefi nição de grupos entre os grupos 2 e 3.\n\n\n\nEstágio 5: Interpretação dos resultados\n\n\nda análise discriminante de três grupos\nO próximo estágio da análise discriminante envolve uma sé- rie de passos na interpretação das funções discriminantes.\n\nCalcular as cargas para cada função e rever a rotação das funções para fi ns de simplifi cação da interpretação.\nExaminar as contribuições das variáveis preditoras: (a) a cada função separadamente (ou seja, cargas discriminan- tes), (b) cumulativamente sobre múltiplas funções discri- minantes com o índice de potência, e (c) grafi camente em uma solução bidimensional para entender a posição relativa de cada grupo e a interpretação das variáveis relevantes na determinação dessa posição.\n\n\nCargas discriminantes e suas rotações\nUma vez que as funções discriminantes são calculadas,\nelas são correlacionadas com todas as variáveis indepen-\ndentes, mesmo aquelas não usadas na função discriminan-\nte, para desenvolver uma matriz estrutural (de cargas).\nTal procedimento nos permite ver onde a discriminação\nocorreria se todas as variáveis independentes fossem in-\ncluídas no modelo (ou seja, se nenhuma fosse excluída por\nmulticolinearidade ou falta de signifi cância estatística).\nTABELA 5-21 Previsões mal classifi cadas para casos individuais na análise discriminante de três grupos\nPERTINÊNCIA A\nGRUPO ESCORES DISCRIMINANTES PROBABILIDADE DE CLASSIFICAÇÃO\nIdentifi cação\ndo caso (X 1 ) Real Previsto\nDistância de\nMahalanobis\nao centróidea Função 1 Função 2 Grupo 1 Grupo 2 Grupo 3\nAmostra de análise/estimação\n10 1 2 0,175 0,81755 –1,32387 0,04173 0,93645 0,02182\n8 2 1 1,747 –0,78395 –1,96454 0,75064 0,24904 0,00032\n100 2 1 2,820 –0,70077 –0,11060 0,54280 0,39170 0,06550\n1 2 3 2,947 –0,07613 0,70175 0,06527 0,28958 0,64515\n5 2 3 3,217 –0,36224 1,16458 0,05471 0,13646 0,80884\n37 2 3 3,217 –0,36224 1,16458 0,05471 0,13646 0,80884\n88 2 3 2,390 0,99763 0,12476 0,00841 0,46212 0,52947\n58 3 2 0,727 0,30687 –0,16637 0,07879 0,70022 0,22099\nAmostra de teste/validação\n25 1 2 1,723 –0,18552 –2,02118 0,40554 0,59341 0,00104\n77 1 2 0,813 0,08688 –0,22477 0,13933 0,70042 0,16025\n97 1 2 1,180 –0,41466 –0,57343 0,42296 0,54291 0,03412\n13 1 3 0,576 1,77156 2,26982 0,00000 0,00184 0,99816\n96 1 3 3,428 –0,26535 0,75928 0,09917 0,27855 0,62228\n83 2 1 2,940 –1,58531 0,40887 0,89141 0,08200 0,02659\n23 2 3 0,972 0,61462 0,99288 0,00399 0,10959 0,88641\n34 2 3 1,717 0,86996 0,41413 0,00712 0,31048 0,68240\n39 2 3 0,694 1,59148 0,82119 0,00028 0,08306 0,91667\n41 2 3 2,220 0,30230 0,58670 0,02733 0,30246 0,67021\n42 2 3 0,210 1,08081 1,97869 0,00006 0,00665 0,99330\n55 2 3 1,717 0,86996 0,41413 0,00712 0,31048 0,68240\n57 2 3 6,041 3,54521 0,47780 0,00000 0,04641 0,95359\n62 2 3 4,088 –0,32690 0,52743 0,17066 0,38259 0,44675\n75 2 3 2,947 –0,07613 0,70175 0,06527 0,28958 0,64515\n78 2 3 0,210 1,08081 1,97869 0,00006 0,00665 0,99330\n85 2 3 2,390 0,99763 0,12476 0,00841 0,46212 0,52947\n89 2 3 0,689 0,54850 1,51411 0,00119 0,03255 0,96625\naDistância de Mahalanobis ao centróide do grupo previsto\na cabo para determinar o real intervalo de tempo de\nclientes, talvez com clientes com mais de 1 ano divididos\nem três grupos ao invés de dois.\n( Continuação )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 277\nCargas discriminantes. As cargas não-rotacionadas re- presentam a associação de cada variável independente com cada função, mesmo que não esteja incluída na fun- ção discriminante. Cargas discriminantes, semelhantes às cargas fatoriais descritas no Capítulo 3, são as correla- ções entre cada variável independente e o escore discri- minante.\nA Tabela 5-19 contém a matriz estrutural de cargas não-\nrotacionadas para ambas as funções discriminantes. Se-\nlecionando variáveis com cargas de 0,40 ou acima como\ndescritivas das funções, percebemos que a função 1 tem\ncinco variáveis excedendo 0,40 ( X 9 , X 18 , X 16 , X 11 e X 6 ),\nenquanto quatro variáveis são descritivas da função 2\n( X 6 , X 18 , X 17 e X 9 ). Ainda que pudéssemos usar essas\nvariáveis para descrever cada função, enfrentaríamos o\nproblema de que três variáveis ( X 9 , X 6 e X 18 ) têm car-\ngas duplas (variáveis selecionadas como descritivas de\nambas as funções). Se fôssemos proceder com as cargas\nnão-rotacionadas, cada função compartilharia mais va-\nriáveis com a outra do que teria feito se fosse única.\nA falta de distinção das cargas com cada variável des- critiva de uma só função pode ser abordada com rotação da matriz estrutural, exatamente como foi feito com car- gas fatoriais. Para uma descrição mais detalhada do pro- cesso de rotação, ver Capítulo 3.\nRotação Depois que as cargas da função discriminante são calculadas, elas podem ser rotacionadas para redis- tribuir a variância (esse conceito é melhor explicado no Capítulo 3). Basicamente, a rotação preserva a estrutura\noriginal e a confi abilidade dos modelos discriminantes e\nfacilita consideravelmente a sua interpretação.\nNa presente aplicação, escolhemos o procedimento mais\namplamente usado de rotação VARIMAX. A rotação\nafeta os coefi cientes da função e as cargas discriminan-\ntes, bem como o cálculo dos escores Z discriminantes e\ndos centróides de grupo (ver Tabela 5-19). Examinar os\ncoefi cientes ou as cargas rotacionados versus não-rota-\ncionados revela um conjunto de resultados um pouco\nmais simples (ou seja, as cargas tendem a se separar em\nvalores altos versus baixos, em vez de se limitarem a um\ndomínio intermediário). As cargas rotacionadas permi-\ntem interpretações muito mais distintas de cada função:\n\nA função 1 é agora descrita por três variáveis ( X 18 , X 9 e X 16 ) que formam o fator Serviço ao Cliente de Pós- Venda durante a análise fatorial (ver Capítulo 3 para mais detalhes), mais X 11 e X 17. Assim, o serviço a clien- te, mais linha de produto e fl exibilidade de preço são descritores da função 1.\nA função 2 mostra apenas uma variável, X 6 (Qualidade do produto), que tem uma carga acima de 0,40 para a segunda função. Apesar de X 17 ter um valor abaixo da referência (–0,356), esta variável tem uma carga maior na primeira função, o que a torna um descritor daquela função. Logo, a segunda função pode ser descrita pela variável de Qualidade do produto.\n\nCom duas ou mais funções estimadas, a rotação pode\nser uma poderosa ferramenta que sempre deve ser consi-\nderada para aumentar a interpretabilidade dos resultados.\nEm nosso exemplo, cada uma das variáveis que entrou no\nX 1 - Tipo de cliente\nCentróides de grupo\nMais de 5 anos\nMais de 5 anos\nDe 1 a 5 anos\nDe 1 a 5 anos\nMenos de 1 ano\nMenos de 1 ano\nFunção 2\nFunção 1\nFIGURA 5-9 Mapa territorial para a análise discriminante de três grupos.\n\n\n278 Análise Multivariada de Dados\nprocesso stepwise era descritiva de uma das funções discri- minantes. O que devemos fazer agora é avaliar o impacto de cada variável em termos da análise discriminante geral (i.e., em ambas as funções).\n\n\nAvaliação da contribuição de variáveis preditoras\nTendo descrito as funções discriminantes em termos das variáveis independentes – tanto aquelas que foram usa- das nas funções discriminantes quanto as que não foram incluídas – voltamos nossa atenção para conseguir uma melhor compreensão do impacto das próprias funções, e então das variáveis individuais.\nImpacto das funções individuais. A primeira tarefa é examinar as funções discriminantes em termos de como elas diferenciam entre os grupos.\nComeçamos examinando os centróides de grupos quan-\nto às duas funções como mostrado na Tabela 5-19. Uma\nabordagem mais fácil é através do mapa territorial (Fi-\ngura 5-9):\n\nExaminando os centróides de grupos e a distribuição de casos em cada grupo, percebemos que a função 1 prioritariamente diferencia entre o grupo 1 e os grupos 2 e 3, enquanto a função 2 distingue entre o grupo 3 e os grupos 1 e 2.\nA sobreposição e a má classifi cação dos casos dos grupos 2 e 3 pode ser tratada via o exame da força das funções discriminantes e dos grupos diferenciados por conta de cada uma. Retomando a Tabela 5-19, a função 1 era, de longe, o discriminador mais potente, e ela prio- ritariamente separava o grupo 1 dos demais. A função 2, que separava o grupo 3 dos outros, era muito mais fraca em termos de poder discriminante. Não é surpresa que a maior sobreposição e má classifi cação ocorreriam en- tre os grupos 2 e 3, que são distinguidos principalmente pela função 2.\n\nEssa abordagem gráfi ca ilustra as diferenças nos gru- pos devido às funções discriminantes, mas não fornece uma base para explicar essas diferenças em termos das variáveis independentes. Para avaliar as contribuições das variáveis individuais, o pesquisador conta com várias medidas – cargas discri- minantes, razões F univariadas e o índice de potência. As técnicas envolvidas no uso de cargas discriminantes e de razões F univariadas foram discutidas no exemplo de dois grupos. Examinaremos mais detalhadamente o índice de potência, um método de avaliação da contribuição de uma variável em múltiplas funções discriminantes.\nÍndice de potência. O índice de potência é uma técnica adicional de interpretação muito útil em situações com mais de uma função discriminante. Ele retrata a contribui- ção de cada variável individual em todas as funções discri- minantes em termos de uma única medida comparável.\nO índice de potência refl ete tanto as cargas de cada\nvariável quanto o poder discriminatório relativo de cada\nfunção. As cargas rotacionadas representam a correlação\nentre a variável independente e o escore Z discriminan-\nte. Assim, a carga ao quadrado é a variância na variável\nindependente associada com a função discriminante. Pon-\nderando a variância explicada de cada função via poder\ndiscriminatório relativo da função e somando nas funções,\no índice de potência representa o efeito discriminante to-\ntal de cada variável ao longo de todas as funções discrimi-\nnantes.\nA Tabela 5-22 fornece os detalhes do cálculo do índice\nde potência para cada variável independente. A com-\nparação das variáveis quanto a seus índices de potência\nrevela o seguinte:\n\nX 18 (Velocidade de entrega) é a variável independente responsável pela maior discriminação entre os três tipos de grupos de clientes.\nEla é seguida em termos de impacto por quatro variá- veis não incluídas na função discriminante ( X 9 , X 16 , X 11 e X 17 ).\nA segunda variável na função discriminante ( X 6 ) tem apenas o sexto maior valor de potência. Por que X 6 tem somente o sexto maior valor de po- tência mesmo sendo uma das duas variáveis incluídas na função discriminante?\nPrimeiro, lembre-se que multicolinearidade afeta solu- ções stepwise devido à redundância entre variáveis alta- mente multicolineares. X 9 e X 16 eram as duas variáveis altamente associadas com X 18 (formando o fator Serviço a Clientes), e assim seu impacto em um sentido univa- riado, refl etido no índice de potência, não era neces- sário na função discriminante devido à presença de X 18.\nAs outras duas variáveis, X 11 e X 17 , entraram através do procedimento stepwise , mas foram removidas uma vez que X 6 foi adicionada, novamente devido à multi- colinearidade. Assim, seu maior poder discriminante está refl etido em seus valores de potência ainda que elas não fossem necessárias na função discriminante, uma vez que X 6 foi acrescentada com X 18 na função discriminante.\nFinalmente, X 6 , a segunda variável na função discrimi- nante, tem um baixo valor de potência por ser associada com a segunda função discriminante, que tem relativa- mente pouco impacto discriminante quando comparada com a primeira função. Logo, a despeito de X 6 ser um elemento necessário na discriminação entre os três gru- pos, seu impacto geral é menor do que aquelas variáveis associadas com a primeira função.\n\nLembre-se que os valores de potência podem ser cal-\nculados para todas as variáveis independentes, mesmo\nque não estejam nas funções discriminantes, pois eles são\nbaseados em cargas discriminantes. A meta do índice de\npotência é fornecer interpretação naqueles casos onde\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 279\nTABELA 5-22\nCálculo dos índices de potência para a análise discriminante de três grupos\nFunção discriminante\n1\nFunção discriminante\n2\nVariáveis independentes\nCarga\nCarga ao quadrado\nAutovalor relativo\nValor de potência\nCarga\nCarga ao quadrado\nAutovalor relativo\nValor de potência\nÍndice de potência\nX^6\nQualidade do produto\n–0,257\n0,066\n0,915\n0,060\n0,967\n0,935\n0,085\n0,079\n0,139\nX^7\nAtividades de comércio eletrônico\n0,061\n0,004\n0,915\n0,056\n–0,207\n0,043\n0,085\n0,004\n0,060\nX^8\nSuporte técnico\n0,033\n0,001\n0,915\n0,001\n0,008\n0,000\n0,085\n0,000\n0,001\nX^9\nSolução de reclamação\n0,739\n0,546\n0,915\n0,500\n0,039\n0,002\n0,085\n0,000\n0,500\nX^10\nAnúncio\n0,165\n0,027\n0,915\n0,025\n–0,138\n0,019\n0,085\n0,002\n0,027\nX^11\nLinha do produto\n0,529\n0,280\n0,915\n0,256\n0,137\n0,019\n0,085\n0,002\n0,258\nX^12\nImagem da equipe de venda\n0,061\n0,004\n0,915\n0,004\n–0,198\n0,039\n0,085\n0,003\n0,007\nX^13\nPreços competitivos\n–0,001\n0,000\n0,915\n0,000\n–0,080\n0,006\n0,085\n0,001\n0,001\nX^14\nGarantia e reclamações\n0,081\n0,007\n0,915\n0,006\n0,044\n0,002\n0,085\n0,000\n0,006\nX^15\nNovos produtos\n0,096\n0,009\n0,915\n0,008\n0,080\n0,006\n0,085\n0,001\n0,009\nX^16\nEncomenda e cobrança\n0,546\n0,298\n0,915\n0,273\n0,143\n0,020\n0,085\n0,002\n0,275\nX^17\nFlexibilidade de preço\n0,470\n0,221\n0,915\n0,202\n–0,356\n0,127\n0,085\n0,011\n0,213\nX^18\nVelocidade de entrega\n0,967\n0,935\n0,915\n0,855\n–0,257\n0,066\n0,085\n0,006\n0,861\nNota\n: O autovalor relativo de cada função discriminante é calculado como o autovalor de cada função (mostrado na Tabela 5-19 como 3,950 e 0,365 para as funções discriminantes I e II, res-\npectivamente) dividido pelo total dos autovalores (3,950 + 0,365 = 4,315).\n\n\n280 Análise Multivariada de Dados\nmulticolinearidade ou outros fatores possam ter evitado a inclusão de uma variável na função discriminante.\nUma visão geral das medidas empíricas de impacto. Como visto nas discussões anteriores, o poder discrimi- natório de variáveis em análise discriminante é refl etido em muitas medidas diferentes, cada uma desempenhando um papel único na interpretação dos resultados discrimi- nantes. Combinando todas essas medidas em nossa ava- liação das variáveis, podemos conquistar uma perspectiva bastante eclética sobre como cada variável se ajusta nos resultados discriminantes.\nDe particular interesse é a interpretação das duas di-\nmensões de discriminação. Essa interpretação pode ser\nfeita somente através do exame das cargas, mas é comple-\nmentada por uma representação gráfi ca das cargas discri-\nminantes, como descrito na próxima seção.\nRepresentação gráfi ca de cargas discriminantes. Para\nrepresentar as diferenças em termos das variáveis pre-\nditoras, as cargas e os centróides de grupos podem ser\nrepresentados grafi camente em espaço discriminante re-\nduzido. Como observado anteriormente, a representação\nmais válida é o uso de vetores de atribuição e centróides\nde grupos expandidos.\nTABELA 5-23 Resumo de medidas interpretativas para análise discriminante de três grupos\nCargas rotacionadas de\nfunção discriminante\nFunção 1 Função 2\nRazão F\nunivariada\nÍndice de\npotência\nX 6 Qualidade do produto –0,257 0,967 32,311 0,139\nX 7 Atividades de comércio eletrônico 0,061 –0,207 1,221 0,060\nX 8 Suporte técnico 0,033 0,008 0,782 0,001\nX 9 Solução de reclamação 0,739 0,039 40,292 0,500\nX 10 Anúncio 0,165 –0,138 1,147 0,027\nX 11 Linha do produto 0,529 0,137 32,583 0,258\nX 12 Imagem da equipe de venda 0,061 –0,198 1,708 0,007\nX 13 Preços competitivos –0,001 –0,080 9,432 0,001\nX 14 Garantia e reclamações 0,081 0,044 2,619 0,006\nX 15 Novos produtos 0,096 0,080 0,216 0,009\nX 16 Encomenda e cobrança 0,546 0,143 25,048 0,275\nX 17 Flexibilidade de preço 0,470 –0,356 12,551 0,213\nX 18 Velocidade de entrega 0,967 –0,257 40,176 0,861\nA Tabela 5-23 apresenta as três medidas interpretativas\npreferidas (cargas rotacionadas, razão F univariada e ín-\ndice de potência) para cada variável independente. Os\nresultados apóiam a análise stepwise , apesar de ilustra-\nrem em diversos casos o impacto de multicolinearidade\nsobre os procedimentos e os resultados.\n\nDuas variáveis ( X 9 e X 18 ) têm os maiores impactos indi- viduais como evidenciado por seus valores F univaria- dos. No entanto, como ambas são altamente associadas (como evidenciado por suas inclusões no fator Serviço ao cliente do Capítulo 3), apenas uma será incluída em uma solução stepwise. Ainda que X 9 tenha um valor F univariado marginalmente maior, a habilidade de X 18 fornecer uma melhor discriminação entre todos os gru- pos (como evidenciado por seu maior valor mínimo D^2 de Mahalanobis descrito anteriormente) fez dela a me- lhor candidata para inclusão. Portanto, X 9 , em uma base individual, tem um poder discriminante comparável, mas X 18 será vista funcionando melhor com outras variáveis.\nTrês variáveis adicionais ( X 6 , X 11 e X 16 ) são as próximas com maior impacto, mas apenas uma, X 6 , é mantida na função discriminante. Note que X 16 é altamente correla- cionada com X 18 (ambas parte do fator Serviço ao clien-\n\nte) e não incluída na função discriminante, enquanto X 11\nentrou na mesma, mas foi uma daquelas variáveis remo-\nvidas depois que X 6 foi adicionada.\n\nFinalmente, duas variáveis ( X 17 e X 13 ) tinham quase os mesmos efeitos univariados, mas somente X 17 tinha uma associação substancial com uma das funções discrimi- nantes (uma carga de 0,470 sobre a primeira função). O resultado é que mesmo que X 17 possa ser considerada descritiva da primeira função e tendo um impacto na discriminação baseado nessas funções, X 13 não tem qualquer impacto, seja em associação com essas duas funções, seja em adição uma vez que estas funções sejam explicadas.\nTodas as variáveis remanescentes tinham pequenos valores F univariados e pequenos valores de potência, o que indica pouco ou nenhum impacto tanto no sentido univariado quanto multivariado.\n\nA Tabela 5-24 mostra os cálculos para a expansão das\ncargas discriminantes (usadas para vetores de atribui-\nção) e de centróides de grupos. O processo de represen-\n( Continua )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 281\n\n\n\nEstágio 6: Validação dos\n\n\nresultados discriminantes\nAs razões de sucesso para as matrizes de classifi cação cru-\nzada e de teste podem ser usadas para avaliar a validade\ninterna e externa, respectivamente, da análise discrimi-\nnante. Se as razões de sucesso excederem os valores de\nreferência nos padrões de comparação, então validade é\nestabelecida. Como anteriormente descrito, os valores de\nreferência são 41,7% para o critério de chance proporcio-\nnal e 43,7% para o critério de chance máxima. Os resulta-\ndos de classifi cação mostrados na Tabela 5-20 fornecem o\nseguinte suporte para validade:\nValidade interna é avaliada pelo método de classifi ca-\nção cruzada, onde o modelo discriminante é estimado dei-\nxando um caso de fora e então prevendo aquele caso com\no modelo estimado. Este processo é feito em turnos para\ncada observação, de modo que uma observação jamais in-\nfl uencia o modelo discriminante que prevê sua classifi ca-\nção em algum grupo.\nComo visto na Tabela 5-20, a razão de sucesso geral para\no método de classifi cação cruzada de 86,7 substancialmen-\nte excede ambos os padrões, tanto geral quanto para cada\ngrupo. Contudo, ainda que todos os três grupos também\ntenham razões individuais de sucesso acima dos padrões,\na razão de sucesso do grupo 2 (53,8) é consideravelmente\nmenor do que aquela sobre os outros dois grupos.\ntação gráfi ca sempre envolve todas as variáveis incluídas\nno modelo pelo procedimento stepwise (em nosso exem-\nplo, X 6 e X 18 ). No entanto, também faremos o gráfi co\ndas variáveis não incluídas na função discriminante se\nsuas respectivas razões F univariadas forem signifi can-\ntes, o que adiciona X 9 , X 11 e X 16 ao espaço discriminante\nreduzido. Esse procedimento mostra a importância de\nvariáveis colineares que não foram incluídas no modelo\nstepwise fi nal, semelhante ao índice de potência.\nOs gráfi cos dos vetores de atribuição expandidos\npara as cargas discriminantes rotacionadas são exibidos\nna Figura 5-10. Os vetores do gráfi co nos quais esse pro-\ncedimento foi usado apontam para os grupos que têm a\nmais alta média na respectiva variável independente e\npara a direção oposta dos grupos que têm os mais baixos\nescores médios. Assim, a interpretação do gráfi co na Fi-\ngura 5-10 indica o seguinte:\n\nComo observado no mapa territorial e na análise dos centróides de grupos, a primeira função discriminante distingue entre grupo 1 e grupos 2 e 3, enquanto a se- gunda diferencia o grupo 3 dos grupos 1 e 2.\nA correspondência de X 11 , X 16 , X 9 e X 18 com o eixo X refl ete a associação delas com a primeira função discri- minante, enquanto vemos que somente X 6 é associada com a segunda função discriminante. A fi gura ilustra grafi camente as cargas rotacionadas para cada função e distingue as variáveis descritivas de cada função.\n\nTABELA 5-24 Cálculo dos vetores de atribuição e dos centróides de grupos expandidos no espaço discriminante reduzido\nCargas da função discrimi-\nnante rotacionada\nCoordenadas no\nespaço reduzido\nVariáveis independentes Função 1 Função 2\nRazão F\nunivariada Função 1 Função 2\nX 6 Qualidade do produto –0,257 0,967 32,311 –8,303 31,244\nX 7 Atividades de comércio eletrônicoa 0,061 –0,207 1,221\nX 8 Suporte técnicoa 0,033 0,008 0,782\nX 9 Solução de reclamação 0,739 0,039 40,292 29,776 1,571\nX 10 Anúncioa 0,165 –0,138 1,147\nX 11 Linha do produto 0,529 0,137 32,583 17,236 4,464\nX 12 Imagem da equipe de vendaa 0,061 –0,198 1,708\nX 13 Preços competitivosa –0,001 –0,080 9,432\nX 14 Garantia e reclamaçõesa 0,081 0,044 2,619\nX 15 Novos produtosa 0,096 0,080 0,216\nX 16 Encomenda e cobrança 0,546 0,143 25,048 13,676 3,581\nX 17 Flexibilidade de preçoa 0,470 –0,356 12,551\nX 18 Velocidade de entrega 0,967 –0,257 40,176 38,850 –10,325\naVariáveis com razões univariadas não-signifi cantes não são representadas no espaço reduzido.\nCentróides de grupo Valor F aproximado\nCoordenadas no\nespaço reduzido\nFunção 1 Função 2 Função 1 Função 2 Função 1 Função 2\nGrupo 1: Menos de 1 ano –1,911 –1,274 66,011 56,954 –126,147 –72,559\nGrupo 2: De 1 a 5 anos 0,597 –0,968 66,011 56,954 39,408 –55,131\nGrupo 3: Mais de 5 anos 1,371 1,625 66,011 56,954 90,501 92,550\n( Continuação )\n\n282 Análise Multivariada de Dados\nValidade externa é tratada através da amostra de tes- te, a qual é uma amostra completamente separada que utiliza as funções discriminantes estimadas com a amostra de análise para previsão de grupos.\nEm nosso exemplo, a amostra de teste tem uma ra-\nzão geral de sucesso de 55,0%, o que excede ambos\nos valores de referência, apesar de isso não ocorrer na\nmagnitude encontrada na abordagem de classifi cação\ncruzada. O grupo 2, contudo, não excedeu qualquer\nvalor de referência. Quando as classifi cações ruins são\nanalisadas, percebemos que mais casos são mal classi-\nfi cados no grupo 3 do que corretamente classifi cados\nno grupo 2, o que sugere que esses casos mal classi-\nfi cados sejam examinados diante da possibilidade de\numa redefi nição dos grupos 2 e 3 para que se crie um\nnovo grupo.\nO pesquisador também é encorajado a estender o processo de validação por meio do perfi l dos grupos quanto a conjuntos adicionais de variáveis ou apli- cando a função discriminante em outra(s) amostra(s) representativa(s) da população geral ou de segmentos da mesma. Além disso, a análise de casos mal classifi - cados ajudará a estabelecer se são necessárias variáveis adicionais ou se a classifi cação de grupos dependentes precisa de revisão.\n\n\n\nUma visão gerencial\nA análise discriminante teve por meta entender as dife- renças perceptuais de clientes com base nos intervalos de tempo como clientes da HBAT. Espera-se que o exame de diferenças em percepções HBAT baseadas na constân- cia como clientes identifi que percepções que são críticas\nao desenvolvimento de uma relação de clientela, o que é\ntipifi cado por aqueles clientes de longo prazo. Três grupos\nde clientela foram formados – menos de 1 ano, de 1 a 5\nanos, e mais de 5 anos – e as percepções quanto à HBAT\nforam medidas sobre 13 variáveis. A análise produziu di-\nversas descobertas importantes, tanto em termos dos tipos\nde variáveis que distinguiam entre os grupos quanto nos\npadrões de mudanças ao longo do tempo:\nGrupo 3\nFunção 2\nFunção 1\nGrupo 2\nGrupo 1\nFIGURA 5-10 Gráfi co de vetores de atribuição expandidos (variáveis) no espaço discriminante reduzido.\n\nPrimeiro, há duas dimensões de discriminação entre os três grupos de clientes. A primeira dimensão é tipifi cada por elevadas percepções de serviço aos clientes (Solu- ção de reclamação, Velocidade de entrega e Encomen- da e cobrança), juntamente com Linha do produto e Flexibilidade de preço. Em contraste, a segunda dimen- são é caracterizada somente em termos de Qualidade do produto.\nO perfi l dos três grupos quanto a essas duas dimensões e variáveis associadas com cada dimensão permite à gerência compreender as diferenças perceptuais entre eles.\n\nO grupo 1, clientes há menos de 1 ano, geralmente tem as menores percepções da HBAT. Para as três variáveis de serviço à clientela (Solução de reclamação, Encomenda e cobrança, e Velocidade de entrega), esses clientes têm percepções menores do que em qualquer outro grupo. Para Qualidade de produto, Linha de produto e Preço competitivo, este grupo é comparável com o 2 (de 1 a 5 anos), mas ainda tem percepções menores do que clientes há mais de 5 anos. Somente para Flexibilidade de preço este grupo é comparável com os clientes mais antigos e ambos têm valores menores do que os clientes de 1 a 5 anos. No geral, as percepções desses clientes mais recentes seguem o padrão esperado de serem menores do que outros da clientela, mas é esperado ( Continua )\n\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 283\nAssim, o gerenciamento leva em conta um input para planejamento estratégico e tático não apenas dos resul- tados diretos da análise discriminante, mas também dos erros de classifi cação.\n\n\n\nREGRESSÃO LOGÍSTICA:\n\n\nREGRESSÃO COM UMA VARIÁVEL\n\n\nDEPENDENTE BINÁRIA\nComo discutimos, a análise discriminante é apropriada\nquando a variável dependente é não-métrica. No entanto,\nquando a variável dependente tem apenas dois grupos, a\nregressão logística pode ser preferida por duas razões:\n\nA análise discriminante depende estritamente de se atende- rem as suposições de normalidade multivariada e de igual- dade entre as matrizes de variância-covariância nos grupos\n\nsuposições que não são atendidas em muitas situações. A regressão logística não depende dessas suposições rígidas e é muito mais robusta quando tais pressupostos não são sa- tisfeitos, o que torna sua aplicação apropriada em muitas situações.\n\nMesmo quando os pressupostos são satisfeitos, muitos pes- quisadores preferem a regressão logística por ser similar à regressão múltipla. Ela tem testes estatísticos diretos, tra- tamentos similares para incorporar variáveis métricas e não-métricas e efeitos não-lineares, e uma vasta gama de diagnósticos. Por essas e outras razões mais técnicas, a regressão lo- gística é equivalente à análise discriminante de dois gru- pos e pode ser mais adequada em muitas situações. Nossa discussão de regressão logística não cobre cada um dos seis passos do processo de decisão, mas destaca as diferenças e semelhanças entre a regressão logística e a análise discriminante ou a regressão múltipla. Para uma revisão completa de regressão múltipla, ver o Capítulo 4.\n\n\n\nRepresentação da variável dependente binária\nEm análise discriminante, o caráter não-métrico de uma\nvariável dependente dicotômica é acomodado fazendo-se\nprevisões de pertinência a grupo baseadas em escores Z\ndiscriminantes. Isso requer o cálculo de escores de corte e\na designação de observações a grupos.\nA regressão logística aborda essa tarefa de uma ma-\nneira mais semelhante à encontrada em regressão múlti-\npla. Regressão logística representa os dois grupos de inte-\nresse como uma variável binária com valores de 0 e 1. Não\nimporta qual grupo é designado com o valor de 1 versus\n0, mas tal designação deve ser observada para a interpre-\ntação dos coefi cientes.\n\nSe os grupos representam características (p.ex., sexo), então um grupo pode ser designado com o valor 1 (p.ex., femini- no) e o outro grupo com o valor 0 (p.ex., masculino). Em tal situação, os coefi cientes refl etiriam o impacto das variáveis independentes sobre a probabilidade da pessoa ser do sexo feminino (ou seja, o grupo codifi cado como 1).\nSe os grupos representam resultados ou eventos (p.ex., su- cesso ou fracasso, compra ou não-compra), a designação dos códigos de grupos causa impacto na interpretação também. Considere que o grupo com sucesso é codifi cado como 1, e aquele com fracasso, como 0. Então, os coefi cientes repre-\n\nque melhorem à medida que permanecerem clientes\nao longo do tempo.\n\nO grupo 2, clientes de 1 a 5 anos, tem semelhanças com os clientes mais novos e os mais antigos. Quanto às três variáveis de serviço à clientela, eles são comparáveis ao grupo 3 (mais de 5 anos). Para Qualidade de produto, Linha de produto e Preço competitivo, suas percepções são mais comparáveis com as dos clientes mais novos (e menores do que as dos clientes mais antigos). Eles mantêm as mais elevadas percepções, dos três grupos, quanto à Flexibilidade de preço.\nO grupo 3, representando os clientes há mais de 5 anos, tem as mais favoráveis percepções da HBAT, como o esperado. Apesar de serem comparáveis aos clientes do grupo 2 quanto às três variáveis de serviço à clientela (com ambos os grupos maiores do que o grupo 1), eles são signifi cantemente maiores que os clientes nos outros dois grupos em termos de Qualidade de produto, Linha de produto e Preço competitivo. Assim, este grupo representa aqueles clientes que têm percepções positivas e têm progredido no estabelecimento de uma relação cliente/HBAT através de um fortalecimento de suas percepções.\nUsando os três grupos como indicadores no desenvolvi- mento de relações de clientela, podemos identifi car dois estágios nos quais as percepções HBAT mudam nesse processo de desenvolvimento:\nEstágio 1: O primeiro conjunto de percepções a mudar é aquele relacionado a serviços a clientes (visto nas diferenças entre os grupos 1 e 2). Este estágio refl ete a habilidade da HBAT de afetar positivamente percepções com operações relativas a serviços.\nEstágio 2: Um desenvolvimento de maior prazo é necessário para promover melhoras em elementos mais centrais (Qualidade de produto, Linha de produto e Preço competitivo). Quando ocorrem essas mudanças, o cliente deve se tornar mais comprometido com a relação, como se evidencia por uma longa permanência com a HBAT.\nDeve ser observado que existe evidência de que vários clientes fazem a transição através do estágio 2 mais ra- pidamente do que os cinco anos, como mostrado pelo considerável número de clientes que têm sido do grupo entre 1 e 5 anos, ainda que mantenham as mesmas per- cepções da clientela mais antiga. Assim, HBAT pode esperar que certos clientes possam se deslocar através desse processo muito rapidamente, e uma análise mais detalhada sobre tais clientes pode identifi car caracte- rísticas que facilitam o desenvolvimento de relações com a clientela.\n\n( Continuação )\n\n284 Análise Multivariada de Dados\nsentam os impactos sobre a probabilidade de sucesso. De maneira igualmente fácil, os códigos poderiam ser inverti- dos (1 agora denota fracasso) e os coefi cientes representa- riam as forças que aumentam a probabilidade de fracasso. A regressão logística difere da regressão múltipla, con- tudo, no sentido de que ela foi especifi camente elaborada para prever a probabilidade de um evento ocorrer (ou seja, a probabilidade de uma observação estar no grupo codifi cado como 1). Apesar de os valores de probabilidade serem me- didas métricas, há diferenças fundamentais entre regressão múltipla e logística.\n\n\nUso da curva logística\nComo a variável dependente tem apenas os valores 0 e 1, o valor previsto (probabilidade) deve ser limitado para cair dentro do mesmo domínio. Para defi nir uma relação limi- tada por 0 e 1, a regressão logística usa a curva logística para representar a relação entre as variáveis independen- tes e dependente (ver Figura 5-11). Em níveis muito bai- xos da variável independente, a probabilidade se aproxima de 0, mas nunca alcança tal valor. Analogamente, quan- do a variável independente aumenta, os valores previstos crescem para acima da curva, mas em seguida a inclina- ção começa a diminuir de modo que em qualquer nível da variável independente a probabilidade se aproximará de 1,0, mas jamais excederá tal valor. Como vimos em nos- sas discussões sobre regressão, no Capítulo 4, os modelos lineares de regressão não podem acomodar tal relação, já que ela é inerentemente não-linear. A relação linear de re- gressão, mesmo com termos adicionais de transformações para efeitos não-lineares, não pode garantir que os valores previstos permaneçam no intervalo de 0 a 1.\n\n\nNatureza única da variável dependente\nA natureza binária da variável dependente (0 ou 1) tem propriedades que violam as suposições da regressão múl- tipla. Primeiro, o termo de erro de uma variável discreta segue a distribuição binomial ao invés da normal, invali- dando assim todos os testes estatísticos que se sustentam\nnas suposições de normalidade. Segundo, a variância de\numa variável dicotômica não é constante, criando casos\nde heteroscedasticidade também. Além disso, nenhuma\nviolação pode ser remediada por meio de transformações\ndas variáveis dependente ou independentes.\nA regressão logística foi desenvolvida para lidar espe-\ncifi camente com essas questões. Não obstante, sua relação\núnica entre variáveis dependente e independentes exige\numa abordagem um tanto diferente para estimar a variá-\nvel estatística, avaliar adequação de ajuste e interpretar os\ncoefi cientes, quando comparada com regressão múltipla.\n\n\n\nEstimação do modelo de regressão logística\nA regressão logística tem uma única variável estatística\ncomposta de coefi cientes estimados para cada variável\nindependente – como na regressão múltipla. Tal variável\nestatística é estimada de uma maneira diferente. A regres-\nsão logística deriva seu nome da transformação logit usa-\nda com a variável dependente, criando diversas diferenças\nno processo de estimação (bem como o processo de inter-\npretação discutido na próxima seção).\n\nTransformação da variável dependente\nComo mostrado anteriormente, o modelo logit usa a for-\nma específi ca da curva logística, que é em forma de S para\nfi car no domínio de 0 a 1. Para estimar um modelo de re-\ngressão logística, essa curva de valores previstos é ajustada\naos dados reais, exatamente como foi feito com uma rela-\nção linear em regressão múltipla. No entanto, como os va-\nlores reais dos dados das variáveis dependentes podem ser\nsomente 0 ou 1, o processo é de algum modo diferente.\nNível da variável independente\nProbabilidade do evento(variável dependente)\nAlto\nFIGURA 5-11 Forma da relação logística entre variáveis dependente e independentes.\nA Figura 5-12 retrata dois exemplos hipotéticos de ajus-\nte de uma relação logística aos dados da amostra. Os\ndados reais representam se um evento acontece ou não\ndesignando valores 1 ou 0 aos resultados (neste caso 1 é\ndesignado quando o evento ocorreu, 0 no caso contrário,\n( Continua )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 285\nMas como prevemos pertinência a grupo a partir da\ncurva logística? Para cada observação, a técnica de regres-\nsão logística prevê um valor de probabilidade entre 0 e\n\nO gráfi co dos valores previstos para todos os valores da variável independente gera a curva exibida na Figura 5-12. Tal probabilidade prevista é baseada nos valores das variáveis independentes e nos coefi cientes estimados. Se a probabilidade prevista é maior do que 0,50, então a pre- visão é de que o resultado seja 1 (o evento ocorreu); caso contrário, o resultado é previsto como sendo 0 (o even- to não ocorreu). Retornemos ao nosso exemplo para ver como isso funciona.\n\nmas tal atribuição poderia facilmente ser invertida). Ob-\nservações são representadas pelos pontos no topo ou na\nbase do gráfi co. Esses resultados (que aconteceram ou\nnão) ocorrem em cada valor da variável independente (o\neixo X ). Na parte (a), a curva logística não pode ajustar\nbem os dados porque há diversos valores da variável in-\ndependente que têm ambos os resultados (1 e 0). Neste\ncaso, a variável independente não distingue entre os dois\nresultados, como se mostra na considerável sobreposi-\nção dos dois grupos.\nNo entanto, na parte (b), uma relação muito melhor\ndefi nida está baseada na variável independente. Valores\nmenores da variável independente correspondem às ob-\nservações com 0 para a variável dependente, enquanto\nvalores maiores correspondem bem àquelas observações\ncom um valor 1 sobre a variável dependente. Assim, a\ncurva logística deve ser capaz de ajustar bem os dados.\n(a) Relação pobremente ajustada\n(b) Relação bem definida\nFIGURA 5-12 Exemplos de ajuste da curva logística aos dados da amostra.\nNas partes (a) e (b) da Figura 5-12, um valor de 6,0 para\nX (a variável independente) corresponde a uma proba-\nbilidade de 0,50. Na parte (a), podemos ver que diversas\nobservações de ambos os grupos recaem em ambos os\nlados deste valor, resultando em diversas classifi cações\n( Continuação )\n( Continua )\n\n\n286 Análise Multivariada de Dados\nLogo, com uma curva logística estimada, podemos es- timar a probabilidade para qualquer observação com base em seus valores para as variáveis independentes e então prever a pertinência a grupo usando 0,50 como valor de corte. Uma vez que temos a pertinência prevista, podemos criar uma matriz de classifi cação exatamente como foi fei- to em análise discriminante e avaliar a precisão preditiva.\n\n\nEstimação dos coefi cientes\nDe onde vem a curva? Em regressão múltipla, estimamos uma relação linear que melhor ajusta os dados. Em re- gressão logística, seguimos o mesmo processo de previ- são da variável dependente por uma variável estatística composta dos coefi cientes logísticos e as correspondentes variáveis independentes. No entanto, o que difere é que em regressão logística os valores previstos jamais podem estar fora do domínio de 0 a 1. Apesar de uma discussão completa sobre os aspectos conceituais e estatísticos en- volvidos no processo de estimação estar além do escopo deste texto, diversas fontes excelentes com tratamentos completos sobre tais aspectos estão disponíveis [3,15,17]. Podemos descrever o processo de estimação em dois pas- sos básicos à medida que introduzimos alguns termos co- muns e fornecemos uma breve visão geral do processo.\nTransformação de uma probabilidade em razão de desi- gualdade e valores logit. Como na regressão múltipla, a regressão logística prevê uma variável dependente métri- ca, neste caso valores de probabilidade restritos ao domí- nio entre 0 e 1. Mas como podemos garantir que valores estimados não recaiam fora desse domínio? A transfor- mação logística perfaz este processo em dois passos.\nReestabelecimento de uma probabilidade como ra- zão de desigualdades. Em sua forma original, probabi- lidades não são restritas a valores entre 0 e 1. Portanto, o que aconteceria se reestabelecêssemos a probabilidade de uma maneira que a nova variável sempre fi casse entre 0 e 1? Fazemos isso expressando uma probabilidade como razão de desigualdades – a razão entre as probabilidades dos dois resultados ou eventos, Prob i /( 1 – Prob i ). Desta forma, qualquer valor de probabilidade é agora dado em uma variável métrica que pode ser diretamente estima- da. Qualquer razão de desigualdade pode ser convertida reciprocamente em uma probabilidade que fi ca entre 0 e\n\nResolvemos nosso problema de restrição dos valores previstos entre 0 e 1 prevendo a razão de desigualdades e então convertendo a mesma em uma probabilidade.\n\nUsemos alguns exemplos da probabilidade de sucesso\nou fracasso para ilustrar como a razão de desigualdades\né calculada. Se a probabilidade de sucesso é 0,80, então\nsabemos também que a probabilidade do resultado alter-\nnativo (ou seja, o fracasso) é 0,20 (0,20 = 1,0 – 0,80). Esta\nprobabilidade signifi ca que as desigualdades de sucesso\nsão 4,0 (0,80/0,20), ou que o sucesso é quatro vezes mais\nprovável de acontecer do que o fracasso. Reciprocamen-\nte, podemos estabelecer as desigualdades de fracasso\ncomo 0,25 (0,20/0,80), ou, em outras palavras, o fracasso\nacontece a um quarto da taxa de sucesso. Assim, qual-\nquer que seja o resultado que busquemos (sucesso ou\nfracasso), podemos estabelecer a probabilidade como\numa chance ou uma razão de desigualdades.\nComo você provavelmente já desconfi ou, uma proba-\nbilidade de 0,50 resulta em razão de desigualdades de 1,0\n(ambos os resultados têm iguais chances de ocorrerem).\nRazão de desigualdades inferior a 1,0 representa proba-\nbilidades menores do que 0,50, e razão de desigualdades\nmaior do que 1,0 corresponde a uma probabilidade maior\ndo que 0,50. Agora temos uma variável métrica que sem-\npre pode ser convertida de volta a uma probabilidade en-\ntre 0 e 1.\nCálculo do valor logit. A variável de razão de desi-\ngualdades resolve o problema de fazer estimativas de pro-\nbabilidade entre 0 e 1, mas temos outro problema: como\nfazemos com que as razões de desigualdades fi quem abai-\nxo de 0, que é o limite inferior (não há limite superior).\nA solução é computar aquilo que é chamado de valor lo-\ngit – calculado via logaritmo das razões de desigualdades.\nRazões menores que 1,0 têm um logit negativo, razões\nmaiores que 1,0 têm valores logit positivos, e a razão de\ndesigualdades igual a 1,0 (correspondente a uma proba-\nbilidade de 0,5) tem um valor logit de 0. Além disso, não\nimporta o quão baixo o valor negativo fi que, ele ainda\npode ser transformado tomando-se o anti-logaritmo em\numa razão de desigualdades maior que 0. O que se segue\nmostra alguns valores típicos de probabilidade e as razões\nde desigualdades correspondentes, bem como valores lo-\ngarítmicos.\nProbabilidade\nRazão de\ndesigualdades\nLogaritmo\n(Logit)\n0,00 0,00 NC\n0,10 0,111 –2,197\n0,30 0,428 –0,847\n0,50 1,000 0,000\n0,70 2,333 0,847\n0,90 9,000 2,197\n1,00 NC NC\nNC = Não pode ser calculado\nruins. As classifi cações ruins são mais perceptíveis para\no grupo com valores 1,0, ainda que diversas observações\nno outro grupo (variável dependente = 0,0) também se-\njam mal classifi cadas. Na parte (b), fazemos classifi cação\nperfeita dos dois grupos quando usamos o valor de pro-\nbabilidade de 0,50 como valor de corte.\n( Continuação )\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 287\nCom o valor logit, agora temos uma variável métrica que pode ter valores positivos e negativos, mas que sem- pre pode ser transformada de volta em um valor de pro- babilidade entre 0 e 1. Observe, no entanto, que o logit jamais pode realmente alcançar 0 ou 1. Esse valor agora se torna a variável dependente do modelo de regressão logística.\nEstimação do modelo. Uma vez que compreendemos como interpretar os valores das razões de desigualdades ou das medidas logit, podemos proceder com o uso delas como medida dependente em nossa regressão logística. O processo de estimação dos coefi cientes logísticos é se- melhante àquele usado em regressão, apesar de que nes- te caso somente dois valores reais são empregados para a variável dependente (0 e 1). Além do mais, em vez de usar os mínimos quadrados ordinários como meio para estimar o modelo, o método de verossimilhança máxima é utilizado.\nEstimação dos coefi cientes. Os coefi cientes esti- mados para as variáveis independentes são estimados usando-se o valor logit ou a razão de desigualdades como medida dependente. Cada uma dessas formulações de modelo é exibida aqui:\nou\nAmbas as formulações de modelo são equivalentes, mas aquela que for escolhida afetará a estimação dos co- efi cientes. Muitos programas de computador fornecem os coefi cientes logísticos em ambas as formas, de modo que o pesquisador deve entender como interpretar cada forma. Discutimos aspectos interpretativos em uma seção posterior. Este processo pode acomodar uma ou mais variáveis independentes, e estas podem ser métricas ou não-métri- cas (binárias). Como vemos adiante em nossa discussão sobre interpretação dos coefi cientes, ambas as formas dos mesmos refl etem a direção e a magnitude da relação, mas são interpretadas de maneiras distintas.\nUso da máxima verossimilhança para estima- ção. Regressão múltipla emprega o método de mínimos quadrados, que minimiza a soma das diferenças quadradas entre os valores reais e previstos da variável dependente. A natureza não-linear da transformação logística requer que outro procedimento, o da máxima verossimilhança,\nseja usado de maneira iterativa para que se encontrem as\nestimativas mais prováveis para os coefi cientes. No lugar\nde minimizar os desvios quadrados (mínimos quadrados),\na regressão logística maximiza a probabilidade de que\num evento ocorra. O valor de probabilidade, ao invés da\nsoma de quadrados, é em seguida usado quando se calcula\numa medida de ajuste geral do modelo. Usar esta técnica\nalternativa de estimação também demanda que avaliemos\no ajuste do modelo de diferentes maneiras.\n\n\n\nAvaliação da qualidade do ajuste\n\n\ndo modelo de estimação\nA qualidade de ajuste para um modelo de regressão lo-\ngística pode ser avaliada de duas maneiras. Uma é a ava-\nliação de ajuste usando valores “pseudo” R^2 , semelhantes\nàqueles encontrados em regressão múltipla. A segunda\nabordagem é examinar precisão preditiva (como a matriz\nde classifi cação em análise discriminante). As duas técni-\ncas examinam ajuste de modelo sob diferentes perspecti-\nvas, mas devem conduzir a conclusões semelhantes.\n\nAjuste de estimação do modelo\nA medida básica do quão bem o procedimento de esti-\nmação de máxima verossimilhança se ajusta é o valor de\nverossimilhança , semelhante aos valores das somas de\nquadrados usadas em regressão múltipla. Regressão logís-\ntica mede o ajuste da estimação do modelo com o valor –2\nvezes o logaritmo do valor da verossimilhança, chamado\nde –2 LL ou –2log verossimilhança. O valor mínimo para\n–2 LL é 0, o que corresponde a um ajuste perfeito (veros-\nsimilhança = 1 e –2 LL é então 0). Assim, quanto menor\no valor –2 LL , melhor o ajuste do modelo. Como será dis-\ncutido na próxima seção, o valor –2 LL pode ser usado\npara comparar equações quanto à variação no ajuste ou\nser utilizado para calcular medidas comparáveis ao R^2 em\nregressão múltipla.\nEntre comparações de modelos. O valor de verossimi-\nlhança pode ser comparado entre equações para avaliar a\ndiferença em ajuste preditivo de uma equação para outra,\ncom testes estatísticos para a signifi cância dessas diferen-\nças. O método básico segue três passos:\n1. Estimar um modelo nulo. O primeiro passo é calcular um modelo nulo, que atua como a referência para fazer com- parações de melhoramento no ajuste do modelo. O modelo nulo mais comum é um sem variáveis independentes, que é semelhante a calcular a soma total de quadrados usando somente a média em regressão múltipla. A lógica por trás desta forma de modelo nulo é que ele pode atuar como uma referência em relação à qual qualquer modelo contendo va- riáveis independentes pode ser comparado. 2. Estimar o modelo proposto. Este modelo contém as variá- veis independentes a serem incluídas no modelo de regres- são logística. Espera-se que o ajuste melhorará em relação ao modelo nulo e que resulte em um valor menor de – 2 LL.\n\n\n288 Análise Multivariada de Dados\nQualquer número de modelos propostos pode ser estimado\n(p.ex., modelos com uma, duas e três variáveis independen-\ntes podem ser propostas distintas).\n3. Avaliar a diferença –2LL. O passo fi nal é avaliar a signifi - cância estatística do valor – 2 LL entre os dois modelos (nulo versus proposto). Se os testes estatísticos suportam diferen- ças signifi cantes, então podemos estabelecer que o conjunto de variáveis independentes no modelo proposto é signifi - cante na melhora do ajuste da estimação do mesmo. De maneira semelhante, comparações também po- dem ser feitas entre dois modelos propostos quaisquer. Em tais casos, a diferença – 2 LL refl ete a diferença em ajuste de modelo devido a distinções de especifi cações. Por exemplo, um modelo com duas variáveis indepen- dentes pode ser comparado com um modelo de três va- riáveis independentes para que se avalie a melhora pelo acréscimo de uma variável. Nesses casos, um modelo é escolhido para atuar como nulo e então é comparado com outro.\nPor exemplo, considere que queremos testar a signifi -\ncância de um conjunto de variáveis independentes cole-\ntivamente para ver se elas melhoram o ajuste do modelo.\nO modelo nulo seria especifi cado como um modelo sem\nessas variáveis, e o modelo proposto incluiria as variá-\nveis a serem avaliadas. A diferença em – 2 LL signifi caria\na melhora a partir do conjunto de variáveis independen-\ntes. Poderíamos fazer testes similares das diferenças em\n- 2 LL entre outros pares de modelos variando o número de variáveis independentes incluídas em cada um.\nO teste do qui-quadrado e o teste associado para sig- nifi cância estatística são usados para se avaliar a redução no logaritmo do valor de verossimilhança. No entanto, esses testes estatísticos são particularmente sensíveis a ta- manho de amostra (para amostras pequenas é mais difícil mostrar signifi cância estatística, e vice-versa para grandes amostras). Portanto, pesquisadores devem ser particular- mente cuidadosos ao tirarem conclusões com base apenas na signifi cância do teste do qui-quadrado em regressão logística.\nMedidas pseudo R^2. Além dos testes qui-quadrado, diversas medidas do tipo R^2 foram desenvolvidas e são apresentadas em vários programas estatísticos para repre- sentarem ajuste geral do modelo. Essas medidas pseudo R^2 são interpretadas de uma maneira parecida com o co- efi ciente de determinação em regressão múltipla. Um va- lor pseudo R^2 pode ser facilmente obtido para regressão logística semelhante ao valor R^2 em análise de regressão [6]. O pseudo R^2 para um modelo logit ( R^2 logit ) pode ser calculado como\nExatamente como na contraparte da regressão múl-\ntipla, o valor R^2 logit varia de 0,0 a 1,0. À medida que o\nmodelo proposto aumenta o ajuste, o – 2 LL diminui. Um\najuste perfeito tem um valor de − 2 LL igual a 0,0 e um\nR^2 LOGIT de 1,0.\nDuas outras medidas são semelhantes ao valor pseudo\nR^2 e são geralmente categorizadas também como medidas\npseudo R^2. A medida R^2 de Cox e Snell opera do mes-\nmo modo, com valores maiores indicando maior ajuste do\nmodelo. No entanto, esta medida é limitada no sentido de\nque não pode atingir o valor máximo de 1, de forma que\nNagelkerke propôs uma modifi cação que tinha o domínio\nde 0 a 1. Essas duas medidas adicionais são interpretadas\ncomo refl etindo a quantia de variação explicada pelo mo-\ndelo logístico, com 1,0 indicando ajuste perfeito.\nUma comparação com regressão múltipla. Ao discutir\nos procedimentos para avaliação de ajuste de modelo em\nregressão logística, fazemos várias referências a similari-\ndades com regressão múltipla em termos de diversas me-\ndidas de ajuste. Na tabela a seguir, mostramos a corres-\npondência entre conceitos usados em regressão múltipla e\nsuas contrapartes em regressão logística.\nCorrespondência de elementos primários de\najuste de modelo\nRegressão múltipla Regressão logística\nSoma total de quadrados –2 LL do modelo base\nSoma de quadrados do erro–2 LL do modelo proposto\nSoma de quadrados da\nregressão\nDiferença de – LL* para\nmodelos base e proposto\nTeste F de ajuste de mo-\ndelo\nTeste de qui-quadrado da\ndiferença –2 LL\nCoefi ciente de determina-\nção ( R^2 )\nMedidas pseudo R^2\nComo podemos ver, os conceitos de regressão múltipla\ne regressão logística são semelhantes. Os métodos básicos\npara testar ajuste geral do modelo são comparáveis, com\nas diferenças surgindo dos métodos de estimação nas duas\ntécnicas.\n\n\nPrecisão preditiva\nAssim como emprestamos o conceito de R^2 da regressão\ncomo uma medida de ajuste geral de modelo, podemos pro-\ncurar na análise discriminante a medida de precisão prediti-\nva geral. As duas técnicas mais comuns são a matriz de clas-\nsifi cação e as medidas de ajuste baseadas no qui-quadrado.\nMatriz de classifi cação. Esta técnica de matriz de classi-\nfi cação é idêntica àquela usada em análise discriminante,\nou seja, medir o quão bem a pertinência a grupo é prevista\ne desenvolver uma razão de sucesso. O caso da regressão\n* N. de R. T.: A frase correta seria “Diferença de –2LL”.\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 289\nlogística sempre incluirá somente dois grupos, mas todas as medidas relacionadas a chances (p.ex., chance máxima, chance proporcional ou Q de Press) usadas anteriormente são aplicáveis aqui também.\nMedida baseada no qui-quadrado. Hosmer e Lemeshow [11] desenvolveram um teste de classifi cação no qual os casos são primeiramente divididos em aproximadamen- te 10 classes iguais. Em seguida, os números de eventos reais e previstos são comparados em cada classe com a estatística qui-quadrado. Esse teste fornece uma medida ampla de precisão preditiva que é baseada não no valor de verossimilhança, mas sim na real previsão da variável dependente. O uso apropriado desse teste requer um ta- manho de amostra de pelo menos 50 casos para garantir que cada classe tenha pelo menos cinco observações e ge- ralmente até mesmo uma amostra maior, uma vez que o número de eventos previstos nunca fi ca abaixo de 1. Além disso, a estatística qui-quadrado é sensível a tamanho da amostra, permitindo assim que essa medida encontre di- ferenças muito pequenas, estatisticamente signifi cantes, quando o tamanho da amostra se torna grande. Tipicamente examinamos tantas dessas medidas de ajuste de modelo quanto possível. Espera-se que uma con- vergência de indicações dessas medidas forneça o suporte necessário ao pesquisador para a avaliação do ajuste geral do modelo.\n\n\n\nTeste da signifi cância dos coefi cientes\nA regressão logística testa hipóteses sobre coefi cientes in- dividuais, como se faz na regressão múltipla. Em regressão múltipla, o teste estatístico era para ver se o coefi ciente era signifi cantemente diferente de 0. Um coefi ciente nulo indi- ca que o mesmo não tem impacto sobre a variável depen- dente. Em regressão logística, usamos também um teste estatístico para ver se o coefi ciente logístico é diferente de\n\nLembre, contudo, que em regressão logística usando o logit como medida dependente, um valor de 0 corresponde à razão de desigualdade de 1,00 ou uma probabilidade de 0,50 – valores que indicam que a probabilidade é igual para cada grupo (i.e., novamente nenhum efeito da variável in- dependente sobre a previsão de pertinência ao grupo). Em regressão múltipla, o valor t é utilizado para ava- liar a signifi cância de cada coefi ciente. Regressão logística usa uma estatística diferente, a estatística Wald. Ela provê a signifi cância estatística para cada coefi ciente estimado de forma que testes de hipóteses podem ocorrer exatamente como se faz em regressão múltipla. Se o coefi ciente logísti- co é estatisticamente signifi cante, podemos interpretá-lo em termos de como o mesmo impacta a probabilidade estimada e conseqüentemente a previsão de pertinência a grupo.\n\n\n\nInterpretação dos coefi cientes\nUma das vantagens da regressão logística é que precisa- mos saber apenas se um evento (compra ou não, risco de\ncrédito ou não, falência de empresa ou sucesso) ocorreu\nou não para defi nir um valor dicotômico como nossa va-\nriável dependente. No entanto, quando analisamos es-\nses dados usando transformação logística, a regressão e\nseus coefi cientes assumem um signifi cado algo diferente\ndaqueles encontrados na regressão com uma variável de-\npendente métrica. Analogamente, cargas discriminantes\nde uma análise discriminante de dois grupos são interpre-\ntadas diferentemente a partir de um coefi ciente logístico.\nA partir do processo de estimação descrito anterior-\nmente, sabemos que os coefi cientes ( B 0 , B 1 , B 2 , ..., Bn )\nsão na verdade medidas das variações na proporção das\nprobabilidades (as razões de desigualdades). No entanto,\ncoefi cientes logísticos são difíceis de interpretar em sua\nforma original, pois eles são expressos em termos de lo-\ngaritmos quando usamos o logit como a medida depen-\ndente. Assim, a maioria dos programas de computador\nfornece também um coefi ciente logístico exponenciado ,\nque é apenas uma transformação (anti-logaritmo) do co-\nefi ciente logístico original. Desse modo, podemos usar os\ncoefi cientes logísticos originais ou exponenciados para a\ninterpretação. Os dois tipos de coefi cientes logísticos dife-\nrem no sentido da relação da variável independente com\nas duas formas da dependente, como mostrado aqui:\nCoefi ciente logístico Refl ete mudanças em...\nOriginal Logit (logaritmo da razão\nde desigualdades)\nExponenciado Razão de desigualdades\nDiscutimos na próxima seção como cada forma do\ncoefi ciente refl ete direção e magnitude da relação da va-\nriável independente, mas requer diferentes métodos de\ninterpretação.\n\nDireção da relação\nA direção da relação (positiva ou negativa) refl ete as mu-\ndanças na variável dependente associadas com mudanças\nna independente. Uma relação positiva signifi ca que um\naumento na variável independente é associado com um\naumento na probabilidade prevista, e vice-versa para uma\nrelação negativa. Veremos que a direção da relação é re-\nfl etida diferentemente nos coefi cientes logísticos original\ne exponenciado.\nInterpretação da direção de coefi cientes originais. O si-\nnal dos coefi cientes originais (positivo ou negativo) indica\na direção da relação, como foi visto nos coefi cientes de\nregressão. Um valor positivo aumenta a probabilidade,\nenquanto um negativo diminui a mesma, pois os coefi -\ncientes originais são expressos em termos de valores logit,\nonde um valor de 0,0 corresponde a um valor de razão de\ndesigualdade de 1,0 e uma probabilidade de 0,50. Assim,\nnúmeros negativos são relativos a razões de desigualdades\nmenores que 1,0 e probabilidades menores que 0,50.\n\n\n290 Análise Multivariada de Dados\nInterpretação da direção de coefi cientes exponenciados. Coefi cientes exponenciados devem ser interpretados di- ferentemente, pois eles são os logaritmos dos coefi cientes originais. Considerando o logaritmo, estamos na verdade estabelecendo o coefi ciente exponenciado em termos de razões de desigualdades, o que signifi ca que exponencia- dos não terão valores negativos. Como o logaritmo de 0 (sem efeito) é 1,0, um coefi ciente exponenciado igual a 1,0 na verdade corresponde a uma relação sem direção. Assim, coefi cientes exponenciados acima de 1,0 refl etem uma relação positiva, e valores menores que 1,0 represen- tam relações negativas.\nUm exemplo de interpretação. Examinemos um exem- plo simples para ver o que queremos dizer em termos de diferenças entre as duas formas de coefi cientes logísticos.\nSe Bi (o coefi ciente original) é positivo, sua transforma-\nção (exponencial do coefi ciente) será maior que 1, o que\nsignifi ca que a razão de desigualdade aumentará para\nqualquer variação positiva da variável independente. As-\nsim, o modelo tem uma maior probabilidade prevista de\nocorrência. De modo semelhante, se Bi é negativo, o coe-\nfi ciente exponenciado é menor que um e a razão de desi-\ngualdades diminui. Um coefi ciente de zero se iguala a um\nvalor de 1,0 no coefi ciente exponenciado, o que resulta\nem nenhuma mudança na razão de desigualdades.\nUma discussão mais detalhada da interpretação de coefi cientes, transformação logística e procedimentos de estimação pode ser encontrada em diversos textos [11].\n\n\nMagnitude da relação\nPara determinar quanto da probabilidade mudará dada uma variação de uma unidade na variável independente, o valor numérico do coefi ciente deve ser avaliado. Exa- tamente como na regressão múltipla, os coefi cientes para variáveis métricas e não-métricas devem ser interpretados de forma diferenciada, pois cada um refl ete diferentes im- pactos sobre a variável dependente.\nInterpretação da magnitude de variáveis independentes métricas. Para variáveis métricas, a questão é: quanto a probabilidade estimada varia por conta de uma varia- ção unitária na variável independente? Em regressão múltipla, sabíamos que o coefi ciente de regressão era o coefi ciente angular da relação linear entre a medida independente e a dependente. Um coefi ciente de 1,35 indicava que a variável dependente aumentava 1,35 uni- dades cada vez que a variável independente aumentava uma unidade. Em regressão logística, sabemos que te- mos uma relação não-linear limitada entre 0 e 1, e assim os coefi cientes devem ser interpretados de forma dife- rente. Além disso, temos os dois coefi cientes original e exponenciado para considerar.\nCoefi cientes logísticos originais. Apesar de mais\napropriados para determinarem a direção da relação, os\ncoefi cientes logísticos originais são menos úteis na deter-\nminação da magnitude da relação. Eles refl etem a varia-\nção no valor logit (logaritmo da razão de desigualdades),\numa unidade de medida particularmente não compreen-\nsível na representação do quanto as probabilidades real-\nmente variam.\nCoefi cientes logísticos exponenciados. Coefi cien-\ntes exponenciados refl etem diretamente a magnitude da\nvariação no valor da razão de desigualdades. Por serem\nexpoentes, eles são interpretados de maneira ligeiramen-\nte diferente. Seu impacto é multiplicativo, o que signifi ca\nque o efeito do coefi ciente não é adicionado à variável\ndependente (a razão de desigualdades), mas multiplica-\ndo para cada variação unitária na variável independente.\nComo tal, um coefi ciente exponenciado de 1,0 denota\nmudança nenhuma (1,0 × variável independente = mu-\ndança nenhuma). Este resultado corresponde à nossa\ndiscussão anterior, onde coefi cientes exponenciados me-\nnores que 1,0 refl etem relações negativas, enquanto va-\nlores acima de 1,0 denotam relações positivas.\nUm exemplo de avaliação da magnitude de variação.\nTalvez uma abordagem mais fácil para determinar a\nquantia de variação na probabilidade a partir desses va-\nlores seja como se segue:\nMudança percentual na razão de desigualdades =\n(coefi ciente exponenciado i – 1,0) × 100\nOs exemplos a seguir ilustram como calcular a varia-\nção de probabilidade devido a uma variação unitária na\nvariável independente para um domínio de coefi cientes\nexponenciados:\nValor\nCoefi ciente expo-\nnenciado ( e b i )\n\n0,20 0,50 1,0 1,5 1,7\ne b i – 1,0 $0,80 $0,50 0,0 0,50 0,70\nVariação percentu-\nal na razão de desi-\ngualdades\n\n\n$80% $50% 0% 50% 70%\nSe o coefi ciente exponenciado é 0,20, uma mudança\nde uma unidade na variável independente reduzirá a\nrazão de desigualdades em 80% (o mesmo se a razão\nde desigualdades fosse multiplicada por 0,20). Analo-\ngamente, um coefi ciente exponenciado de 1,5 denota\num aumento de 50% na razão de desigualdades.\nUm pesquisador que conhece a razão de desigualda-\ndes existente e deseja calcular o novo valor dessa razão\n\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 291\npara uma mudança na variável independente pode fazê-lo diretamente através do coefi ciente exponenciado, como se segue:\nNovo valor de razão de desigualdade = Valor antigo × Coefi ciente exponenciado × Variação na variável independente Usemos um exemplo simples para ilustrar a maneira como o coefi ciente exponenciado afeta o valor da razão de desigualdades.\nConsidere que a razão de desigualdade é 1,0 (ou seja,\n50-50) quando a variável independente tem um valor de\n5,5 e o coefi ciente exponenciado é 2,35. Sabemos que se\neste coefi ciente for maior do que 1,0, então a relação é\npositiva, mas gostaríamos de saber o quanto a razão de\ndesigualdades mudaria. Se esperamos que o valor da va-\nriável independente aumente 1,5 pontos para 7,0, pode-\nmos calcular o seguinte:\nNova razão de desigualdades = 1,0 × 2,35\n× (7,0 – 5,5)! 3,525\nRazões de desigualdades podem ser traduzidas em\ntermos de valores de probabilidade pela fórmula simples\nde Probabilidade = Razão de desigualdades/(1+Razão\nde desigualdades). Logo, a razão de 3,525 se traduz em\numa probabilidade de 77,9% (3,25/(1 + 3,25)= 0,779), in-\ndicando que um aumento na variável independente de\num ponto e meio aumenta a probabilidade de 50% para\n78%, um aumento de 28%.\nA natureza não-linear da curva logística é demons-\ntrada, porém, quando novamente aplicamos o mesmo\naumento à razão de desigualdades. Dessa vez, considere\nque a variável independente aumenta mais 1,5 pontos,\npara 8,5. Podemos esperar que a probabilidade aumente\noutros 28%? Não, pois isso faria a probabilidade ultra-\npassar os 100% (78% + 28% = 106%). Assim, o aumen-\nto ou diminuição da probabilidade diminui à medida que\na curva se aproxima, mas jamais alcança, os dois pontos\nextremos (0 e 1). Neste exemplo, outro aumento de 1,5\ncria um novo valor de razão de desigualdades de 12,426,\ntraduzindo-se como uma razão de desigualdades de\n92,6%, um aumento de 14%. Observe que neste caso de\naumento de probabilidade a partir de 78%, o aumento\nna mesma para a variação de 1,5 na variável indepen-\ndente é metade (14%) daquilo que foi para o mesmo au-\nmento quando a probabilidade era de 50%.\nO pesquisador pode descobrir que coefi cientes expo- nenciados são bastante úteis não apenas na avaliação do impacto de uma variável independente, mas no cálculo da magnitude dos efeitos.\nInterpretação da magnitude para variáveis independentes não-métricas (dicotômicas). Como discutimos em re-\ngressão múltipla, variáveis dicotômicas representam uma\núnica categoria de uma variável não-métrica (ver Capítulo\n4 para uma discussão mais detalhada sobre o tema). Como\ntais, elas não são como variáveis métricas que variam em\num intervalo de valores, mas assumem apenas os valores\nde 1 ou 0, indicando a presença ou ausência de uma carac-\nterística. Como vimos na discussão anterior para variáveis\nmétricas, os coefi cientes exponenciados são a melhor ma-\nneira de interpretar o impacto da variável dicotômica, mas\nsão interpretados diferentemente das variáveis métricas.\nSempre que uma variável dicotômica é usada, é essen-\ncial notar a categoria de referência ou omitida. Em uma\nmaneira semelhante à interpretação em regressão, o co-\nefi ciente exponenciado representa o nível relativo da va-\nriável dependente para o grupo representado versus o\ngrupo omitido. Podemos estabelecer essa relação como se\nsegue:\nUsemos um exemplo simples de dois grupos para ilus-\ntrar esses pontos.\nSe a variável não-métrica é sexo, as duas possibilidades\nsão masculino e feminino. A variável dicotômica pode\nser defi nida como representando homens (i.e., valor 1 se\nfor homem e 0 se for mulher) ou mulheres (i.e., valor\n1 se for mulher e 0 se for homem). Qualquer que seja\no caminho escolhido, porém, ele se determina como o\ncoefi ciente é interpretado. Consideremos que um valor\n1 é dado às mulheres, fazendo com que o coefi ciente\nexponenciado represente o percentual da razão de de-\nsigualdades de mulheres comparada com homens. Se o\ncoefi ciente é 1,25, então as mulheres têm uma razão de\ndesigualdades 25% maior do que os homens (1,25 – 1,0 =\n0,25). Analogamente, se o coefi ciente é 0,80, então a ra-\nzão de desigualdades para mulheres é 20% menor (0,80\n\n1,0 = – 0,20) do que para os homens.\n\n\n\nCálculo de probabilidades para um valor\n\n\nespecífi co da variável independente\nNa discussão anterior da distribuição assumida de possí-\nveis variáveis dependentes, descrevemos uma curva em\nforma de S, ou logística. Para representar a relação entre\nas variáveis dependente e independentes, os coefi cientes\ndevem, na verdade, representar relações não-lineares\nentre as variáveis dependente e independentes. Apesar\nde o processo de transformação que envolve logaritmos\nfornecer uma linearização da relação, o pesquisador deve\nlembrar que os coefi cientes na verdade correspondem a\ndiferentes coefi cientes angulares na relação ao longo dos\nvalores da variável independente. Desse modo, a distri-\nbuição em forma de S pode ser estimada. Se o pesquisa-\n\n\n292 Análise Multivariada de Dados\ndor estiver interessado no coefi ciente angular da relação em vários valores da variável independente, os coefi cien- tes podem ser calculados e a relação, avaliada [6].\n\n\nVisão geral da interpretação dos coefi cientes\nA similaridade dos coefi cientes com aqueles encontrados em regressão múltipla tem sido uma razão prioritária para a popularidade da regressão logística. Como vimos na dis- cussão anterior, muitos aspectos são bastante semelhan- tes, mas o caráter único da variável dependente (a razão de desigualdades) e a forma logarítmica da variável esta- tística (necessitando uso dos coefi cientes exponenciados) requer uma abordagem de algum modo de interpretação diferente. O pesquisador, contudo, ainda tem a habilidade para avaliar a direção e a magnitude do impacto de cada variável independente sobre a medida dependente e, em última instância, a precisão de classifi cação do modelo lo- gístico.\n\n\n\nResumo\nO pesquisador que se defronta com uma variável depen- dente dicotômica não precisa apelar para métodos elabo- rados para acomodar as limitações da regressão múltipla, e nem precisa ser forçado a empregar a análise discrimi- nante, especialmente se suas suposições estatísticas são violadas. A regressão logística aborda esses problemas e fornece um método desenvolvido para lidar diretamente com essa situação da maneira mais efi ciente possível.\n\n\nUM EXEMPLO ILUSTRATIVO\n\n\nDE REGRESSÃO LOGÍSTICA\nA regressão logística é uma alternativa atraente à análise discriminante sempre que a variável dependente tem ape- nas duas categorias. Suas vantagens em relação à análise discriminante incluem as seguintes:\n1. É menos afetada do que a análise discriminante pelas de- sigualdades de variância-covariância ao longo dos grupos, uma suposição básica da análise discriminante. 2. Lida facilmente com variáveis independentes categóricas, enquanto na análise discriminante o uso de variáveis dico- tômicas cria problemas com igualdades de variância-cova- riância. 3. Os resultados empíricos acompanham paralelamente os da regressão múltipla em termos de sua interpretação e das medidas diagnósticas de casos disponíveis para exame de resíduos. O exemplo a seguir, idêntico ao da análise discrimi- nante de dois grupos discutido anteriormente, ilustra essas vantagens e a similaridade da regressão logística com os resultados obtidos da regressão múltipla. Como veremos, ainda que a regressão logística tenha muitas vantagens como alternativa à análise discriminante, o pesquisador deve interpretar cuidadosamente os resultados devido aos\naspectos ímpares de como a regressão logística lida com a\nprevisão de probabilidades e de pertinência a grupos.\n\n\nEstágios 1, 2 e 3: Objetivos da\n\n\npesquisa, planejamento de pesquisa\n\n\ne suposições estatísticas\nAs questões abordadas nos primeiros três estágios do pro-\ncesso de decisão são idênticas para a análise discriminante\nde dois grupos e para a regressão logística.\nO problema de pesquisa ainda é determinar se as dife-\nrenças de percepções de HBAT ( X 6 a X 18 ) existem entre\nos clientes dos EUA/América do Norte e aqueles do res-\nto do mundo ( X 4 ). A amostra de 100 clientes é dividida\nem uma amostra de análise de 60 observações, com as\n40 observações restantes constituindo a amostra de va-\nlidação.\nAgora nos concentramos sobre os resultados obtidos\na partir do uso de regressão logística para estimar e com-\npreender as diferenças entre esses dois tipos de clientes.\n\n\nEstágio 4: Estimação do modelo de regressão\n\n\nlogística e avaliação do ajuste geral\nAntes que comece o processo de estimação, é possível\nrever as variáveis individuais e avaliar seus resultados\nunivariados em termos de diferenciação entre grupos.\nSabendo-se que os objetivos da análise discriminante e da\nregressão logística são os mesmos, podemos usar as mes-\n\nRegressão logística\n\nRegressão logística é o método preferido para variáveis dependentes de dois grupos (binárias) devido à sua robustez, facilidade de interpretação e diagnóstico\nTestes de signifi cância de modelo são feitos com um teste de qui-quadrado sobre as diferenças no logaritmo da verossimilhança ( – 2 LL ) entre dois modelos\nCoefi cientes são expressos em duas formas: original e exponenciado, para auxiliar na interpretação\nA interpretação dos coefi cientes quanto a direção e magnitude é:\n\nDireção pode ser avaliada diretamente nos coefi cientes originais (sinais positivos ou negativos) ou indiretamente nos exponenciados (menor que 1 é negativa e maior que 1 é positiva)\nMagnitude é avaliada melhor pelo coefi ciente exponenciado, com a variação percentual na variável dependente mostrada por: Variação percentual = (Coefi ciente exponenciado – 1,0) × 100\n\n\n\nREGRAS PRÁTICAS 5-5\n\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 293\nmas medidas de discriminação para avaliar efeitos univa- riados, como foi feito para a análise discriminante.\nSe revisarmos nossa discussão a respeito das diferenças\ndos grupos quanto às 13 variáveis independentes (olhar\na Tabela 5-5), lembraremos que cinco variáveis ( X 6 , X 11 ,\nX 12 , X 13 , e X 17 ) tinham diferenças estatisticamente signi-\nfi cantes entre os dois grupos. Se você olhar novamente a\ndiscussão no exemplo de dois grupos, lembre de uma in-\ndicação de multicolinearidade entre essas variáveis, pois\nambas X 6 e X 13 eram parte do fator Valor do produto\nderivado pela análise fatorial (ver Capítulo 3). A regres-\nsão logística é afetada por multicolinearidade entre as\nvariáveis independentes de uma maneira semelhante à\nanálise discriminante e análise de regressão.\nExatamente como em análise discriminante, essas cinco variáveis seriam as candidatas lógicas para inclu- são na variável estatística de regressão logística, pois elas demonstram as maiores diferenças entre grupos. Regres- são logística pode incluir uma ou mais dessas variáveis no modelo, bem como outras variáveis que não apresentam diferenças signifi cantes neste estágio se elas operam em combinação com outras variáveis para signifi cativamente melhorar a previsão.\n\n\nEstimação do modelo\nA regressão logística é estimada de maneira análoga à re- gressão múltipla, no sentido de que um modelo base é pri- meiramente estimado para fornecer um padrão para com- paração (ver discussão anterior para maiores detalhes). Em regressão múltipla, a média é usada para estabelecer\no modelo base e calcular a soma total de quadrados. Em\nregressão logística, o mesmo processo é empregado, com\na média usada no modelo estimado não para estabelecer a\nsoma de quadrados, mas para estabelecer o valor do loga-\nritmo da verossimilhança. A partir desse modelo, podem\nser estabelecidas as correlações parciais para cada variá-\nvel e a variável mais discriminante pode ser escolhida de\nacordo com os critérios de seleção.\nEstimação do modelo base. A Tabela 5-25 contém os\nresultados do modelo base para a análise de regressão lo-\ngística. O valor do logaritmo da verossimilhança (–2 LL )\naqui é 82,108. A estatística escore, uma medida de asso-\nciação usada em regressão logística, é a medida usada\npara selecionar variáveis no procedimento stepwise. Di-\nversos critérios podem ser empregados para orientar a\nentrada: maior redução no valor –2 LL , maior coefi ciente\nde Wald, ou maior probabilidade condicional. Em nosso\nexemplo, empregamos o critério da redução da razão do\nlogaritmo da verossimilhança.\nAo revermos a estatística de escores de variáveis não\npresentes no modelo neste momento, percebemos que as\nmesmas cinco variáveis com diferenças estatisticamente\nsignifi cantes ( X 6 , X 11 , X 12 , X 13 e X 17 ) também são s únicas\nvariáveis com estatística de escore signifi cante na Tabela\n5-25. Como o procedimento stepwise seleciona a variável\ncom a maior estatística de escore, X 13 deve ser a variável\nadicionada no primeiro passo.\nEstimação stepwise : adição da primeira variável,\nX 13. Como esperado, X 13 foi escolhida para entrada\nno primeiro passo do processo de estimação (ver Tabela\nTABELA 5-25 Resultados do modelo base da regressão logística\nAjuste geral do modelo: medidas da qualidade do ajuste\nValor\n–2 Logaritmo de verossimilhança (–2 LL ) 82,108\nVariáveis fora da equação\nVariáveis independentes Estatística de escore Signifi cância\nX 6 Qualidade do produto 11,925 0,001\nX 7 Atividades de comércio eletrônico 2,052 0,152\nX 8 Suporte técnico 1,609 0,205\nX 9 Solução de reclamação 0,866 0,352\nX 10 Anúncio 0,791 0,374\nX 11 Linha do produto 18,323 0,000\nX 12 Imagem da equipe de venda 8,622 0,003\nX 13 Preços competitivos 21,330 0,000\nX 14 Garantia e reclamações 0,465 0,495\nX 15 Novos produtos 0,614 0,433\nX 16 Encomenda e cobrança 0,090 0,764\nX 17 Flexibilidade de preço 21,204 0,000\nX 18 Velocidade de entrega 0,157 0,692\n( Continua )\n\n\n294 Análise Multivariada de Dados\nTABELA 5-26 Estimação stepwise da regressão logística: Adição de X 13 (Preços competitivos)\nAjuste geral do modelo: medidas da qualidade de ajuste\nVARIAÇÃO EM –2 LL\nDo modelo base Do passo anterior\nValor Variação Signifi cância Variação Signifi cância\n–2 Logaritmo de verossimilhança (–2 LL ) 56,971 25,136 0,000 25,136 0,000\nR^2 de Cox e Snell 0,342\nR^2 de Nagelkerke 0,459\nPseudo R^2 0,306\nValor Signifi cância\n%^2 de Hosmer e Lemeshow 17,329 0,027\nVariáveis na equação\nVariável independente B Erro padrão Wald df Sig. Exp(B)\nX 13 Preços competitivos 1,129 0,287 15,471 1 0,000 3,092\nConstante –7,008 1,836 14,570 1 0,000 0,001\nB = coefi ciente logístico, Exp(B) = coefi ciente exponenciado\nVariáveis fora da equação\nVariáveis independentes Estatística de escore Signifi cância\nX 6 Qualidade do produto 4,859 0,028\nX 7 Atividades de comércio eletrônico 0,132 0,716\nX 8 Suporte técnico 0,007 0,932\nX 9 Solução de reclamação 1,379 0,240\nX 10 Anúncio 0,129 0,719\nX 11 Linha do produto 6,154 0,013\nX 12 Imagem da equipe de venda 2,745 0,098\nX 14 Garantia e reclamações 0,640 0,424\nX 15 Novos produtos 0,344 0,557\nX 16 Encomenda e cobrança 2,529 0,112\nX 17 Flexibilidade de preço 13,723 0,000\nX 18 Velocidade de entrega 1,206 0,272\nMatriz de classifi cação\nPertinência prevista em grupoc\nAMOSTRA DE ANÁLISEa AMOSTRA DE TESTEb\nX 4 Região X 4 Região\nPertinência real em grupo\nEUA/América\ndo Norte\nFora da Amé-\nrica do Norte Total\nEUA/América\ndo Norte\nFora da Amé-\nrica do Norte Total\nEUA/América do Norte 19 7 26 4 9 13\n(73,1) (30,8)\nFora da América do Norte 9 25 34 1 26 27\n(73,5) (96,3)\na73,3% de amostra de análise corretamente classifi cada.\nb75,0% da amostra de teste corretamente classifi cada.\ncValores entre parênteses são percentuais corretamente classifi cados (razão de sucesso).\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 295\nEstimação stepwise : Adição da segunda variável, X 17. Es- pera-se que um ou mais passos no procedimento stepwise resulte na inclusão de todas as variáveis independentes com estatística de escore signifi cante, bem como sejam atingidas razões aceitáveis de sucesso (geral e específi cas de grupos) tanto para a amostra de análise quanto para a de teste.\nX 17 , com a maior estatística de escore depois de adicionar\nX 13 , foi escolhida para entrada no passo 2 (Tabela 5-27).\nMelhoras em todas as medidas de ajuste de modelo varia-\nram de uma queda no valor –2 LL até as várias medidas\nR^2. Mais importante sob uma perspectiva de estimação\nde modelo, nenhuma das variáveis fora da equação tinha\nvariações estatisticamente signifi cantes de escores.\nAssim, o modelo logístico de duas variáveis incluindo X 13 e X 17 será o modelo fi nal a ser usado para fi ns de ava- liação de ajuste do mesmo, de precisão preditiva e de in- terpretação dos coefi cientes.\n\n\nAvaliação do ajuste geral do modelo\nAo se fazer uma avaliação do ajuste geral de um mode- lo logístico de regressão, podemos empregar três abor- dagens: medidas estatísticas de ajuste geral do modelo, medidas pseudo R^2 , e precisão de classifi cação expressada na razão de sucesso. Cada uma dessas abordagens será examinada para os modelos de regressão logística de uma variável e de duas variáveis que resultaram do procedi- mento stepwise.\nMedidas estatísticas. A primeira medida estatística é o teste qui-quadrado para a variação no valor –2 LL do mo- delo base, que é comparável com o teste F geral em regres- são múltipla. Valores menores da medida –2 LL indicam um\nmelhor ajuste de modelo, e o teste estatístico está disponí-\nvel para avaliar a diferença entre o modelo base e os demais\nmodelos propostos (em um procedimento stepwise , este tes-\nte está sempre baseado na melhora do passo anterior).\n\nNo modelo de uma só variável (ver Tabela 5-26), o va- lor –2 LL é reduzido a partir do valor do modelo base de 82,108 para 59,971*, uma queda de 25,136. Este aumen- to em ajuste de modelo foi estatisticamente signifi cante no nível 0,000.\nNo modelo de duas variáveis, o valor –2 LL diminuiu mais para 39,960, resultando em quedas signifi cantes não apenas do modelo base (42,148), mas também uma queda signifi cante do modelo de uma variável (17,011). Ambas as melhoras de ajuste foram signifi cantes no nível 0,000.\n\nA segunda medida estatística é a de Hosmer e Le-\nmeshow de ajuste geral [11]. Este teste estatístico mede a\ncorrespondência dos valores reais e previstos da variável\ndependente. Neste caso, um ajuste melhor de modelo é\nindicado por uma diferença menor na classifi cação obser-\nvada e prevista.\nO teste de Hosmer e Lemeshow mostra signifi cância\npara o modelo logístico de uma variável (0,027 da Ta-\nbela 5-26), indicando que diferenças signifi cantes ainda\npermanecem entre valores reais e esperados. O modelo\nde duas variáveis, contudo, reduz o nível de signifi cância\npara 0,722 (ver Tabela 5-27), um valor não-signifi cante\nque aponta para um ajuste aceitável.\nPara o modelo logístico de duas variáveis, ambas as\nmedidas estatísticas de ajuste geral do modelo indicam\nque o mesmo é aceitável e em um nível estatisticamente\nsignifi cante. No entanto, é necessário examinar as outras\nmedidas de ajuste geral do modelo para avaliar se os re-\nsultados alcançam os níveis necessários de signifi cância\nprática também.\nMedidas de pseudo R^2. Três medidas disponíveis são\ncomparáveis com a medida R^2 em regressão múltipla: R^2\nde Cox e Snell, R^2 de Nagelkerke, e a medida pseudo R^2\nbaseada na redução no valor –2 LL.\n5-26). Ela corresponde à maior estatística de escore em\ntodas as 13 variáveis de percepções. A entrada de X 13\nno modelo de regressão logística conseguiu um razoável\najuste, com valores pseudo R^2 variando de 0,306 a 0,459\ne as razões de sucesso de 73,3% e 75% para as amostras\nde análise e de teste, respectivamente.\nO exame dos resultados, porém, identifi ca duas razões\npara se considerar um estágio extra para adicionar variá-\nveis ao modelo de regressão logística:\n\nTrês variáveis não presentes no modelo logístico cor- rente ( X 17 , X 11 e X 6 ) têm estatísticas de escore estatis- ticamente signifi cantes, indicando que a inclusão das mesmas melhoraria consideravelmente o ajuste geral do modelo.\nA razão de sucesso geral para a amostra de teste é boa (75,0%), mas um dos grupos (Clientes dos EUA/Améri- ca do Norte) tem uma razão de sucesso inaceitavelmen- te baixa de 30,8%.\n\n( Continuação )\nPara o modelo de regressão logística de uma variável,\nesses valores eram 0,342, 0,459 e 0,306, respectivamen-\nte. Combinados, eles indicam que o modelo de regressão\nde uma variável explica aproximadamente um terço da\nvariação na medida dependente. Apesar de o modelo de\numa variável ser considerado estatisticamente signifi can-\nte em diversas medidas de ajuste geral, esses valores de\nR^2 são um pouco baixos para fi ns de signifi cância prática.\n( Continua )\n* N. de R. T.: O número correto é 56,971.\n\n\n296 Análise Multivariada de Dados\nTABELA 5-27 Estimação stepwise da regressão logística: adição de X 17 (Flexibilidade de preços)\nAjuste geral do modelo: medidas da qualidade de ajuste\nVARIAÇÃO EM –2 LL\nDo modelo base Do passo anterior\nValor Variação Signifi cância Variação Signifi cância\n–2 Logaritmo de verossimilhança (–2 LL ) 39,960 42,148 0,000 17,011 0,000\nR^2 de Cox e Snell 0,505\nR^2 de Nagelkerke 0,677\nPseudo R^2 0,513\nValor Signifi cância\n%^2 de Hosmer e Lemeshow 5,326 0,722\nVariáveis na equação\nVariável independente B Erro padrão Wald df Sig. Exp(B)\nX 13 Preços competitivos 1,079 0,357 9,115 1 0,003 2,942\nX 17 Flexibilidade de preços 1,844 0,639 8,331 1 0,004 6,321\nConstante –14,192 3,712 14,614 1 0,000 0,000\nB = coefi ciente logístico, Exp(B) = coefi ciente exponenciado\nVariáveis fora da equação\nVariáveis independentes Estatística de escore Signifi cância\nX 6 Qualidade do produto 0,656 0,418\nX 7 Atividades de comércio eletrônico 3,501 0,061\nX 8 Suporte técnico 0,006 0,937\nX 9 Solução de reclamação 0,693 0,405\nX 10 Anúncio 0,091 0,762\nX 11 Linha do produto 3,409 0,065\nX 12 Imagem da equipe de venda 0,849 0,357\nX 14 Garantia e reclamações 2,327 0,127\nX 15 Novos produtos 0,026 0,873\nX 16 Encomenda e cobrança 0,010 0,919\nX 18 Velocidade de entrega 2,907 0,088\nMatriz de classifi cação\nPertinência prevista em grupoc\nAMOSTRA DE ANÁLISEa AMOSTRA DE TESTEb\nX 4 Região X 4 Região\nPertinência real em grupo\nEUA/América\ndo Norte\nFora da Amé-\nrica do Norte Total\nEUA/América\ndo Norte\nFora da Amé-\nrica do Norte Total\nEUA/América do Norte 25 1 26 9 4 13\n(96,2) (69,2)\nFora da América do Norte 6 28 34 2 25 27\n(82,4) (92,6)\na88,3% de amostra de análise corretamente classifi cada.\nb85,0% da amostra de teste corretamente classifi cada.\ncValores entre parênteses são percentuais corretamente classifi cados (razão de sucesso).\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 297\nOs valores R^2 do modelo de duas variáveis exibiram considerável melhora sobre o modelo de uma variável e indicam bom ajuste quando comparados aos valores R^2 geralmente encontrados em regressão múltipla. De acor- do com as medidas de ajuste de caráter estatístico, o mo- delo é considerado aceitável em termos de signifi cância estatística e prática.\nPrecisão de classifi cação. O terceiro exame de ajuste ge- ral do modelo será para avaliar a precisão de classifi cação do modelo em uma medida fi nal de signifi cância prática. As matrizes de classifi cação, idênticas em natureza àque- las empregadas em análise discriminante, representam os níveis de precisão preditiva atingidos pelo modelo logís- tico. A medida de precisão preditiva usada é a razão de sucesso, o percentual de casos corretamente classifi cados. Esses valores serão calculados tanto para a amostra de análise quanto a de teste, e medidas específi cas de grupos serão examinadas além das medidas gerais. Além disso, comparações podem ser feitas, como ocorreu em análise discriminante, com padrões de comparação representan- do os níveis de precisão preditiva conseguidos por chan- ces (ver discussão mais detalhada na seção sobre análise discriminante).\nEm todos os três dos tipos básicos de medida de\najuste geral, o modelo de duas variáveis (com X 13 e X 17 )\ndemonstra níveis aceitáveis de signifi cância estatística e\nprática. Com ajuste de modelo geral aceitável, voltamos\nnossa atenção para a avaliação dos testes estatísticos dos\ncoefi cientes logísticos a fi m de identifi car os coefi cien-\ntes que têm relações signifi cantes afetando pertinência\na grupo.\n\n\nSignifi cância estatística dos coefi cientes\nOs coefi cientes estimados para as duas variáveis indepen-\ndentes e a constante também podem ser avaliados quanto\nà signifi cância estatística. A estatística Wald é usada para\navaliar signifi cância de um modo semelhante ao teste t uti-\nlizado em regressão múltipla.\nOs coefi cientes logísticos para X 13 (1,079) e X 17 (1,844) e a\nconstante (–14,190*) são todos signifi cantes no nível 0,01\ncom base no teste estatístico de Wald. Nenhuma outra\nvariável consegue entrar no modelo e atingir pelo menos\num nível de signifi cância de 0,05.\nAssim, as variáveis individuais são signifi cantes e po-\ndem ser interpretadas para identifi car as relações que\nafetam as probabilidades previstas e subseqüentemente a\npertinência a grupo.\n\n\nDiagnósticos por casos\nA análise da má classifi cação de observações individuais\npode fornecer uma melhor visão sobre possíveis melhora-\nmentos do modelo. Diagnósticos por casos, como resídu-\nos e medidas de infl uências, estão disponíveis, bem como\na análise de perfi l discutida anteriormente para a análise\ndiscriminante.\nO modelo de duas variáveis (ver Tabela 5-27) tem\nvalores R^2 que são ambos maiores que 0,50, apontando\npara um modelo de regressão logística que explica pelo\nmenos metade da variação entre os dois grupos de clien-\ntes. Sempre se deseja melhorar tais valores, mas tal nível\né considerado praticamente signifi cante nesta situação.\n( Continuação )\nOs padrões de comparação para as razões de sucesso\nda matriz de classifi cação serão os mesmos que foram\ncalculados para a análise discriminante de dois grupos.\nOs valores são 65,5% para o critério de chance propor-\ncional (a medida preferida) e 76,3% para o critério de\nchance máxima. Se você não estiver familiarizado com\nos métodos de cálculo de tais medidas, veja a discussão\nanterior no capítulo que trata de avaliação da precisão\nde classifi cação.\n\nAs razões de sucesso geral para o modelo logístico de uma variável são 73,3% e 75,0% para as amostras de análise e de teste, respectivamente. Mesmo que as ra- zões de sucesso geral sejam maiores do que o critério de chance proporcional e comparáveis com o critério de chance máxima, um problema considerável surge na amostra de teste para os clientes dos EUA/América do Norte, onde a razão de sucesso é de somente 30,8%. Este nível está abaixo de ambos os padrões e demanda que o modelo logístico seja expandido até o ponto em que, espera-se, esta razão de sucesso específi ca de grupo exceda os padrões.\nO modelo de duas variáveis exibe melhora substancial na razão de sucesso geral e nos valores específi cos de\n\ngrupos. As razões de sucesso geral subiram para 88,3%\ne 85,0% para as amostras de análise e de teste, respec-\ntivamente. Além disso, a problemática razão de suces-\nso na amostra de teste aumenta para 69,2%, acima do\nvalor padrão para o critério de chance proporcional.\nCom essas melhoras nos níveis geral e específi cos,\no modelo de regressão logística de duas variáveis é\nconsiderado aceitável em termos de precisão de classi-\nfi cação.\nNeste caso, apenas 13 casos foram mal classifi cados (7\nna amostra de análise e 6 na de teste). Dado o elevado\ngrau de correspondência entre esses casos e aqueles mal\nclassifi cados estudados na análise discriminante de dois\ngrupos, o processo de estabelecimento de perfi l não será\nnovamente levado adiante (leitores interessados podem\nrever o exemplo de dois grupos). Diagnóstico por casos,\n* N. de R. T.: O número correto é -14,192.\n\n\n298 Análise Multivariada de Dados\n\n\n\nEstágio 5: Interpretação dos resultados\nO procedimento de regressão logística stepwise produziu uma variável estatística muito semelhante àquela da aná- lise discriminante de dois grupos, apesar de ter uma variá- vel independente a menos. Examinaremos os coefi cientes logísticos para avaliarmos a direção e o impacto que cada variável tem sobre a probabilidade prevista e a pertinên- cia a grupo.\n\nInterpretação dos coefi cientes logísticos\nO modelo fi nal de regressão logística inclui duas variá-\nveis ( X 13 e X 17 ) com coefi cientes de regressão de 1,079\ne 1,844, respectivamente, e uma constante de –14,190*\n(ver Tabela 5-27). A comparação desses resultados com\na análise discriminante de dois grupos revela resultados\nquase idênticos, uma vez que a análise discriminante in-\ncluiu três variáveis no modelo de dois grupos – X 13 e X 17\njuntamente com X 11.\nDireção das relações. Para avaliar a direção da relação de cada variável, podemos examinar ou os coefi cientes logísticos originais, ou os coefi cientes exponenciados. Co- mecemos com os originais.\nSe você recordar de nossa discussão anterior, podemos\ninterpretar a direção da relação diretamente a partir do\nsinal dos coefi cientes logísticos originais. Neste caso, am-\nbas as variáveis têm sinais positivos, o que aponta para\numa relação positiva entre ambas as variáveis indepen-\ndentes e a probabilidade prevista. À medida que os va-\nlores de X 13 ou X 17 aumentam, a probabilidade prevista\naumenta, fazendo crescer assim a possibilidade de que\num cliente seja categorizado como residindo fora da\nAmérica do Norte.\nVoltando nossa atenção para os coefi cientes expoen-\nciados, devemos recordar que valores acima de 1,0 indi-\ncam uma relação positiva e valores abaixo de 1,0 apontam\npara uma relação negativa. Em nosso caso, os valores de\n2,942 e 6,319 também refl etem relações positivas.\nMagnitude das relações. O método mais direto para avaliar a magnitude da variação na probabilidade devido a cada variável independente é examinar os coefi cientes exponenciados. Como você deve lembrar, o coefi ciente exponenciado menos um é igual à variação percentual da razão de desigualdades.\nEm nosso caso, isso signifi ca que um aumento de um\nponto aumenta a razão de desigualdades em 194% para\nX 13 e 531% para X 17. Esses números podem exceder\n100% de variação porque eles estão aumentando a razão\nde desigualdades e não as probabilidades propriamente\nditas. Os impactos são grandes porque o termo constan-\nte (–14,190*) defi ne um ponto inicial de quase zero para\nos valores de probabilidade. Logo, grandes aumentos na\nrazão de desigualdades são necessários para se conseguir\nvalores maiores de probabilidades.\nOutra abordagem na compreensão sobre como os coefi -\ncientes logísticos defi nem probabilidade é calcular a proba-\nbilidade prevista para qualquer conjunto de valores para as\nvariáveis independentes.\nPara as variáveis independentes X 13 e X 17 , usemos as\nmédias para os dois grupos. Dessa maneira podemos ver\nqual seria a probabilidade prevista para um membro mé-\ndio de cada grupo.\nA Tabela 5-28 mostra os cálculos para a previsão da\nprobabilidade para os dois centróides de grupo. Como\npodemos perceber, o centróide para o grupo 0 (clientes\nna América do Norte) tem uma probabilidade prevista\nde 18,9%, enquanto o centróide para o grupo 1 (fora da\nAmérica do Norte) tem uma probabilidade prevista de\n94,8%. Este exemplo demonstra que o modelo logístico\ncria de fato uma separação entre os dois centróides de\ngrupo em termos de probabilidade prevista, gerando ex-\ncelentes resultados de classifi cação conquistados para as\namostras de análise e de teste.\nOs coefi cientes logísticos defi nem relações positivas\npara ambas as variáveis independentes e fornecem uma\nmaneira de avaliar o impacto de uma variação em uma ou\nambas as variáveis sobre a razão de desigualdades e conse-\nqüentemente sobre a probabilidade prevista. Fica evidente\npor que muitos pesquisadores preferem regressão logística\nà análise discriminante quando comparações são feitas so-\nbre a informação mais útil disponível nos coefi cientes logís-\nticos em contrapartida com as cargas discriminantes.\n\n\n\nEstágio 6: Validação dos resultados\nA validação do modelo de regressão logística é consegui-\nda neste exemplo através do mesmo método usado em\nanálise discriminante: criação de amostras de análises e\nde teste. Examinando a razão de sucesso para a amostra\nde teste, o pesquisador pode avaliar a validade externa e a\nsignifi cância prática do modelo de regressão logística.\ncomo resíduos e medidas de infl uência estão disponí-\nveis. Dados os baixos níveis de má classifi cação, porém,\nnenhuma análise complementar de classifi cação ruim é\nexecutada.\nPara o modelo fi nal de regressão logística de duas va-\nriáveis, as razões de sucesso para as amostras de análi-\n( Continua )\n* N. de R. T.: O número correto é -14,192.\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 299\nEsses resultados levam à conclusão de que o modelo de regressão logística, como também descoberto com o modelo de análise discriminante, demonstrou validade externa sufi ciente para a completa aceitação dos resul- tados.\n\n\n\nUma visão gerencial\nA regressão logística apresenta uma alternativa à analise discriminante que pode ser mais confortável para muitos pesquisadores devido à sua similaridade com regressão múltipla. Dada a sua robustez diante das condições de dados que podem afetar negativamente a análise discri- minante (p.ex., matrizes diferentes de variância-covariân- cia), a regressão logística é também a técnica preferida de estimação em muitas aplicações.\nQuando comparada com análise discriminante, a re-\ngressão logística fornece precisão preditiva compa-\nrável com uma variável estatística mais simples que\nusava a mesma interpretação substancial, apenas\ncom uma variável a menos. A partir dos resultados\nda regressão logística, o pesquisador pode se concen-\ntrar na competitividade e na fl exibilidade de preços\ncomo as principais variáveis de diferenciação entre\nos dois grupos de clientes. A meta nesta análise não\né aumentar probabilidade (como poderia ser o caso\nde se analisar sucesso versus fracasso), ainda que a\nregressão logística forneça uma técnica direta para a\nHBAT compreender o impacto relativo de cada va-\nriável independente na criação de diferenças entre os\ndois grupos de clientes.\n\n\nResumo\nA natureza intrínseca, os conceitos e a abordagem para a\nanálise discriminante múltipla e a regressão logística fo-\nram apresentadas. Orientações básicas para sua aplicação\ne interpretação foram incluídas para melhor esclarecer os\nconceitos metodológicos. Este capítulo ajuda você a fazer\no seguinte:\nEstabelecer as circunstâncias sob as quais a análise discri-\nminante linear ou a regressão logística devem ser usadas\nao invés da regressão múltipla. Ao se escolher uma téc-\nnica analítica apropriada, às vezes encontramos um pro-\nblema que envolve uma variável dependente categórica\ne diversas variáveis independentes métricas. Lembre-se\nque a variável dependente em regressão foi medida me-\ntricamente. Análise discriminante múltipla e regressão\nlogística são as técnicas estatísticas apropriadas quando o\nproblema de pesquisa envolve uma única variável depen-\ndente categórica e diversas variáveis independentes mé-\ntricas. Em muitos casos, a variável dependente consiste de\ndois grupos ou classifi cações, por exemplo, masculino ver-\nsus feminino, alto versus baixo, ou bom versus ruim. Em\noutros casos, mais de dois grupos estão envolvidos, como\nclassifi cações baixas, médias e altas. A análise discrimi-\nnante e a regressão logística são capazes de lidar com dois\nou múltiplos (três ou mais) grupos. Os resultados de uma\nanálise discriminante e de uma regressão logística podem\nauxiliar no perfi l das características entre-grupos dos indi-\nvíduos e na correspondência dos mesmos com seus grupos\nadequados.\nIdentifi car os principais problemas relacionados aos tipos\nde variáveis usados e os tamanhos de amostras exigidos na\naplicação de análise discriminante. Para aplicar análise\ndiscriminante, o pesquisador deve primeiramente especi-\nfi car quais variáveis devem ser medidas independentes e\nqual é a dependente. O pesquisador deve se concentrar\nprimeiro na variável dependente. O número de grupos da\nvariável dependente (categorias) pode ser dois ou mais,\nmas tais grupos devem ser mutuamente excludentes e\nexaustivos. Depois que uma decisão foi tomada sobre a\nvariável dependente, o pesquisador deve decidir quais\nTABELA 5-28 Cálculo de valores de probabilidade estimada para os centróides\nde grupos da região X 4\nX 4 (Região)\nGrupo 0: EUA/América\ndo Norte\nGrupo 1: Fora da\nAmérica do Norte\nCentróide: X 13 5,60 7,42\nCentróide: X 17 3,63 4,93\nValor logit a –1,452 2,909\nRazão de desigualdades b 0,234 18,332\nProbabilidadec 0,189 0,948\na bCalculado como: Logit = $14,190 ” 1,079 X 13 ” 1,844 X (^17) cCalculada como: Razão de desigualdades = eLogit Calculada como: Probabilidade = Razão de desigualdades/(1+Razão de desigualdades) se e de teste excedem todos os padrões de comparação (critérios de chance proporcional e de chance máxima). Além disso, todas as razões de sucesso específi cas de grupos são sufi cientemente grandes para a aceitação. Esse aspecto é especialmente importante para a amos- tra de teste, que é o principal indicador de validade ex- terna. ( Continuação )\n\n300 Análise Multivariada de Dados\nvariáveis independentes devem ser incluídas na análise. Variáveis independentes são escolhidas de duas manei- ras: (1) identifi cando variáveis de pesquisa anterior ou do modelo teórico inerente à questão de pesquisa, e (2) uti- lizando o conhecimento e a intuição do pesquisador para selecionar variáveis para as quais nenhuma pesquisa ou teoria anterior existem mas que logicamente podem estar relacionadas com a previsão de grupos da variável depen- dente. A análise discriminante, como as demais técnicas mul- tivariadas, é afetada pelo tamanho da amostra sob análi- se. Uma proporção de 20 observações para cada variável preditora é recomendada. Como os resultados se tornam instáveis à medida que o tamanho da amostra diminui relativamente ao número de variáveis independentes, o tamanho mínimo recomendado é de cinco observações por variável independente. O tamanho amostral de cada grupo também deve ser considerado. No mínimo, o ta- manho do menor grupo de uma categoria deve exceder o número de variáveis independentes. Como orientação prática, cada categoria deve ter pelo menos 20 observa- ções. Mesmo que todas as categorias ultrapassem 20 ob- servações, porém, o pesquisador também deve considerar os tamanhos relativos dos grupos. Variações grandes nos tamanhos dos grupos afetam a estimação da função discri- minante e a classifi cação de observações.\nCompreender as suposições subjacentes à análise discri- minante na avaliação de sua adequação a um problema em particular. As suposições da análise discriminante se relacionam aos processos estatísticos envolvidos nos pro- cedimentos de estimação e classifi cação, bem como aos problemas que afetam a interpretação dos resultados. As suposições-chave para se obter a função discriminante são normalidade multivariada das variáveis independentes, e estruturas (matrizes) desconhecidas (mas iguais) de dis- persão e covariância para os grupos como defi nidos pela variável dependente. Se as suposições são violadas, o pes- quisador deve entender o impacto sobre os resultados que podem ser esperados e considerar métodos alternativos para análise (p.ex., regressão logística).\nDescrever as duas abordagens computacionais para análi- se discriminante e o método para avaliação de ajuste geral do modelo. As duas técnicas para análise discriminante são os métodos simultâneo (direto) e stepwise. A estima- ção simultânea envolve a computação da função discrimi- nante considerando todas as variáveis independentes ao mesmo tempo. Portanto, a função discriminante é com- putada com base no conjunto inteiro de variáveis inde- pendentes, independentemente do poder discriminante de cada variável independente. A estimação stepwise é uma alternativa ao método simultâneo. Ela envolve a en- trada de variáveis independentes uma por vez com base no poder discriminante das mesmas. O método stepwise segue um processo seqüencial de adição ou eliminação de\nvariáveis da função discriminante. Depois que esta é esti-\nmada, o pesquisador deve avaliar a signifi cância ou ajuste\nda mesma. Quando um método simultâneo é empregado,\no lambda de Wilks, o traço de Hotelling e o critério de\nPillai calculam a signifi cância estatística do poder discri-\nminatório da função estimada. Se um método stepwise é\nusado para estimar a função discriminante, o D^2 de Maha-\nlanobis e a medida V de Rao são os mais adequados para\navaliar ajuste.\nExplicar o que é uma matriz de classifi cação e como de-\nsenvolver uma, e descrever as maneiras de se avaliar a\nprecisão preditiva da função discriminante. Os testes\nestatísticos para avaliar a signifi cância das funções discri-\nminantes avaliam apenas o grau de diferença entre grupos\ncom base nos escores Z discriminantes, mas não indicam\no quão bem as funções prevêem. Para determinar a habi-\nlidade preditiva de uma função discriminante, o pesqui-\nsador deve construir matrizes de classifi cação. O procedi-\nmento da matriz de classifi cação fornece uma perspectiva\nsobre signifi cância prática no lugar de signifi cância esta-\ntística. Antes que uma matriz de classifi cação possa ser\nconstruída, no entanto, o pesquisador deve determinar o\nescore de corte para cada função discriminante. O escore\nde corte representa o ponto de divisão utilizado para clas-\nsifi car observações em cada um dos grupos, baseado no\nescore da função discriminante. O cálculo de um escore\nde corte entre dois grupos quaisquer é sustentado pelos\ndois centróides de grupo (média dos escores discriminan-\ntes) e pelos tamanhos relativos dos dois grupos. Os resul-\ntados do procedimento de classifi cação são apresentados\nem forma matricial. As entradas na diagonal da matriz\nrepresentam o número de indivíduos corretamente clas-\nsifi cados. Os números fora da diagonal correspondem a\nclassifi cações incorretas. O percentual corretamente clas-\nsifi cado, também conhecido como razão de sucesso , revela\no quão bem a função discriminante prevê os objetos. Se os\ncustos da má classifi cação forem aproximadamente iguais\npara todos os grupos, o escore de corte ótimo será aquele\nque classifi car mal o menor número de objetos ao longo\nde todos os grupos. Se os custos de má classifi cação forem\ndesiguais, o escore de corte ótimo será aquele que mini-\nmiza os custos de má classifi cação. Para avaliar a razão de\nsucesso, devemos olhar para uma classifi cação por chan-\nces. Quando os tamanhos de grupos são iguais, a determi-\nnação da classifi cação por chances se baseia no número de\ngrupos. Quando os tamanhos dos grupos são distintos, o\ncálculo da classifi cação por chances pode ser feito de duas\nmaneiras: chance máxima e chance proporcional.\nDizer como identifi car variáveis independentes com po-\nder discriminatório. Se a função discriminante é estatis-\nticamente signifi cante e a precisão de classifi cação (razão\nde sucesso) é aceitável, o pesquisador deve se concentrar\nna realização de interpretações substanciais das descober-\ntas. Este processo envolve a determinação da importância\n\n\nCAPÍTULO 5 Análise Discriminante Múltipla e Regressão Logística 301\nrelativa de cada variável independente na discriminação entre os grupos. Três métodos de determinação da impor- tância relativa foram propostos: (1) pesos discriminan- tes padronizados, (2) cargas discriminantes (correlações estruturais) e (3) valores F parciais. A abordagem tradi- cional para interpretar funções discriminantes examina o sinal e a magnitude do peso discriminante padronizado designado para cada variável na computação das funções discriminantes. Variáveis independentes com pesos re- lativamente maiores contribuem mais para o poder dis- criminatório da função do que variáveis com pesos me- nores. O sinal denota se a variável contribui negativa ou positivamente. Cargas discriminantes são cada vez mais usadas como uma base para interpretação por conta das defi ciências na utilização de pesos. Medindo a correla- ção linear simples entre cada variável independente e a função discriminante, as cargas discriminantes refl etem a variância que as variáveis independentes compartilham com a função discriminante. Elas podem ser interpretadas como cargas fatoriais na avaliação da contribuição relati- va de cada variável independente à função discriminante. Quando um método de estimação stepwise é usado, uma maneira adicional de interpretar o poder discriminatório relativo das variáveis independentes é através do empre- go de valores F parciais, o que se consegue examinando-se os tamanhos absolutos dos valores F signifi cantes e orde- nando-os. Valores F grandes indicam um poder discrimi- natório maior.\nJustifi car o uso de um método de divisão de amostra para validação. O estágio fi nal de uma análise discriminante envolve a validação dos resultados discriminantes para fornecer garantias de que os mesmos têm tanto validade interna quanto externa. Além de validar as razões de su- cesso, o pesquisador deve usar o perfi l dos grupos para garantir que as médias deles são indicadores válidos do modelo conceitual utilizado na seleção das variáveis in- dependentes. Validação pode ocorrer com uma amostra separada (de teste) ou utilizando um procedimento que repetidamente processa a amostra de estimação. Valida- ção das razões de sucesso é executada muito freqüente- mente criando-se uma amostra de teste, também chama- da de amostra de validação. O propósito da utilização de uma amostra de teste para fi ns de validação é perceber o quão bem a função discriminante funciona em uma amos- tra de observações que não foram usadas para obtê-la. Tal avaliação envolve o desenvolvimento de uma função dis- criminante com a amostra de análise e então a aplicação da função à amostra de teste.\nEntender as vantagens e desvantagens da regressão lo- gística comparada com análise discriminante e regressão múltipla. Análise discriminante é apropriada quando a variável dependente é não-métrica. Se ela tiver apenas dois grupos, então a regressão logística pode ser prefe- rível por duas razões. Primeiro, a análise discriminante\napóia-se no atendimento estrito das suposições de nor-\nmalidade multivariada e igualdade entre as matrizes de\nvariância-covariância nos grupos – premissas que não são\natendidas em muitas situações. A regressão logística não\nse depara com tais restrições e é muito mais robusta quan-\ndo essas suposições não são atendidas, tornando sua apli-\ncação adequada em muitos casos. Segundo, mesmo que\nas suposições sejam atendidas, muitos pesquisadores pre-\nferem a regressão logística por ser semelhante à regres-\nsão múltipla. Como tal, ela tem testes estatísticos diretos,\nmétodos semelhantes para incorporar variáveis métricas e\nnão-métricas e efeitos não-lineares, bem como uma vasta\ngama de diagnósticos. A regressão logística é equivalen-\nte à análise discriminante de dois grupos e pode ser mais\nadequada em muitas situações.\nInterpretar os resultados de uma análise de regressão lo-\ngística, com comparações com regressão múltipla e análise\ndiscriminante. A adequação de ajuste para um modelo\nde regressão logística pode ser avaliada de duas maneiras:\n(1) usando valores pseudo R^2 , semelhantes àqueles en-\ncontrados em regressão múltipla, e (2) examinando pre-\ncisão preditiva (i.e., a matriz de classifi cação em análise\ndiscriminante). As duas abordagens examinam ajuste de\nmodelo sob diferentes perspectivas, mas devem conduzir\na resultados semelhantes. Uma das vantagens da regres-\nsão logística é que precisamos saber apenas se um evento\nocorreu para defi nir um valor dicotômico como nossa va-\nriável dependente. Quando analisamos esses dados usan-\ndo transformação logística, contudo, a regressão logísti-\nca e seus coefi cientes assumem um signifi cado um tanto\ndiferente daqueles encontrados em regressão com uma\nvariável dependente métrica. Analogamente, cargas em\nanálise discriminante são interpretadas diferentemente\nde um coefi ciente logístico. Este último refl ete a direção\ne a magnitude da relação da variável independente, mas\nrequer diferentes métodos de interpretação. A direção\nda relação (positiva ou negativa) retrata as variações na\nvariável dependente associadas com mudanças na inde-\npendente. Uma relação positiva signifi ca que um aumento\nna variável independente é associado com um aumento\nna probabilidade prevista, e vice-versa para uma relação\nnegativa.Para determinar a magnitude do coefi ciente, ou\no quanto que a probabilidade mudará dada uma unidade\nde variação na variável independente, o valor numérico\ndo coefi ciente deve ser avaliado. Exatamente como em\nregressão múltipla, os coefi cientes para variáveis métricas\ne não-métricas devem ser interpretados diferentemente\nporque cada um refl ete diferentes impactos sobre a variá-\nvel dependente.\nA análise discriminante múltipla e a regressão logís-\ntica ajudam a compreender e explicar problemas de pes-\nquisa que envolvem uma variável dependente categórica\ne diversas variáveis independentes métricas. Ambas as\ntécnicas podem ser usadas para estabelecer o perfi l das\n\n\n302 Análise Multivariada de Dados\ncaracterísticas entre grupos dos indivíduos e designar os mesmos a seus grupos apropriados. Aplicações potenciais dessas duas técnicas tanto em negócios como em outras áreas são inúmeras.\n\n\n\nQuestões\n\nComo você diferenciaria entre análise discriminante múl- tipla, análise de regressão, regressão logística e análise de variância?\nQuando você empregaria regressão logística no lugar de análise discriminante? Quais são as vantagens e desvanta- gens dessa decisão?\nQuais critérios você poderia usar para decidir se deve parar uma análise discriminante depois de estimar a função discri- minante? Depois do estágio de interpretação?\nQual procedimento você seguiria para dividir sua amostra em grupos de análise e de teste? Como você mudaria este procedimento se sua amostra consistisse de menos do que 100 indivíduos ou objetos?\nComo você determinaria o escore de corte ótimo?\nComo você determinaria se a precisão de classifi cação da função discriminante é sufi cientemente alta relativamente a uma classifi cação ao acaso?\nComo uma análise discriminante de dois grupos difere de uma análise de três grupos?\nPor que um pesquisador deve expandir as cargas e dados do centróide ao representar grafi camente uma solução de análise discriminante?\nComo a regressão logística e a análise discriminante lidam com a relação das variáveis dependente e independentes? 1 0. Q u a i s s ã o a s d i f e r e n ç a s d e e s t i m a ç ã o e i n t e r p r e t a ç ã o e n t r e regressão logística e análise discriminante? 1 1. E x p l i q u e o c o n c e i t o d e r a z ã o d e d e s i g u a l d a d e s e p o r q u e e l a é usada para prever probabilidade em um procedimento de regressão logística.\n\n\n\nLeituras sugeridas\nUma lista de leituras sugeridas ilustrando questões e apli- cações da análise discriminante e regressão logística está disponível na Web em http://www.prenhall.com/hair (em inglês).\n\n\nReferências\n\nCohen, J. 1988. Statistical Power Analysis for the Behavioral Sciences, 2nd ed. Hillsdale, NJ: Lawrence Erlbaum Associates. 2. Crask, M., and W. Perreault. 1977. Validation of Discriminant Analysis in Marketing Research. Journal of Marketing Research 14 (February): 60–68. 3. Demaris, A. 1995. A Tutorial in Logistic Regression. Journal of Marriage and the Family 57: 956–68. 4. Dillon, W. R., and M. Goldstein. 1984. Multivariate Analysis: Methods and Applications. New York: Wiley. 5. Frank, R. E., W. E. Massey, and D. G. Morrison. 1965. Bias in Multiple Discriminant Analysis. Journal of Marketing Research 2(3): 250–58. 6. Gessner, Guy, N. K. Maholtra, W. A. Kamakura, and M. E. Zmijewski. 1988. Estimating Models with Binary Dependent Variables: Some Theoretical and Empirical Observations. Journal of Business Research 16(1): 49–65. 7. Green, P. E., D. Tull, and G. Albaum. 1988. Research for Marketing Decisions. Upper Saddle River, NJ: Prentice Hall. 8. Green, P. E. 1978. Analyzing Multivariate Data. Hinsdale, IL: Holt, Rinehart and Winston. 9. Green, P. E., and J. D. Carroll. 1978. Mathematical Tools for Applied Multivariate Analysis. New York: Academic Press. 1 0. H a r r i s , R. J. 2 0 0 1. A Primer of Multivariate Statistics, 3rd ed. Hillsdale, NJ: Lawrence Erlbaum Associates. 11. Hosmer, D. W., and S. Lemeshow. 2000. Applied Logistic Regression, 2nd ed. New York: Wiley. 12. Huberty, C. J. 1984. Issues in the Use and Interpretation of Discriminant Analysis. Psychological Bulletin 95: 156– 71. 13. Huberty, C. J., J. W. Wisenbaker, and J. C. Smith. 1987. Assessing Predictive Accuracy in Discriminant Analysis. Multivariate Behavioral Research 22 (July): 307–29. 14. Johnson, N., and D. Wichern. 2002. Applied Multivariate Statistical Analysis, 5th ed. Upper Saddle River, NJ: Prentice Hall. 1 5. L o n g , J. S. 1 9 9 7. Regression Models for Categorical and-Limited Dependent Variables: Analysis and Interpretation. Thousand Oaks, CA:-Sage. 16. Morrison, D. G. 1969. On the Interpretation of Discriminant Analysis. Journal of Marketing Research 6(2): 156–63. 17. Pampel, F. C. 2000. Logistic Regression: A Primer, Sage University Papers Series on Quantitative Applications in the Social Sciences, # 07–096. Newbury Park, CA: Sage. 18. Perreault, W. D., D. N. Behrman, and G. M. Armstrong. 1979. Alternative Approaches for Interpretation of Multiple Discriminant Analysis in Marketing Research. Journal of Business Research 7: 151–73."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ANÁLISE DISCRIMINANTE",
    "section": "",
    "text": "library(MASS)\nlibrary(klaR)\nlibrary(car)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(corrplot)\nlibrary(caret)\nlibrary(skimr)\nlibrary(MVN)\nlibrary(biotools)\nlibrary(GGally)\nlibrary(nnet)\nlibrary(pROC)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(haven)\nlibrary(gridExtra)\nlibrary(reshape2)\nlibrary(viridis)\nlibrary(plotly)\nlibrary(RColorBrewer)"
  },
  {
    "objectID": "index.html#análise-discriminante---exemplo-hbat",
    "href": "index.html#análise-discriminante---exemplo-hbat",
    "title": "ANÁLISE DISCRIMINANTE",
    "section": "Análise Discriminante - Exemplo HBAT",
    "text": "Análise Discriminante - Exemplo HBAT\n\nReprodução do Exemplo de Hair et al. - Dataset HBAT\nNesta seção, reproduziremos a análise discriminante apresentada no livro Hair et al., utilizando o dataset HBAT para classificar clientes em três grupos baseados no tempo de relacionamento com a empresa.\nO HBAT é um dataset educacional fictício amplamente utilizado no livro clássico “Multivariate Data Analysis” de Joseph Hair et al., representando uma empresa de distribuição industrial. O dataset contém 100 observações de clientes classificados em três grupos baseados no tempo de relacionamento: Grupo 1 (menos de 1 ano), Grupo 2 (1 a 5 anos) e Grupo 3 (mais de 5 anos). As variáveis incluem a variável dependente X1 (Customer Type) e 13 variáveis independentes (X6-X18) que medem percepções dos clientes sobre diferentes aspectos da empresa, como qualidade do produto (X6), atividades de e-commerce (X7), suporte técnico (X8), resolução de reclamações (X9), propaganda (X10), linha de produtos (X11), imagem da força de vendas (X12), preços competitivos (X13), garantia e reclamações (X14), novos produtos (X15), pedidos e faturamento (X16), flexibilidade de preços (X17) e velocidade de entrega (X18). Todas as variáveis independentes utilizam uma escala de 0-10, facilitando comparações e interpretações. Este dataset é ideal para demonstrar técnicas de análise multivariada, especialmente análise discriminante, pois oferece um contexto empresarial realista com dados limpos e estruturados, permitindo focar na aplicação das técnicas estatísticas sem se preocupar com problemas complexos de qualidade de dados típicos de datasets reais.\n\n\nEstágio 1: Objetivos da Análise Discriminante\nO objetivo é identificar as características perceptuais que distinguem clientes baseados no tempo de relacionamento: - Grupo 1: Menos de 1 ano - Grupo 2: De 1 a 5 anos\n- Grupo 3: Mais de 5 anos\n\nCarregamento e Inspeção dos Dados do arquivo spss\n\n# Carregando os dados HBAT\nhbat &lt;- haven::read_sav(\"data/hbat.sav\")\n\nglimpse(hbat)\n\nRows: 100\nColumns: 24\n$ id  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,…\n$ x1  &lt;dbl+lbl&gt; 2, 3, 3, 1, 2, 1, 1, 2, 2, 1, 3, 1, 1, 3, 2, 3, 2, 2, 2, 3, 1,…\n$ x2  &lt;dbl+lbl&gt; 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,…\n$ x3  &lt;dbl+lbl&gt; 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,…\n$ x4  &lt;dbl+lbl&gt; 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,…\n$ x5  &lt;dbl+lbl&gt; 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,…\n$ x6  &lt;dbl+lbl&gt; 8.5, 8.2, 9.2, 6.4, 9.0, 6.5, 6.9, 6.2, 5.8, 6.4, 8.7, 6.1, 9.…\n$ x7  &lt;dbl+lbl&gt; 3.9, 2.7, 3.4, 3.3, 3.4, 2.8, 3.7, 3.3, 3.6, 4.5, 3.2, 4.9, 5.…\n$ x8  &lt;dbl+lbl&gt; 2.5, 5.1, 5.6, 7.0, 5.2, 3.1, 5.0, 3.9, 5.1, 5.1, 4.6, 6.3, 4.…\n$ x9  &lt;dbl+lbl&gt; 5.9, 7.2, 5.6, 3.7, 4.6, 4.1, 2.6, 4.8, 6.7, 6.1, 4.8, 3.9, 6.…\n$ x10 &lt;dbl+lbl&gt; 4.8, 3.4, 5.4, 4.7, 2.2, 4.0, 2.1, 4.6, 3.7, 4.7, 2.7, 4.4, 5.…\n$ x11 &lt;dbl+lbl&gt; 4.9, 7.9, 7.4, 4.7, 6.0, 4.3, 2.3, 3.6, 5.9, 5.7, 6.8, 3.9, 6.…\n$ x12 &lt;dbl+lbl&gt; 6.0, 3.1, 5.8, 4.5, 4.5, 3.7, 5.4, 5.1, 5.8, 5.7, 4.6, 6.4, 6.…\n$ x13 &lt;dbl+lbl&gt; 6.8, 5.3, 4.5, 8.8, 6.8, 8.5, 8.9, 6.9, 9.3, 8.4, 6.8, 8.2, 7.…\n$ x14 &lt;dbl+lbl&gt; 4.7, 5.5, 6.2, 7.0, 6.1, 5.1, 4.8, 5.4, 5.9, 5.4, 5.8, 5.8, 6.…\n$ x15 &lt;dbl+lbl&gt; 4.3, 4.0, 4.6, 3.6, 4.5, 9.5, 2.5, 4.8, 4.4, 5.3, 7.5, 5.9, 5.…\n$ x16 &lt;dbl+lbl&gt; 5.0, 3.9, 5.4, 4.3, 4.5, 3.6, 2.1, 4.3, 4.4, 4.1, 3.8, 3.0, 5.…\n$ x17 &lt;dbl+lbl&gt; 5.1, 4.3, 4.0, 4.1, 3.5, 4.7, 4.2, 6.3, 6.1, 5.8, 3.7, 4.9, 4.…\n$ x18 &lt;dbl+lbl&gt; 3.7, 4.9, 4.5, 3.0, 3.5, 3.3, 2.0, 3.7, 4.6, 4.4, 4.0, 3.2, 4.…\n$ x19 &lt;dbl+lbl&gt; 8.2, 5.7, 8.9, 4.8, 7.1, 4.7, 5.7, 6.3, 7.0, 5.5, 7.4, 6.0, 8.…\n$ x20 &lt;dbl+lbl&gt; 8.0, 6.5, 8.4, 6.0, 6.6, 6.3, 7.8, 5.8, 7.5, 5.9, 7.0, 6.3, 8.…\n$ x21 &lt;dbl+lbl&gt; 8.4, 7.5, 9.0, 7.2, 9.0, 6.1, 7.2, 7.7, 8.2, 6.7, 8.4, 6.6, 7.…\n$ x22 &lt;dbl+lbl&gt; 65.1, 67.1, 72.1, 40.1, 57.1, 50.1, 41.1, 56.1, 56.1, 59.1, 68…\n$ x23 &lt;dbl+lbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,…\n\n\n\n\nDefinição das Variáveis do Modelo\nCom base na inspeção dos dados, identificamos que o dataset HBAT possui exatamente as variáveis necessárias: - x1: Variável dependente (Customer Type: 1=Menos de 1 ano, 2=De 1 a 5 anos, 3=Mais de 5 anos) - x6-x18: Variáveis independentes (percepções sobre a HBAT)\nConfiguração das Variáveis:\n\nVariável dependente: x1\nVariáveis independentes: x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18\nTotal de variáveis independentes: 13\n\n\n\nPreparação do Dataset Final\nResumo da Preparação dos Dados:\n\nTotal de observações: 100\nVariáveis independentes: 13\nGrupos identificados: 3\n\nDistribuição da Variável Dependente (X1):\n\n\n\n\n\nGrupo\nFrequência\n\n\n\n\nMenos de 1 ano\n32\n\n\nDe 1 a 5 anos\n35\n\n\nMais de 5 anos\n33\n\n\n\n\n\nDescrições das Variáveis:\n\n\n\nCódigo\nDescrição\n\n\n\n\nX1\nCustomer Type\n\n\nX6\nProduct Quality\n\n\nX7\nE-Commerce Activities\n\n\nX8\nTechnical Support\n\n\nX9\nComplaint Resolution\n\n\nX10\nAdvertising\n\n\nX11\nProduct Line\n\n\nX12\nSalesforce Image\n\n\nX13\nCompetitive Pricing\n\n\nX14\nWarranty & Claims\n\n\nX15\nNew Products\n\n\nX16\nOrdering & Billing\n\n\nX17\nPrice Flexibility\n\n\nX18\nDelivery Speed\n\n\n\n\n\n\nEstágio 2: Delineamento da Pesquisa de Análise Discriminante\n\n# Divisão em amostras de análise e validação\nset.seed(123)\nn_total &lt;- nrow(hbat_clean)\nindices_analise &lt;- sample(1:n_total, size = floor(0.6 * n_total))\n\namostra_analise &lt;- hbat_clean[indices_analise, ]\namostra_validacao &lt;- hbat_clean[-indices_analise, ]\n\n# Verificar balanceamento dos grupos\nprop_analise &lt;- table(amostra_analise$X1) / nrow(amostra_analise)\nprop_validacao &lt;- table(amostra_validacao$X1) / nrow(amostra_validacao)\n\nA análise discriminante requer a divisão dos dados em amostras de estimação e validação para avaliar adequadamente o desempenho do modelo. Utilizamos uma divisão de 60% para análise e 40% para validação.\nCaracterísticas das Amostras:\n\nAmostra de análise: 60 casos\nAmostra de validação: 40 casos\n\nDistribuição dos Grupos por Amostra:\n\n\n\nGrupo\nAnálise (n)\nAnálise (%)\nValidação (n)\nValidação (%)\n\n\n\n\nMenos de 1 ano\n20\n33.3%\n12\n30%\n\n\nDe 1 a 5 anos\n22\n36.7%\n13\n32.5%\n\n\nMais de 5 anos\n18\n30%\n15\n37.5%\n\n\n\n\n\nEstágio 3: Pressupostos da Análise Discriminante\n\n3.1 Normalidade Multivariada\nO teste de normalidade multivariada é fundamental para verificar se os dados seguem uma distribuição normal multivariada, pressuposto da análise discriminante linear. Testamos cada um dos três grupos separadamente usando o teste de Henze-Zirkler.\n\nlibrary(MVN)\n\n# Armazenar resultados dos testes de normalidade\nresultados_normalidade &lt;- list()\n\nfor(grupo in levels(amostra_analise$X1)) {\n  dados_grupo &lt;- amostra_analise[amostra_analise$X1 == grupo, variaveis_independentes]\n  \n  # Usando parâmetros corretos da função mvn\n  resultado_mvn &lt;- mvn(dados_grupo, mvn_test = \"hz\", univariate_test = \"SW\")\n  resultados_normalidade[[grupo]] &lt;- resultado_mvn$multivariate_normality\n  \n  # Teste alternativo se o primeiro falhar\n  if(is.null(resultado_mvn$multivariate_normality)) {\n    resultado_mardia &lt;- mvn(dados_grupo, mvn_test = \"mardia\")\n    resultados_normalidade[[grupo]] &lt;- resultado_mardia$multivariate_normality\n  }\n}\n\n# Mostrar resultados\nprint(resultados_normalidade)\n\n$`Menos de 1 ano`\n           Test Statistic p.value     Method      MVN\n1 Henze-Zirkler      0.99   0.113 asymptotic ✓ Normal\n\n$`De 1 a 5 anos`\n           Test Statistic p.value     Method      MVN\n1 Henze-Zirkler     0.993   0.063 asymptotic ✓ Normal\n\n$`Mais de 5 anos`\n           Test Statistic p.value     Method          MVN\n1 Henze-Zirkler     0.994   0.035 asymptotic ✗ Not normal\n\n\nResumo dos Testes de Normalidade:\nCom base nos resultados obtidos, 2 dos 3 grupos atendem ao pressuposto de normalidade multivariada ao nível de significância de 5%. O grupo que apresentou desvio (p = 0.035) está próximo do limite aceitável, e a análise discriminante pode prosseguir com confiança.\n\n\n3.2 Homogeneidade das Matrizes de Covariância\nO teste M de Box verifica se as matrizes de covariância dos grupos são homogêneas, outro pressuposto importante da análise discriminante. Este teste avalia se as 13 variáveis independentes apresentam estruturas de covariância similares entre os grupos.\nInterpretação dos Resultados do Teste M de Box:\nConclusão: Com p-valor = 0.01122 &lt; 0.05, rejeitamos a hipótese nula de homogeneidade das matrizes de covariância. Isso indica que há diferenças significativas entre as estruturas de covariância dos grupos.\nImplicações Práticas: - A violação da homogeneidade das covariâncias sugere que a Análise Discriminante Quadrática (QDA) poderia ser mais apropriada que a Linear (LDA) - No entanto, a LDA é robusta a violações moderadas deste pressuposto, especialmente quando os tamanhos das amostras são similares - Como os grupos estão relativamente balanceados (conforme mostrado acima), podemos prosseguir com cautela usando LDA - Os resultados devem ser interpretados considerando esta limitação\n\nlibrary(biotools)\n\ndados_teste &lt;- amostra_analise[, variaveis_independentes]\ngrupos_teste &lt;- amostra_analise$X1\n\n# Teste M de Box com tratamento de erro\ntryCatch({\n  teste_box &lt;- boxM(dados_teste, grupos_teste)\n  print(teste_box)\n}, error = function(e) {\n  message(\"Teste M de Box não pôde ser executado: \", e$message)\n  \n  for(grupo in levels(amostra_analise$X1)) {\n    dados_grupo &lt;- amostra_analise[amostra_analise$X1 == grupo, variaveis_independentes]\n    cov_grupo &lt;- cov(dados_grupo)\n    message(\"\\nMatriz de Covariância - Grupo: \", grupo)\n    print(round(cov_grupo, 3))\n  }\n})\n\n\n    Box's M-test for Homogeneity of Covariance Matrices\n\ndata:  dados_teste\nChi-Sq (approx.) = 228.34, df = 182, p-value = 0.01122\n\n\n\n\n3.3 Multicolinearidade\nA presença de multicolinearidade pode afetar a estabilidade dos resultados da análise discriminante. O determinante da matriz de correlação e os valores VIF nos ajudam a identificar possíveis problemas de multicolinearidade entre as variáveis.\nInterpretação dos Valores VIF:\nOs Fatores de Inflação da Variância (VIF) revelam problemas significativos de multicolinearidade:\n\nVIF &lt; 5: Multicolinearidade baixa (aceitável)\n\nX6 (1.90), X7 (4.56), X8 (4.71), X10 (1.65), X13 (1.76), X14 (4.16), X15 (1.23), X16 (4.33)\n\nVIF entre 5-10: Multicolinearidade moderada (preocupante)\n\nX9 (5.33), X12 (5.78)\n\nVIF &gt; 10: Multicolinearidade alta (problemática)\n\nX11 (Product Line): VIF = 52.77\nX17 (Price Flexibility): VIF = 41.49\n\nX18 (Delivery Speed): VIF = 56.34\n\n\nImplicações: - As variáveis X11, X17 e X18 apresentam alta correlação com outras variáveis independentes - Isso pode causar instabilidade nos coeficientes discriminantes - O determinante da matriz de correlação confirma a presença de multicolinearidade - Apesar disso, seguimos o exemplo de Hair et al. usando X6 e X18, reconhecendo esta limitação\n\n# Matriz de correlação com visualização aprimorada\nmatriz_cor &lt;- cor(amostra_analise[, variaveis_independentes])\n\n# Gráfico de correlação personalizado\ncorrplot::corrplot(matriz_cor, method = \"color\", type = \"upper\", \n                   order = \"hclust\", tl.cex = 0.8, tl.col = \"black\",\n                   col = RColorBrewer::brewer.pal(n = 8, name = \"RdYlBu\"),\n                   title = \"Matriz de Correlação das Variáveis Independentes\",\n                   mar = c(0,0,2,0))\n\n\n\n\n\n\n\n# Determinante da matriz de correlação\ndet_cor &lt;- det(matriz_cor)\n\n# VIF para identificar multicolinearidade\nmodelo_temp &lt;- lm(as.numeric(X1) ~ ., data = amostra_analise[, c(\"X1\", variaveis_independentes)])\nvif_valores &lt;- car::vif(modelo_temp)\n\nAnálise de Multicolinearidade:\n\nDeterminante da matriz de correlação: 8^{-6}\n\nClassificação dos Valores VIF:\n\n\n\nCategoria\nCritério\nVariáveis\n\n\n\n\nBaixa (&lt; 5)\nAceitável\nX6, X7, X8, X10, X13, X14, X15, X16\n\n\nModerada (5-10)\nPreocupante\nX9, X12\n\n\nAlta (≥ 10)\nProblemática\nX11, X17, X18\n\n\n\nVariáveis com Multicolinearidade Severa:\n\n\n\n\n\nVariável\nDescrição\nVIF\n\n\n\n\nX11\nProduct Line\n52.77\n\n\nX17\nPrice Flexibility\n41.49\n\n\nX18\nDelivery Speed\n56.34\n\n\n\n\n\n\n\n\nEstágio 4: Estimação do Modelo Discriminante e Avaliação do Ajuste Geral\n\n4.1 Método Stepwise\n\nlibrary(klaR)\nlibrary(MASS)\n\n# Implementando stepwise manual baseado em critérios estatísticos\nf_univariados &lt;- numeric(length(variaveis_independentes))\np_univariados &lt;- numeric(length(variaveis_independentes))\nnames(f_univariados) &lt;- variaveis_independentes\nnames(p_univariados) &lt;- variaveis_independentes\n\nfor(i in seq_along(variaveis_independentes)) {\n  var &lt;- variaveis_independentes[i]\n  formula_temp &lt;- as.formula(paste(var, \"~ X1\"))\n  \n  tryCatch({\n    anova_temp &lt;- aov(formula_temp, data = amostra_analise)\n    anova_summary &lt;- summary(anova_temp)\n    f_univariados[i] &lt;- anova_summary[[1]][\"X1\", \"F value\"]\n    p_univariados[i] &lt;- anova_summary[[1]][\"X1\", \"Pr(&gt;F)\"]\n  }, error = function(e) {\n    f_univariados[i] &lt;- 0\n    p_univariados[i] &lt;- 1\n  })\n}\n\n# Ordenando variáveis por poder discriminante\nordem_importancia &lt;- order(f_univariados, decreasing = TRUE)\nvars_ordenadas &lt;- variaveis_independentes[ordem_importancia]\nvars_significativas &lt;- names(p_univariados[p_univariados &lt; 0.05])\n\n# Testando modelo Hair et al.: X6 + X18\nformula_hair &lt;- as.formula(\"cbind(X6, X18) ~ X1\")\nmanova_hair &lt;- manova(formula_hair, data = amostra_analise)\nresultado_hair &lt;- summary(manova_hair, test = \"Wilks\")\n\nmodelo_stepwise &lt;- list(\n  formula = \"X1 ~ X6 + X18\",\n  selected_vars = c(\"X6\", \"X18\"),\n  wilks_lambda = resultado_hair$stats[\"X1\", \"Wilks\"],\n  f_statistic = resultado_hair$stats[\"X1\", \"approx F\"],\n  p_value = resultado_hair$stats[\"X1\", \"Pr(&gt;F)\"]\n)\n\nAnálise Univariada de Variáveis:\nRanking por Poder Discriminante (Top 5):\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosição\nVariável\nDescrição\nF.value\np.valor\nSignificância\n\n\n\n\n1\nX18\nDelivery Speed\n24.425\n0\n***\n\n\n2\nX6\nProduct Quality\n22.885\n0\n***\n\n\n3\nX9\nComplaint Resolution\n22.739\n0\n***\n\n\n4\nX11\nProduct Line\n20.721\n0\n***\n\n\n5\nX16\nOrdering & Billing\n17.664\n0\n***\n\n\n\n\n\nModelo Stepwise Final:\n\nFórmula selecionada: X1 ~ X6 + X18\nVariáveis incluídas: X6 + X18\nLambda de Wilks: 0.2901\nEstatística F: 23.99\np-valor: 2.388e-14\nTotal de variáveis significativas: 7 de 13\n\nJustificativa da Seleção: Embora X18 seja a variável mais discriminante univariadamente, seguimos o exemplo de Hair et al. usando X6 (Product Quality) + X18 (Delivery Speed) por razões teóricas e interpretabilidade gerencial.\n\n\n4.2 Análise Discriminante Linear\n\n# Modelo final conforme Hair et al. (X6 e X18)\nmodelo_final &lt;- lda(X1 ~ X6 + X18, data = amostra_analise)\n\n# Autovalores e variância explicada\neigenvalues &lt;- modelo_final$svd^2\nvariancia_explicada &lt;- eigenvalues / sum(eigenvalues) * 100\n\nO modelo discriminante final utiliza as variáveis X6 (Product Quality) e X18 (Delivery Speed), seguindo o exemplo de Hair et al.\nCaracterísticas do Modelo:\n\nNúmero de funções discriminantes: 2\nVariância explicada pela Função 1: 83.5%\nVariância explicada pela Função 2: 16.5%\nVariância total explicada: 100%\n\nAutovalores:\n\n\n\n\n\nFunção\nAutovalor\nVariância.Explicada….\n\n\n\n\nLD 1\n45.9897\n83.5\n\n\nLD 2\n9.0940\n16.5\n\n\n\n\n\n\n\n4.3 Significância Estatística\nO teste de significância avalia se o modelo discriminante é estatisticamente significativo.\n\nmodelo_manova &lt;- manova(cbind(X6, X18) ~ X1, data = amostra_analise)\nsummary(modelo_manova, test = \"Wilks\")\n\n          Df   Wilks approx F num Df den Df    Pr(&gt;F)    \nX1         2 0.29005    23.99      4    112 2.388e-14 ***\nResiduals 57                                             \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.aov(modelo_manova)\n\n Response X6 :\n            Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nX1           2 51.890 25.9451  22.885 5.062e-08 ***\nResiduals   57 64.622  1.1337                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response X18 :\n            Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nX1           2 15.643  7.8216  24.425 2.182e-08 ***\nResiduals   57 18.253  0.3202                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nInterpretação dos Resultados de Significância:\nTeste MANOVA (Multivariado): - Lambda de Wilks = 0.29005: Valor baixo indica boa discriminação entre grupos - F aproximado = 23.99: Estatística F alta sugere diferenças significativas - p-valor = 2.388e-14: Altamente significativo (p &lt; 0.001) - Conclusão: O modelo discriminante é estatisticamente significativo\nAnálises Univariadas por Variável:\nX6 (Product Quality): - F = 22.885: Alta capacidade discriminante individual - p-valor = 5.062e-08: Altamente significativo - Interpretação: A qualidade do produto varia significativamente entre os grupos de tempo de relacionamento\nX18 (Delivery Speed): - F = 24.425: Maior capacidade discriminante individual entre as duas variáveis - p-valor = 2.182e-08: Altamente significativo\n- Interpretação: A percepção da velocidade de entrega é o melhor discriminador individual entre os grupos\nImplicações Gerenciais: 1. Ambas as variáveis contribuem significativamente para distinguir os grupos 2. Velocidade de entrega (X18) é ligeiramente mais discriminante que qualidade (X6) 3. O modelo como um todo tem poder discriminante muito forte 4. As percepções evoluem significativamente com o tempo de relacionamento\n\n\n4.4 Centróides dos Grupos\nOs centróides representam o “centro” de cada grupo no espaço discriminante.\n\ncentroides &lt;- aggregate(amostra_analise[, c(\"X6\", \"X18\")], \n                       by = list(amostra_analise$X1), FUN = mean)\nnames(centroides)[1] &lt;- \"Grupo\"\n\npredict_centroides &lt;- predict(modelo_final, centroides[, c(\"X6\", \"X18\")])\ncentroides_discriminantes &lt;- predict_centroides$x\nrownames(centroides_discriminantes) &lt;- centroides$Grupo\nprint(\"\\nCentróides no Espaço Discriminante:\")\n\n[1] \"\\nCentróides no Espaço Discriminante:\"\n\nprint(centroides_discriminantes)\n\n                      LD1        LD2\nMenos de 1 ano -1.6066271  0.3095983\nDe 1 a 5 anos   0.2579251 -0.7144520\nMais de 5 anos  1.4698995  0.5292210\n\n\nAnálise dos Centróides no Espaço Discriminante:\nPosicionamento dos Grupos:\n\n\n\n\n\n\n\n\n\nGrupo\nLD1\nLD2\nInterpretação\n\n\n\n\nMenos de 1 ano\n-1.61\n0.31\nPercepções mais baixas, posicionamento único\n\n\nDe 1 a 5 anos\n0.26\n-0.71\nPercepções intermediárias, diferenciação moderada\n\n\nMais de 5 anos\n1.47\n0.53\nPercepções mais elevadas, alta satisfação\n\n\n\nPadrões Identificados:\n\nEvolução Linear em LD1: Os valores de LD1 crescem progressivamente (-1.61 → 0.26 → 1.47), indicando melhoria das percepções com o tempo de relacionamento\nSeparação Clara: A distância entre centróides confirma que os grupos são bem diferenciados no espaço discriminante\nTrajetória de Relacionamento:\n\nClientes novos (&lt; 1 ano): Expectativas em formação, percepções iniciais mais críticas\nClientes intermediários (1-5 anos): Período de consolidação das percepções\nClientes estabelecidos (&gt; 5 anos): Relacionamento maduro, percepções mais positivas\n\n\nInterpretação das Funções Discriminantes:\n\nLD1: Representa principalmente a evolução temporal das percepções (experiência acumulada)\nLD2: Representa diferenças qualitativas específicas entre os grupos intermediários e extremos\n\nImplicações Estratégicas: - Foco na retenção inicial: Clientes novos precisam de atenção especial - Gestão da jornada: Processo gradual de melhoria das percepções - Fidelização: Clientes de longo prazo são verdadeiros advogados da marca\n\n\n\nEstágio 5: Interpretação dos Resultados\n\n5.1 Cargas Discriminantes (Matriz Estrutural)\nAs cargas discriminantes mostram a correlação entre cada variável independente e as funções discriminantes.\n\n# Calculando cargas discriminantes (correlações entre variáveis e funções)\n# Escores discriminantes para todas as observações\nescores_discriminantes &lt;- predict(modelo_final, amostra_analise)$x\n\n# Matriz de cargas (correlações)\nvariaveis_completas &lt;- amostra_analise[, variaveis_independentes]\ncargas_discriminantes &lt;- cor(variaveis_completas, escores_discriminantes)\n\nprint(\"Matriz de Cargas Discriminantes (não-rotacionadas):\")\n\n[1] \"Matriz de Cargas Discriminantes (não-rotacionadas):\"\n\nprint(round(cargas_discriminantes, 3))\n\n       LD1    LD2\nX6   0.736  0.677\nX7   0.235 -0.313\nX8   0.103  0.182\nX9   0.728 -0.467\nX10  0.177 -0.237\nX11  0.773 -0.049\nX12  0.192 -0.418\nX13 -0.251 -0.286\nX14  0.163  0.058\nX15  0.041 -0.084\nX16  0.699 -0.416\nX17  0.012 -0.699\nX18  0.765 -0.644\n\n# Identificando variáveis descritivas (|carga| &gt;= 0.40)\ncargas_importantes &lt;- abs(cargas_discriminantes) &gt;= 0.40\nprint(\"\\nVariáveis Descritivas por Função (|carga| &gt;= 0.40):\")\n\n[1] \"\\nVariáveis Descritivas por Função (|carga| &gt;= 0.40):\"\n\nfor(i in 1:ncol(cargas_discriminantes)) {\n  cat(\"Função\", i, \":\", names(which(cargas_importantes[, i])), \"\\n\")\n}\n\nFunção 1 : X6 X9 X11 X16 X18 \nFunção 2 : X6 X9 X12 X16 X17 X18 \n\n\nInterpretação da Matriz de Cargas Discriminantes:\nAnálise da Função Discriminante 1 (LD1):\nVariáveis com Cargas Altas (|carga| ≥ 0.40): - X11 (Product Line): 0.773 - Maior contribuição para LD1 - X18 (Delivery Speed): 0.765 - Forte correlação positiva - X6 (Product Quality): 0.736 - Alta correlação positiva\n- X9 (Complaint Resolution): 0.728 - Contribuição significativa - X16 (Ordering & Billing): 0.699 - Forte correlação\nInterpretação de LD1: Representa a dimensão geral de satisfação com aspectos operacionais e de qualidade da HBAT. Valores altos indicam percepções positivas em qualidade, entrega, linha de produtos e resolução de problemas.\nAnálise da Função Discriminante 2 (LD2):\nVariáveis com Cargas Altas (|carga| ≥ 0.40): - X17 (Price Flexibility): -0.699 - Maior magnitude (negativa) - X6 (Product Quality): 0.677 - Correlação positiva forte - X18 (Delivery Speed): -0.644 - Correlação negativa significativa - X9 (Complaint Resolution): -0.467 - Contribuição moderada negativa - X16 (Ordering & Billing): -0.416 - Correlação negativa - X12 (Salesforce Image): -0.418 - Contribuição moderada negativa\nInterpretação de LD2: Representa um contraste entre qualidade percebida versus flexibilidade operacional. Separa grupos com diferentes prioridades: qualidade versus agilidade/flexibilidade.\n\n\n5.2 Rotação VARIMAX\n\n# Aplicando rotação VARIMAX às cargas discriminantes\nlibrary(stats)\n\nif(ncol(cargas_discriminantes) &gt; 1) {\n  rotacao_varimax &lt;- varimax(cargas_discriminantes)\n  cargas_rotacionadas &lt;- rotacao_varimax$loadings[]\n  \n  print(\"Matriz de Cargas Discriminantes (rotacionadas - VARIMAX):\")\n  print(round(cargas_rotacionadas, 3))\n  \n  # Variáveis descritivas após rotação\n  cargas_rot_importantes &lt;- abs(cargas_rotacionadas) &gt;= 0.40\n  print(\"\\nVariáveis Descritivas por Função Rotacionada (|carga| &gt;= 0.40):\")\n  for(i in 1:ncol(cargas_rotacionadas)) {\n    cat(\"Função\", i, \":\", names(which(cargas_rot_importantes[, i])), \"\\n\")\n  }\n} else {\n  cargas_rotacionadas &lt;- cargas_discriminantes\n  print(\"Apenas uma função discriminante - rotação não aplicável\")\n}\n\n[1] \"Matriz de Cargas Discriminantes (rotacionadas - VARIMAX):\"\n       LD1    LD2\nX6   1.000  0.003\nX7  -0.038 -0.390\nX8   0.199  0.064\nX9   0.222 -0.836\nX10 -0.029 -0.294\nX11  0.538 -0.558\nX12 -0.140 -0.438\nX13 -0.378 -0.042\nX14  0.160 -0.067\nX15 -0.027 -0.090\nX16  0.235 -0.779\nX17 -0.462 -0.524\nX18  0.129 -0.992\n[1] \"\\nVariáveis Descritivas por Função Rotacionada (|carga| &gt;= 0.40):\"\nFunção 1 : X6 X11 X17 \nFunção 2 : X9 X11 X12 X16 X17 X18 \n\n\nInterpretação das Cargas Rotacionadas (VARIMAX):\nA rotação VARIMAX simplifica a estrutura, criando fatores mais interpretáveis:\nFunção 1 Rotacionada: - X6 (Product Quality): 1.000 - Carga perfeitamente concentrada - X11 (Product Line): 0.538 - Contribuição moderada - X17 (Price Flexibility): -0.462 - Contribuição negativa moderada\nInterpretação: LD1 rotacionada representa essencialmente a “Dimensão de Qualidade”, contrastando qualidade percebida com flexibilidade de preços.\nFunção 2 Rotacionada: - X18 (Delivery Speed): -0.992 - Concentração quase perfeita (negativa) - X9 (Complaint Resolution): -0.836 - Alta correlação negativa\n- X16 (Ordering & Billing): -0.779 - Correlação negativa forte - X11 (Product Line): -0.558 - Contribuição moderada - X17 (Price Flexibility): -0.524 - Contribuição moderada\nInterpretação: LD2 rotacionada representa a “Dimensão Operacional”, focando em velocidade, eficiência e aspectos transacionais.\nVantagem da Rotação: - Simplifica interpretação: Cada função tem foco mais claro - Reduz ambiguidade: Menos variáveis com cargas altas em múltiplas funções - Facilita comunicação gerencial: Dimensões mais intuitivas\n\n\n5.3 Índice de Potência\n\n# Calculando índice de potência conforme Hair et al.\nif(ncol(cargas_discriminantes) &gt; 1) {\n  # Autovalores relativos\n  autovalores_relativos &lt;- eigenvalues / sum(eigenvalues)\n  \n  # Índice de potência para cada variável\n  indice_potencia &lt;- numeric(nrow(cargas_rotacionadas))\n  names(indice_potencia) &lt;- rownames(cargas_rotacionadas)\n  \n  for(i in 1:nrow(cargas_rotacionadas)) {\n    potencia_total &lt;- 0\n    for(j in 1:ncol(cargas_rotacionadas)) {\n      potencia_total &lt;- potencia_total + (cargas_rotacionadas[i, j]^2 * autovalores_relativos[j])\n    }\n    indice_potencia[i] &lt;- potencia_total\n  }\n  \n  # Ordenando por índice de potência\n  indice_potencia_ordenado &lt;- sort(indice_potencia, decreasing = TRUE)\n  \n  print(\"Índice de Potência das Variáveis:\")\n  print(round(indice_potencia_ordenado, 3))\n}\n\n[1] \"Índice de Potência das Variáveis:\"\n   X6   X11   X17   X18    X9   X16   X13   X12    X8    X7   X14   X10   X15 \n0.835 0.293 0.224 0.176 0.157 0.146 0.120 0.048 0.034 0.026 0.022 0.015 0.002 \n\n\nInterpretação do Índice de Potência:\nO índice de potência combina a contribuição de cada variável em todas as funções, ponderada pela importância relativa de cada função:\nRanking por Poder Discriminante Total:\n\n\n\n\n\n\n\n\n\n\nPosição\nVariável\nDescrição\nÍndice\nInterpretação\n\n\n\n\n1º\nX6\nProduct Quality\n0.835\nDiscriminador principal - fundamental para diferenciação\n\n\n2º\nX11\nProduct Line\n0.293\nSegundo mais importante - variedade de produtos relevante\n\n\n3º\nX17\nPrice Flexibility\n0.224\nTerceiro lugar - flexibilidade de preços diferencia grupos\n\n\n4º\nX18\nDelivery Speed\n0.176\nQuarto lugar - velocidade importante apesar de estar no modelo\n\n\n5º\nX9\nComplaint Resolution\n0.157\nModeradamente importante - resolução de problemas diferencia\n\n\n\nInsights Principais:\n\nX6 (Product Quality) é o discriminador dominante, responsável por mais de 83% do poder discriminante total\nX18 (Delivery Speed), apesar de estar no modelo final, ocupa apenas a 4ª posição no índice de potência\nX11 (Product Line) aparece como segundo mais importante, sugerindo que variedade de produtos é crucial\nA concentração de poder nas primeiras variáveis indica que poucas dimensões explicam a maior parte da discriminação\n\nImplicações Gerenciais: - Prioridade máxima: Investir em qualidade do produto - Segunda prioridade: Expandir e melhorar linha de produtos - Terceira prioridade: Desenvolver flexibilidade de preços - Monitoramento: Acompanhar velocidade de entrega e resolução de reclamações\n\n\n5.4 Razões F Univariadas\n\n# Calculando razões F univariadas para cada variável\nrazoes_f &lt;- numeric(length(variaveis_independentes))\nnames(razoes_f) &lt;- variaveis_independentes\n\nfor(var in variaveis_independentes) {\n  formula_temp &lt;- as.formula(paste(var, \"~ X1\"))\n  anova_temp &lt;- aov(formula_temp, data = amostra_analise)\n  razoes_f[var] &lt;- summary(anova_temp)[[1]][\"X1\", \"F value\"]\n}\n\n# Ordenando por valor F\nrazoes_f_ordenadas &lt;- sort(razoes_f, decreasing = TRUE)\n\nprint(\"Razões F Univariadas:\")\n\n[1] \"Razões F Univariadas:\"\n\nprint(round(razoes_f_ordenadas, 3))\n\n   X18     X6     X9    X11    X16    X17    X13    X12    X14     X7    X10 \n24.425 22.885 22.739 20.721 17.664 13.892  9.075  2.873  0.919  0.799  0.753 \n    X8    X15 \n 0.715  0.599 \n\n# Teste de significância (α = 0.05)\np_valores &lt;- numeric(length(variaveis_independentes))\nnames(p_valores) &lt;- variaveis_independentes\n\nfor(var in variaveis_independentes) {\n  formula_temp &lt;- as.formula(paste(var, \"~ X1\"))\n  anova_temp &lt;- aov(formula_temp, data = amostra_analise)\n  p_valores[var] &lt;- summary(anova_temp)[[1]][\"X1\", \"Pr(&gt;F)\"]\n}\n\nprint(\"\\nVariáveis Significativas (p &lt; 0.05):\")\n\n[1] \"\\nVariáveis Significativas (p &lt; 0.05):\"\n\nprint(names(p_valores[p_valores &lt; 0.05]))\n\n[1] \"X6\"  \"X9\"  \"X11\" \"X13\" \"X16\" \"X17\" \"X18\"\n\n\nInterpretação das Razões F Univariadas:\nRanking de Poder Discriminante Individual:\n\n\n\n\n\n\n\n\n\n\n\nPosição\nVariável\nF-value\np-valor\nStatus\nInterpretação\n\n\n\n\n1º\nX18 (Delivery Speed)\n24.425\n&lt; 0.001\n***\nMelhor discriminador individual\n\n\n2º\nX6 (Product Quality)\n22.885\n&lt; 0.001\n***\nSegundo melhor discriminador\n\n\n3º\nX9 (Complaint Resolution)\n22.739\n&lt; 0.001\n***\nTerceiro em poder discriminante\n\n\n4º\nX11 (Product Line)\n20.721\n&lt; 0.001\n***\nQuarto colocado significativo\n\n\n5º\nX16 (Ordering & Billing)\n17.664\n&lt; 0.001\n***\nQuinto em importância\n\n\n\nVariáveis Significativas (p &lt; 0.05): X6, X9, X11, X13, X16, X17, X18 (7 de 13 variáveis)\nComparação: Poder Individual vs. Poder Combinado:\n\nX18 (Delivery Speed):\n\nIndividual: 1º lugar (F = 24.425)\nCombinado: 4º lugar (Índice = 0.176)\nInterpretação: Excelente discriminador individual, mas com alguma redundância no modelo conjunto\n\nX6 (Product Quality):\n\nIndividual: 2º lugar (F = 22.885)\n\nCombinado: 1º lugar (Índice = 0.835)\nInterpretação: Forte individual e dominante no modelo conjunto\n\n\nInsights sobre Seleção de Variáveis:\n\nCritério Hair et al.: Usar X6 + X18 é justificado pelo alto poder discriminante individual de ambas\nPotencial de otimização: X9 (Complaint Resolution) tem poder individual muito alto e poderia ser considerada\nRedundância: Várias variáveis significativas sugerem multicolinearidade (confirmada pelos VIF altos)\n\nRecomendações Gerenciais: 1. Foco primário: Delivery Speed e Product Quality (variáveis do modelo) 2. Foco secundário: Complaint Resolution (alto poder discriminante individual)\n3. Monitoramento: Product Line e Ordering & Billing (significativas e importantes) 4. Revisão: Considerar modelo expandido incluindo X9 para melhor discriminação\n\n\n5.5 Gráfico de Vetores de Atribuição no Espaço Discriminante\n\n# Gráfico dos valores F univariados com descrições\nf_df &lt;- data.frame(\n  Variavel = names(f_univariados),\n  F_Value = f_univariados,\n  P_Value = p_univariados,\n  Significativo = p_univariados &lt; 0.05\n) %&gt;%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\np_f_values &lt;- ggplot2::ggplot(f_df, ggplot2::aes(x = reorder(Variavel_Desc, F_Value), \n                                                 y = F_Value, fill = Significativo)) +\n  ggplot2::geom_col(alpha = 0.8) +\n  ggplot2::geom_text(ggplot2::aes(label = round(F_Value, 1)), hjust = -0.1, size = 3) +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"TRUE\" = \"steelblue\", \"FALSE\" = \"gray70\"),\n                            labels = c(\"FALSE\" = \"Não Significativo\", \"TRUE\" = \"Significativo\")) +\n  ggplot2::labs(title = \"Valores F Univariados para Seleção de Variáveis\",\n                subtitle = \"Poder discriminante individual de cada variável\",\n                x = \"Variáveis\", y = \"Estatística F\",\n                fill = \"Significância\\n(p &lt; 0.05)\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.y = ggplot2::element_text(size = 9))\n\nprint(p_f_values)\n\n\n\n\n\n\n\n# Criando gráfico de vetores de atribuição (variáveis no espaço discriminante)\nescores_todos &lt;- predict(modelo_final, amostra_analise)$x\ndf_escores &lt;- data.frame(\n  Funcao1 = escores_todos[, 1],\n  Funcao2 = escores_todos[, 2],\n  Grupo = amostra_analise$X1,\n  Probabilidades = apply(predict(modelo_final, amostra_analise)$posterior, 1, max)\n)\n\n# Adicionando centróides\ndf_centroides &lt;- data.frame(\n  Funcao1 = centroides_discriminantes[, 1],\n  Funcao2 = centroides_discriminantes[, 2],\n  Grupo = factor(rownames(centroides_discriminantes), \n                levels = levels(amostra_analise$X1))\n)\n\n# Escalonando as cargas para melhor visualização\nescala_vetor &lt;- 3  # Fator de escala para os vetores\ncargas_escalonadas &lt;- cargas_discriminantes * escala_vetor\n\n# Preparando dados dos vetores com descrições\nvetores_df &lt;- data.frame(\n  Variavel = rownames(cargas_discriminantes),\n  LD1_start = 0,\n  LD2_start = 0,\n  LD1_end = cargas_escalonadas[, 1],\n  LD2_end = cargas_escalonadas[, 2],\n  Magnitude = sqrt(cargas_discriminantes[, 1]^2 + cargas_discriminantes[, 2]^2),\n  Significativa = rownames(cargas_discriminantes) %in% vars_significativas\n) %&gt;%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\n# Gráfico de vetores de atribuição expandidos\np_vetores &lt;- ggplot2::ggplot() +\n  # Pontos dos grupos (mais transparentes para não ofuscar os vetores)\n  ggplot2::geom_point(data = df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo), \n                      alpha = 0.3, size = 1) +\n  # Centróides dos grupos\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 6, shape = 17, color = \"black\") +\n  # LABELS DOS CENTRÓIDES - NOVO\n  ggplot2::geom_text(data = df_centroides, \n                     ggplot2::aes(x = Funcao1, y = Funcao2, label = Grupo),\n                     vjust = -1.5, hjust = 0.5, color = \"black\", \n                     fontface = \"bold\", size = 3.5,\n                     box.padding = 0.5) +\n  # Vetores das variáveis\n  ggplot2::geom_segment(data = vetores_df,\n                        ggplot2::aes(x = LD1_start, y = LD2_start, \n                                     xend = LD1_end, yend = LD2_end,\n                                     color = Significativa, size = Magnitude),\n                        arrow = ggplot2::arrow(length = ggplot2::unit(0.3, \"cm\")),\n                        alpha = 0.8) +\n  # Labels das variáveis com descrições\n  ggplot2::geom_text(data = vetores_df,\n                     ggplot2::aes(x = LD1_end * 1.1, y = LD2_end * 1.1, \n                                  label = Variavel_Desc, color = Significativa),\n                     size = 2.5, fontface = \"bold\") +\n  # Eixos de referência\n  ggplot2::geom_hline(yintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  ggplot2::geom_vline(xintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  # Escalas e temas\n  ggplot2::scale_color_manual(values = c(\"FALSE\" = \"gray50\", \"TRUE\" = \"red\")) +\n  ggplot2::scale_size_continuous(range = c(0.5, 2), guide = \"none\") +\n  ggplot2::labs(title = \"Vetores de Atribuição das Variáveis no Espaço Discriminante\",\n                subtitle = paste(\"Vetores mostram contribuição das variáveis para as funções discriminantes\\n\",\n                                \"Triângulos pretos = centróides dos grupos | Escala dos vetores: \", escala_vetor, \"x\"),\n                x = paste(\"Função Discriminante 1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"Função Discriminante 2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Variável\\nSignificativa\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 plot.subtitle = ggplot2::element_text(size = 10))\n\nWarning in ggplot2::geom_text(data = df_centroides, ggplot2::aes(x = Funcao1, :\nIgnoring unknown parameters: `box.padding`\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\nprint(p_vetores)\n\n\n\n\n\n\n\n# IDENTIFICAÇÃO DOS GRUPOS DA VARIÁVEL DEPENDENTE\ncat(\"\\n=== IDENTIFICAÇÃO DOS GRUPOS DA VARIÁVEL DEPENDENTE ===\\n\")\n\n\n=== IDENTIFICAÇÃO DOS GRUPOS DA VARIÁVEL DEPENDENTE ===\n\ncat(\"Variável Dependente: X1 (Customer Type)\\n\")\n\nVariável Dependente: X1 (Customer Type)\n\ncat(\"Descrição: Tempo de relacionamento com a empresa HBAT\\n\\n\")\n\nDescrição: Tempo de relacionamento com a empresa HBAT\n\n# Grupos identificados no gráfico\ngrupos_identificados &lt;- levels(amostra_analise$X1)\nfreq_grupos &lt;- table(amostra_analise$X1)\ncentroides_info &lt;- centroides_discriminantes\n\ncat(\"GRUPOS REPRESENTADOS NO GRÁFICO:\\n\")\n\nGRUPOS REPRESENTADOS NO GRÁFICO:\n\nfor(i in 1:length(grupos_identificados)) {\n  grupo_nome &lt;- grupos_identificados[i]\n  freq &lt;- freq_grupos[i]\n  ld1_pos &lt;- round(centroides_info[grupo_nome, \"LD1\"], 2)\n  ld2_pos &lt;- round(centroides_info[grupo_nome, \"LD2\"], 2)\n  \n  cat(sprintf(\"🔺 GRUPO %d: %s\\n\", i, grupo_nome))\n  cat(sprintf(\"   - Frequência: %d casos (%.1f%%)\\n\", \n              freq, (freq/sum(freq_grupos))*100))\n  cat(sprintf(\"   - Posição no gráfico: LD1 = %.2f, LD2 = %.2f\\n\", ld1_pos, ld2_pos))\n  cat(sprintf(\"   - Característica: %s\\n\", \n              switch(i,\n                     \"Clientes com relacionamento recente - percepções iniciais\",\n                     \"Clientes com relacionamento estabelecido - percepções moderadas\", \n                     \"Clientes com relacionamento consolidado - percepções elevadas\")))\n  cat(\"\\n\")\n}\n\n🔺 GRUPO 1: Menos de 1 ano\n   - Frequência: 20 casos (33.3%)\n   - Posição no gráfico: LD1 = -1.61, LD2 = 0.31\n   - Característica: Clientes com relacionamento recente - percepções iniciais\n\n🔺 GRUPO 2: De 1 a 5 anos\n   - Frequência: 22 casos (36.7%)\n   - Posição no gráfico: LD1 = 0.26, LD2 = -0.71\n   - Característica: Clientes com relacionamento estabelecido - percepções moderadas\n\n🔺 GRUPO 3: Mais de 5 anos\n   - Frequência: 18 casos (30.0%)\n   - Posição no gráfico: LD1 = 1.47, LD2 = 0.53\n   - Característica: Clientes com relacionamento consolidado - percepções elevadas\n\n# Interpretação dos centróides no espaço discriminante\ncat(\"INTERPRETAÇÃO DOS CENTRÓIDES (TRIÂNGULOS PRETOS):\\n\")\n\nINTERPRETAÇÃO DOS CENTRÓIDES (TRIÂNGULOS PRETOS):\n\ncat(\"- Os triângulos pretos representam o 'centro' de cada grupo no espaço discriminante\\n\")\n\n- Os triângulos pretos representam o 'centro' de cada grupo no espaço discriminante\n\ncat(\"- Sua posição indica as características médias de cada grupo\\n\")\n\n- Sua posição indica as características médias de cada grupo\n\ncat(\"- A distância entre centróides mostra o grau de separação entre grupos\\n\")\n\n- A distância entre centróides mostra o grau de separação entre grupos\n\n# Análise das posições dos centróides\ncat(\"\\nANÁLISE DAS POSIÇÕES:\\n\")\n\n\nANÁLISE DAS POSIÇÕES:\n\nfor(i in 1:nrow(centroides_info)) {\n  grupo_nome &lt;- rownames(centroides_info)[i]\n  ld1_val &lt;- centroides_info[i, \"LD1\"]\n  ld2_val &lt;- centroides_info[i, \"LD2\"]\n  \n  # Interpretação baseada na posição\n  interpretacao_ld1 &lt;- ifelse(ld1_val &gt; 0, \"valores altos em LD1\", \"valores baixos em LD1\")\n  interpretacao_ld2 &lt;- ifelse(ld2_val &gt; 0, \"valores altos em LD2\", \"valores baixos em LD2\")\n  \n  cat(sprintf(\"- %s: Caracterizado por %s e %s\\n\", \n              grupo_nome, interpretacao_ld1, interpretacao_ld2))\n}\n\n- Menos de 1 ano: Caracterizado por valores baixos em LD1 e valores altos em LD2\n- De 1 a 5 anos: Caracterizado por valores altos em LD1 e valores baixos em LD2\n- Mais de 5 anos: Caracterizado por valores altos em LD1 e valores altos em LD2\n\ncat(\"\\nLEGENDA DO GRÁFICO:\\n\")\n\n\nLEGENDA DO GRÁFICO:\n\ncat(\"🔺 Triângulos pretos = Centróides dos grupos\\n\")\n\n🔺 Triângulos pretos = Centróides dos grupos\n\ncat(\"● Pontos coloridos = Observações individuais por grupo\\n\")\n\n● Pontos coloridos = Observações individuais por grupo\n\ncat(\"→ Vetores vermelhos = Variáveis significativas (p &lt; 0.05)\\n\")\n\n→ Vetores vermelhos = Variáveis significativas (p &lt; 0.05)\n\ncat(\"→ Vetores cinza = Variáveis não significativas\\n\")\n\n→ Vetores cinza = Variáveis não significativas\n\ncat(\"📏 Comprimento do vetor = Magnitude da contribuição discriminante\\n\")\n\n📏 Comprimento do vetor = Magnitude da contribuição discriminante\n\n# Interpretação dos vetores\ncat(\"\\n=== INTERPRETAÇÃO DOS VETORES DE ATRIBUIÇÃO ===\\n\")\n\n\n=== INTERPRETAÇÃO DOS VETORES DE ATRIBUIÇÃO ===\n\n\n\n\n6.4 Análise das Distâncias entre Grupos\n\n# Calculando distâncias Mahalanobis entre centróides\ncentroides_matriz &lt;- as.matrix(centroides_discriminantes)\n\n# Matriz de distâncias entre centróides\nn_grupos &lt;- nrow(centroides_matriz)\ndist_centroides &lt;- matrix(0, n_grupos, n_grupos)\nrownames(dist_centroides) &lt;- rownames(centroides_matriz)\ncolnames(dist_centroides) &lt;- rownames(centroides_matriz)\n\nfor(i in 1:n_grupos) {\n  for(j in 1:n_grupos) {\n    dist_centroides[i, j] &lt;- sqrt(sum((centroides_matriz[i, ] - centroides_matriz[j, ])^2))\n  }\n}\n\nprint(\"Matriz de Distâncias Euclidianas entre Centróides:\")\n\n[1] \"Matriz de Distâncias Euclidianas entre Centróides:\"\n\nprint(round(dist_centroides, 3))\n\n               Menos de 1 ano De 1 a 5 anos Mais de 5 anos\nMenos de 1 ano          0.000         2.127          3.084\nDe 1 a 5 anos           2.127         0.000          1.737\nMais de 5 anos          3.084         1.737          0.000\n\n# Visualização das distâncias como heatmap\ndist_df &lt;- reshape2::melt(dist_centroides)\nnames(dist_df) &lt;- c(\"Grupo1\", \"Grupo2\", \"Distancia\")\n\np_distancias &lt;- ggplot2::ggplot(dist_df, ggplot2::aes(x = Grupo1, y = Grupo2, fill = Distancia)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = round(Distancia, 2)), \n                     color = \"white\", fontface = \"bold\", size = 5) +\n  ggplot2::scale_fill_viridis_c(name = \"Distância\\nEuclidiana\") +\n  ggplot2::labs(title = \"Matriz de Distâncias entre Centróides dos Grupos\",\n                subtitle = \"Distâncias calculadas no espaço discriminante\",\n                x = \"Grupo\", y = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\nprint(p_distancias)\n\n\n\n\n\n\n\n# Análise de separação\ndist_matrix_upper &lt;- dist_centroides[upper.tri(dist_centroides)]\n\n# Identificando grupos mais próximos e mais distantes\ndist_indices &lt;- which(dist_centroides == min(dist_matrix_upper), arr.ind = TRUE)[1, ]\ngrupos_proximos &lt;- c(rownames(dist_centroides)[dist_indices[1]], \n                    colnames(dist_centroides)[dist_indices[2]])\n\ndist_indices_max &lt;- which(dist_centroides == max(dist_matrix_upper), arr.ind = TRUE)[1, ]\ngrupos_distantes &lt;- c(rownames(dist_centroides)[dist_indices_max[1]], \n                     colnames(dist_centroides)[dist_indices_max[2]])\n\nInterpretação da Análise de Distâncias:\nMatriz de Distâncias Euclidianas: - Menor distância: “De 1 a 5 anos” ↔︎ “Mais de 5 anos” (1.737) - Maior distância: “Menos de 1 ano” ↔︎ “Mais de 5 anos” (3.084) - Distância intermediária: “Menos de 1 ano” ↔︎ “De 1 a 5 anos” (2.127)\nPadrões de Similaridade:\n\nGrupos Intermediário e Maduro são mais próximos:\n\nDistância de apenas 1.737 unidades\nInterpretação: Após 1 ano, as percepções começam a convergir\nImplicação: O primeiro ano é crítico para formar percepções duradouras\n\nClientes Novos são mais distantes de todos:\n\nMaior distância dos clientes maduros (3.084)\nInterpretação: Período inicial tem características muito distintas\nImplicação: Estratégias específicas necessárias para novos clientes\n\nProgressão Não-Linear:\n\nA evolução “Novo → Intermediário → Maduro” não é uniforme\nMaior salto entre “Novo” e “Intermediário” (2.127)\nMenor progressão entre “Intermediário” e “Maduro” (1.737)\n\n\nInsights Gerenciais:\n\nPeríodo Crítico: Os primeiros 12 meses são fundamentais para retenção\nConvergência: Após 1 ano, clientes tendem a desenvolver percepções similares\nSegmentação: Dois grandes segmentos emergem: “Novos” vs. “Estabelecidos” (intermediários + maduros)\n\n\n\n6.5 Comparação Visual: Espaço Original vs. Espaço Discriminante\n\n# Comparando visualização no espaço original (X6, X18) vs. espaço discriminante\np_original &lt;- ggplot2::ggplot(amostra_analise, ggplot2::aes(x = X6, y = X18, color = X1)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = centroides, ggplot2::aes(x = X6, y = X18), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Espaço Original\",\n                subtitle = \"Variáveis originais do modelo discriminante\",\n                x = descricoes_variaveis[\"X6\"], \n                y = descricoes_variaveis[\"X18\"],\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 12, face = \"bold\"))\n\np_discriminante &lt;- ggplot2::ggplot(df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Espaço Discriminante (LD1 vs LD2)\",\n                subtitle = \"Funções discriminantes otimizadas para separação\",\n                x = paste(\"LD1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"LD2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 12, face = \"bold\"))\n\n# Combinando os gráficos\ncomparacao &lt;- gridExtra::grid.arrange(\n  p_original, p_discriminante, \n  ncol = 2,\n  top = grid::textGrob(\"Comparação: Espaço Original vs. Espaço Discriminante\", \n                       gp = grid::gpar(fontsize = 16, fontface = \"bold\"))\n)\n\n\n\n\n\n\n\nprint(comparacao)\n\nTableGrob (2 x 2) \"arrange\": 3 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (2-2,2-2) arrange      gtable[layout]\n3 3 (1-1,1-2) arrange text[GRID.text.321]\n\n# Interpretação da comparação\ncat(\"\\n=== INTERPRETAÇÃO DA COMPARAÇÃO ===\\n\")\n\n\n=== INTERPRETAÇÃO DA COMPARAÇÃO ===\n\ncat(\"- Espaço Original: mostra sobreposição entre grupos\\n\")\n\n- Espaço Original: mostra sobreposição entre grupos\n\ncat(\"- Espaço Discriminante: maximiza separação entre grupos\\n\")\n\n- Espaço Discriminante: maximiza separação entre grupos\n\ncat(\"- A transformação discriminante melhora a separabilidade\\n\")\n\n- A transformação discriminante melhora a separabilidade\n\ncat(\"- LD1 e LD2 são combinações lineares que maximizam discriminação\\n\")\n\n- LD1 e LD2 são combinações lineares que maximizam discriminação\n\n\n\n\n\nEstágio 6: Validação dos Resultados\n\n6.6 Matriz de Classificação e Validação\n\n# Classificação da amostra de análise\npredicoes_analise &lt;- predict(modelo_final, amostra_analise)\nmatriz_confusao_analise &lt;- table(Predito = predicoes_analise$class, \n                                Real = amostra_analise$X1)\n\nprint(\"Matriz de Classificação - Amostra de Análise:\")\n\n[1] \"Matriz de Classificação - Amostra de Análise:\"\n\nprint(matriz_confusao_analise)\n\n                Real\nPredito          Menos de 1 ano De 1 a 5 anos Mais de 5 anos\n  Menos de 1 ano             16             2              0\n  De 1 a 5 anos               3            14              1\n  Mais de 5 anos              1             6             17\n\n# Taxa de acerto geral\nacerto_geral_analise &lt;- sum(diag(matriz_confusao_analise)) / sum(matriz_confusao_analise)\n\n# Taxa de acerto por grupo\nacerto_por_grupo_analise &lt;- diag(matriz_confusao_analise) / rowSums(matriz_confusao_analise)\nprint(\"Taxa de Acerto por Grupo (Análise):\")\n\n[1] \"Taxa de Acerto por Grupo (Análise):\"\n\nprint(round(acerto_por_grupo_analise * 100, 1))\n\nMenos de 1 ano  De 1 a 5 anos Mais de 5 anos \n          88.9           77.8           70.8 \n\n# Visualização da matriz de confusão\nmatriz_conf_df &lt;- as.data.frame(matriz_confusao_analise)\nnames(matriz_conf_df) &lt;- c(\"Predito\", \"Real\", \"Freq\")\n\np_matriz_conf &lt;- ggplot2::ggplot(matriz_conf_df, ggplot2::aes(x = Real, y = Predito, fill = Freq)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = Freq), color = \"white\", size = 6, fontface = \"bold\") +\n  ggplot2::scale_fill_viridis_c(name = \"Frequência\") +\n  ggplot2::labs(title = \"Matriz de Confusão - Amostra de Análise\",\n                subtitle = paste(\"Taxa de Acerto Geral:\", round(acerto_geral_analise * 100, 1), \"%\"),\n                x = \"Grupo Real\", y = \"Grupo Predito\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\nprint(p_matriz_conf)\n\n\n\n\n\n\n\n\nTaxa de Acerto Geral (Análise): 78.3%\nTaxa de Acerto por Grupo (Análise):\n\n\n\n\n\nGrupo\nTaxa.de.Acerto….\n\n\n\n\nMenos de 1 ano\n88.9\n\n\nDe 1 a 5 anos\n77.8\n\n\nMais de 5 anos\n70.8\n\n\n\n\n\n\n\n6.7 Validação Cruzada\n\n# Função para validação cruzada\nvalidacao_cruzada &lt;- function(dados, formula) {\n  n &lt;- nrow(dados)\n  predicoes &lt;- character(n)\n  \n  for(i in 1:n) {\n    # Treina modelo sem a observação i\n    dados_treino &lt;- dados[-i, ]\n    modelo_temp &lt;- MASS::lda(formula, data = dados_treino)\n    \n    # Prediz a observação i\n    predicao_temp &lt;- predict(modelo_temp, dados[i, ])\n    predicoes[i] &lt;- as.character(predicao_temp$class)\n  }\n  \n  return(factor(predicoes, levels = levels(dados$X1)))\n}\n\n# Aplicando validação cruzada\npredicoes_cv &lt;- validacao_cruzada(amostra_analise, X1 ~ X6 + X18)\nmatriz_confusao_cv &lt;- table(Predito = predicoes_cv, Real = amostra_analise$X1)\n\nprint(\"Matriz de Classificação - Validação Cruzada:\")\n\n[1] \"Matriz de Classificação - Validação Cruzada:\"\n\nprint(matriz_confusao_cv)\n\n                Real\nPredito          Menos de 1 ano De 1 a 5 anos Mais de 5 anos\n  Menos de 1 ano             16             2              0\n  De 1 a 5 anos               3            14              1\n  Mais de 5 anos              1             6             17\n\n# Taxa de acerto validação cruzada\nacerto_geral_cv &lt;- sum(diag(matriz_confusao_cv)) / sum(matriz_confusao_cv)\n\nTaxa de Acerto Geral (Validação Cruzada): 78.3%\n\n\n6.8 Validação Externa\n\n# Classificação da amostra de validação\npredicoes_validacao &lt;- predict(modelo_final, amostra_validacao)\nmatriz_confusao_validacao &lt;- table(Predito = predicoes_validacao$class, \n                                  Real = amostra_validacao$X1)\n\nprint(\"Matriz de Classificação - Amostra de Validação:\")\n\n[1] \"Matriz de Classificação - Amostra de Validação:\"\n\nprint(matriz_confusao_validacao)\n\n                Real\nPredito          Menos de 1 ano De 1 a 5 anos Mais de 5 anos\n  Menos de 1 ano             10             1              0\n  De 1 a 5 anos               1            10              4\n  Mais de 5 anos              1             2             11\n\n# Taxa de acerto amostra de validação\nacerto_geral_validacao &lt;- sum(diag(matriz_confusao_validacao)) / sum(matriz_confusao_validacao)\n\n# Taxa de acerto por grupo\nacerto_por_grupo_validacao &lt;- diag(matriz_confusao_validacao) / rowSums(matriz_confusao_validacao)\nprint(\"Taxa de Acerto por Grupo (Validação):\")\n\n[1] \"Taxa de Acerto por Grupo (Validação):\"\n\nprint(round(acerto_por_grupo_validacao * 100, 1))\n\nMenos de 1 ano  De 1 a 5 anos Mais de 5 anos \n          90.9           66.7           78.6 \n\n\nTaxa de Acerto Geral (Validação): 77.5%\n\n\n6.9 Critérios de Chance\n\n# Calculando critérios de chance\ntamanhos_grupos &lt;- table(amostra_analise$X1)\nproporcoes_grupos &lt;- tamanhos_grupos / sum(tamanhos_grupos)\n\n# Critério de chance proporcional\ncriterio_chance_proporcional &lt;- sum(proporcoes_grupos^2) * 100\n\n# Critério de chance máxima\ncriterio_chance_maxima &lt;- max(proporcoes_grupos) * 100\n\n# Gráfico de comparação das taxas de acerto\ntaxas_acerto &lt;- data.frame(\n  Metodo = c(\"Análise\", \"Validação Cruzada\", \"Validação Externa\", \n             \"Critério Proporcional\", \"Critério Máximo\"),\n  Taxa = c(acerto_geral_analise * 100, \n           acerto_geral_cv * 100,\n           acerto_geral_validacao * 100,\n           criterio_chance_proporcional,\n           criterio_chance_maxima),\n  Tipo = c(\"Modelo\", \"Modelo\", \"Modelo\", \"Referência\", \"Referência\")\n)\n\np_performance &lt;- ggplot2::ggplot(taxas_acerto, ggplot2::aes(x = reorder(Metodo, Taxa), y = Taxa, fill = Tipo)) +\n  ggplot2::geom_col(alpha = 0.8, width = 0.7) +\n  ggplot2::geom_text(ggplot2::aes(label = paste0(round(Taxa, 1), \"%\")), \n                     hjust = -0.1, size = 4, fontface = \"bold\") +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"Modelo\" = \"steelblue\", \"Referência\" = \"coral\")) +\n  ggplot2::labs(title = \"Comparação das Taxas de Acerto\",\n                subtitle = \"Modelo vs. Critérios de Chance\",\n                x = \"Método de Validação\", \n                y = \"Taxa de Acerto (%)\",\n                fill = \"Tipo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"))\n\nprint(p_performance)\n\n\n\n\n\n\n\n\nCritérios de Chance:\n\nCritério de Chance Proporcional: 33.6%\nCritério de Chance Máxima: 36.7%\n\nComparação com Resultados Obtidos:\n\nTaxa de Acerto Análise: 78.3% vs Critério Proporcional: 33.6%\nTaxa de Acerto Validação Cruzada: 78.3% vs Critério Proporcional: 33.6%\n\nTaxa de Acerto Validação: 77.5% vs Critério Proporcional: 33.6%\n\n\n\n\nResumo da Interpretação Gerencial\nOs resultados da análise discriminante revelam insights importantes sobre a diferenciação de clientes baseada no tempo de relacionamento. Com o dataset completo analisado, identificamos que de 13 variáveis independentes testadas, apenas 2 foram suficientes para uma discriminação efetiva.\n\nPrincipais Descobertas:\n\nVariáveis Discriminantes: X6 (Product Quality) e X18 (Delivery Speed) são os principais diferenciadores, representando aproximadamente 100% da variância discriminante total.\nPrecisão do Modelo: O modelo alcança alta taxa de acertos na amostra de análise, superando significativamente os critérios de chance.\nDiferenças entre Grupos:\n\nClientes novos (&lt; 1 ano): Menores percepções de qualidade e velocidade\nClientes intermediários (1-5 anos): Percepções moderadas\nClientes estabelecidos (&gt; 5 anos): Maiores percepções de qualidade e velocidade\n\n\n\n\nImplicações Gerenciais:\n\nFoco na Qualidade: Investir na melhoria da qualidade do produto é fundamental para reter clientes\nOtimização de Entregas: A velocidade de entrega é um diferencial competitivo crítico\nSegmentação: Os 3 grupos identificados requerem estratégias diferenciadas\n\n\n# Médias dos grupos para interpretação\nmedias_grupos &lt;- aggregate(amostra_analise[, variaveis_independentes], \n                          by = list(amostra_analise$X1), FUN = mean)\nnames(medias_grupos)[1] &lt;- \"Grupo\"\n\n# Corrigindo erro na impressão das médias dos grupos\nmedias_grupos_numericas &lt;- medias_grupos[, -1]  # Remove coluna 'Grupo'\nrownames(medias_grupos_numericas) &lt;- medias_grupos$Grupo\n\nprint(\"Médias dos Grupos nas Variáveis Independentes:\")\n\n[1] \"Médias dos Grupos nas Variáveis Independentes:\"\n\nprint(round(medias_grupos_numericas, 2))\n\n                 X6   X7   X8   X9  X10  X11  X12  X13  X14  X15  X16  X17  X18\nMenos de 1 ano 6.99 3.56 5.28 4.30 3.83 4.72 4.75 7.42 5.98 5.38 3.53 4.29 3.14\nDe 1 a 5 anos  7.34 3.85 5.30 5.99 4.27 5.65 5.49 7.75 5.98 4.91 4.70 5.54 4.27\nMais de 5 anos 9.18 3.73 5.82 5.92 4.01 7.00 5.12 5.99 6.32 5.37 4.65 3.94 4.17\n\ncat(\"\\n=== INTERPRETAÇÃO DAS FUNÇÕES DISCRIMINANTES ===\\n\")\n\n\n=== INTERPRETAÇÃO DAS FUNÇÕES DISCRIMINANTES ===\n\ncat(\"Função 1: Diferencia principalmente entre Grupo 1 e Grupos 2-3\\n\")\n\nFunção 1: Diferencia principalmente entre Grupo 1 e Grupos 2-3\n\ncat(\"Função 2: Diferencia principalmente entre Grupo 3 e Grupos 1-2\\n\")\n\nFunção 2: Diferencia principalmente entre Grupo 3 e Grupos 1-2\n\ncat(\"\\n=== VARIÁVEIS MAIS IMPORTANTES ===\\n\")\n\n\n=== VARIÁVEIS MAIS IMPORTANTES ===\n\nif(exists(\"indice_potencia_ordenado\")) {\n  cat(\"Por Índice de Potência:\\n\")\n  print(names(indice_potencia_ordenado)[1:min(5, length(indice_potencia_ordenado))])\n}\n\nPor Índice de Potência:\n[1] \"X6\"  \"X11\" \"X17\" \"X18\" \"X9\" \n\ncat(\"\\nPor Razão F Univariada:\\n\")\n\n\nPor Razão F Univariada:\n\nprint(names(razoes_f_ordenadas)[1:min(5, length(razoes_f_ordenadas))])\n\n[1] \"X18\" \"X6\"  \"X9\"  \"X11\" \"X16\"\n\ncat(\"\\n=== RESUMO FINAL ===\\n\")\n\n\n=== RESUMO FINAL ===\n\ncat(\"Modelo discriminante final: X1 ~ X6 + X18\\n\")\n\nModelo discriminante final: X1 ~ X6 + X18\n\ncat(\"Variáveis selecionadas:\\n\")\n\nVariáveis selecionadas:\n\ncat(\"- X6: Qualidade do produto\\n\")\n\n- X6: Qualidade do produto\n\ncat(\"- X18: Velocidade de entrega\\n\")\n\n- X18: Velocidade de entrega\n\nif(exists(\"modelo_stepwise\")) {\n  cat(\"\\nVariáveis selecionadas pelo procedimento stepwise:\\n\")\n  print(modelo_stepwise$formula)\n}\n\n\nVariáveis selecionadas pelo procedimento stepwise:\n[1] \"X1 ~ X6 + X18\"\n\ncat(\"\\n=== CONCLUSÕES GERENCIAIS ===\\n\")\n\n\n=== CONCLUSÕES GERENCIAIS ===\n\ncat(\"1. A qualidade do produto (X6) e velocidade de entrega (X18) são os principais diferenciadores entre os grupos de clientes.\\n\")\n\n1. A qualidade do produto (X6) e velocidade de entrega (X18) são os principais diferenciadores entre os grupos de clientes.\n\ncat(\"2. O modelo consegue discriminar bem entre os três grupos de tempo de relacionamento.\\n\")\n\n2. O modelo consegue discriminar bem entre os três grupos de tempo de relacionamento.\n\ncat(\"3. Clientes de longo prazo valorizam mais qualidade e velocidade de entrega.\\n\")\n\n3. Clientes de longo prazo valorizam mais qualidade e velocidade de entrega.\n\ncat(\"4. Ações de melhoria devem focar nestas duas dimensões para reter clientes.\\n\")\n\n4. Ações de melhoria devem focar nestas duas dimensões para reter clientes.\n\n\nAnálise das Médias por Grupo:\nOs resultados mostram um padrão claro de evolução das percepções com o tempo de relacionamento, com melhorias progressivas nas percepções de qualidade e velocidade de entrega conforme aumenta o tempo de relacionamento com a empresa.\n\n\n\nApêndice: Informações Técnicas do Dataset\n\nCaracterísticas do Dataset HBAT\n\n# Informações sobre o dataset após limpeza\ncat(\"=== CARACTERÍSTICAS DO DATASET FINAL ===\\n\")\n\n=== CARACTERÍSTICAS DO DATASET FINAL ===\n\ncat(\"Total de observações:\", nrow(hbat_clean), \"\\n\")\n\nTotal de observações: 100 \n\ncat(\"Variáveis independentes analisadas:\", length(variaveis_independentes), \"\\n\")\n\nVariáveis independentes analisadas: 13 \n\ncat(\"Grupos da variável dependente:\", nlevels(hbat_clean$X1), \"\\n\")\n\nGrupos da variável dependente: 3 \n\n# Distribuição dos grupos\ndist_grupos &lt;- table(hbat_clean$X1)\nprop_grupos &lt;- prop.table(dist_grupos) * 100\n\ncat(\"\\nDistribuição dos grupos:\\n\")\n\n\nDistribuição dos grupos:\n\nfor(i in 1:length(dist_grupos)) {\n  cat(\"- \", names(dist_grupos)[i], \": \", dist_grupos[i], \" casos (\", \n      round(prop_grupos[i], 1), \"%)\\n\", sep = \"\")\n}\n\n- Menos de 1 ano: 32 casos (32%)\n- De 1 a 5 anos: 35 casos (35%)\n- Mais de 5 anos: 33 casos (33%)\n\n\n\n\nQualidade dos Dados\n\nMissing values: Removidos através de listwise deletion\nBalanceamento: Dataset relativamente balanceado entre os grupos\nEscala das variáveis: Todas as variáveis independentes estão na escala de 0-10\n\n\n# Informações detalhadas sobre o dataset HBAT\ncat(\"=== INFORMAÇÕES DO DATASET HBAT ===\\n\")\n\n=== INFORMAÇÕES DO DATASET HBAT ===\n\ncat(\"Total de observações:\", nrow(hbat_clean), \"\\n\")\n\nTotal de observações: 100 \n\ncat(\"Variáveis independentes:\", length(variaveis_independentes), \"\\n\")\n\nVariáveis independentes: 13 \n\ncat(\"Grupos da variável dependente:\", nlevels(hbat_clean$X1), \"\\n\")\n\nGrupos da variável dependente: 3 \n\n# Descrição das variáveis (baseado nos labels originais) - ATUALIZADO\ncat(\"\\n=== DESCRIÇÃO COMPLETA DAS VARIÁVEIS ===\\n\")\n\n\n=== DESCRIÇÃO COMPLETA DAS VARIÁVEIS ===\n\nfor(var in names(descricoes_variaveis)) {\n  cat(var, \"-\", descricoes_variaveis[var], \"\\n\")\n}\n\nX1 - Customer Type \nX6 - Product Quality \nX7 - E-Commerce Activities \nX8 - Technical Support \nX9 - Complaint Resolution \nX10 - Advertising \nX11 - Product Line \nX12 - Salesforce Image \nX13 - Competitive Pricing \nX14 - Warranty & Claims \nX15 - New Products \nX16 - Ordering & Billing \nX17 - Price Flexibility \nX18 - Delivery Speed \n\n# Estatísticas descritivas finais\ncat(\"\\n=== ESTATÍSTICAS DESCRITIVAS FINAIS ===\\n\")\n\n\n=== ESTATÍSTICAS DESCRITIVAS FINAIS ===\n\nprint(summary(hbat_clean))\n\n              X1           X6               X7              X8       \n Menos de 1 ano:32   Min.   : 5.000   Min.   :2.200   Min.   :1.300  \n De 1 a 5 anos :35   1st Qu.: 6.575   1st Qu.:3.275   1st Qu.:4.250  \n Mais de 5 anos:33   Median : 8.000   Median :3.600   Median :5.400  \n                     Mean   : 7.810   Mean   :3.672   Mean   :5.365  \n                     3rd Qu.: 9.100   3rd Qu.:3.925   3rd Qu.:6.625  \n                     Max.   :10.000   Max.   :5.700   Max.   :8.500  \n       X9             X10             X11             X12       \n Min.   :2.600   Min.   :1.900   Min.   :2.300   Min.   :2.900  \n 1st Qu.:4.600   1st Qu.:3.175   1st Qu.:4.700   1st Qu.:4.500  \n Median :5.450   Median :4.000   Median :5.750   Median :4.900  \n Mean   :5.442   Mean   :4.010   Mean   :5.805   Mean   :5.123  \n 3rd Qu.:6.325   3rd Qu.:4.800   3rd Qu.:6.800   3rd Qu.:5.800  \n Max.   :7.800   Max.   :6.500   Max.   :8.400   Max.   :8.200  \n      X13             X14             X15            X16             X17      \n Min.   :3.700   Min.   :4.100   Min.   :1.70   Min.   :2.000   Min.   :2.60  \n 1st Qu.:5.875   1st Qu.:5.400   1st Qu.:4.10   1st Qu.:3.700   1st Qu.:3.70  \n Median :7.100   Median :6.100   Median :5.00   Median :4.400   Median :4.35  \n Mean   :6.974   Mean   :6.043   Mean   :5.15   Mean   :4.278   Mean   :4.61  \n 3rd Qu.:8.400   3rd Qu.:6.600   3rd Qu.:6.30   3rd Qu.:4.800   3rd Qu.:5.60  \n Max.   :9.900   Max.   :8.100   Max.   :9.50   Max.   :6.700   Max.   :7.30  \n      X18       \n Min.   :1.600  \n 1st Qu.:3.400  \n Median :3.900  \n Mean   :3.886  \n 3rd Qu.:4.425  \n Max.   :5.500"
  }
]