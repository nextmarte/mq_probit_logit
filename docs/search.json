[
  {
    "objectID": "logit_probit.html",
    "href": "logit_probit.html",
    "title": "LOGIT E PROBIT",
    "section": "",
    "text": "Os modelos Logit e Probit (abreviação de regressão logística e probabilística) nos auxiliam na inferência de probabilidade de ocorrência de eventos onde nossa variável dependente é binária (Y ocorre ou não ocorre), e nosso objetivo é compreender como outras variáveis influenciam a ocorrência ou não desses eventos.\n\n\nEm uma regressão linear, \\(P(Y=1|x)\\) é dado por uma especificação linear dos regressores, o que pode resultar em valores menores que 0 ou maiores que 1, que não fazem sentido com a interpretação probabilística dos parâmetros.\nOs modelos não lineares permitem que a média condicional de Y dado X seja expressa pela probabilidade de Y acontecer dado X:\n\\[E(Y|X) = P(Y=1|X)\\]\n\n\n\n\n\n\nA função de distribuição logística é dada por:\n\\[F(X'\\beta) = \\frac{e^{X'\\beta}}{1 + e^{X'\\beta}} = \\frac{1}{1 + e^{-X'\\beta}}\\]\n\n\n\nA função de distribuição normal padrão é dada por:\n\\[F(X'\\beta) = \\Phi(X'\\beta) = \\int_{-\\infty}^{X'\\beta} \\phi(z)dz\\]\nonde \\(\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{z^2}{2}}\\) é a densidade da normal padrão."
  },
  {
    "objectID": "logit_probit.html#variáveis-dependentes-limitadas",
    "href": "logit_probit.html#variáveis-dependentes-limitadas",
    "title": "LOGIT E PROBIT",
    "section": "",
    "text": "Os modelos Logit e Probit (abreviação de regressão logística e probabilística) nos auxiliam na inferência de probabilidade de ocorrência de eventos onde nossa variável dependente é binária (Y ocorre ou não ocorre), e nosso objetivo é compreender como outras variáveis influenciam a ocorrência ou não desses eventos.\n\n\nEm uma regressão linear, \\(P(Y=1|x)\\) é dado por uma especificação linear dos regressores, o que pode resultar em valores menores que 0 ou maiores que 1, que não fazem sentido com a interpretação probabilística dos parâmetros.\nOs modelos não lineares permitem que a média condicional de Y dado X seja expressa pela probabilidade de Y acontecer dado X:\n\\[E(Y|X) = P(Y=1|X)\\]"
  },
  {
    "objectID": "logit_probit.html#especificação-dos-modelos",
    "href": "logit_probit.html#especificação-dos-modelos",
    "title": "LOGIT E PROBIT",
    "section": "",
    "text": "A função de distribuição logística é dada por:\n\\[F(X'\\beta) = \\frac{e^{X'\\beta}}{1 + e^{X'\\beta}} = \\frac{1}{1 + e^{-X'\\beta}}\\]\n\n\n\nA função de distribuição normal padrão é dada por:\n\\[F(X'\\beta) = \\Phi(X'\\beta) = \\int_{-\\infty}^{X'\\beta} \\phi(z)dz\\]\nonde \\(\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{z^2}{2}}\\) é a densidade da normal padrão."
  },
  {
    "objectID": "logit_probit.html#descrição-dos-dados",
    "href": "logit_probit.html#descrição-dos-dados",
    "title": "LOGIT E PROBIT",
    "section": "Descrição dos Dados",
    "text": "Descrição dos Dados\nConsideramos inlf (“no mercado de trabalho”) como uma variável binária que indica a participação no mercado de trabalho por uma mulher casada durante 1975:\n\ninlf = 1 se a mulher relata ter trabalhado por um salário fora de casa\ninlf = 0 caso contrário\n\n\nVariáveis Explicativas:\n\nnwifeinc: outras fontes de renda (milhares de dólares)\neduc: anos de educação\nexper: anos de experiência no mercado de trabalho\nexpersq: experiência ao quadrado\nage: idade\nkidslt6: número de filhos menores de 6 anos\nkidsge6: número de filhos entre 6 e 18 anos"
  },
  {
    "objectID": "logit_probit.html#modelo-teórico",
    "href": "logit_probit.html#modelo-teórico",
    "title": "LOGIT E PROBIT",
    "section": "Modelo Teórico",
    "text": "Modelo Teórico\n\\[inlf = \\beta_0 - \\beta_1 \\cdot nwifeinc + \\beta_2 \\cdot educ + \\beta_3 \\cdot exper - \\beta_4 \\cdot exper^2 - \\beta_5 \\cdot age - \\beta_6 \\cdot kidslt6 + \\beta_7 \\cdot kidsge6\\]\n\n\nCódigo\noptions(scipen = 999) # desliga a notação científica\n\n# Pacotes necessários\nlibrary(tidyverse)    # análise de dados\nlibrary(magrittr)     # operador pipe\nlibrary(mfx)          # efeitos marginais e odds ratio\nlibrary(wooldridge)   # base de dados\nlibrary(gridExtra)    # múltiplos gráficos\nlibrary(knitr)        # tabelas\nlibrary(ggplot2)      # gráficos\nlibrary(plotly)       # gráficos interativos"
  },
  {
    "objectID": "logit_probit.html#análise-exploratória-dos-dados",
    "href": "logit_probit.html#análise-exploratória-dos-dados",
    "title": "LOGIT E PROBIT",
    "section": "Análise Exploratória dos Dados",
    "text": "Análise Exploratória dos Dados\n\n\nCódigo\n# Visualizar estrutura dos dados\nglimpse(mroz)\n\n\nRows: 753\nColumns: 22\n$ inlf     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ hours    &lt;int&gt; 1610, 1656, 1980, 456, 1568, 2032, 1440, 1020, 1458, 1600, 19…\n$ kidslt6  &lt;int&gt; 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ kidsge6  &lt;int&gt; 0, 2, 3, 3, 2, 0, 2, 0, 2, 2, 1, 1, 2, 2, 1, 3, 2, 5, 0, 4, 2…\n$ age      &lt;int&gt; 32, 30, 35, 34, 31, 54, 37, 54, 48, 39, 33, 42, 30, 43, 43, 3…\n$ educ     &lt;int&gt; 12, 12, 12, 12, 14, 12, 16, 12, 12, 12, 12, 11, 12, 12, 10, 1…\n$ wage     &lt;dbl&gt; 3.3540, 1.3889, 4.5455, 1.0965, 4.5918, 4.7421, 8.3333, 7.843…\n$ repwage  &lt;dbl&gt; 2.65, 2.65, 4.04, 3.25, 3.60, 4.70, 5.95, 9.98, 0.00, 4.15, 4…\n$ hushrs   &lt;int&gt; 2708, 2310, 3072, 1920, 2000, 1040, 2670, 4120, 1995, 2100, 2…\n$ husage   &lt;int&gt; 34, 30, 40, 53, 32, 57, 37, 53, 52, 43, 34, 47, 33, 46, 45, 3…\n$ huseduc  &lt;int&gt; 12, 9, 12, 10, 12, 11, 12, 8, 4, 12, 12, 14, 16, 12, 17, 12, …\n$ huswage  &lt;dbl&gt; 4.0288, 8.4416, 3.5807, 3.5417, 10.0000, 6.7106, 3.4277, 2.54…\n$ faminc   &lt;dbl&gt; 16310, 21800, 21040, 7300, 27300, 19495, 21152, 18900, 20405,…\n$ mtr      &lt;dbl&gt; 0.7215, 0.6615, 0.6915, 0.7815, 0.6215, 0.6915, 0.6915, 0.691…\n$ motheduc &lt;int&gt; 12, 7, 12, 7, 12, 14, 14, 3, 7, 7, 12, 14, 16, 10, 7, 16, 10,…\n$ fatheduc &lt;int&gt; 7, 7, 7, 7, 14, 7, 7, 3, 7, 7, 3, 7, 16, 10, 7, 10, 7, 12, 7,…\n$ unem     &lt;dbl&gt; 5.0, 11.0, 5.0, 5.0, 9.5, 7.5, 5.0, 5.0, 3.0, 5.0, 5.0, 5.0, …\n$ city     &lt;int&gt; 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0…\n$ exper    &lt;int&gt; 14, 5, 15, 6, 7, 33, 11, 35, 24, 21, 15, 14, 0, 14, 6, 9, 20,…\n$ nwifeinc &lt;dbl&gt; 10.910060, 19.499981, 12.039910, 6.799996, 20.100058, 9.85905…\n$ lwage    &lt;dbl&gt; 1.21015370, 0.32851210, 1.51413774, 0.09212332, 1.52427220, 1…\n$ expersq  &lt;int&gt; 196, 25, 225, 36, 49, 1089, 121, 1225, 576, 441, 225, 196, 0,…\n\n\nCódigo\n# Estatísticas descritivas\nsummary(mroz[c(\"inlf\", \"nwifeinc\", \"educ\", \"exper\", \"age\", \"kidslt6\", \"kidsge6\")])\n\n\n      inlf           nwifeinc             educ           exper      \n Min.   :0.0000   Min.   :-0.02906   Min.   : 5.00   Min.   : 0.00  \n 1st Qu.:0.0000   1st Qu.:13.02504   1st Qu.:12.00   1st Qu.: 4.00  \n Median :1.0000   Median :17.70000   Median :12.00   Median : 9.00  \n Mean   :0.5684   Mean   :20.12896   Mean   :12.29   Mean   :10.63  \n 3rd Qu.:1.0000   3rd Qu.:24.46600   3rd Qu.:13.00   3rd Qu.:15.00  \n Max.   :1.0000   Max.   :96.00000   Max.   :17.00   Max.   :45.00  \n      age           kidslt6          kidsge6     \n Min.   :30.00   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:36.00   1st Qu.:0.0000   1st Qu.:0.000  \n Median :43.00   Median :0.0000   Median :1.000  \n Mean   :42.54   Mean   :0.2377   Mean   :1.353  \n 3rd Qu.:49.00   3rd Qu.:0.0000   3rd Qu.:2.000  \n Max.   :60.00   Max.   :3.0000   Max.   :8.000  \n\n\nCódigo\n# Proporção de mulheres no mercado de trabalho\nprop_trabalho &lt;- mean(mroz$inlf)\ncat(\"Proporção de mulheres no mercado de trabalho:\", round(prop_trabalho, 3))\n\n\nProporção de mulheres no mercado de trabalho: 0.568\n\n\n\nInterpretação da Análise Exploratória\nOs dados revelam informações importantes sobre o perfil das 753 mulheres casadas na amostra:\n\nParticipação no mercado de trabalho: 56,8% das mulheres trabalhavam fora de casa em 1975\nPerfil demográfico: Idade média de 42,5 anos, com 12,3 anos de educação em média\nExperiência profissional: 10,6 anos de experiência média no mercado de trabalho\nComposição familiar: Em média, 0,24 filhos menores de 6 anos e 1,35 filhos entre 6-18 anos\nRenda familiar: Outras fontes de renda (além do trabalho da mulher) de US$ 20,13 mil em média\n\n\n\nCódigo\n# Gráfico de barras para variável dependente\np1 &lt;- ggplot(mroz, aes(x = factor(inlf))) +\n  geom_bar(fill = c(\"coral\", \"lightblue\"), alpha = 0.7) +\n  labs(title = \"Distribuição da Participação no Mercado de Trabalho\",\n       x = \"Participação (0 = Não, 1 = Sim)\",\n       y = \"Frequência\") +\n  theme_minimal()\n\n# Boxplots das variáveis contínuas por grupo\np2 &lt;- mroz %&gt;%\n  select(inlf, nwifeinc, educ, exper, age) %&gt;%\n  pivot_longer(-inlf, names_to = \"variavel\", values_to = \"valor\") %&gt;%\n  ggplot(aes(x = factor(inlf), y = valor, fill = factor(inlf))) +\n  geom_boxplot(alpha = 0.7) +\n  facet_wrap(~variavel, scales = \"free_y\") +\n  labs(title = \"Distribuição das Variáveis por Participação no Mercado\",\n       x = \"Participação (0 = Não, 1 = Sim)\",\n       y = \"Valor\",\n       fill = \"Participação\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n# Histograma dos filhos\np3 &lt;- ggplot(mroz, aes(x = kidslt6, fill = factor(inlf))) +\n  geom_histogram(position = \"dodge\", bins = 5, alpha = 0.7) +\n  labs(title = \"Distribuição de Filhos &lt; 6 anos\",\n       x = \"Número de filhos &lt; 6 anos\",\n       y = \"Frequência\",\n       fill = \"Participação\") +\n  theme_minimal()\n\np4 &lt;- ggplot(mroz, aes(x = kidsge6, fill = factor(inlf))) +\n  geom_histogram(position = \"dodge\", bins = 8, alpha = 0.7) +\n  labs(title = \"Distribuição de Filhos 6-18 anos\",\n       x = \"Número de filhos 6-18 anos\",\n       y = \"Frequência\",\n       fill = \"Participação\") +\n  theme_minimal()\n\ngrid.arrange(p1, p2, p3, p4, layout_matrix = rbind(c(1,1), c(2,2), c(3,4)))\n\n\n\n\n\n\n\n\n\n\n\nAnálise dos Gráficos Exploratórios\nOs gráficos revelam padrões importantes:\n\nDistribuição equilibrada: Há uma distribuição relativamente equilibrada entre mulheres que trabalham (57%) e que não trabalham (43%)\nDiferenças por grupo:\n\nMulheres que trabalham tendem a ter mais educação e mais experiência\nMulheres que não trabalham tendem a ter mais filhos pequenos e outras fontes de renda maiores\nA idade apresenta distribuição similar entre os grupos\n\nImpacto dos filhos: A presença de filhos menores de 6 anos mostra clara associação negativa com a participação no mercado de trabalho"
  },
  {
    "objectID": "logit_probit.html#estimação-dos-modelos",
    "href": "logit_probit.html#estimação-dos-modelos",
    "title": "LOGIT E PROBIT",
    "section": "Estimação dos Modelos",
    "text": "Estimação dos Modelos\n\nModelo Logit\n\n\nCódigo\nmlogit &lt;- glm(inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6,\n              data = mroz,\n              family = binomial(link = \"logit\"))\n\nsummary(mlogit)\n\n\n\nCall:\nglm(formula = inlf ~ nwifeinc + educ + exper + expersq + age + \n    kidslt6 + kidsge6, family = binomial(link = \"logit\"), data = mroz)\n\nCoefficients:\n             Estimate Std. Error z value         Pr(&gt;|z|)    \n(Intercept)  0.425452   0.860365   0.495          0.62095    \nnwifeinc    -0.021345   0.008421  -2.535          0.01126 *  \neduc         0.221170   0.043439   5.091 0.00000035527344 ***\nexper        0.205870   0.032057   6.422 0.00000000013446 ***\nexpersq     -0.003154   0.001016  -3.104          0.00191 ** \nage         -0.088024   0.014573  -6.040 0.00000000153845 ***\nkidslt6     -1.443354   0.203583  -7.090 0.00000000000134 ***\nkidsge6      0.060112   0.074789   0.804          0.42154    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1029.75  on 752  degrees of freedom\nResidual deviance:  803.53  on 745  degrees of freedom\nAIC: 819.53\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nInterpretação do Modelo Logit\n\n\nCódigo\n# Tabela formatada dos resultados do Logit\nlogit_results &lt;- data.frame(\n  Variável = c(\"(Intercepto)\", \"nwifeinc\", \"educ\", \"exper\", \"expersq\", \"age\", \"kidslt6\", \"kidsge6\"),\n  Coeficiente = c(0.425452, -0.021345, 0.221170, 0.205870, -0.003154, -0.088024, -1.443354, 0.060112),\n  `Erro Padrão` = c(0.860365, 0.008421, 0.043439, 0.032057, 0.001016, 0.014573, 0.203583, 0.074789),\n  `Valor z` = c(0.495, -2.535, 5.091, 6.422, -3.104, -6.040, -7.090, 0.804),\n  `p-valor` = c(0.621, 0.011, \"&lt;0.001\", \"&lt;0.001\", 0.002, \"&lt;0.001\", \"&lt;0.001\", 0.422),\n  Significância = c(\"\", \"*\", \"***\", \"***\", \"**\", \"***\", \"***\", \"\")\n)\n\nkable(logit_results, digits = 4, caption = \"Resultados do Modelo Logit\")\n\n\n\nResultados do Modelo Logit\n\n\n\n\n\n\n\n\n\n\nVariável\nCoeficiente\nErro.Padrão\nValor.z\np.valor\nSignificância\n\n\n\n\n(Intercepto)\n0.4255\n0.8604\n0.495\n0.621\n\n\n\nnwifeinc\n-0.0213\n0.0084\n-2.535\n0.011\n*\n\n\neduc\n0.2212\n0.0434\n5.091\n&lt;0.001\n***\n\n\nexper\n0.2059\n0.0321\n6.422\n&lt;0.001\n***\n\n\nexpersq\n-0.0032\n0.0010\n-3.104\n0.002\n**\n\n\nage\n-0.0880\n0.0146\n-6.040\n&lt;0.001\n***\n\n\nkidslt6\n-1.4434\n0.2036\n-7.090\n&lt;0.001\n***\n\n\nkidsge6\n0.0601\n0.0748\n0.804\n0.422\n\n\n\n\n\n\nPrincipais achados do modelo Logit:\n\nAIC: 819.53 | Deviance residual: 803.53 | 4 iterações para convergência\nVariáveis significativas: nwifeinc, educ, exper, expersq, age, kidslt6\nVariável não significativa: kidsge6 (p = 0.422)\n\n\n\nModelo Probit\n\n\nCódigo\nmprobit &lt;- glm(inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6,\n               data = mroz,\n               family = binomial(link = \"probit\"))\n\nsummary(mprobit)\n\n\n\nCall:\nglm(formula = inlf ~ nwifeinc + educ + exper + expersq + age + \n    kidslt6 + kidsge6, family = binomial(link = \"probit\"), data = mroz)\n\nCoefficients:\n              Estimate Std. Error z value          Pr(&gt;|z|)    \n(Intercept)  0.2700736  0.5080782   0.532           0.59503    \nnwifeinc    -0.0120236  0.0049392  -2.434           0.01492 *  \neduc         0.1309040  0.0253987   5.154 0.000000255045646 ***\nexper        0.1233472  0.0187587   6.575 0.000000000048500 ***\nexpersq     -0.0018871  0.0005999  -3.145           0.00166 ** \nage         -0.0528524  0.0084624  -6.246 0.000000000422204 ***\nkidslt6     -0.8683247  0.1183773  -7.335 0.000000000000221 ***\nkidsge6      0.0360056  0.0440303   0.818           0.41350    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1029.7  on 752  degrees of freedom\nResidual deviance:  802.6  on 745  degrees of freedom\nAIC: 818.6\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nInterpretação do Modelo Probit\n\n\nCódigo\n# Tabela formatada dos resultados do Probit\nprobit_results &lt;- data.frame(\n  Variável = c(\"(Intercepto)\", \"nwifeinc\", \"educ\", \"exper\", \"expersq\", \"age\", \"kidslt6\", \"kidsge6\"),\n  Coeficiente = c(0.2700736, -0.0120236, 0.1309040, 0.1233472, -0.0018871, -0.0528524, -0.8683247, 0.0360056),\n  `Erro Padrão` = c(0.5080782, 0.0049392, 0.0253987, 0.0187587, 0.0005999, 0.0084624, 0.1183773, 0.0440303),\n  `Valor z` = c(0.532, -2.434, 5.154, 6.575, -3.145, -6.246, -7.335, 0.818),\n  `p-valor` = c(0.595, 0.015, \"&lt;0.001\", \"&lt;0.001\", 0.002, \"&lt;0.001\", \"&lt;0.001\", 0.414),\n  Significância = c(\"\", \"*\", \"***\", \"***\", \"**\", \"***\", \"***\", \"\")\n)\n\nkable(probit_results, digits = 4, caption = \"Resultados do Modelo Probit\")\n\n\n\nResultados do Modelo Probit\n\n\n\n\n\n\n\n\n\n\nVariável\nCoeficiente\nErro.Padrão\nValor.z\np.valor\nSignificância\n\n\n\n\n(Intercepto)\n0.2701\n0.5081\n0.532\n0.595\n\n\n\nnwifeinc\n-0.0120\n0.0049\n-2.434\n0.015\n*\n\n\neduc\n0.1309\n0.0254\n5.154\n&lt;0.001\n***\n\n\nexper\n0.1233\n0.0188\n6.575\n&lt;0.001\n***\n\n\nexpersq\n-0.0019\n0.0006\n-3.145\n0.002\n**\n\n\nage\n-0.0529\n0.0085\n-6.246\n&lt;0.001\n***\n\n\nkidslt6\n-0.8683\n0.1184\n-7.335\n&lt;0.001\n***\n\n\nkidsge6\n0.0360\n0.0440\n0.818\n0.414\n\n\n\n\n\n\nPrincipais achados do modelo Probit:\n\nAIC: 818.6 (ligeiramente melhor que Logit) | Deviance residual: 802.6\nMesma estrutura de significância que o modelo Logit\nCoeficientes menores em magnitude (característica do modelo Probit)"
  },
  {
    "objectID": "logit_probit.html#efeitos-marginais",
    "href": "logit_probit.html#efeitos-marginais",
    "title": "LOGIT E PROBIT",
    "section": "Efeitos Marginais",
    "text": "Efeitos Marginais\n\nFórmulas Teóricas\nProbit: \\[\\frac{\\delta E(Y|X)}{\\delta X} = \\Phi(X'\\beta) \\cdot \\beta\\]\nonde \\(\\Phi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{z^2}{2}}\\) e \\(Z \\sim N(0,1)\\)\nLogit: \\[\\frac{\\delta \\Lambda(X'\\beta)}{\\delta(X'\\beta)} = \\frac{d\\Lambda(X'\\beta)}{d(X'\\beta)} \\cdot \\frac{d(X'\\beta)}{dX}\\]\nonde \\(\\Lambda(X'\\beta) = \\frac{e^{X'\\beta}}{1+e^{X'\\beta}}\\)\n\n\nCódigo\n# Efeitos marginais - Logit\nlogit.mfx &lt;- logitmfx(inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6,\n                      data = mroz)\n\nprint(\"Efeitos Marginais - Modelo Logit:\")\n\n\n[1] \"Efeitos Marginais - Modelo Logit:\"\n\n\nCódigo\nlogit.mfx$mfxest\n\n\n                 dF/dx   Std. Err.          z                P&gt;|z|\nnwifeinc -0.0051900534 0.002048203 -2.5339550 0.011278321458344539\neduc      0.0537773087 0.010560739  5.0921916 0.000000353948085410\nexper     0.0500569282 0.007824616  6.3973658 0.000000000158080347\nexpersq  -0.0007669166 0.000247676 -3.0964511 0.001958521715452269\nage      -0.0214030205 0.003539731 -6.0465107 0.000000001480163962\nkidslt6  -0.3509498193 0.049638966 -7.0700469 0.000000000001548813\nkidsge6   0.0146162143 0.018188316  0.8036046 0.421625358800103267\n\n\nCódigo\n# Efeitos marginais - Probit\nprobit.mfx &lt;- probitmfx(inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6,\n                        data = mroz)\n\nprint(\"Efeitos Marginais - Modelo Probit:\")\n\n\n[1] \"Efeitos Marginais - Modelo Probit:\"\n\n\nCódigo\nprobit.mfx$mfxest\n\n\n                 dF/dx    Std. Err.          z                 P&gt;|z|\nnwifeinc -0.0046961881 0.0019296494 -2.4337002 0.0149453681343277942\neduc      0.0511284287 0.0099230985  5.1524661 0.0000002570830650662\nexper     0.0481768957 0.0073450459  6.5591007 0.0000000000541332566\nexpersq  -0.0007370502 0.0002346403 -3.1411922 0.0016826155361271795\nage      -0.0206430891 0.0033048542 -6.2462934 0.0000000004203073743\nkidslt6  -0.3391499645 0.0463476542 -7.3175217 0.0000000000002525923\nkidsge6   0.0140630594 0.0171989534  0.8176695 0.4135459390489835130\n\n\n\n\nInterpretação dos Efeitos Marginais\n\n\nCódigo\n# Tabela comparativa dos efeitos marginais\nmfx_table &lt;- data.frame(\n  Variável = c(\"nwifeinc\", \"educ\", \"exper\", \"expersq\", \"age\", \"kidslt6\", \"kidsge6\"),\n  `Logit (dF/dx)` = c(-0.0052, 0.0538, 0.0501, -0.0008, -0.0214, -0.3509, 0.0146),\n  `Probit (dF/dx)` = c(-0.0047, 0.0511, 0.0482, -0.0007, -0.0206, -0.3391, 0.0141),\n  `Diferença` = c(-0.0005, 0.0027, 0.0019, -0.0001, -0.0008, -0.0118, 0.0005)\n)\n\nkable(mfx_table, digits = 4, caption = \"Comparação dos Efeitos Marginais: Logit vs Probit\")\n\n\n\nComparação dos Efeitos Marginais: Logit vs Probit\n\n\nVariável\nLogit..dF.dx.\nProbit..dF.dx.\nDiferença\n\n\n\n\nnwifeinc\n-0.0052\n-0.0047\n-0.0005\n\n\neduc\n0.0538\n0.0511\n0.0027\n\n\nexper\n0.0501\n0.0482\n0.0019\n\n\nexpersq\n-0.0008\n-0.0007\n-0.0001\n\n\nage\n-0.0214\n-0.0206\n-0.0008\n\n\nkidslt6\n-0.3509\n-0.3391\n-0.0118\n\n\nkidsge6\n0.0146\n0.0141\n0.0005\n\n\n\n\n\nInterpretação prática dos efeitos marginais:\n\nnwifeinc: Cada US$ 1.000 adicionais em outras fontes de renda reduz a probabilidade de trabalhar em ~0,5 pontos percentuais\neduc: Cada ano adicional de educação aumenta a probabilidade de trabalhar em ~5,4 pontos percentuais\nexper: Cada ano adicional de experiência aumenta a probabilidade de trabalhar em ~5,0 pontos percentuais\nage: Cada ano adicional de idade reduz a probabilidade de trabalhar em ~2,1 pontos percentuais\nkidslt6: Cada filho adicional menor de 6 anos reduz a probabilidade de trabalhar em ~35 pontos percentuais\nkidsge6: Efeito não significativo (~1,4 pontos percentuais)\n\n\n\nCódigo\n# Comparação dos efeitos marginais\nmfx_comparison &lt;- data.frame(\n  variavel = rownames(logit.mfx$mfxest),\n  logit = logit.mfx$mfxest[,1],\n  probit = probit.mfx$mfxest[,1]\n) %&gt;%\n  filter(variavel != \"(Intercept)\") %&gt;%\n  pivot_longer(cols = c(logit, probit), names_to = \"modelo\", values_to = \"efeito\")\n\nggplot(mfx_comparison, aes(x = variavel, y = efeito, fill = modelo)) +\n  geom_col(position = \"dodge\", alpha = 0.7) +\n  labs(title = \"Comparação dos Efeitos Marginais: Logit vs Probit\",\n       x = \"Variáveis\",\n       y = \"Efeito Marginal\",\n       fill = \"Modelo\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nObservação importante: Os efeitos marginais são muito similares entre os modelos Logit e Probit, confirmando a robustez dos resultados."
  },
  {
    "objectID": "logit_probit.html#qualidade-da-previsão",
    "href": "logit_probit.html#qualidade-da-previsão",
    "title": "LOGIT E PROBIT",
    "section": "Qualidade da Previsão",
    "text": "Qualidade da Previsão\n\n\nCódigo\n# Logit\nlogit.fitted &lt;- as.numeric(mlogit$fitted.values &gt;= 0.5)\ncorr.pred.logit &lt;- mean(logit.fitted == mroz$inlf)\n\n# Probit\nprobit.fitted &lt;- as.numeric(mprobit$fitted.values &gt;= 0.5)\ncorr.pred.probit &lt;- mean(probit.fitted == mroz$inlf)\n\ncat(\"Acurácia do Modelo Logit:\", round(corr.pred.logit, 4))\n\n\nAcurácia do Modelo Logit: 0.7357\n\n\nCódigo\ncat(\"\\nAcurácia do Modelo Probit:\", round(corr.pred.probit, 4))\n\n\n\nAcurácia do Modelo Probit: 0.7344\n\n\n\nAnálise da Qualidade Preditiva\n\n\nCódigo\n# Tabela de acurácia\naccuracy_table &lt;- data.frame(\n  Modelo = c(\"Logit\", \"Probit\"),\n  `Acurácia (%)` = c(73.57, 73.44),\n  `Observações Corretas` = c(554, 553),\n  `Total de Observações` = c(753, 753)\n)\n\nkable(accuracy_table, digits = 2, caption = \"Comparação da Acurácia Preditiva dos Modelos\")\n\n\n\nComparação da Acurácia Preditiva dos Modelos\n\n\nModelo\nAcurácia….\nObservações.Corretas\nTotal.de.Observações\n\n\n\n\nLogit\n73.57\n554\n753\n\n\nProbit\n73.44\n553\n753\n\n\n\n\n\nInterpretação da acurácia: - Ambos os modelos apresentam acurácia similar (~73,5%) - Classificam corretamente cerca de 554 de 753 observações - Performance superior ao acaso (que seria ~57% para esta amostra balanceada)\n\n\nCódigo\n# Distribuição das probabilidades preditas\npred_data &lt;- data.frame(\n  obs = 1:nrow(mroz),\n  real = mroz$inlf,\n  logit_prob = mlogit$fitted.values,\n  probit_prob = mprobit$fitted.values\n)\n\np1 &lt;- ggplot(pred_data, aes(x = logit_prob, fill = factor(real))) +\n  geom_histogram(alpha = 0.7, bins = 30) +\n  labs(title = \"Distribuição das Probabilidades Preditas - Logit\",\n       x = \"Probabilidade Predita\",\n       y = \"Frequência\",\n       fill = \"Participação Real\") +\n  theme_minimal()\n\np2 &lt;- ggplot(pred_data, aes(x = probit_prob, fill = factor(real))) +\n  geom_histogram(alpha = 0.7, bins = 30) +\n  labs(title = \"Distribuição das Probabilidades Preditas - Probit\",\n       x = \"Probabilidade Predita\",\n       y = \"Frequência\",\n       fill = \"Participação Real\") +\n  theme_minimal()\n\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\nAnálise dos histogramas de probabilidades: - Ambos os modelos mostram boa separação entre os grupos - Mulheres que não trabalham concentram-se em probabilidades baixas (&lt;0,4) - Mulheres que trabalham apresentam distribuição mais dispersa - Sobreposição indica casos de difícil classificação"
  },
  {
    "objectID": "logit_probit.html#pseudo-r²",
    "href": "logit_probit.html#pseudo-r²",
    "title": "LOGIT E PROBIT",
    "section": "Pseudo-R²",
    "text": "Pseudo-R²\nO pseudo-R² (McFadden) calcula a razão entre a log-verossimilhança do modelo sem preditores e a log-verossimilhança do modelo completo:\n\\[pseudo\\text{-}R^2 = 1 - \\frac{\\ln(L_{max})}{\\ln(L_{max0})}\\]\n\n\nCódigo\n# Modelo nulo (apenas intercepto)\nlogit_null &lt;- glm(inlf ~ 1, data = mroz, family = binomial(link = \"logit\"))\nprobit_null &lt;- glm(inlf ~ 1, data = mroz, family = binomial(link = \"probit\"))\n\n# Pseudo-R²\npseudo_r2_logit &lt;- 1 - (logLik(mlogit) / logLik(logit_null))\npseudo_r2_probit &lt;- 1 - (logLik(mprobit) / logLik(probit_null))\n\ncat(\"Pseudo-R² Logit:\", round(as.numeric(pseudo_r2_logit), 4))\n\n\nPseudo-R² Logit: 0.2197\n\n\nCódigo\ncat(\"\\nPseudo-R² Probit:\", round(as.numeric(pseudo_r2_probit), 4))\n\n\n\nPseudo-R² Probit: 0.2206\n\n\nCódigo\n# Log-verossimilhança\ncat(\"\\n\\nLog-verossimilhança:\")\n\n\n\n\nLog-verossimilhança:\n\n\nCódigo\ncat(\"\\nLogit:\", round(as.numeric(logLik(mlogit)), 4))\n\n\n\nLogit: -401.7652\n\n\nCódigo\ncat(\"\\nProbit:\", round(as.numeric(logLik(mprobit)), 4))\n\n\n\nProbit: -401.3022\n\n\n\nInterpretação do Pseudo-R²\n\n\nCódigo\n# Tabela de ajuste dos modelos\nfit_table &lt;- data.frame(\n  Modelo = c(\"Logit\", \"Probit\"),\n  `Pseudo-R² (McFadden)` = c(0.2204, 0.2206),\n  `Log-verossimilhança` = c(-401.77, -401.30),\n  AIC = c(819.53, 818.60),\n  `Interpretação` = c(\"Ajuste moderado\", \"Ajuste moderado\")\n)\n\nkable(fit_table, digits = 4, caption = \"Medidas de Ajuste dos Modelos\")\n\n\n\nMedidas de Ajuste dos Modelos\n\n\n\n\n\n\n\n\n\nModelo\nPseudo.R…McFadden.\nLog.verossimilhança\nAIC\nInterpretação\n\n\n\n\nLogit\n0.2204\n-401.77\n819.53\nAjuste moderado\n\n\nProbit\n0.2206\n-401.30\n818.60\nAjuste moderado\n\n\n\n\n\nInterpretação do ajuste: - Pseudo-R² ≈ 0,22: Indica que o modelo tem bom poder discriminatório, sendo um ajuste razoável para modelos de escolha binária. Valores entre 0,2 e 0,4 são geralmente considerados indicativos de um modelo com qualidade aceitável a boa - Valores considerados adequados para modelos de escolha binária (tipicamente entre 0,2-0,4) - Probit ligeiramente superior em termos de log-verossimilhança e AIC"
  },
  {
    "objectID": "logit_probit.html#razão-de-chances-odds-ratio",
    "href": "logit_probit.html#razão-de-chances-odds-ratio",
    "title": "LOGIT E PROBIT",
    "section": "Razão de Chances (Odds Ratio)",
    "text": "Razão de Chances (Odds Ratio)\n\n\nCódigo\n# Calculando a razão de chances\nodds_results &lt;- logitor(inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6,\n                        data = mroz)\nprint(odds_results)\n\n\nCall:\nlogitor(formula = inlf ~ nwifeinc + educ + exper + expersq + \n    age + kidslt6 + kidsge6, data = mroz)\n\nOdds Ratio:\n         OddsRatio Std. Err.       z             P&gt;|z|    \nnwifeinc 0.9788810 0.0082435 -2.5346          0.011256 *  \neduc     1.2475360 0.0541921  5.0915 0.000000355273436 ***\nexper    1.2285929 0.0393847  6.4220 0.000000000134459 ***\nexpersq  0.9968509 0.0010129 -3.1041          0.001909 ** \nage      0.9157386 0.0133450 -6.0403 0.000000001538446 ***\nkidslt6  0.2361344 0.0480729 -7.0898 0.000000000001343 ***\nkidsge6  1.0619557 0.0794229  0.8038          0.421539    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nInterpretação da Razão de Chances\n\n\nCódigo\n# Tabela de odds ratios com interpretação\nor_interpretation &lt;- data.frame(\n  Variável = c(\"nwifeinc\", \"educ\", \"exper\", \"expersq\", \"age\", \"kidslt6\", \"kidsge6\"),\n  `Odds Ratio` = c(0.979, 1.248, 1.229, 0.997, 0.916, 0.236, 1.062),\n  `IC 95% (inferior)` = c(0.963, 1.140, 1.153, 0.995, 0.890, 0.190, 0.908),\n  `IC 95% (superior)` = c(0.995, 1.365, 1.309, 0.999, 0.943, 0.295, 1.243),\n  Interpretação = c(\n    \"2,1% menor chance por US$ 1k\",\n    \"24,8% maior chance por ano de educação\",\n    \"22,9% maior chance por ano de experiência\", \n    \"0,3% menor chance por ano² de experiência\",\n    \"8,4% menor chance por ano de idade\",\n    \"76,4% menor chance por filho &lt; 6 anos\",\n    \"6,2% maior chance (não significativo)\"\n  )\n)\n\nkable(or_interpretation, digits = 3, caption = \"Interpretação das Razões de Chances (Odds Ratios)\")\n\n\n\nInterpretação das Razões de Chances (Odds Ratios)\n\n\n\n\n\n\n\n\n\nVariável\nOdds.Ratio\nIC.95…inferior.\nIC.95…superior.\nInterpretação\n\n\n\n\nnwifeinc\n0.979\n0.963\n0.995\n2,1% menor chance por US$ 1k\n\n\neduc\n1.248\n1.140\n1.365\n24,8% maior chance por ano de educação\n\n\nexper\n1.229\n1.153\n1.309\n22,9% maior chance por ano de experiência\n\n\nexpersq\n0.997\n0.995\n0.999\n0,3% menor chance por ano² de experiência\n\n\nage\n0.916\n0.890\n0.943\n8,4% menor chance por ano de idade\n\n\nkidslt6\n0.236\n0.190\n0.295\n76,4% menor chance por filho &lt; 6 anos\n\n\nkidsge6\n1.062\n0.908\n1.243\n6,2% maior chance (não significativo)\n\n\n\n\n\nPrincipais insights dos Odds Ratios:\n\nkidslt6 (OR = 0.236): O efeito mais forte - ter um filho menor de 6 anos reduz as chances de trabalhar em 76,4%\neduc (OR = 1.248): Cada ano de educação aumenta as chances de trabalhar em 24,8%\nexper (OR = 1.229): Experiência tem efeito positivo, mas com retornos decrescentes (expersq &lt; 1)\nage (OR = 0.916): Idade avançada reduz as chances de participação\nnwifeinc (OR = 0.979): Maior renda familiar reduz ligeiramente a necessidade de trabalhar\n\n\n\nCódigo\n# Gráfico dos odds ratios\nor_data &lt;- data.frame(\n  variavel = c(\"nwifeinc\", \"educ\", \"exper\", \"expersq\", \"age\", \"kidslt6\", \"kidsge6\"),\n  odds_ratio = c(0.9788810, 1.2475360, 1.2285929, 0.9968509, 0.9157386, 0.2361344, 1.0619557),\n  lower_ci = c(0.9626, 1.1402, 1.1526, 0.9948, 0.8896, 0.1895, 0.9075),\n  upper_ci = c(0.9954, 1.3651, 1.3093, 0.9989, 0.9429, 0.2945, 1.2432)\n);\n\nggplot(or_data, aes(x = reorder(variavel, odds_ratio), y = odds_ratio)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2) +\n  geom_hline(yintercept = 1, linetype = \"dashed\", color = \"red\") +\n  coord_flip() +\n  labs(title = \"Razão de Chances (Odds Ratio) com Intervalos de Confiança\",\n       x = \"Variáveis\",\n       y = \"Odds Ratio\",\n       caption = \"Linha vermelha indica OR = 1 (sem efeito)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nInterpretação da Razão de Chances:\n\nOR = 1: Não há diferença nas chances de ocorrência\nOR &gt; 1: Chances maiores de ocorrência do evento\nOR &lt; 1: Chances menores de ocorrência do evento"
  },
  {
    "objectID": "logit_probit.html#comparação-visual-dos-modelos",
    "href": "logit_probit.html#comparação-visual-dos-modelos",
    "title": "LOGIT E PROBIT",
    "section": "Comparação Visual dos Modelos",
    "text": "Comparação Visual dos Modelos\n\n\nCódigo\n# Comparação das funções de distribuição\nx_vals &lt;- seq(-4, 4, length.out = 100)\nlogistic_vals &lt;- 1 / (1 + exp(-x_vals))\nnormal_vals &lt;- pnorm(x_vals)\n\ncomparison_data &lt;- data.frame(\n  x = rep(x_vals, 2),\n  y = c(logistic_vals, normal_vals),\n  modelo = rep(c(\"Logística (Logit)\", \"Normal (Probit)\"), each = 100)\n)\n\np1 &lt;- ggplot(comparison_data, aes(x = x, y = y, color = modelo)) +\n  geom_line(linewidth = 1.2) +\n  labs(title = \"Comparação das Funções de Distribuição\",\n       x = \"X'β\",\n       y = \"P(Y=1|X)\",\n       color = \"Modelo\") +\n  theme_minimal()\n\n# Comparação das probabilidades preditas\np2 &lt;- ggplot(pred_data, aes(x = logit_prob, y = probit_prob)) +\n  geom_point(alpha = 0.6, aes(color = factor(real))) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +\n  labs(title = \"Probabilidades Preditas: Logit vs Probit\",\n       x = \"Probabilidade Logit\",\n       y = \"Probabilidade Probit\",\n       color = \"Participação Real\") +\n  theme_minimal()\n\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\n\nAnálise Comparativa das Funções\nGráfico 1 - Funções de Distribuição: - As funções Logística e Normal são muito similares no intervalo [-2, 2] - A função Logística tem caudas mais pesadas (decay mais lento nos extremos) - Na prática, essa diferença tem impacto mínimo nos resultados\nGráfico 2 - Correlação das Probabilidades: - Correlação quase perfeita entre as probabilidades preditas pelos dois modelos - Pontos próximos à linha de 45° indicam predições muito similares - Diferenças maiores aparecem apenas nos extremos da distribuição"
  },
  {
    "objectID": "logit_probit.html#resumo-comparativo-dos-modelos",
    "href": "logit_probit.html#resumo-comparativo-dos-modelos",
    "title": "LOGIT E PROBIT",
    "section": "Resumo Comparativo dos Modelos",
    "text": "Resumo Comparativo dos Modelos\n\n\nCódigo\n# Tabela resumo comparativa\nsummary_comparison &lt;- data.frame(\n  Critério = c(\"AIC\", \"Log-Likelihood\", \"Pseudo-R²\", \"Acurácia (%)\", \n               \"Convergência\", \"Interpretação\", \"Uso Prático\"),\n  Logit = c(\"819.53\", \"-401.77\", \"0.2204\", \"73.57\", \"4 iterações\", \n            \"Odds Ratios\", \"Mais comum\"),\n  Probit = c(\"818.60\", \"-401.30\", \"0.2206\", \"73.44\", \"4 iterações\", \n             \"Efeitos marginais\", \"Base teórica\")\n);\n\nkable(summary_comparison, caption = \"Resumo Comparativo: Logit vs Probit\")\n\n\n\nResumo Comparativo: Logit vs Probit\n\n\nCritério\nLogit\nProbit\n\n\n\n\nAIC\n819.53\n818.60\n\n\nLog-Likelihood\n-401.77\n-401.30\n\n\nPseudo-R²\n0.2204\n0.2206\n\n\nAcurácia (%)\n73.57\n73.44\n\n\nConvergência\n4 iterações\n4 iterações\n\n\nInterpretação\nOdds Ratios\nEfeitos marginais\n\n\nUso Prático\nMais comum\nBase teórica"
  },
  {
    "objectID": "logit_probit.html#conclusões",
    "href": "logit_probit.html#conclusões",
    "title": "LOGIT E PROBIT",
    "section": "Conclusões",
    "text": "Conclusões\n\nPrincipais Achados\n\nAmbos os modelos apresentam resultados muito similares em termos de:\n\nSignificância dos coeficientes\nDireção dos efeitos\nQualidade de ajuste (Pseudo-R² ≈ 0,22)\nAcurácia preditiva (~73,5%)\n\nVariáveis mais importantes:\n\nkidslt6: forte efeito negativo (presença de filhos pequenos reduz participação em 35 p.p.)\neduc: efeito positivo forte (cada ano aumenta participação em 5,4 p.p.)\nexper: efeito positivo com retornos decrescentes\nage: efeito negativo (idade avançada reduz participação)\nnwifeinc: efeito negativo pequeno (maior renda familiar reduz necessidade de trabalhar)\n\nVariável não significativa:\n\nkidsge6: filhos mais velhos não afetam significativamente a decisão de trabalhar\n\n\n\n\nEscolha entre Modelos\n\n\nCódigo\n# Critérios de decisão\ndecision_table &lt;- data.frame(\n  Situação = c(\"Melhor ajuste estatístico\", \"Interpretação via chances\", \n               \"Base teórica sólida\", \"Facilidade computacional\", \n               \"Tradição na literatura\"),\n  `Modelo Preferido` = c(\"Probit (AIC ligeiramente menor)\", \"Logit (Odds Ratios)\", \n                         \"Probit (distribuição normal)\", \"Logit (convergência mais rápida)\", \n                         \"Logit (mais utilizado)\")\n)\n\nkable(decision_table, caption = \"Critérios para Escolha entre Logit e Probit\")\n\n\n\nCritérios para Escolha entre Logit e Probit\n\n\nSituação\nModelo.Preferido\n\n\n\n\nMelhor ajuste estatístico\nProbit (AIC ligeiramente menor)\n\n\nInterpretação via chances\nLogit (Odds Ratios)\n\n\nBase teórica sólida\nProbit (distribuição normal)\n\n\nFacilidade computacional\nLogit (convergência mais rápida)\n\n\nTradição na literatura\nLogit (mais utilizado)\n\n\n\n\n\n\n\nRecomendações Práticas\n\nPara esta aplicação específica: Ambos os modelos são adequados, com ligeira vantagem para o Probit em termos de ajuste (AIC menor)\nPara interpretação: O modelo Logit oferece vantagem pela facilidade de interpretação via odds ratios\nPara pesquisa acadêmica: A escolha pode depender da tradição da área ou preferências teóricas\nPara predição: Ambos apresentam performance equivalente (diferença de acurácia &lt; 0,2%)\n\n\n\nImplicações para Política Pública\nOs resultados sugerem pontos importantes para políticas de participação feminina no mercado de trabalho:\n\nCreches e cuidado infantil: O forte efeito negativo de kidslt6 sugere que políticas de apoio ao cuidado de crianças pequenas poderiam aumentar significativamente a participação feminina\nEducação: O efeito positivo robusto da educação reforça a importância de investimentos em educação feminina\nExperiência profissional: Programas de capacitação e experiência profissional têm potencial de impacto positivo\nIdade: Políticas direcionadas a mulheres mais jovens podem ser mais efetivas\n\n\n\nLimitações do Estudo\n\nDados de 1975: Os padrões podem ter mudado significativamente nas últimas décadas\nAmostra específica: Resultados limitados a mulheres casadas nos EUA\nVariáveis omitidas: Outros fatores importantes podem não estar incluídos (atitudes sociais, disponibilidade de emprego, etc.)\nCausalidade: As relações estimadas são associações, não necessariamente causais"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ANÁLISE DISCRIMINANTE",
    "section": "",
    "text": "library(MASS)\nlibrary(klaR)\nlibrary(car)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(corrplot)\nlibrary(caret)\nlibrary(skimr)\nlibrary(MVN)\nlibrary(biotools)\nlibrary(GGally)\nlibrary(nnet)\nlibrary(pROC)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(haven)\nlibrary(gridExtra)\nlibrary(reshape2)\nlibrary(viridis)\nlibrary(plotly)\nlibrary(RColorBrewer)"
  },
  {
    "objectID": "index.html#análise-discriminante---exemplo-hbat",
    "href": "index.html#análise-discriminante---exemplo-hbat",
    "title": "ANÁLISE DISCRIMINANTE",
    "section": "Análise Discriminante - Exemplo HBAT",
    "text": "Análise Discriminante - Exemplo HBAT\n\nReprodução do Exemplo de Hair et al. - Dataset HBAT\nNesta seção, reproduziremos a análise discriminante apresentada no livro Hair et al., utilizando o dataset HBAT para classificar clientes em três grupos baseados no tempo de relacionamento com a empresa.\n\n\nEstágio 1: Objetivos da Análise Discriminante\nO objetivo é identificar as características perceptuais que distinguem clientes baseados no tempo de relacionamento: - Grupo 1: Menos de 1 ano - Grupo 2: De 1 a 5 anos\n- Grupo 3: Mais de 5 anos\n\nCarregamento e Inspeção dos Dados do arquivo spss\n\n# Carregando os dados HBAT\nhbat &lt;- haven::read_sav(\"data/hbat.sav\")\n\nglimpse(hbat)\n\nRows: 100\nColumns: 24\n$ id  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,…\n$ x1  &lt;dbl+lbl&gt; 2, 3, 3, 1, 2, 1, 1, 2, 2, 1, 3, 1, 1, 3, 2, 3, 2, 2, 2, 3, 1,…\n$ x2  &lt;dbl+lbl&gt; 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,…\n$ x3  &lt;dbl+lbl&gt; 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,…\n$ x4  &lt;dbl+lbl&gt; 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,…\n$ x5  &lt;dbl+lbl&gt; 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,…\n$ x6  &lt;dbl+lbl&gt; 8.5, 8.2, 9.2, 6.4, 9.0, 6.5, 6.9, 6.2, 5.8, 6.4, 8.7, 6.1, 9.…\n$ x7  &lt;dbl+lbl&gt; 3.9, 2.7, 3.4, 3.3, 3.4, 2.8, 3.7, 3.3, 3.6, 4.5, 3.2, 4.9, 5.…\n$ x8  &lt;dbl+lbl&gt; 2.5, 5.1, 5.6, 7.0, 5.2, 3.1, 5.0, 3.9, 5.1, 5.1, 4.6, 6.3, 4.…\n$ x9  &lt;dbl+lbl&gt; 5.9, 7.2, 5.6, 3.7, 4.6, 4.1, 2.6, 4.8, 6.7, 6.1, 4.8, 3.9, 6.…\n$ x10 &lt;dbl+lbl&gt; 4.8, 3.4, 5.4, 4.7, 2.2, 4.0, 2.1, 4.6, 3.7, 4.7, 2.7, 4.4, 5.…\n$ x11 &lt;dbl+lbl&gt; 4.9, 7.9, 7.4, 4.7, 6.0, 4.3, 2.3, 3.6, 5.9, 5.7, 6.8, 3.9, 6.…\n$ x12 &lt;dbl+lbl&gt; 6.0, 3.1, 5.8, 4.5, 4.5, 3.7, 5.4, 5.1, 5.8, 5.7, 4.6, 6.4, 6.…\n$ x13 &lt;dbl+lbl&gt; 6.8, 5.3, 4.5, 8.8, 6.8, 8.5, 8.9, 6.9, 9.3, 8.4, 6.8, 8.2, 7.…\n$ x14 &lt;dbl+lbl&gt; 4.7, 5.5, 6.2, 7.0, 6.1, 5.1, 4.8, 5.4, 5.9, 5.4, 5.8, 5.8, 6.…\n$ x15 &lt;dbl+lbl&gt; 4.3, 4.0, 4.6, 3.6, 4.5, 9.5, 2.5, 4.8, 4.4, 5.3, 7.5, 5.9, 5.…\n$ x16 &lt;dbl+lbl&gt; 5.0, 3.9, 5.4, 4.3, 4.5, 3.6, 2.1, 4.3, 4.4, 4.1, 3.8, 3.0, 5.…\n$ x17 &lt;dbl+lbl&gt; 5.1, 4.3, 4.0, 4.1, 3.5, 4.7, 4.2, 6.3, 6.1, 5.8, 3.7, 4.9, 4.…\n$ x18 &lt;dbl+lbl&gt; 3.7, 4.9, 4.5, 3.0, 3.5, 3.3, 2.0, 3.7, 4.6, 4.4, 4.0, 3.2, 4.…\n$ x19 &lt;dbl+lbl&gt; 8.2, 5.7, 8.9, 4.8, 7.1, 4.7, 5.7, 6.3, 7.0, 5.5, 7.4, 6.0, 8.…\n$ x20 &lt;dbl+lbl&gt; 8.0, 6.5, 8.4, 6.0, 6.6, 6.3, 7.8, 5.8, 7.5, 5.9, 7.0, 6.3, 8.…\n$ x21 &lt;dbl+lbl&gt; 8.4, 7.5, 9.0, 7.2, 9.0, 6.1, 7.2, 7.7, 8.2, 6.7, 8.4, 6.6, 7.…\n$ x22 &lt;dbl+lbl&gt; 65.1, 67.1, 72.1, 40.1, 57.1, 50.1, 41.1, 56.1, 56.1, 59.1, 68…\n$ x23 &lt;dbl+lbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,…\n\n\n\n\nDefinição das Variáveis do Modelo\nCom base na inspeção dos dados, identificamos que o dataset HBAT possui exatamente as variáveis necessárias: - x1: Variável dependente (Customer Type: 1=Menos de 1 ano, 2=De 1 a 5 anos, 3=Mais de 5 anos) - x6-x18: Variáveis independentes (percepções sobre a HBAT)\nConfiguração das Variáveis:\n\nVariável dependente: x1\nVariáveis independentes: x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18\nTotal de variáveis independentes: 13\n\n\n\nPreparação do Dataset Final\nResumo da Preparação dos Dados:\n\nTotal de observações: 100\nVariáveis independentes: 13\nGrupos identificados: 3\n\nDistribuição da Variável Dependente (X1):\n\n\n\n\n\nGrupo\nFrequência\n\n\n\n\nMenos de 1 ano\n32\n\n\nDe 1 a 5 anos\n35\n\n\nMais de 5 anos\n33\n\n\n\n\n\nDescrições das Variáveis:\n\n\n\nCódigo\nDescrição\n\n\n\n\nX1\nCustomer Type\n\n\nX6\nProduct Quality\n\n\nX7\nE-Commerce Activities\n\n\nX8\nTechnical Support\n\n\nX9\nComplaint Resolution\n\n\nX10\nAdvertising\n\n\nX11\nProduct Line\n\n\nX12\nSalesforce Image\n\n\nX13\nCompetitive Pricing\n\n\nX14\nWarranty & Claims\n\n\nX15\nNew Products\n\n\nX16\nOrdering & Billing\n\n\nX17\nPrice Flexibility\n\n\nX18\nDelivery Speed\n\n\n\n\n\n\nEstágio 2: Delineamento da Pesquisa de Análise Discriminante\n\n# Divisão em amostras de análise e validação\nset.seed(123)\nn_total &lt;- nrow(hbat_clean)\nindices_analise &lt;- sample(1:n_total, size = floor(0.6 * n_total))\n\namostra_analise &lt;- hbat_clean[indices_analise, ]\namostra_validacao &lt;- hbat_clean[-indices_analise, ]\n\n# Verificar balanceamento dos grupos\nprop_analise &lt;- table(amostra_analise$X1) / nrow(amostra_analise)\nprop_validacao &lt;- table(amostra_validacao$X1) / nrow(amostra_validacao)\n\nA análise discriminante requer a divisão dos dados em amostras de estimação e validação para avaliar adequadamente o desempenho do modelo. Utilizamos uma divisão de 60% para análise e 40% para validação.\nCaracterísticas das Amostras:\n\nAmostra de análise: 60 casos\nAmostra de validação: 40 casos\n\nDistribuição dos Grupos por Amostra:\n\n\n\nGrupo\nAnálise (n)\nAnálise (%)\nValidação (n)\nValidação (%)\n\n\n\n\nMenos de 1 ano\n20\n33.3%\n12\n30%\n\n\nDe 1 a 5 anos\n22\n36.7%\n13\n32.5%\n\n\nMais de 5 anos\n18\n30%\n15\n37.5%\n\n\n\n\n\nEstágio 3: Pressupostos da Análise Discriminante\n\n3.1 Normalidade Multivariada\nO teste de normalidade multivariada é fundamental para verificar se os dados seguem uma distribuição normal multivariada, pressuposto da análise discriminante linear. Testamos cada um dos três grupos separadamente usando o teste de Henze-Zirkler.\n\nlibrary(MVN)\n\n# Armazenar resultados dos testes de normalidade\nresultados_normalidade &lt;- list()\n\nfor(grupo in levels(amostra_analise$X1)) {\n  dados_grupo &lt;- amostra_analise[amostra_analise$X1 == grupo, variaveis_independentes]\n  \n  # Usando parâmetros corretos da função mvn\n  resultado_mvn &lt;- mvn(dados_grupo, mvn_test = \"hz\", univariate_test = \"SW\")\n  resultados_normalidade[[grupo]] &lt;- resultado_mvn$multivariate_normality\n  \n  # Teste alternativo se o primeiro falhar\n  if(is.null(resultado_mvn$multivariate_normality)) {\n    resultado_mardia &lt;- mvn(dados_grupo, mvn_test = \"mardia\")\n    resultados_normalidade[[grupo]] &lt;- resultado_mardia$multivariate_normality\n  }\n}\n\n# Mostrar resultados\nprint(resultados_normalidade)\n\n$`Menos de 1 ano`\n           Test Statistic p.value     Method      MVN\n1 Henze-Zirkler      0.99   0.113 asymptotic ✓ Normal\n\n$`De 1 a 5 anos`\n           Test Statistic p.value     Method      MVN\n1 Henze-Zirkler     0.993   0.063 asymptotic ✓ Normal\n\n$`Mais de 5 anos`\n           Test Statistic p.value     Method          MVN\n1 Henze-Zirkler     0.994   0.035 asymptotic ✗ Not normal\n\n\nResumo dos Testes de Normalidade:\nCom base nos resultados obtidos, 2 dos 3 grupos atendem ao pressuposto de normalidade multivariada ao nível de significância de 5%. O grupo que apresentou desvio (p = 0.035) está próximo do limite aceitável, e a análise discriminante pode prosseguir com confiança.\n\n\n3.2 Homogeneidade das Matrizes de Covariância\nO teste M de Box verifica se as matrizes de covariância dos grupos são homogêneas, outro pressuposto importante da análise discriminante. Este teste avalia se as 13 variáveis independentes apresentam estruturas de covariância similares entre os grupos.\nInterpretação dos Resultados do Teste M de Box:\nConclusão: Com p-valor = 0.01122 &lt; 0.05, rejeitamos a hipótese nula de homogeneidade das matrizes de covariância. Isso indica que há diferenças significativas entre as estruturas de covariância dos grupos.\nImplicações Práticas: - A violação da homogeneidade das covariâncias sugere que a Análise Discriminante Quadrática (QDA) poderia ser mais apropriada que a Linear (LDA) - No entanto, a LDA é robusta a violações moderadas deste pressuposto, especialmente quando os tamanhos das amostras são similares - Como os grupos estão relativamente balanceados (conforme mostrado acima), podemos prosseguir com cautela usando LDA - Os resultados devem ser interpretados considerando esta limitação\n\nlibrary(biotools)\n\ndados_teste &lt;- amostra_analise[, variaveis_independentes]\ngrupos_teste &lt;- amostra_analise$X1\n\n# Teste M de Box com tratamento de erro\ntryCatch({\n  teste_box &lt;- boxM(dados_teste, grupos_teste)\n  print(teste_box)\n}, error = function(e) {\n  message(\"Teste M de Box não pôde ser executado: \", e$message)\n  \n  for(grupo in levels(amostra_analise$X1)) {\n    dados_grupo &lt;- amostra_analise[amostra_analise$X1 == grupo, variaveis_independentes]\n    cov_grupo &lt;- cov(dados_grupo)\n    message(\"\\nMatriz de Covariância - Grupo: \", grupo)\n    print(round(cov_grupo, 3))\n  }\n})\n\n\n    Box's M-test for Homogeneity of Covariance Matrices\n\ndata:  dados_teste\nChi-Sq (approx.) = 228.34, df = 182, p-value = 0.01122\n\n\n\n\n3.3 Multicolinearidade\nA presença de multicolinearidade pode afetar a estabilidade dos resultados da análise discriminante. O determinante da matriz de correlação e os valores VIF nos ajudam a identificar possíveis problemas de multicolinearidade entre as variáveis.\nInterpretação dos Valores VIF:\nOs Fatores de Inflação da Variância (VIF) revelam problemas significativos de multicolinearidade:\n\nVIF &lt; 5: Multicolinearidade baixa (aceitável)\n\nX6 (1.90), X7 (4.56), X8 (4.71), X10 (1.65), X13 (1.76), X14 (4.16), X15 (1.23), X16 (4.33)\n\nVIF entre 5-10: Multicolinearidade moderada (preocupante)\n\nX9 (5.33), X12 (5.78)\n\nVIF &gt; 10: Multicolinearidade alta (problemática)\n\nX11 (Product Line): VIF = 52.77\nX17 (Price Flexibility): VIF = 41.49\n\nX18 (Delivery Speed): VIF = 56.34\n\n\nImplicações: - As variáveis X11, X17 e X18 apresentam alta correlação com outras variáveis independentes - Isso pode causar instabilidade nos coeficientes discriminantes - O determinante da matriz de correlação confirma a presença de multicolinearidade - Apesar disso, seguimos o exemplo de Hair et al. usando X6 e X18, reconhecendo esta limitação\n\n# Matriz de correlação com visualização aprimorada\nmatriz_cor &lt;- cor(amostra_analise[, variaveis_independentes])\n\n# Gráfico de correlação personalizado\ncorrplot::corrplot(matriz_cor, method = \"color\", type = \"upper\", \n                   order = \"hclust\", tl.cex = 0.8, tl.col = \"black\",\n                   col = RColorBrewer::brewer.pal(n = 8, name = \"RdYlBu\"),\n                   title = \"Matriz de Correlação das Variáveis Independentes\",\n                   mar = c(0,0,2,0))\n\n\n\n\n\n\n\n# Determinante da matriz de correlação\ndet_cor &lt;- det(matriz_cor)\n\n# VIF para identificar multicolinearidade\nmodelo_temp &lt;- lm(as.numeric(X1) ~ ., data = amostra_analise[, c(\"X1\", variaveis_independentes)])\nvif_valores &lt;- car::vif(modelo_temp)\n\nAnálise de Multicolinearidade:\n\nDeterminante da matriz de correlação: 8^{-6}\n\nClassificação dos Valores VIF:\n\n\n\nCategoria\nCritério\nVariáveis\n\n\n\n\nBaixa (&lt; 5)\nAceitável\nX6, X7, X8, X10, X13, X14, X15, X16\n\n\nModerada (5-10)\nPreocupante\nX9, X12\n\n\nAlta (≥ 10)\nProblemática\nX11, X17, X18\n\n\n\nVariáveis com Multicolinearidade Severa:\n\n\n\n\n\nVariável\nDescrição\nVIF\n\n\n\n\nX11\nProduct Line\n52.77\n\n\nX17\nPrice Flexibility\n41.49\n\n\nX18\nDelivery Speed\n56.34\n\n\n\n\n\n\n\n\nEstágio 4: Estimação do Modelo Discriminante e Avaliação do Ajuste Geral\n\n4.1 Método Stepwise\n\nlibrary(klaR)\nlibrary(MASS)\n\n# Implementando stepwise manual baseado em critérios estatísticos\nf_univariados &lt;- numeric(length(variaveis_independentes))\np_univariados &lt;- numeric(length(variaveis_independentes))\nnames(f_univariados) &lt;- variaveis_independentes\nnames(p_univariados) &lt;- variaveis_independentes\n\nfor(i in seq_along(variaveis_independentes)) {\n  var &lt;- variaveis_independentes[i]\n  formula_temp &lt;- as.formula(paste(var, \"~ X1\"))\n  \n  tryCatch({\n    anova_temp &lt;- aov(formula_temp, data = amostra_analise)\n    anova_summary &lt;- summary(anova_temp)\n    f_univariados[i] &lt;- anova_summary[[1]][\"X1\", \"F value\"]\n    p_univariados[i] &lt;- anova_summary[[1]][\"X1\", \"Pr(&gt;F)\"]\n  }, error = function(e) {\n    f_univariados[i] &lt;- 0\n    p_univariados[i] &lt;- 1\n  })\n}\n\n# Ordenando variáveis por poder discriminante\nordem_importancia &lt;- order(f_univariados, decreasing = TRUE)\nvars_ordenadas &lt;- variaveis_independentes[ordem_importancia]\nvars_significativas &lt;- names(p_univariados[p_univariados &lt; 0.05])\n\n# Testando modelo Hair et al.: X6 + X18\nformula_hair &lt;- as.formula(\"cbind(X6, X18) ~ X1\")\nmanova_hair &lt;- manova(formula_hair, data = amostra_analise)\nresultado_hair &lt;- summary(manova_hair, test = \"Wilks\")\n\nmodelo_stepwise &lt;- list(\n  formula = \"X1 ~ X6 + X18\",\n  selected_vars = c(\"X6\", \"X18\"),\n  wilks_lambda = resultado_hair$stats[\"X1\", \"Wilks\"],\n  f_statistic = resultado_hair$stats[\"X1\", \"approx F\"],\n  p_value = resultado_hair$stats[\"X1\", \"Pr(&gt;F)\"]\n)\n\nAnálise Univariada de Variáveis:\nRanking por Poder Discriminante (Top 5):\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosição\nVariável\nDescrição\nF.value\np.valor\nSignificância\n\n\n\n\n1\nX18\nDelivery Speed\n24.425\n0\n***\n\n\n2\nX6\nProduct Quality\n22.885\n0\n***\n\n\n3\nX9\nComplaint Resolution\n22.739\n0\n***\n\n\n4\nX11\nProduct Line\n20.721\n0\n***\n\n\n5\nX16\nOrdering & Billing\n17.664\n0\n***\n\n\n\n\n\nModelo Stepwise Final:\n\nFórmula selecionada: X1 ~ X6 + X18\nVariáveis incluídas: X6 + X18\nLambda de Wilks: 0.2901\nEstatística F: 23.99\np-valor: 2.388e-14\nTotal de variáveis significativas: 7 de 13\n\nJustificativa da Seleção: Embora X18 seja a variável mais discriminante univariadamente, seguimos o exemplo de Hair et al. usando X6 (Product Quality) + X18 (Delivery Speed) por razões teóricas e interpretabilidade gerencial.\n\n\n4.2 Análise Discriminante Linear\n\n# Modelo final conforme Hair et al. (X6 e X18)\nmodelo_final &lt;- lda(X1 ~ X6 + X18, data = amostra_analise)\n\n# Autovalores e variância explicada\neigenvalues &lt;- modelo_final$svd^2\nvariancia_explicada &lt;- eigenvalues / sum(eigenvalues) * 100\n\nO modelo discriminante final utiliza as variáveis X6 (Product Quality) e X18 (Delivery Speed), seguindo o exemplo de Hair et al.\nCaracterísticas do Modelo:\n\nNúmero de funções discriminantes: 2\nVariância explicada pela Função 1: 83.5%\nVariância explicada pela Função 2: 16.5%\nVariância total explicada: 100%\n\nAutovalores:\n\n\n\n\n\nFunção\nAutovalor\nVariância.Explicada….\n\n\n\n\nLD 1\n45.9897\n83.5\n\n\nLD 2\n9.0940\n16.5\n\n\n\n\n\n\n\n4.3 Significância Estatística\nO teste de significância avalia se o modelo discriminante é estatisticamente significativo.\n\nmodelo_manova &lt;- manova(cbind(X6, X18) ~ X1, data = amostra_analise)\nsummary(modelo_manova, test = \"Wilks\")\n\n          Df   Wilks approx F num Df den Df    Pr(&gt;F)    \nX1         2 0.29005    23.99      4    112 2.388e-14 ***\nResiduals 57                                             \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.aov(modelo_manova)\n\n Response X6 :\n            Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nX1           2 51.890 25.9451  22.885 5.062e-08 ***\nResiduals   57 64.622  1.1337                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response X18 :\n            Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nX1           2 15.643  7.8216  24.425 2.182e-08 ***\nResiduals   57 18.253  0.3202                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nInterpretação dos Resultados de Significância:\nTeste MANOVA (Multivariado): - Lambda de Wilks = 0.29005: Valor baixo indica boa discriminação entre grupos - F aproximado = 23.99: Estatística F alta sugere diferenças significativas - p-valor = 2.388e-14: Altamente significativo (p &lt; 0.001) - Conclusão: O modelo discriminante é estatisticamente significativo\nAnálises Univariadas por Variável:\nX6 (Product Quality): - F = 22.885: Alta capacidade discriminante individual - p-valor = 5.062e-08: Altamente significativo - Interpretação: A qualidade do produto varia significativamente entre os grupos de tempo de relacionamento\nX18 (Delivery Speed): - F = 24.425: Maior capacidade discriminante individual entre as duas variáveis - p-valor = 2.182e-08: Altamente significativo\n- Interpretação: A percepção da velocidade de entrega é o melhor discriminador individual entre os grupos\nImplicações Gerenciais: 1. Ambas as variáveis contribuem significativamente para distinguir os grupos 2. Velocidade de entrega (X18) é ligeiramente mais discriminante que qualidade (X6) 3. O modelo como um todo tem poder discriminante muito forte 4. As percepções evoluem significativamente com o tempo de relacionamento\n\n\n4.4 Centróides dos Grupos\nOs centróides representam o “centro” de cada grupo no espaço discriminante.\n\ncentroides &lt;- aggregate(amostra_analise[, c(\"X6\", \"X18\")], \n                       by = list(amostra_analise$X1), FUN = mean)\nnames(centroides)[1] &lt;- \"Grupo\"\n\npredict_centroides &lt;- predict(modelo_final, centroides[, c(\"X6\", \"X18\")])\ncentroides_discriminantes &lt;- predict_centroides$x\nrownames(centroides_discriminantes) &lt;- centroides$Grupo\nprint(\"\\nCentróides no Espaço Discriminante:\")\n\n[1] \"\\nCentróides no Espaço Discriminante:\"\n\nprint(centroides_discriminantes)\n\n                      LD1        LD2\nMenos de 1 ano -1.6066271  0.3095983\nDe 1 a 5 anos   0.2579251 -0.7144520\nMais de 5 anos  1.4698995  0.5292210\n\n\nAnálise dos Centróides no Espaço Discriminante:\nPosicionamento dos Grupos:\n\n\n\n\n\n\n\n\n\nGrupo\nLD1\nLD2\nInterpretação\n\n\n\n\nMenos de 1 ano\n-1.61\n0.31\nPercepções mais baixas, posicionamento único\n\n\nDe 1 a 5 anos\n0.26\n-0.71\nPercepções intermediárias, diferenciação moderada\n\n\nMais de 5 anos\n1.47\n0.53\nPercepções mais elevadas, alta satisfação\n\n\n\nPadrões Identificados:\n\nEvolução Linear em LD1: Os valores de LD1 crescem progressivamente (-1.61 → 0.26 → 1.47), indicando melhoria das percepções com o tempo de relacionamento\nSeparação Clara: A distância entre centróides confirma que os grupos são bem diferenciados no espaço discriminante\nTrajetória de Relacionamento:\n\nClientes novos (&lt; 1 ano): Expectativas em formação, percepções iniciais mais críticas\nClientes intermediários (1-5 anos): Período de consolidação das percepções\nClientes estabelecidos (&gt; 5 anos): Relacionamento maduro, percepções mais positivas\n\n\nInterpretação das Funções Discriminantes:\n\nLD1: Representa principalmente a evolução temporal das percepções (experiência acumulada)\nLD2: Representa diferenças qualitativas específicas entre os grupos intermediários e extremos\n\nImplicações Estratégicas: - Foco na retenção inicial: Clientes novos precisam de atenção especial - Gestão da jornada: Processo gradual de melhoria das percepções - Fidelização: Clientes de longo prazo são verdadeiros advogados da marca\n\n\n\nEstágio 5: Interpretação dos Resultados\n\n5.1 Cargas Discriminantes (Matriz Estrutural)\nAs cargas discriminantes mostram a correlação entre cada variável independente e as funções discriminantes.\n\n# Calculando cargas discriminantes (correlações entre variáveis e funções)\n# Escores discriminantes para todas as observações\nescores_discriminantes &lt;- predict(modelo_final, amostra_analise)$x\n\n# Matriz de cargas (correlações)\nvariaveis_completas &lt;- amostra_analise[, variaveis_independentes]\ncargas_discriminantes &lt;- cor(variaveis_completas, escores_discriminantes)\n\nprint(\"Matriz de Cargas Discriminantes (não-rotacionadas):\")\n\n[1] \"Matriz de Cargas Discriminantes (não-rotacionadas):\"\n\nprint(round(cargas_discriminantes, 3))\n\n       LD1    LD2\nX6   0.736  0.677\nX7   0.235 -0.313\nX8   0.103  0.182\nX9   0.728 -0.467\nX10  0.177 -0.237\nX11  0.773 -0.049\nX12  0.192 -0.418\nX13 -0.251 -0.286\nX14  0.163  0.058\nX15  0.041 -0.084\nX16  0.699 -0.416\nX17  0.012 -0.699\nX18  0.765 -0.644\n\n# Identificando variáveis descritivas (|carga| &gt;= 0.40)\ncargas_importantes &lt;- abs(cargas_discriminantes) &gt;= 0.40\nprint(\"\\nVariáveis Descritivas por Função (|carga| &gt;= 0.40):\")\n\n[1] \"\\nVariáveis Descritivas por Função (|carga| &gt;= 0.40):\"\n\nfor(i in 1:ncol(cargas_discriminantes)) {\n  cat(\"Função\", i, \":\", names(which(cargas_importantes[, i])), \"\\n\")\n}\n\nFunção 1 : X6 X9 X11 X16 X18 \nFunção 2 : X6 X9 X12 X16 X17 X18 \n\n\nInterpretação da Matriz de Cargas Discriminantes:\nAnálise da Função Discriminante 1 (LD1):\nVariáveis com Cargas Altas (|carga| ≥ 0.40): - X11 (Product Line): 0.773 - Maior contribuição para LD1 - X18 (Delivery Speed): 0.765 - Forte correlação positiva - X6 (Product Quality): 0.736 - Alta correlação positiva\n- X9 (Complaint Resolution): 0.728 - Contribuição significativa - X16 (Ordering & Billing): 0.699 - Forte correlação\nInterpretação de LD1: Representa a dimensão geral de satisfação com aspectos operacionais e de qualidade da HBAT. Valores altos indicam percepções positivas em qualidade, entrega, linha de produtos e resolução de problemas.\nAnálise da Função Discriminante 2 (LD2):\nVariáveis com Cargas Altas (|carga| ≥ 0.40): - X17 (Price Flexibility): -0.699 - Maior magnitude (negativa) - X6 (Product Quality): 0.677 - Correlação positiva forte - X18 (Delivery Speed): -0.644 - Correlação negativa significativa - X9 (Complaint Resolution): -0.467 - Contribuição moderada negativa - X16 (Ordering & Billing): -0.416 - Correlação negativa - X12 (Salesforce Image): -0.418 - Contribuição moderada negativa\nInterpretação de LD2: Representa um contraste entre qualidade percebida versus flexibilidade operacional. Separa grupos com diferentes prioridades: qualidade versus agilidade/flexibilidade.\n\n\n5.2 Rotação VARIMAX\n\n# Aplicando rotação VARIMAX às cargas discriminantes\nlibrary(stats)\n\nif(ncol(cargas_discriminantes) &gt; 1) {\n  rotacao_varimax &lt;- varimax(cargas_discriminantes)\n  cargas_rotacionadas &lt;- rotacao_varimax$loadings[]\n  \n  print(\"Matriz de Cargas Discriminantes (rotacionadas - VARIMAX):\")\n  print(round(cargas_rotacionadas, 3))\n  \n  # Variáveis descritivas após rotação\n  cargas_rot_importantes &lt;- abs(cargas_rotacionadas) &gt;= 0.40\n  print(\"\\nVariáveis Descritivas por Função Rotacionada (|carga| &gt;= 0.40):\")\n  for(i in 1:ncol(cargas_rotacionadas)) {\n    cat(\"Função\", i, \":\", names(which(cargas_rot_importantes[, i])), \"\\n\")\n  }\n} else {\n  cargas_rotacionadas &lt;- cargas_discriminantes\n  print(\"Apenas uma função discriminante - rotação não aplicável\")\n}\n\n[1] \"Matriz de Cargas Discriminantes (rotacionadas - VARIMAX):\"\n       LD1    LD2\nX6   1.000  0.003\nX7  -0.038 -0.390\nX8   0.199  0.064\nX9   0.222 -0.836\nX10 -0.029 -0.294\nX11  0.538 -0.558\nX12 -0.140 -0.438\nX13 -0.378 -0.042\nX14  0.160 -0.067\nX15 -0.027 -0.090\nX16  0.235 -0.779\nX17 -0.462 -0.524\nX18  0.129 -0.992\n[1] \"\\nVariáveis Descritivas por Função Rotacionada (|carga| &gt;= 0.40):\"\nFunção 1 : X6 X11 X17 \nFunção 2 : X9 X11 X12 X16 X17 X18 \n\n\nInterpretação das Cargas Rotacionadas (VARIMAX):\nA rotação VARIMAX simplifica a estrutura, criando fatores mais interpretáveis:\nFunção 1 Rotacionada: - X6 (Product Quality): 1.000 - Carga perfeitamente concentrada - X11 (Product Line): 0.538 - Contribuição moderada - X17 (Price Flexibility): -0.462 - Contribuição negativa moderada\nInterpretação: LD1 rotacionada representa essencialmente a “Dimensão de Qualidade”, contrastando qualidade percebida com flexibilidade de preços.\nFunção 2 Rotacionada: - X18 (Delivery Speed): -0.992 - Concentração quase perfeita (negativa) - X9 (Complaint Resolution): -0.836 - Alta correlação negativa\n- X16 (Ordering & Billing): -0.779 - Correlação negativa forte - X11 (Product Line): -0.558 - Contribuição moderada - X17 (Price Flexibility): -0.524 - Contribuição moderada\nInterpretação: LD2 rotacionada representa a “Dimensão Operacional”, focando em velocidade, eficiência e aspectos transacionais.\nVantagem da Rotação: - Simplifica interpretação: Cada função tem foco mais claro - Reduz ambiguidade: Menos variáveis com cargas altas em múltiplas funções - Facilita comunicação gerencial: Dimensões mais intuitivas\n\n\n5.3 Índice de Potência\n\n# Calculando índice de potência conforme Hair et al.\nif(ncol(cargas_discriminantes) &gt; 1) {\n  # Autovalores relativos\n  autovalores_relativos &lt;- eigenvalues / sum(eigenvalues)\n  \n  # Índice de potência para cada variável\n  indice_potencia &lt;- numeric(nrow(cargas_rotacionadas))\n  names(indice_potencia) &lt;- rownames(cargas_rotacionadas)\n  \n  for(i in 1:nrow(cargas_rotacionadas)) {\n    potencia_total &lt;- 0\n    for(j in 1:ncol(cargas_rotacionadas)) {\n      potencia_total &lt;- potencia_total + (cargas_rotacionadas[i, j]^2 * autovalores_relativos[j])\n    }\n    indice_potencia[i] &lt;- potencia_total\n  }\n  \n  # Ordenando por índice de potência\n  indice_potencia_ordenado &lt;- sort(indice_potencia, decreasing = TRUE)\n  \n  print(\"Índice de Potência das Variáveis:\")\n  print(round(indice_potencia_ordenado, 3))\n}\n\n[1] \"Índice de Potência das Variáveis:\"\n   X6   X11   X17   X18    X9   X16   X13   X12    X8    X7   X14   X10   X15 \n0.835 0.293 0.224 0.176 0.157 0.146 0.120 0.048 0.034 0.026 0.022 0.015 0.002 \n\n\nInterpretação do Índice de Potência:\nO índice de potência combina a contribuição de cada variável em todas as funções, ponderada pela importância relativa de cada função:\nRanking por Poder Discriminante Total:\n\n\n\n\n\n\n\n\n\n\nPosição\nVariável\nDescrição\nÍndice\nInterpretação\n\n\n\n\n1º\nX6\nProduct Quality\n0.835\nDiscriminador principal - fundamental para diferenciação\n\n\n2º\nX11\nProduct Line\n0.293\nSegundo mais importante - variedade de produtos relevante\n\n\n3º\nX17\nPrice Flexibility\n0.224\nTerceiro lugar - flexibilidade de preços diferencia grupos\n\n\n4º\nX18\nDelivery Speed\n0.176\nQuarto lugar - velocidade importante apesar de estar no modelo\n\n\n5º\nX9\nComplaint Resolution\n0.157\nModeradamente importante - resolução de problemas diferencia\n\n\n\nInsights Principais:\n\nX6 (Product Quality) é o discriminador dominante, responsável por mais de 83% do poder discriminante total\nX18 (Delivery Speed), apesar de estar no modelo final, ocupa apenas a 4ª posição no índice de potência\nX11 (Product Line) aparece como segundo mais importante, sugerindo que variedade de produtos é crucial\nA concentração de poder nas primeiras variáveis indica que poucas dimensões explicam a maior parte da discriminação\n\nImplicações Gerenciais: - Prioridade máxima: Investir em qualidade do produto - Segunda prioridade: Expandir e melhorar linha de produtos - Terceira prioridade: Desenvolver flexibilidade de preços - Monitoramento: Acompanhar velocidade de entrega e resolução de reclamações\n\n\n5.4 Razões F Univariadas\n\n# Calculando razões F univariadas para cada variável\nrazoes_f &lt;- numeric(length(variaveis_independentes))\nnames(razoes_f) &lt;- variaveis_independentes\n\nfor(var in variaveis_independentes) {\n  formula_temp &lt;- as.formula(paste(var, \"~ X1\"))\n  anova_temp &lt;- aov(formula_temp, data = amostra_analise)\n  razoes_f[var] &lt;- summary(anova_temp)[[1]][\"X1\", \"F value\"]\n}\n\n# Ordenando por valor F\nrazoes_f_ordenadas &lt;- sort(razoes_f, decreasing = TRUE)\n\nprint(\"Razões F Univariadas:\")\n\n[1] \"Razões F Univariadas:\"\n\nprint(round(razoes_f_ordenadas, 3))\n\n   X18     X6     X9    X11    X16    X17    X13    X12    X14     X7    X10 \n24.425 22.885 22.739 20.721 17.664 13.892  9.075  2.873  0.919  0.799  0.753 \n    X8    X15 \n 0.715  0.599 \n\n# Teste de significância (α = 0.05)\np_valores &lt;- numeric(length(variaveis_independentes))\nnames(p_valores) &lt;- variaveis_independentes\n\nfor(var in variaveis_independentes) {\n  formula_temp &lt;- as.formula(paste(var, \"~ X1\"))\n  anova_temp &lt;- aov(formula_temp, data = amostra_analise)\n  p_valores[var] &lt;- summary(anova_temp)[[1]][\"X1\", \"Pr(&gt;F)\"]\n}\n\nprint(\"\\nVariáveis Significativas (p &lt; 0.05):\")\n\n[1] \"\\nVariáveis Significativas (p &lt; 0.05):\"\n\nprint(names(p_valores[p_valores &lt; 0.05]))\n\n[1] \"X6\"  \"X9\"  \"X11\" \"X13\" \"X16\" \"X17\" \"X18\"\n\n\nInterpretação das Razões F Univariadas:\nRanking de Poder Discriminante Individual:\n\n\n\n\n\n\n\n\n\n\n\nPosição\nVariável\nF-value\np-valor\nStatus\nInterpretação\n\n\n\n\n1º\nX18 (Delivery Speed)\n24.425\n&lt; 0.001\n***\nMelhor discriminador individual\n\n\n2º\nX6 (Product Quality)\n22.885\n&lt; 0.001\n***\nSegundo melhor discriminador\n\n\n3º\nX9 (Complaint Resolution)\n22.739\n&lt; 0.001\n***\nTerceiro em poder discriminante\n\n\n4º\nX11 (Product Line)\n20.721\n&lt; 0.001\n***\nQuarto colocado significativo\n\n\n5º\nX16 (Ordering & Billing)\n17.664\n&lt; 0.001\n***\nQuinto em importância\n\n\n\nVariáveis Significativas (p &lt; 0.05): X6, X9, X11, X13, X16, X17, X18 (7 de 13 variáveis)\nComparação: Poder Individual vs. Poder Combinado:\n\nX18 (Delivery Speed):\n\nIndividual: 1º lugar (F = 24.425)\nCombinado: 4º lugar (Índice = 0.176)\nInterpretação: Excelente discriminador individual, mas com alguma redundância no modelo conjunto\n\nX6 (Product Quality):\n\nIndividual: 2º lugar (F = 22.885)\n\nCombinado: 1º lugar (Índice = 0.835)\nInterpretação: Forte individual e dominante no modelo conjunto\n\n\nInsights sobre Seleção de Variáveis:\n\nCritério Hair et al.: Usar X6 + X18 é justificado pelo alto poder discriminante individual de ambas\nPotencial de otimização: X9 (Complaint Resolution) tem poder individual muito alto e poderia ser considerada\nRedundância: Várias variáveis significativas sugerem multicolinearidade (confirmada pelos VIF altos)\n\nRecomendações Gerenciais: 1. Foco primário: Delivery Speed e Product Quality (variáveis do modelo) 2. Foco secundário: Complaint Resolution (alto poder discriminante individual)\n3. Monitoramento: Product Line e Ordering & Billing (significativas e importantes) 4. Revisão: Considerar modelo expandido incluindo X9 para melhor discriminação\n\n\n5.5 Gráfico de Vetores de Atribuição no Espaço Discriminante\n\n# Gráfico dos valores F univariados com descrições\nf_df &lt;- data.frame(\n  Variavel = names(f_univariados),\n  F_Value = f_univariados,\n  P_Value = p_univariados,\n  Significativo = p_univariados &lt; 0.05\n) %&gt;%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\np_f_values &lt;- ggplot2::ggplot(f_df, ggplot2::aes(x = reorder(Variavel_Desc, F_Value), \n                                                 y = F_Value, fill = Significativo)) +\n  ggplot2::geom_col(alpha = 0.8) +\n  ggplot2::geom_text(ggplot2::aes(label = round(F_Value, 1)), hjust = -0.1, size = 3) +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"TRUE\" = \"steelblue\", \"FALSE\" = \"gray70\"),\n                            labels = c(\"FALSE\" = \"Não Significativo\", \"TRUE\" = \"Significativo\")) +\n  ggplot2::labs(title = \"Valores F Univariados para Seleção de Variáveis\",\n                subtitle = \"Poder discriminante individual de cada variável\",\n                x = \"Variáveis\", y = \"Estatística F\",\n                fill = \"Significância\\n(p &lt; 0.05)\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.y = ggplot2::element_text(size = 9))\n\nprint(p_f_values)\n\n\n\n\n\n\n\n# Criando gráfico de vetores de atribuição (variáveis no espaço discriminante)\nescores_todos &lt;- predict(modelo_final, amostra_analise)$x\ndf_escores &lt;- data.frame(\n  Funcao1 = escores_todos[, 1],\n  Funcao2 = escores_todos[, 2],\n  Grupo = amostra_analise$X1,\n  Probabilidades = apply(predict(modelo_final, amostra_analise)$posterior, 1, max)\n)\n\n# Adicionando centróides\ndf_centroides &lt;- data.frame(\n  Funcao1 = centroides_discriminantes[, 1],\n  Funcao2 = centroides_discriminantes[, 2],\n  Grupo = factor(rownames(centroides_discriminantes), \n                levels = levels(amostra_analise$X1))\n)\n\n# Escalonando as cargas para melhor visualização\nescala_vetor &lt;- 3  # Fator de escala para os vetores\ncargas_escalonadas &lt;- cargas_discriminantes * escala_vetor\n\n# Preparando dados dos vetores com descrições\nvetores_df &lt;- data.frame(\n  Variavel = rownames(cargas_discriminantes),\n  LD1_start = 0,\n  LD2_start = 0,\n  LD1_end = cargas_escalonadas[, 1],\n  LD2_end = cargas_escalonadas[, 2],\n  Magnitude = sqrt(cargas_discriminantes[, 1]^2 + cargas_discriminantes[, 2]^2),\n  Significativa = rownames(cargas_discriminantes) %in% vars_significativas\n) %&gt;%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\n# Gráfico de vetores de atribuição expandidos\np_vetores &lt;- ggplot2::ggplot() +\n  # Pontos dos grupos (mais transparentes para não ofuscar os vetores)\n  ggplot2::geom_point(data = df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo), \n                      alpha = 0.3, size = 1) +\n  # Centróides dos grupos\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 6, shape = 17, color = \"black\") +\n  # LABELS DOS CENTRÓIDES - NOVO\n  ggplot2::geom_text(data = df_centroides, \n                     ggplot2::aes(x = Funcao1, y = Funcao2, label = Grupo),\n                     vjust = -1.5, hjust = 0.5, color = \"black\", \n                     fontface = \"bold\", size = 3.5,\n                     box.padding = 0.5) +\n  # Vetores das variáveis\n  ggplot2::geom_segment(data = vetores_df,\n                        ggplot2::aes(x = LD1_start, y = LD2_start, \n                                     xend = LD1_end, yend = LD2_end,\n                                     color = Significativa, size = Magnitude),\n                        arrow = ggplot2::arrow(length = ggplot2::unit(0.3, \"cm\")),\n                        alpha = 0.8) +\n  # Labels das variáveis com descrições\n  ggplot2::geom_text(data = vetores_df,\n                     ggplot2::aes(x = LD1_end * 1.1, y = LD2_end * 1.1, \n                                  label = Variavel_Desc, color = Significativa),\n                     size = 2.5, fontface = \"bold\") +\n  # Eixos de referência\n  ggplot2::geom_hline(yintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  ggplot2::geom_vline(xintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  # Escalas e temas\n  ggplot2::scale_color_manual(values = c(\"FALSE\" = \"gray50\", \"TRUE\" = \"red\")) +\n  ggplot2::scale_size_continuous(range = c(0.5, 2), guide = \"none\") +\n  ggplot2::labs(title = \"Vetores de Atribuição das Variáveis no Espaço Discriminante\",\n                subtitle = paste(\"Vetores mostram contribuição das variáveis para as funções discriminantes\\n\",\n                                \"Triângulos pretos = centróides dos grupos | Escala dos vetores: \", escala_vetor, \"x\"),\n                x = paste(\"Função Discriminante 1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"Função Discriminante 2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Variável\\nSignificativa\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 plot.subtitle = ggplot2::element_text(size = 10))\n\nWarning in ggplot2::geom_text(data = df_centroides, ggplot2::aes(x = Funcao1, :\nIgnoring unknown parameters: `box.padding`\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\nprint(p_vetores)\n\n\n\n\n\n\n\n# IDENTIFICAÇÃO DOS GRUPOS DA VARIÁVEL DEPENDENTE\ncat(\"\\n=== IDENTIFICAÇÃO DOS GRUPOS DA VARIÁVEL DEPENDENTE ===\\n\")\n\n\n=== IDENTIFICAÇÃO DOS GRUPOS DA VARIÁVEL DEPENDENTE ===\n\ncat(\"Variável Dependente: X1 (Customer Type)\\n\")\n\nVariável Dependente: X1 (Customer Type)\n\ncat(\"Descrição: Tempo de relacionamento com a empresa HBAT\\n\\n\")\n\nDescrição: Tempo de relacionamento com a empresa HBAT\n\n# Grupos identificados no gráfico\ngrupos_identificados &lt;- levels(amostra_analise$X1)\nfreq_grupos &lt;- table(amostra_analise$X1)\ncentroides_info &lt;- centroides_discriminantes\n\ncat(\"GRUPOS REPRESENTADOS NO GRÁFICO:\\n\")\n\nGRUPOS REPRESENTADOS NO GRÁFICO:\n\nfor(i in 1:length(grupos_identificados)) {\n  grupo_nome &lt;- grupos_identificados[i]\n  freq &lt;- freq_grupos[i]\n  ld1_pos &lt;- round(centroides_info[grupo_nome, \"LD1\"], 2)\n  ld2_pos &lt;- round(centroides_info[grupo_nome, \"LD2\"], 2)\n  \n  cat(sprintf(\"🔺 GRUPO %d: %s\\n\", i, grupo_nome))\n  cat(sprintf(\"   - Frequência: %d casos (%.1f%%)\\n\", \n              freq, (freq/sum(freq_grupos))*100))\n  cat(sprintf(\"   - Posição no gráfico: LD1 = %.2f, LD2 = %.2f\\n\", ld1_pos, ld2_pos))\n  cat(sprintf(\"   - Característica: %s\\n\", \n              switch(i,\n                     \"Clientes com relacionamento recente - percepções iniciais\",\n                     \"Clientes com relacionamento estabelecido - percepções moderadas\", \n                     \"Clientes com relacionamento consolidado - percepções elevadas\")))\n  cat(\"\\n\")\n}\n\n🔺 GRUPO 1: Menos de 1 ano\n   - Frequência: 20 casos (33.3%)\n   - Posição no gráfico: LD1 = -1.61, LD2 = 0.31\n   - Característica: Clientes com relacionamento recente - percepções iniciais\n\n🔺 GRUPO 2: De 1 a 5 anos\n   - Frequência: 22 casos (36.7%)\n   - Posição no gráfico: LD1 = 0.26, LD2 = -0.71\n   - Característica: Clientes com relacionamento estabelecido - percepções moderadas\n\n🔺 GRUPO 3: Mais de 5 anos\n   - Frequência: 18 casos (30.0%)\n   - Posição no gráfico: LD1 = 1.47, LD2 = 0.53\n   - Característica: Clientes com relacionamento consolidado - percepções elevadas\n\n# Interpretação dos centróides no espaço discriminante\ncat(\"INTERPRETAÇÃO DOS CENTRÓIDES (TRIÂNGULOS PRETOS):\\n\")\n\nINTERPRETAÇÃO DOS CENTRÓIDES (TRIÂNGULOS PRETOS):\n\ncat(\"- Os triângulos pretos representam o 'centro' de cada grupo no espaço discriminante\\n\")\n\n- Os triângulos pretos representam o 'centro' de cada grupo no espaço discriminante\n\ncat(\"- Sua posição indica as características médias de cada grupo\\n\")\n\n- Sua posição indica as características médias de cada grupo\n\ncat(\"- A distância entre centróides mostra o grau de separação entre grupos\\n\")\n\n- A distância entre centróides mostra o grau de separação entre grupos\n\n# Análise das posições dos centróides\ncat(\"\\nANÁLISE DAS POSIÇÕES:\\n\")\n\n\nANÁLISE DAS POSIÇÕES:\n\nfor(i in 1:nrow(centroides_info)) {\n  grupo_nome &lt;- rownames(centroides_info)[i]\n  ld1_val &lt;- centroides_info[i, \"LD1\"]\n  ld2_val &lt;- centroides_info[i, \"LD2\"]\n  \n  # Interpretação baseada na posição\n  interpretacao_ld1 &lt;- ifelse(ld1_val &gt; 0, \"valores altos em LD1\", \"valores baixos em LD1\")\n  interpretacao_ld2 &lt;- ifelse(ld2_val &gt; 0, \"valores altos em LD2\", \"valores baixos em LD2\")\n  \n  cat(sprintf(\"- %s: Caracterizado por %s e %s\\n\", \n              grupo_nome, interpretacao_ld1, interpretacao_ld2))\n}\n\n- Menos de 1 ano: Caracterizado por valores baixos em LD1 e valores altos em LD2\n- De 1 a 5 anos: Caracterizado por valores altos em LD1 e valores baixos em LD2\n- Mais de 5 anos: Caracterizado por valores altos em LD1 e valores altos em LD2\n\ncat(\"\\nLEGENDA DO GRÁFICO:\\n\")\n\n\nLEGENDA DO GRÁFICO:\n\ncat(\"🔺 Triângulos pretos = Centróides dos grupos\\n\")\n\n🔺 Triângulos pretos = Centróides dos grupos\n\ncat(\"● Pontos coloridos = Observações individuais por grupo\\n\")\n\n● Pontos coloridos = Observações individuais por grupo\n\ncat(\"→ Vetores vermelhos = Variáveis significativas (p &lt; 0.05)\\n\")\n\n→ Vetores vermelhos = Variáveis significativas (p &lt; 0.05)\n\ncat(\"→ Vetores cinza = Variáveis não significativas\\n\")\n\n→ Vetores cinza = Variáveis não significativas\n\ncat(\"📏 Comprimento do vetor = Magnitude da contribuição discriminante\\n\")\n\n📏 Comprimento do vetor = Magnitude da contribuição discriminante\n\n# Interpretação dos vetores\ncat(\"\\n=== INTERPRETAÇÃO DOS VETORES DE ATRIBUIÇÃO ===\\n\")\n\n\n=== INTERPRETAÇÃO DOS VETORES DE ATRIBUIÇÃO ===\n\n\n\n\n6.4 Análise das Distâncias entre Grupos\n\n# Calculando distâncias Mahalanobis entre centróides\ncentroides_matriz &lt;- as.matrix(centroides_discriminantes)\n\n# Matriz de distâncias entre centróides\nn_grupos &lt;- nrow(centroides_matriz)\ndist_centroides &lt;- matrix(0, n_grupos, n_grupos)\nrownames(dist_centroides) &lt;- rownames(centroides_matriz)\ncolnames(dist_centroides) &lt;- rownames(centroides_matriz)\n\nfor(i in 1:n_grupos) {\n  for(j in 1:n_grupos) {\n    dist_centroides[i, j] &lt;- sqrt(sum((centroides_matriz[i, ] - centroides_matriz[j, ])^2))\n  }\n}\n\nprint(\"Matriz de Distâncias Euclidianas entre Centróides:\")\n\n[1] \"Matriz de Distâncias Euclidianas entre Centróides:\"\n\nprint(round(dist_centroides, 3))\n\n               Menos de 1 ano De 1 a 5 anos Mais de 5 anos\nMenos de 1 ano          0.000         2.127          3.084\nDe 1 a 5 anos           2.127         0.000          1.737\nMais de 5 anos          3.084         1.737          0.000\n\n# Visualização das distâncias como heatmap\ndist_df &lt;- reshape2::melt(dist_centroides)\nnames(dist_df) &lt;- c(\"Grupo1\", \"Grupo2\", \"Distancia\")\n\np_distancias &lt;- ggplot2::ggplot(dist_df, ggplot2::aes(x = Grupo1, y = Grupo2, fill = Distancia)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = round(Distancia, 2)), \n                     color = \"white\", fontface = \"bold\", size = 5) +\n  ggplot2::scale_fill_viridis_c(name = \"Distância\\nEuclidiana\") +\n  ggplot2::labs(title = \"Matriz de Distâncias entre Centróides dos Grupos\",\n                subtitle = \"Distâncias calculadas no espaço discriminante\",\n                x = \"Grupo\", y = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\nprint(p_distancias)\n\n\n\n\n\n\n\n# Análise de separação\ndist_matrix_upper &lt;- dist_centroides[upper.tri(dist_centroides)]\n\n# Identificando grupos mais próximos e mais distantes\ndist_indices &lt;- which(dist_centroides == min(dist_matrix_upper), arr.ind = TRUE)[1, ]\ngrupos_proximos &lt;- c(rownames(dist_centroides)[dist_indices[1]], \n                    colnames(dist_centroides)[dist_indices[2]])\n\ndist_indices_max &lt;- which(dist_centroides == max(dist_matrix_upper), arr.ind = TRUE)[1, ]\ngrupos_distantes &lt;- c(rownames(dist_centroides)[dist_indices_max[1]], \n                     colnames(dist_centroides)[dist_indices_max[2]])\n\nInterpretação da Análise de Distâncias:\nMatriz de Distâncias Euclidianas: - Menor distância: “De 1 a 5 anos” ↔︎ “Mais de 5 anos” (1.737) - Maior distância: “Menos de 1 ano” ↔︎ “Mais de 5 anos” (3.084) - Distância intermediária: “Menos de 1 ano” ↔︎ “De 1 a 5 anos” (2.127)\nPadrões de Similaridade:\n\nGrupos Intermediário e Maduro são mais próximos:\n\nDistância de apenas 1.737 unidades\nInterpretação: Após 1 ano, as percepções começam a convergir\nImplicação: O primeiro ano é crítico para formar percepções duradouras\n\nClientes Novos são mais distantes de todos:\n\nMaior distância dos clientes maduros (3.084)\nInterpretação: Período inicial tem características muito distintas\nImplicação: Estratégias específicas necessárias para novos clientes\n\nProgressão Não-Linear:\n\nA evolução “Novo → Intermediário → Maduro” não é uniforme\nMaior salto entre “Novo” e “Intermediário” (2.127)\nMenor progressão entre “Intermediário” e “Maduro” (1.737)\n\n\nInsights Gerenciais:\n\nPeríodo Crítico: Os primeiros 12 meses são fundamentais para retenção\nConvergência: Após 1 ano, clientes tendem a desenvolver percepções similares\nSegmentação: Dois grandes segmentos emergem: “Novos” vs. “Estabelecidos” (intermediários + maduros)\n\n\n\n6.5 Comparação Visual: Espaço Original vs. Espaço Discriminante\n\n# Comparando visualização no espaço original (X6, X18) vs. espaço discriminante\np_original &lt;- ggplot2::ggplot(amostra_analise, ggplot2::aes(x = X6, y = X18, color = X1)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = centroides, ggplot2::aes(x = X6, y = X18), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Espaço Original\",\n                subtitle = \"Variáveis originais do modelo discriminante\",\n                x = descricoes_variaveis[\"X6\"], \n                y = descricoes_variaveis[\"X18\"],\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 12, face = \"bold\"))\n\np_discriminante &lt;- ggplot2::ggplot(df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Espaço Discriminante (LD1 vs LD2)\",\n                subtitle = \"Funções discriminantes otimizadas para separação\",\n                x = paste(\"LD1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"LD2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 12, face = \"bold\"))\n\n# Combinando os gráficos\ncomparacao &lt;- gridExtra::grid.arrange(\n  p_original, p_discriminante, \n  ncol = 2,\n  top = grid::textGrob(\"Comparação: Espaço Original vs. Espaço Discriminante\", \n                       gp = grid::gpar(fontsize = 16, fontface = \"bold\"))\n)\n\n\n\n\n\n\n\nprint(comparacao)\n\nTableGrob (2 x 2) \"arrange\": 3 grobs\n  z     cells    name                grob\n1 1 (2-2,1-1) arrange      gtable[layout]\n2 2 (2-2,2-2) arrange      gtable[layout]\n3 3 (1-1,1-2) arrange text[GRID.text.321]\n\n# Interpretação da comparação\ncat(\"\\n=== INTERPRETAÇÃO DA COMPARAÇÃO ===\\n\")\n\n\n=== INTERPRETAÇÃO DA COMPARAÇÃO ===\n\ncat(\"- Espaço Original: mostra sobreposição entre grupos\\n\")\n\n- Espaço Original: mostra sobreposição entre grupos\n\ncat(\"- Espaço Discriminante: maximiza separação entre grupos\\n\")\n\n- Espaço Discriminante: maximiza separação entre grupos\n\ncat(\"- A transformação discriminante melhora a separabilidade\\n\")\n\n- A transformação discriminante melhora a separabilidade\n\ncat(\"- LD1 e LD2 são combinações lineares que maximizam discriminação\\n\")\n\n- LD1 e LD2 são combinações lineares que maximizam discriminação\n\n\n\n\n\nEstágio 6: Validação dos Resultados\n\n6.6 Matriz de Classificação e Validação\n\n# Classificação da amostra de análise\npredicoes_analise &lt;- predict(modelo_final, amostra_analise)\nmatriz_confusao_analise &lt;- table(Predito = predicoes_analise$class, \n                                Real = amostra_analise$X1)\n\nprint(\"Matriz de Classificação - Amostra de Análise:\")\n\n[1] \"Matriz de Classificação - Amostra de Análise:\"\n\nprint(matriz_confusao_analise)\n\n                Real\nPredito          Menos de 1 ano De 1 a 5 anos Mais de 5 anos\n  Menos de 1 ano             16             2              0\n  De 1 a 5 anos               3            14              1\n  Mais de 5 anos              1             6             17\n\n# Taxa de acerto geral\nacerto_geral_analise &lt;- sum(diag(matriz_confusao_analise)) / sum(matriz_confusao_analise)\n\n# Taxa de acerto por grupo\nacerto_por_grupo_analise &lt;- diag(matriz_confusao_analise) / rowSums(matriz_confusao_analise)\nprint(\"Taxa de Acerto por Grupo (Análise):\")\n\n[1] \"Taxa de Acerto por Grupo (Análise):\"\n\nprint(round(acerto_por_grupo_analise * 100, 1))\n\nMenos de 1 ano  De 1 a 5 anos Mais de 5 anos \n          88.9           77.8           70.8 \n\n# Visualização da matriz de confusão\nmatriz_conf_df &lt;- as.data.frame(matriz_confusao_analise)\nnames(matriz_conf_df) &lt;- c(\"Predito\", \"Real\", \"Freq\")\n\np_matriz_conf &lt;- ggplot2::ggplot(matriz_conf_df, ggplot2::aes(x = Real, y = Predito, fill = Freq)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = Freq), color = \"white\", size = 6, fontface = \"bold\") +\n  ggplot2::scale_fill_viridis_c(name = \"Frequência\") +\n  ggplot2::labs(title = \"Matriz de Confusão - Amostra de Análise\",\n                subtitle = paste(\"Taxa de Acerto Geral:\", round(acerto_geral_analise * 100, 1), \"%\"),\n                x = \"Grupo Real\", y = \"Grupo Predito\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\nprint(p_matriz_conf)\n\n\n\n\n\n\n\n\nTaxa de Acerto Geral (Análise): 78.3%\nTaxa de Acerto por Grupo (Análise):\n\n\n\n\n\nGrupo\nTaxa.de.Acerto….\n\n\n\n\nMenos de 1 ano\n88.9\n\n\nDe 1 a 5 anos\n77.8\n\n\nMais de 5 anos\n70.8\n\n\n\n\n\n\n\n6.7 Validação Cruzada\n\n# Função para validação cruzada\nvalidacao_cruzada &lt;- function(dados, formula) {\n  n &lt;- nrow(dados)\n  predicoes &lt;- character(n)\n  \n  for(i in 1:n) {\n    # Treina modelo sem a observação i\n    dados_treino &lt;- dados[-i, ]\n    modelo_temp &lt;- MASS::lda(formula, data = dados_treino)\n    \n    # Prediz a observação i\n    predicao_temp &lt;- predict(modelo_temp, dados[i, ])\n    predicoes[i] &lt;- as.character(predicao_temp$class)\n  }\n  \n  return(factor(predicoes, levels = levels(dados$X1)))\n}\n\n# Aplicando validação cruzada\npredicoes_cv &lt;- validacao_cruzada(amostra_analise, X1 ~ X6 + X18)\nmatriz_confusao_cv &lt;- table(Predito = predicoes_cv, Real = amostra_analise$X1)\n\nprint(\"Matriz de Classificação - Validação Cruzada:\")\n\n[1] \"Matriz de Classificação - Validação Cruzada:\"\n\nprint(matriz_confusao_cv)\n\n                Real\nPredito          Menos de 1 ano De 1 a 5 anos Mais de 5 anos\n  Menos de 1 ano             16             2              0\n  De 1 a 5 anos               3            14              1\n  Mais de 5 anos              1             6             17\n\n# Taxa de acerto validação cruzada\nacerto_geral_cv &lt;- sum(diag(matriz_confusao_cv)) / sum(matriz_confusao_cv)\n\nTaxa de Acerto Geral (Validação Cruzada): 78.3%\n\n\n6.8 Validação Externa\n\n# Classificação da amostra de validação\npredicoes_validacao &lt;- predict(modelo_final, amostra_validacao)\nmatriz_confusao_validacao &lt;- table(Predito = predicoes_validacao$class, \n                                  Real = amostra_validacao$X1)\n\nprint(\"Matriz de Classificação - Amostra de Validação:\")\n\n[1] \"Matriz de Classificação - Amostra de Validação:\"\n\nprint(matriz_confusao_validacao)\n\n                Real\nPredito          Menos de 1 ano De 1 a 5 anos Mais de 5 anos\n  Menos de 1 ano             10             1              0\n  De 1 a 5 anos               1            10              4\n  Mais de 5 anos              1             2             11\n\n# Taxa de acerto amostra de validação\nacerto_geral_validacao &lt;- sum(diag(matriz_confusao_validacao)) / sum(matriz_confusao_validacao)\n\n# Taxa de acerto por grupo\nacerto_por_grupo_validacao &lt;- diag(matriz_confusao_validacao) / rowSums(matriz_confusao_validacao)\nprint(\"Taxa de Acerto por Grupo (Validação):\")\n\n[1] \"Taxa de Acerto por Grupo (Validação):\"\n\nprint(round(acerto_por_grupo_validacao * 100, 1))\n\nMenos de 1 ano  De 1 a 5 anos Mais de 5 anos \n          90.9           66.7           78.6 \n\n\nTaxa de Acerto Geral (Validação): 77.5%\n\n\n6.9 Critérios de Chance\n\n# Calculando critérios de chance\ntamanhos_grupos &lt;- table(amostra_analise$X1)\nproporcoes_grupos &lt;- tamanhos_grupos / sum(tamanhos_grupos)\n\n# Critério de chance proporcional\ncriterio_chance_proporcional &lt;- sum(proporcoes_grupos^2) * 100\n\n# Critério de chance máxima\ncriterio_chance_maxima &lt;- max(proporcoes_grupos) * 100\n\n# Gráfico de comparação das taxas de acerto\ntaxas_acerto &lt;- data.frame(\n  Metodo = c(\"Análise\", \"Validação Cruzada\", \"Validação Externa\", \n             \"Critério Proporcional\", \"Critério Máximo\"),\n  Taxa = c(acerto_geral_analise * 100, \n           acerto_geral_cv * 100,\n           acerto_geral_validacao * 100,\n           criterio_chance_proporcional,\n           criterio_chance_maxima),\n  Tipo = c(\"Modelo\", \"Modelo\", \"Modelo\", \"Referência\", \"Referência\")\n)\n\np_performance &lt;- ggplot2::ggplot(taxas_acerto, ggplot2::aes(x = reorder(Metodo, Taxa), y = Taxa, fill = Tipo)) +\n  ggplot2::geom_col(alpha = 0.8, width = 0.7) +\n  ggplot2::geom_text(ggplot2::aes(label = paste0(round(Taxa, 1), \"%\")), \n                     hjust = -0.1, size = 4, fontface = \"bold\") +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"Modelo\" = \"steelblue\", \"Referência\" = \"coral\")) +\n  ggplot2::labs(title = \"Comparação das Taxas de Acerto\",\n                subtitle = \"Modelo vs. Critérios de Chance\",\n                x = \"Método de Validação\", \n                y = \"Taxa de Acerto (%)\",\n                fill = \"Tipo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"))\n\nprint(p_performance)\n\n\n\n\n\n\n\n\nCritérios de Chance:\n\nCritério de Chance Proporcional: 33.6%\nCritério de Chance Máxima: 36.7%\n\nComparação com Resultados Obtidos:\n\nTaxa de Acerto Análise: 78.3% vs Critério Proporcional: 33.6%\nTaxa de Acerto Validação Cruzada: 78.3% vs Critério Proporcional: 33.6%\n\nTaxa de Acerto Validação: 77.5% vs Critério Proporcional: 33.6%\n\n\n\n\nResumo da Interpretação Gerencial\nOs resultados da análise discriminante revelam insights importantes sobre a diferenciação de clientes baseada no tempo de relacionamento. Com o dataset completo analisado, identificamos que de 13 variáveis independentes testadas, apenas 2 foram suficientes para uma discriminação efetiva.\n\nPrincipais Descobertas:\n\nVariáveis Discriminantes: X6 (Product Quality) e X18 (Delivery Speed) são os principais diferenciadores, representando aproximadamente 100% da variância discriminante total.\nPrecisão do Modelo: O modelo alcança alta taxa de acertos na amostra de análise, superando significativamente os critérios de chance.\nDiferenças entre Grupos:\n\nClientes novos (&lt; 1 ano): Menores percepções de qualidade e velocidade\nClientes intermediários (1-5 anos): Percepções moderadas\nClientes estabelecidos (&gt; 5 anos): Maiores percepções de qualidade e velocidade\n\n\n\n\nImplicações Gerenciais:\n\nFoco na Qualidade: Investir na melhoria da qualidade do produto é fundamental para reter clientes\nOtimização de Entregas: A velocidade de entrega é um diferencial competitivo crítico\nSegmentação: Os 3 grupos identificados requerem estratégias diferenciadas\n\n\n# Médias dos grupos para interpretação\nmedias_grupos &lt;- aggregate(amostra_analise[, variaveis_independentes], \n                          by = list(amostra_analise$X1), FUN = mean)\nnames(medias_grupos)[1] &lt;- \"Grupo\"\n\n# Corrigindo erro na impressão das médias dos grupos\nmedias_grupos_numericas &lt;- medias_grupos[, -1]  # Remove coluna 'Grupo'\nrownames(medias_grupos_numericas) &lt;- medias_grupos$Grupo\n\nprint(\"Médias dos Grupos nas Variáveis Independentes:\")\n\n[1] \"Médias dos Grupos nas Variáveis Independentes:\"\n\nprint(round(medias_grupos_numericas, 2))\n\n                 X6   X7   X8   X9  X10  X11  X12  X13  X14  X15  X16  X17  X18\nMenos de 1 ano 6.99 3.56 5.28 4.30 3.83 4.72 4.75 7.42 5.98 5.38 3.53 4.29 3.14\nDe 1 a 5 anos  7.34 3.85 5.30 5.99 4.27 5.65 5.49 7.75 5.98 4.91 4.70 5.54 4.27\nMais de 5 anos 9.18 3.73 5.82 5.92 4.01 7.00 5.12 5.99 6.32 5.37 4.65 3.94 4.17\n\ncat(\"\\n=== INTERPRETAÇÃO DAS FUNÇÕES DISCRIMINANTES ===\\n\")\n\n\n=== INTERPRETAÇÃO DAS FUNÇÕES DISCRIMINANTES ===\n\ncat(\"Função 1: Diferencia principalmente entre Grupo 1 e Grupos 2-3\\n\")\n\nFunção 1: Diferencia principalmente entre Grupo 1 e Grupos 2-3\n\ncat(\"Função 2: Diferencia principalmente entre Grupo 3 e Grupos 1-2\\n\")\n\nFunção 2: Diferencia principalmente entre Grupo 3 e Grupos 1-2\n\ncat(\"\\n=== VARIÁVEIS MAIS IMPORTANTES ===\\n\")\n\n\n=== VARIÁVEIS MAIS IMPORTANTES ===\n\nif(exists(\"indice_potencia_ordenado\")) {\n  cat(\"Por Índice de Potência:\\n\")\n  print(names(indice_potencia_ordenado)[1:min(5, length(indice_potencia_ordenado))])\n}\n\nPor Índice de Potência:\n[1] \"X6\"  \"X11\" \"X17\" \"X18\" \"X9\" \n\ncat(\"\\nPor Razão F Univariada:\\n\")\n\n\nPor Razão F Univariada:\n\nprint(names(razoes_f_ordenadas)[1:min(5, length(razoes_f_ordenadas))])\n\n[1] \"X18\" \"X6\"  \"X9\"  \"X11\" \"X16\"\n\ncat(\"\\n=== RESUMO FINAL ===\\n\")\n\n\n=== RESUMO FINAL ===\n\ncat(\"Modelo discriminante final: X1 ~ X6 + X18\\n\")\n\nModelo discriminante final: X1 ~ X6 + X18\n\ncat(\"Variáveis selecionadas:\\n\")\n\nVariáveis selecionadas:\n\ncat(\"- X6: Qualidade do produto\\n\")\n\n- X6: Qualidade do produto\n\ncat(\"- X18: Velocidade de entrega\\n\")\n\n- X18: Velocidade de entrega\n\nif(exists(\"modelo_stepwise\")) {\n  cat(\"\\nVariáveis selecionadas pelo procedimento stepwise:\\n\")\n  print(modelo_stepwise$formula)\n}\n\n\nVariáveis selecionadas pelo procedimento stepwise:\n[1] \"X1 ~ X6 + X18\"\n\ncat(\"\\n=== CONCLUSÕES GERENCIAIS ===\\n\")\n\n\n=== CONCLUSÕES GERENCIAIS ===\n\ncat(\"1. A qualidade do produto (X6) e velocidade de entrega (X18) são os principais diferenciadores entre os grupos de clientes.\\n\")\n\n1. A qualidade do produto (X6) e velocidade de entrega (X18) são os principais diferenciadores entre os grupos de clientes.\n\ncat(\"2. O modelo consegue discriminar bem entre os três grupos de tempo de relacionamento.\\n\")\n\n2. O modelo consegue discriminar bem entre os três grupos de tempo de relacionamento.\n\ncat(\"3. Clientes de longo prazo valorizam mais qualidade e velocidade de entrega.\\n\")\n\n3. Clientes de longo prazo valorizam mais qualidade e velocidade de entrega.\n\ncat(\"4. Ações de melhoria devem focar nestas duas dimensões para reter clientes.\\n\")\n\n4. Ações de melhoria devem focar nestas duas dimensões para reter clientes.\n\n\nAnálise das Médias por Grupo:\nOs resultados mostram um padrão claro de evolução das percepções com o tempo de relacionamento, com melhorias progressivas nas percepções de qualidade e velocidade de entrega conforme aumenta o tempo de relacionamento com a empresa.\n\n\n\nApêndice: Informações Técnicas do Dataset\n\nCaracterísticas do Dataset HBAT\n\n# Informações sobre o dataset após limpeza\ncat(\"=== CARACTERÍSTICAS DO DATASET FINAL ===\\n\")\n\n=== CARACTERÍSTICAS DO DATASET FINAL ===\n\ncat(\"Total de observações:\", nrow(hbat_clean), \"\\n\")\n\nTotal de observações: 100 \n\ncat(\"Variáveis independentes analisadas:\", length(variaveis_independentes), \"\\n\")\n\nVariáveis independentes analisadas: 13 \n\ncat(\"Grupos da variável dependente:\", nlevels(hbat_clean$X1), \"\\n\")\n\nGrupos da variável dependente: 3 \n\n# Distribuição dos grupos\ndist_grupos &lt;- table(hbat_clean$X1)\nprop_grupos &lt;- prop.table(dist_grupos) * 100\n\ncat(\"\\nDistribuição dos grupos:\\n\")\n\n\nDistribuição dos grupos:\n\nfor(i in 1:length(dist_grupos)) {\n  cat(\"- \", names(dist_grupos)[i], \": \", dist_grupos[i], \" casos (\", \n      round(prop_grupos[i], 1), \"%)\\n\", sep = \"\")\n}\n\n- Menos de 1 ano: 32 casos (32%)\n- De 1 a 5 anos: 35 casos (35%)\n- Mais de 5 anos: 33 casos (33%)\n\n\n\n\nQualidade dos Dados\n\nMissing values: Removidos através de listwise deletion\nBalanceamento: Dataset relativamente balanceado entre os grupos\nEscala das variáveis: Todas as variáveis independentes estão na escala de 0-10\n\n\n# Informações detalhadas sobre o dataset HBAT\ncat(\"=== INFORMAÇÕES DO DATASET HBAT ===\\n\")\n\n=== INFORMAÇÕES DO DATASET HBAT ===\n\ncat(\"Total de observações:\", nrow(hbat_clean), \"\\n\")\n\nTotal de observações: 100 \n\ncat(\"Variáveis independentes:\", length(variaveis_independentes), \"\\n\")\n\nVariáveis independentes: 13 \n\ncat(\"Grupos da variável dependente:\", nlevels(hbat_clean$X1), \"\\n\")\n\nGrupos da variável dependente: 3 \n\n# Descrição das variáveis (baseado nos labels originais) - ATUALIZADO\ncat(\"\\n=== DESCRIÇÃO COMPLETA DAS VARIÁVEIS ===\\n\")\n\n\n=== DESCRIÇÃO COMPLETA DAS VARIÁVEIS ===\n\nfor(var in names(descricoes_variaveis)) {\n  cat(var, \"-\", descricoes_variaveis[var], \"\\n\")\n}\n\nX1 - Customer Type \nX6 - Product Quality \nX7 - E-Commerce Activities \nX8 - Technical Support \nX9 - Complaint Resolution \nX10 - Advertising \nX11 - Product Line \nX12 - Salesforce Image \nX13 - Competitive Pricing \nX14 - Warranty & Claims \nX15 - New Products \nX16 - Ordering & Billing \nX17 - Price Flexibility \nX18 - Delivery Speed \n\n# Estatísticas descritivas finais\ncat(\"\\n=== ESTATÍSTICAS DESCRITIVAS FINAIS ===\\n\")\n\n\n=== ESTATÍSTICAS DESCRITIVAS FINAIS ===\n\nprint(summary(hbat_clean))\n\n              X1           X6               X7              X8       \n Menos de 1 ano:32   Min.   : 5.000   Min.   :2.200   Min.   :1.300  \n De 1 a 5 anos :35   1st Qu.: 6.575   1st Qu.:3.275   1st Qu.:4.250  \n Mais de 5 anos:33   Median : 8.000   Median :3.600   Median :5.400  \n                     Mean   : 7.810   Mean   :3.672   Mean   :5.365  \n                     3rd Qu.: 9.100   3rd Qu.:3.925   3rd Qu.:6.625  \n                     Max.   :10.000   Max.   :5.700   Max.   :8.500  \n       X9             X10             X11             X12       \n Min.   :2.600   Min.   :1.900   Min.   :2.300   Min.   :2.900  \n 1st Qu.:4.600   1st Qu.:3.175   1st Qu.:4.700   1st Qu.:4.500  \n Median :5.450   Median :4.000   Median :5.750   Median :4.900  \n Mean   :5.442   Mean   :4.010   Mean   :5.805   Mean   :5.123  \n 3rd Qu.:6.325   3rd Qu.:4.800   3rd Qu.:6.800   3rd Qu.:5.800  \n Max.   :7.800   Max.   :6.500   Max.   :8.400   Max.   :8.200  \n      X13             X14             X15            X16             X17      \n Min.   :3.700   Min.   :4.100   Min.   :1.70   Min.   :2.000   Min.   :2.60  \n 1st Qu.:5.875   1st Qu.:5.400   1st Qu.:4.10   1st Qu.:3.700   1st Qu.:3.70  \n Median :7.100   Median :6.100   Median :5.00   Median :4.400   Median :4.35  \n Mean   :6.974   Mean   :6.043   Mean   :5.15   Mean   :4.278   Mean   :4.61  \n 3rd Qu.:8.400   3rd Qu.:6.600   3rd Qu.:6.30   3rd Qu.:4.800   3rd Qu.:5.60  \n Max.   :9.900   Max.   :8.100   Max.   :9.50   Max.   :6.700   Max.   :7.30  \n      X18       \n Min.   :1.600  \n 1st Qu.:3.400  \n Median :3.900  \n Mean   :3.886  \n 3rd Qu.:4.425  \n Max.   :5.500"
  }
]