{"title":"ANÁLISE DISCRIMINANTE","markdown":{"yaml":{"title":"ANÁLISE DISCRIMINANTE","lang":"pt-BR","author":[{"name":"Marcus Antonio Cardoso Ramalho","email":"marcus.ramalho@coppead.ufrj.br","affiliations":[{"name":"COPPEAD - UNIVERSIDADE FEDERAL DO RIO DE JANEIRO","address":"Rua Pascoal Lemme, 355","city":"Rio de Janeiro","state":"RJ","postal-code":"21941-918"}]},{"name":"Claudia Regina da Costa de Souza"},{"name":"Ben Hur Correia"}],"date":"today"},"headingText":"Carregando os pacotes necessários","containsRefs":false,"markdown":"\n\n```{r}\n#| include: false\n#| echo: true\n#| message: false\n#| warning: false\n\nif (!require(\"MASS\")) install.packages(\"MASS\")\nif (!require(\"klaR\")) install.packages(\"klaR\")\nif (!require(\"car\")) install.packages(\"car\")\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nif (!require(\"corrplot\")) install.packages(\"corrplot\")\nif (!require(\"caret\")) install.packages(\"caret\")\nif (!require(\"skimr\")) install.packages(\"skimr\")\nif (!require(\"MVN\")) install.packages(\"MVN\")\nif (!require(\"biotools\")) install.packages(\"biotools\")\nif (!require(\"GGally\")) install.packages(\"GGally\")\nif (!require(\"nnet\")) install.packages(\"nnet\")\nif (!require(\"pROC\")) install.packages(\"pROC\")\nif (!require(\"tidyr\")) install.packages(\"tidyr\")\nif (!require(\"readr\")) install.packages(\"readr\")\nif (!require(\"haven\")) install.packages(\"haven\")\nif (!require(\"gridExtra\")) install.packages(\"gridExtra\")\nif (!require(\"reshape2\")) install.packages(\"reshape2\")\nif (!require(\"viridis\")) install.packages(\"viridis\")\nif (!require(\"plotly\")) install.packages(\"plotly\")\nif (!require(\"RColorBrewer\")) install.packages(\"RColorBrewer\")\n\n```\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\n\nlibrary(MASS)\nlibrary(klaR)\nlibrary(car)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(corrplot)\nlibrary(caret)\nlibrary(skimr)\nlibrary(MVN)\nlibrary(biotools)\nlibrary(GGally)\nlibrary(nnet)\nlibrary(pROC)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(haven)\nlibrary(gridExtra)\nlibrary(reshape2)\nlibrary(viridis)\nlibrary(plotly)\nlibrary(RColorBrewer)\n```\n\n## Análise Discriminante - Exemplo HBAT\n\n\n### Reprodução do Exemplo de Hair et al. - Dataset HBAT\n\nNesta seção, reproduziremos a análise discriminante apresentada no livro Hair et al., utilizando o dataset HBAT para classificar clientes em três grupos baseados no tempo de relacionamento com a empresa.\n\n\nO **HBAT** é um dataset educacional fictício amplamente utilizado no livro clássico \"Multivariate Data Analysis\" de Joseph Hair et al., representando uma empresa de distribuição industrial. O dataset contém **100 observações** de clientes classificados em três grupos baseados no tempo de relacionamento: **Grupo 1** (menos de 1 ano), **Grupo 2** (1 a 5 anos) e **Grupo 3** (mais de 5 anos). As variáveis incluem a **variável dependente X1** (Customer Type) e **13 variáveis independentes** (X6-X18) que medem percepções dos clientes sobre diferentes aspectos da empresa, como qualidade do produto (X6), atividades de e-commerce (X7), suporte técnico (X8), resolução de reclamações (X9), propaganda (X10), linha de produtos (X11), imagem da força de vendas (X12), preços competitivos (X13), garantia e reclamações (X14), novos produtos (X15), pedidos e faturamento (X16), flexibilidade de preços (X17) e velocidade de entrega (X18). Todas as variáveis independentes utilizam uma **escala de 0-10**, facilitando comparações e interpretações. Este dataset é ideal para demonstrar técnicas de análise multivariada, especialmente análise discriminante, pois oferece um contexto empresarial realista com dados limpos e estruturados, permitindo focar na aplicação das técnicas estatísticas sem se preocupar com problemas complexos de qualidade de dados típicos de datasets reais.\n\n### Estágio 1: Objetivos da Análise Discriminante\n\nO objetivo é identificar as características perceptuais que distinguem clientes baseados no tempo de relacionamento:\n- **Grupo 1**: Menos de 1 ano\n- **Grupo 2**: De 1 a 5 anos  \n- **Grupo 3**: Mais de 5 anos\n\n#### Carregamento e Inspeção dos Dados do arquivo spss\n\n```{r}\n# Carregando os dados HBAT\nhbat <- haven::read_sav(\"data/hbat.sav\")\n\nglimpse(hbat)\n\n```\n\n\n```{r}\n#| include: false\n#| echo: false\n\n\n# Gráfico da distribuição da variável dependente\np_dist_grupos <- ggplot2::ggplot(data.frame(x1 = hbat$x1), ggplot2::aes(x = factor(x1))) +\n  ggplot2::geom_bar(fill = \"steelblue\", alpha = 0.7) +\n  ggplot2::geom_text(stat = \"count\", ggplot2::aes(label = after_stat(count)), \n                     vjust = -0.5, size = 4) +\n  ggplot2::labs(title = \"Distribuição dos Grupos por Tempo de Relacionamento\",\n                x = \"Grupo (1=<1 ano, 2=1-5 anos, 3=>5 anos)\",\n                y = \"Frequência\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"))\n\nprint(p_dist_grupos)\n```\n\n\n\n```{r}\n#| include: false\n#| echo: false\n\n# Identificando as variáveis corretas baseado na estrutura real do dataset\n# Primeiro vamos ver quais variáveis existem realmente\nprint(\"Variáveis disponíveis no dataset:\")\nprint(colnames(hbat))\n\n# Verificando se existem variáveis que correspondem às do exemplo Hair\n# Procurando por padrões de nomes que possam corresponder a X1, X6-X18\npossiveis_vars <- grep(\"^[Xx][0-9]+\", names(hbat), value = TRUE)\nprint(\"Possíveis variáveis X encontradas:\")\nprint(possiveis_vars)\n\n# Se não encontrar, vamos procurar por outras variáveis categóricas e numéricas\ncat(\"\\nEstrutura das primeiras 10 variáveis:\\n\")\nstr(hbat[,1:min(10, ncol(hbat))])\n```\n\n\n\n```{r}\n#| include: false\n#| echo: false\n\n\n# Preparando os dados baseado na estrutura real encontrada\n# Vamos adaptar baseado nas variáveis que realmente existem\n\n# Primeiro, identificar a variável dependente (tempo de relacionamento)\n# Procurar por variáveis categóricas que possam representar grupos de tempo\n\n# Listar variáveis categóricas\nvars_categoricas <- sapply(hbat, function(x) is.factor(x) || length(unique(x)) <= 10)\nprint(\"Variáveis categóricas ou com poucos valores únicos:\")\nprint(names(hbat)[vars_categoricas])\n\n# Examinar algumas variáveis categóricas potenciais\nfor(var in names(hbat)[vars_categoricas][1:min(5, sum(vars_categoricas))]) {\n  cat(\"\\nVariável:\", var, \"\\n\")\n  print(table(hbat[[var]], useNA = \"ifany\"))\n}\n```\n\n#### Definição das Variáveis do Modelo\n\nCom base na inspeção dos dados, identificamos que o dataset HBAT possui exatamente as variáveis necessárias:\n- **x1**: Variável dependente (Customer Type: 1=Menos de 1 ano, 2=De 1 a 5 anos, 3=Mais de 5 anos)\n- **x6-x18**: Variáveis independentes (percepções sobre a HBAT)\n\n```{r}\n#| include: false\n#| echo: false\n# Agora que sabemos a estrutura, vamos usar as variáveis corretas\nvariavel_dependente <- \"x1\"  # Customer Type - exatamente o que precisamos\nvariaveis_independentes <- paste0(\"x\", 6:18)  # x6 a x18 - percepções\n\n# Verificando se x1 tem os valores corretos\nprint(table(hbat$x1, useNA = \"ifany\"))\n\n# Verificando os labels da variável x1\nif(haven::is.labelled(hbat$x1)) {\n  print(haven::as_factor(hbat$x1))\n  print(table(haven::as_factor(hbat$x1)))\n}\n```\n\n**Configuração das Variáveis:**\n\n- **Variável dependente**: `r variavel_dependente`\n- **Variáveis independentes**: `r paste(variaveis_independentes, collapse = \", \")`\n- **Total de variáveis independentes**: `r length(variaveis_independentes)`\n\n#### Preparação do Dataset Final\n\n```{r}\n#| include: false\n# Criando dataset limpo com as variáveis corretas identificadas\nhbat_clean <- hbat %>%\n  dplyr::select(dplyr::all_of(c(variavel_dependente, variaveis_independentes))) %>%\n  na.omit()\n\n# Converter x1 para fator com os labels corretos do exemplo Hair\nhbat_clean <- hbat_clean %>%\n  dplyr::mutate(\n    X1 = factor(x1, \n                levels = 1:3,\n                labels = c(\"Menos de 1 ano\", \"De 1 a 5 anos\", \"Mais de 5 anos\"))\n  ) %>%\n  dplyr::select(-x1)\n\n# Renomear variáveis independentes para seguir padrão X6-X18 (maiúsculas)\nnomes_independentes <- paste0(\"X\", 6:18)\nnames(hbat_clean)[names(hbat_clean) != \"X1\"] <- nomes_independentes\n\n# Reordenar colunas para X1 ficar primeiro\nhbat_clean <- hbat_clean %>%\n  dplyr::select(X1, dplyr::everything())\n\n# Atualizar lista de variáveis independentes\nvariaveis_independentes <- nomes_independentes\n\n# Criando dicionário de descrições das variáveis\ndescricoes_variaveis <- c(\n  \"X1\" = \"Customer Type\",\n  \"X6\" = \"Product Quality\",\n  \"X7\" = \"E-Commerce Activities\",\n  \"X8\" = \"Technical Support\",\n  \"X9\" = \"Complaint Resolution\",\n  \"X10\" = \"Advertising\",\n  \"X11\" = \"Product Line\",\n  \"X12\" = \"Salesforce Image\",\n  \"X13\" = \"Competitive Pricing\",\n  \"X14\" = \"Warranty & Claims\",\n  \"X15\" = \"New Products\",\n  \"X16\" = \"Ordering & Billing\",\n  \"X17\" = \"Price Flexibility\",\n  \"X18\" = \"Delivery Speed\"\n)\n\n# Função para obter descrição completa da variável\nobter_descricao <- function(var) {\n  if(var %in% names(descricoes_variaveis)) {\n    return(descricoes_variaveis[var])\n  } else {\n    return(var)\n  }\n}\n```\n\n**Resumo da Preparação dos Dados:**\n\n- **Total de observações**: `r nrow(hbat_clean)`\n- **Variáveis independentes**: `r length(variaveis_independentes)`\n- **Grupos identificados**: `r nlevels(hbat_clean$X1)`\n\n**Distribuição da Variável Dependente (X1):**\n```{r}\n#| echo: false\nknitr::kable(table(hbat_clean$X1), col.names = c(\"Grupo\", \"Frequência\"))\n```\n\n**Descrições das Variáveis:**\n\n| Código | Descrição |\n|--------|-----------|\n| X1 | Customer Type |\n| X6 | Product Quality |\n| X7 | E-Commerce Activities |\n| X8 | Technical Support |\n| X9 | Complaint Resolution |\n| X10 | Advertising |\n| X11 | Product Line |\n| X12 | Salesforce Image |\n| X13 | Competitive Pricing |\n| X14 | Warranty & Claims |\n| X15 | New Products |\n| X16 | Ordering & Billing |\n| X17 | Price Flexibility |\n| X18 | Delivery Speed |\n\n### Estágio 2: Delineamento da Pesquisa de Análise Discriminante\n\n```{r}\n# Divisão em amostras de análise e validação\nset.seed(123)\nn_total <- nrow(hbat_clean)\nindices_analise <- sample(1:n_total, size = floor(0.6 * n_total))\n\namostra_analise <- hbat_clean[indices_analise, ]\namostra_validacao <- hbat_clean[-indices_analise, ]\n\n# Verificar balanceamento dos grupos\nprop_analise <- table(amostra_analise$X1) / nrow(amostra_analise)\nprop_validacao <- table(amostra_validacao$X1) / nrow(amostra_validacao)\n```\n\nA análise discriminante requer a divisão dos dados em amostras de estimação e validação para avaliar adequadamente o desempenho do modelo. Utilizamos uma divisão de 60% para análise e 40% para validação.\n\n**Características das Amostras:**\n\n- **Amostra de análise**: `r nrow(amostra_analise)` casos\n- **Amostra de validação**: `r nrow(amostra_validacao)` casos\n\n**Distribuição dos Grupos por Amostra:**\n\n| Grupo | Análise (n) | Análise (%) | Validação (n) | Validação (%) |\n|-------|-------------|-------------|---------------|---------------|\n| Menos de 1 ano | `r table(amostra_analise$X1)[1]` | `r round(prop_analise[1] * 100, 1)`% | `r table(amostra_validacao$X1)[1]` | `r round(prop_validacao[1] * 100, 1)`% |\n| De 1 a 5 anos | `r table(amostra_analise$X1)[2]` | `r round(prop_analise[2] * 100, 1)`% | `r table(amostra_validacao$X1)[2]` | `r round(prop_validacao[2] * 100, 1)`% |\n| Mais de 5 anos | `r table(amostra_analise$X1)[3]` | `r round(prop_analise[3] * 100, 1)`% | `r table(amostra_validacao$X1)[3]` | `r round(prop_validacao[3] * 100, 1)`% |\n\n### Estágio 3: Pressupostos da Análise Discriminante\n\n#### 3.1 Normalidade Multivariada\n\nO teste de normalidade multivariada é fundamental para verificar se os dados seguem uma distribuição normal multivariada, pressuposto da análise discriminante linear. Testamos cada um dos três grupos separadamente usando o teste de Henze-Zirkler.\n\n\n```{r}\nlibrary(MVN)\n\n# Armazenar resultados dos testes de normalidade\nresultados_normalidade <- list()\n\nfor(grupo in levels(amostra_analise$X1)) {\n  dados_grupo <- amostra_analise[amostra_analise$X1 == grupo, variaveis_independentes]\n  \n  # Usando parâmetros corretos da função mvn\n  resultado_mvn <- mvn(dados_grupo, mvn_test = \"hz\", univariate_test = \"SW\")\n  resultados_normalidade[[grupo]] <- resultado_mvn$multivariate_normality\n  \n  # Teste alternativo se o primeiro falhar\n  if(is.null(resultado_mvn$multivariate_normality)) {\n    resultado_mardia <- mvn(dados_grupo, mvn_test = \"mardia\")\n    resultados_normalidade[[grupo]] <- resultado_mardia$multivariate_normality\n  }\n}\n\n# Mostrar resultados\nprint(resultados_normalidade)\n```\n\n**Resumo dos Testes de Normalidade:**\n\nCom base nos resultados obtidos, 2 dos 3 grupos atendem ao pressuposto de normalidade multivariada ao nível de significância de 5%. O grupo que apresentou desvio (p = 0.035) está próximo do limite aceitável, e a análise discriminante pode prosseguir com confiança.\n\n#### 3.2 Homogeneidade das Matrizes de Covariância\n\nO teste M de Box verifica se as matrizes de covariância dos grupos são homogêneas, outro pressuposto importante da análise discriminante. Este teste avalia se as 13 variáveis independentes apresentam estruturas de covariância similares entre os grupos.\n\n**Interpretação dos Resultados do Teste M de Box:**\n\n**Conclusão**: Com p-valor = 0.01122 < 0.05, rejeitamos a hipótese nula de homogeneidade das matrizes de covariância. Isso indica que **há diferenças significativas** entre as estruturas de covariância dos grupos.\n\n**Implicações Práticas:**\n- A violação da homogeneidade das covariâncias sugere que a **Análise Discriminante Quadrática (QDA)** poderia ser mais apropriada que a Linear (LDA)\n- No entanto, a LDA é robusta a violações moderadas deste pressuposto, especialmente quando os tamanhos das amostras são similares\n- Como os grupos estão relativamente balanceados (conforme mostrado acima), podemos prosseguir com cautela usando LDA\n- Os resultados devem ser interpretados considerando esta limitação\n\n```{r}\nlibrary(biotools)\n\ndados_teste <- amostra_analise[, variaveis_independentes]\ngrupos_teste <- amostra_analise$X1\n\n# Teste M de Box com tratamento de erro\ntryCatch({\n  teste_box <- boxM(dados_teste, grupos_teste)\n  print(teste_box)\n}, error = function(e) {\n  message(\"Teste M de Box não pôde ser executado: \", e$message)\n  \n  for(grupo in levels(amostra_analise$X1)) {\n    dados_grupo <- amostra_analise[amostra_analise$X1 == grupo, variaveis_independentes]\n    cov_grupo <- cov(dados_grupo)\n    message(\"\\nMatriz de Covariância - Grupo: \", grupo)\n    print(round(cov_grupo, 3))\n  }\n})\n```\n\n#### 3.3 Multicolinearidade\n\nA presença de multicolinearidade pode afetar a estabilidade dos resultados da análise discriminante. O determinante da matriz de correlação e os valores VIF nos ajudam a identificar possíveis problemas de multicolinearidade entre as variáveis.\n\n**Interpretação dos Valores VIF:**\n\nOs Fatores de Inflação da Variância (VIF) revelam problemas significativos de multicolinearidade:\n\n- **VIF < 5**: Multicolinearidade baixa (aceitável)\n  - X6 (1.90), X7 (4.56), X8 (4.71), X10 (1.65), X13 (1.76), X14 (4.16), X15 (1.23), X16 (4.33)\n\n- **VIF entre 5-10**: Multicolinearidade moderada (preocupante)\n  - X9 (5.33), X12 (5.78)\n\n- **VIF > 10**: Multicolinearidade alta (problemática)\n  - **X11 (Product Line)**: VIF = 52.77\n  - **X17 (Price Flexibility)**: VIF = 41.49  \n  - **X18 (Delivery Speed)**: VIF = 56.34\n\n**Implicações:**\n- As variáveis X11, X17 e X18 apresentam alta correlação com outras variáveis independentes\n- Isso pode causar instabilidade nos coeficientes discriminantes\n- O determinante da matriz de correlação confirma a presença de multicolinearidade\n- Apesar disso, seguimos o exemplo de Hair et al. usando X6 e X18, reconhecendo esta limitação\n\n```{r}\n# Matriz de correlação com visualização aprimorada\nmatriz_cor <- cor(amostra_analise[, variaveis_independentes])\n\n# Gráfico de correlação personalizado\ncorrplot::corrplot(matriz_cor, method = \"color\", type = \"upper\", \n                   order = \"hclust\", tl.cex = 0.8, tl.col = \"black\",\n                   col = RColorBrewer::brewer.pal(n = 8, name = \"RdYlBu\"),\n                   title = \"Matriz de Correlação das Variáveis Independentes\",\n                   mar = c(0,0,2,0))\n\n# Determinante da matriz de correlação\ndet_cor <- det(matriz_cor)\n\n# VIF para identificar multicolinearidade\nmodelo_temp <- lm(as.numeric(X1) ~ ., data = amostra_analise[, c(\"X1\", variaveis_independentes)])\nvif_valores <- car::vif(modelo_temp)\n```\n\n**Análise de Multicolinearidade:**\n\n- **Determinante da matriz de correlação**: `r round(det_cor, 6)`\n\n**Classificação dos Valores VIF:**\n\n| Categoria | Critério | Variáveis |\n|-----------|----------|-----------|\n| **Baixa** (< 5) | Aceitável | `r paste(names(vif_valores[vif_valores < 5]), collapse = \", \")` |\n| **Moderada** (5-10) | Preocupante | `r paste(names(vif_valores[vif_valores >= 5 & vif_valores < 10]), collapse = \", \")` |\n| **Alta** (≥ 10) | Problemática | `r paste(names(vif_valores[vif_valores >= 10]), collapse = \", \")` |\n\n**Variáveis com Multicolinearidade Severa:**\n```{r}\n#| echo: false\nvif_altos <- vif_valores[vif_valores >= 10]\nknitr::kable(data.frame(\n  Variável = names(vif_altos),\n  Descrição = sapply(names(vif_altos), obter_descricao),\n  VIF = round(vif_altos, 2)\n), row.names = FALSE)\n```\n\n### Estágio 4: Estimação do Modelo Discriminante e Avaliação do Ajuste Geral\n\n#### 4.1 Método Stepwise\n\n```{r}\nlibrary(klaR)\nlibrary(MASS)\n\n# Implementando stepwise manual baseado em critérios estatísticos\nf_univariados <- numeric(length(variaveis_independentes))\np_univariados <- numeric(length(variaveis_independentes))\nnames(f_univariados) <- variaveis_independentes\nnames(p_univariados) <- variaveis_independentes\n\nfor(i in seq_along(variaveis_independentes)) {\n  var <- variaveis_independentes[i]\n  formula_temp <- as.formula(paste(var, \"~ X1\"))\n  \n  tryCatch({\n    anova_temp <- aov(formula_temp, data = amostra_analise)\n    anova_summary <- summary(anova_temp)\n    f_univariados[i] <- anova_summary[[1]][\"X1\", \"F value\"]\n    p_univariados[i] <- anova_summary[[1]][\"X1\", \"Pr(>F)\"]\n  }, error = function(e) {\n    f_univariados[i] <- 0\n    p_univariados[i] <- 1\n  })\n}\n\n# Ordenando variáveis por poder discriminante\nordem_importancia <- order(f_univariados, decreasing = TRUE)\nvars_ordenadas <- variaveis_independentes[ordem_importancia]\nvars_significativas <- names(p_univariados[p_univariados < 0.05])\n\n# Testando modelo Hair et al.: X6 + X18\nformula_hair <- as.formula(\"cbind(X6, X18) ~ X1\")\nmanova_hair <- manova(formula_hair, data = amostra_analise)\nresultado_hair <- summary(manova_hair, test = \"Wilks\")\n\nmodelo_stepwise <- list(\n  formula = \"X1 ~ X6 + X18\",\n  selected_vars = c(\"X6\", \"X18\"),\n  wilks_lambda = resultado_hair$stats[\"X1\", \"Wilks\"],\n  f_statistic = resultado_hair$stats[\"X1\", \"approx F\"],\n  p_value = resultado_hair$stats[\"X1\", \"Pr(>F)\"]\n)\n```\n\n**Análise Univariada de Variáveis:**\n\n**Ranking por Poder Discriminante (Top 5):**\n```{r}\n#| echo: false\ntop5 <- data.frame(\n  Posição = 1:5,\n  Variável = vars_ordenadas[1:5],\n  Descrição = sapply(vars_ordenadas[1:5], obter_descricao),\n  `F-value` = round(f_univariados[vars_ordenadas[1:5]], 3),\n  `p-valor` = round(p_univariados[vars_ordenadas[1:5]], 4),\n  Significância = ifelse(p_univariados[vars_ordenadas[1:5]] < 0.001, \"***\",\n                        ifelse(p_univariados[vars_ordenadas[1:5]] < 0.01, \"**\",\n                              ifelse(p_univariados[vars_ordenadas[1:5]] < 0.05, \"*\", \"\")))\n)\nknitr::kable(top5, row.names = FALSE)\n```\n\n**Modelo Stepwise Final:**\n\n- **Fórmula selecionada**: `r modelo_stepwise$formula`\n- **Variáveis incluídas**: `r paste(modelo_stepwise$selected_vars, collapse = \" + \")`\n- **Lambda de Wilks**: `r round(modelo_stepwise$wilks_lambda, 4)`\n- **Estatística F**: `r round(modelo_stepwise$f_statistic, 3)`\n- **p-valor**: `r formatC(modelo_stepwise$p_value, format = \"e\", digits = 3)`\n- **Total de variáveis significativas**: `r length(vars_significativas)` de `r length(variaveis_independentes)`\n\n**Justificativa da Seleção:**\nEmbora `r vars_ordenadas[1]` seja a variável mais discriminante univariadamente, seguimos o exemplo de Hair et al. usando X6 (Product Quality) + X18 (Delivery Speed) por razões teóricas e interpretabilidade gerencial.\n\n#### 4.2 Análise Discriminante Linear\n\n```{r}\n# Modelo final conforme Hair et al. (X6 e X18)\nmodelo_final <- lda(X1 ~ X6 + X18, data = amostra_analise)\n\n# Autovalores e variância explicada\neigenvalues <- modelo_final$svd^2\nvariancia_explicada <- eigenvalues / sum(eigenvalues) * 100\n```\n\nO modelo discriminante final utiliza as variáveis X6 (Product Quality) e X18 (Delivery Speed), seguindo o exemplo de Hair et al.\n\n**Características do Modelo:**\n\n- **Número de funções discriminantes**: `r length(eigenvalues)`\n- **Variância explicada pela Função 1**: `r round(variancia_explicada[1], 1)`%\n- **Variância explicada pela Função 2**: `r round(variancia_explicada[2], 1)`%\n- **Variância total explicada**: `r round(sum(variancia_explicada), 1)`%\n\n**Autovalores:**\n```{r}\n#| echo: false\nknitr::kable(data.frame(\n  Função = paste(\"LD\", 1:length(eigenvalues)),\n  Autovalor = round(eigenvalues, 4),\n  `Variância Explicada (%)` = round(variancia_explicada, 1)\n), row.names = FALSE)\n```\n\n#### 4.3 Significância Estatística\n\nO teste de significância avalia se o modelo discriminante é estatisticamente significativo.\n\n```{r}\nmodelo_manova <- manova(cbind(X6, X18) ~ X1, data = amostra_analise)\nsummary(modelo_manova, test = \"Wilks\")\n\nsummary.aov(modelo_manova)\n```\n\n**Interpretação dos Resultados de Significância:**\n\n**Teste MANOVA (Multivariado):**\n- **Lambda de Wilks = 0.29005**: Valor baixo indica boa discriminação entre grupos\n- **F aproximado = 23.99**: Estatística F alta sugere diferenças significativas\n- **p-valor = 2.388e-14**: Altamente significativo (p < 0.001)\n- **Conclusão**: O modelo discriminante é estatisticamente significativo\n\n**Análises Univariadas por Variável:**\n\n**X6 (Product Quality):**\n- **F = 22.885**: Alta capacidade discriminante individual\n- **p-valor = 5.062e-08**: Altamente significativo\n- **Interpretação**: A qualidade do produto varia significativamente entre os grupos de tempo de relacionamento\n\n**X18 (Delivery Speed):**\n- **F = 24.425**: Maior capacidade discriminante individual entre as duas variáveis\n- **p-valor = 2.182e-08**: Altamente significativo  \n- **Interpretação**: A percepção da velocidade de entrega é o melhor discriminador individual entre os grupos\n\n**Implicações Gerenciais:**\n1. Ambas as variáveis contribuem significativamente para distinguir os grupos\n2. Velocidade de entrega (X18) é ligeiramente mais discriminante que qualidade (X6)\n3. O modelo como um todo tem poder discriminante muito forte\n4. As percepções evoluem significativamente com o tempo de relacionamento\n\n#### 4.4 Centróides dos Grupos\n\nOs centróides representam o \"centro\" de cada grupo no espaço discriminante.\n\n```{r}\ncentroides <- aggregate(amostra_analise[, c(\"X6\", \"X18\")], \n                       by = list(amostra_analise$X1), FUN = mean)\nnames(centroides)[1] <- \"Grupo\"\n\npredict_centroides <- predict(modelo_final, centroides[, c(\"X6\", \"X18\")])\ncentroides_discriminantes <- predict_centroides$x\nrownames(centroides_discriminantes) <- centroides$Grupo\nprint(\"\\nCentróides no Espaço Discriminante:\")\nprint(centroides_discriminantes)\n```\n\n**Análise dos Centróides no Espaço Discriminante:**\n\n**Posicionamento dos Grupos:**\n\n| Grupo | LD1 | LD2 | Interpretação |\n|-------|-----|-----|---------------|\n| Menos de 1 ano | -1.61 | 0.31 | Percepções mais baixas, posicionamento único |\n| De 1 a 5 anos | 0.26 | -0.71 | Percepções intermediárias, diferenciação moderada |\n| Mais de 5 anos | 1.47 | 0.53 | Percepções mais elevadas, alta satisfação |\n\n**Padrões Identificados:**\n\n1. **Evolução Linear em LD1**: Os valores de LD1 crescem progressivamente (-1.61 → 0.26 → 1.47), indicando melhoria das percepções com o tempo de relacionamento\n\n2. **Separação Clara**: A distância entre centróides confirma que os grupos são bem diferenciados no espaço discriminante\n\n3. **Trajetória de Relacionamento**: \n   - **Clientes novos** (< 1 ano): Expectativas em formação, percepções iniciais mais críticas\n   - **Clientes intermediários** (1-5 anos): Período de consolidação das percepções\n   - **Clientes estabelecidos** (> 5 anos): Relacionamento maduro, percepções mais positivas\n\n**Interpretação das Funções Discriminantes:**\n\n- **LD1**: Representa principalmente a **evolução temporal** das percepções (experiência acumulada)\n- **LD2**: Representa **diferenças qualitativas** específicas entre os grupos intermediários e extremos\n\n**Implicações Estratégicas:**\n- Foco na **retenção inicial**: Clientes novos precisam de atenção especial\n- **Gestão da jornada**: Processo gradual de melhoria das percepções\n- **Fidelização**: Clientes de longo prazo são verdadeiros advogados da marca\n\n### Estágio 5: Interpretação dos Resultados\n\n#### 5.1 Cargas Discriminantes (Matriz Estrutural)\n\nAs cargas discriminantes mostram a correlação entre cada variável independente e as funções discriminantes.\n\n```{r}\n# Calculando cargas discriminantes (correlações entre variáveis e funções)\n# Escores discriminantes para todas as observações\nescores_discriminantes <- predict(modelo_final, amostra_analise)$x\n\n# Matriz de cargas (correlações)\nvariaveis_completas <- amostra_analise[, variaveis_independentes]\ncargas_discriminantes <- cor(variaveis_completas, escores_discriminantes)\n\nprint(\"Matriz de Cargas Discriminantes (não-rotacionadas):\")\nprint(round(cargas_discriminantes, 3))\n\n# Identificando variáveis descritivas (|carga| >= 0.40)\ncargas_importantes <- abs(cargas_discriminantes) >= 0.40\nprint(\"\\nVariáveis Descritivas por Função (|carga| >= 0.40):\")\nfor(i in 1:ncol(cargas_discriminantes)) {\n  cat(\"Função\", i, \":\", names(which(cargas_importantes[, i])), \"\\n\")\n}\n```\n\n**Interpretação da Matriz de Cargas Discriminantes:**\n\n**Análise da Função Discriminante 1 (LD1):**\n\n**Variáveis com Cargas Altas (|carga| ≥ 0.40):**\n- **X11 (Product Line)**: 0.773 - Maior contribuição para LD1\n- **X18 (Delivery Speed)**: 0.765 - Forte correlação positiva\n- **X6 (Product Quality)**: 0.736 - Alta correlação positiva  \n- **X9 (Complaint Resolution)**: 0.728 - Contribuição significativa\n- **X16 (Ordering & Billing)**: 0.699 - Forte correlação\n\n**Interpretação de LD1**: Representa a **dimensão geral de satisfação** com aspectos operacionais e de qualidade da HBAT. Valores altos indicam percepções positivas em qualidade, entrega, linha de produtos e resolução de problemas.\n\n**Análise da Função Discriminante 2 (LD2):**\n\n**Variáveis com Cargas Altas (|carga| ≥ 0.40):**\n- **X17 (Price Flexibility)**: -0.699 - Maior magnitude (negativa)\n- **X6 (Product Quality)**: 0.677 - Correlação positiva forte\n- **X18 (Delivery Speed)**: -0.644 - Correlação negativa significativa\n- **X9 (Complaint Resolution)**: -0.467 - Contribuição moderada negativa\n- **X16 (Ordering & Billing)**: -0.416 - Correlação negativa\n- **X12 (Salesforce Image)**: -0.418 - Contribuição moderada negativa\n\n**Interpretação de LD2**: Representa um **contraste entre qualidade percebida** versus **flexibilidade operacional**. Separa grupos com diferentes prioridades: qualidade versus agilidade/flexibilidade.\n\n#### 5.2 Rotação VARIMAX\n\n```{r}\n# Aplicando rotação VARIMAX às cargas discriminantes\nlibrary(stats)\n\nif(ncol(cargas_discriminantes) > 1) {\n  rotacao_varimax <- varimax(cargas_discriminantes)\n  cargas_rotacionadas <- rotacao_varimax$loadings[]\n  \n  print(\"Matriz de Cargas Discriminantes (rotacionadas - VARIMAX):\")\n  print(round(cargas_rotacionadas, 3))\n  \n  # Variáveis descritivas após rotação\n  cargas_rot_importantes <- abs(cargas_rotacionadas) >= 0.40\n  print(\"\\nVariáveis Descritivas por Função Rotacionada (|carga| >= 0.40):\")\n  for(i in 1:ncol(cargas_rotacionadas)) {\n    cat(\"Função\", i, \":\", names(which(cargas_rot_importantes[, i])), \"\\n\")\n  }\n} else {\n  cargas_rotacionadas <- cargas_discriminantes\n  print(\"Apenas uma função discriminante - rotação não aplicável\")\n}\n```\n\n**Interpretação das Cargas Rotacionadas (VARIMAX):**\n\nA rotação VARIMAX simplifica a estrutura, criando fatores mais interpretáveis:\n\n**Função 1 Rotacionada:**\n- **X6 (Product Quality)**: 1.000 - Carga perfeitamente concentrada\n- **X11 (Product Line)**: 0.538 - Contribuição moderada\n- **X17 (Price Flexibility)**: -0.462 - Contribuição negativa moderada\n\n**Interpretação**: LD1 rotacionada representa essencialmente a **\"Dimensão de Qualidade\"**, contrastando qualidade percebida com flexibilidade de preços.\n\n**Função 2 Rotacionada:**\n- **X18 (Delivery Speed)**: -0.992 - Concentração quase perfeita (negativa)\n- **X9 (Complaint Resolution)**: -0.836 - Alta correlação negativa  \n- **X16 (Ordering & Billing)**: -0.779 - Correlação negativa forte\n- **X11 (Product Line)**: -0.558 - Contribuição moderada\n- **X17 (Price Flexibility)**: -0.524 - Contribuição moderada\n\n**Interpretação**: LD2 rotacionada representa a **\"Dimensão Operacional\"**, focando em velocidade, eficiência e aspectos transacionais.\n\n**Vantagem da Rotação:**\n- **Simplifica interpretação**: Cada função tem foco mais claro\n- **Reduz ambiguidade**: Menos variáveis com cargas altas em múltiplas funções\n- **Facilita comunicação gerencial**: Dimensões mais intuitivas\n\n#### 5.3 Índice de Potência\n\n```{r}\n# Calculando índice de potência conforme Hair et al.\nif(ncol(cargas_discriminantes) > 1) {\n  # Autovalores relativos\n  autovalores_relativos <- eigenvalues / sum(eigenvalues)\n  \n  # Índice de potência para cada variável\n  indice_potencia <- numeric(nrow(cargas_rotacionadas))\n  names(indice_potencia) <- rownames(cargas_rotacionadas)\n  \n  for(i in 1:nrow(cargas_rotacionadas)) {\n    potencia_total <- 0\n    for(j in 1:ncol(cargas_rotacionadas)) {\n      potencia_total <- potencia_total + (cargas_rotacionadas[i, j]^2 * autovalores_relativos[j])\n    }\n    indice_potencia[i] <- potencia_total\n  }\n  \n  # Ordenando por índice de potência\n  indice_potencia_ordenado <- sort(indice_potencia, decreasing = TRUE)\n  \n  print(\"Índice de Potência das Variáveis:\")\n  print(round(indice_potencia_ordenado, 3))\n}\n```\n\n**Interpretação do Índice de Potência:**\n\nO índice de potência combina a contribuição de cada variável em todas as funções, ponderada pela importância relativa de cada função:\n\n**Ranking por Poder Discriminante Total:**\n\n| Posição | Variável | Descrição | Índice | Interpretação |\n|---------|----------|-----------|--------|---------------|\n| 1º | X6 | Product Quality | 0.835 | **Discriminador principal** - fundamental para diferenciação |\n| 2º | X11 | Product Line | 0.293 | **Segundo mais importante** - variedade de produtos relevante |\n| 3º | X17 | Price Flexibility | 0.224 | **Terceiro lugar** - flexibilidade de preços diferencia grupos |\n| 4º | X18 | Delivery Speed | 0.176 | **Quarto lugar** - velocidade importante apesar de estar no modelo |\n| 5º | X9 | Complaint Resolution | 0.157 | **Moderadamente importante** - resolução de problemas diferencia |\n\n**Insights Principais:**\n\n1. **X6 (Product Quality)** é o discriminador dominante, responsável por mais de 83% do poder discriminante total\n2. **X18 (Delivery Speed)**, apesar de estar no modelo final, ocupa apenas a 4ª posição no índice de potência\n3. **X11 (Product Line)** aparece como segundo mais importante, sugerindo que variedade de produtos é crucial\n4. A **concentração de poder** nas primeiras variáveis indica que poucas dimensões explicam a maior parte da discriminação\n\n**Implicações Gerenciais:**\n- **Prioridade máxima**: Investir em qualidade do produto\n- **Segunda prioridade**: Expandir e melhorar linha de produtos\n- **Terceira prioridade**: Desenvolver flexibilidade de preços\n- **Monitoramento**: Acompanhar velocidade de entrega e resolução de reclamações\n\n#### 5.4 Razões F Univariadas\n\n```{r}\n# Calculando razões F univariadas para cada variável\nrazoes_f <- numeric(length(variaveis_independentes))\nnames(razoes_f) <- variaveis_independentes\n\nfor(var in variaveis_independentes) {\n  formula_temp <- as.formula(paste(var, \"~ X1\"))\n  anova_temp <- aov(formula_temp, data = amostra_analise)\n  razoes_f[var] <- summary(anova_temp)[[1]][\"X1\", \"F value\"]\n}\n\n# Ordenando por valor F\nrazoes_f_ordenadas <- sort(razoes_f, decreasing = TRUE)\n\nprint(\"Razões F Univariadas:\")\nprint(round(razoes_f_ordenadas, 3))\n\n# Teste de significância (α = 0.05)\np_valores <- numeric(length(variaveis_independentes))\nnames(p_valores) <- variaveis_independentes\n\nfor(var in variaveis_independentes) {\n  formula_temp <- as.formula(paste(var, \"~ X1\"))\n  anova_temp <- aov(formula_temp, data = amostra_analise)\n  p_valores[var] <- summary(anova_temp)[[1]][\"X1\", \"Pr(>F)\"]\n}\n\nprint(\"\\nVariáveis Significativas (p < 0.05):\")\nprint(names(p_valores[p_valores < 0.05]))\n```\n\n**Interpretação das Razões F Univariadas:**\n\n**Ranking de Poder Discriminante Individual:**\n\n| Posição | Variável | F-value | p-valor | Status | Interpretação |\n|---------|----------|---------|---------|--------|---------------|\n| 1º | X18 (Delivery Speed) | 24.425 | < 0.001 | *** | **Melhor discriminador individual** |\n| 2º | X6 (Product Quality) | 22.885 | < 0.001 | *** | **Segundo melhor discriminador** |\n| 3º | X9 (Complaint Resolution) | 22.739 | < 0.001 | *** | **Terceiro em poder discriminante** |\n| 4º | X11 (Product Line) | 20.721 | < 0.001 | *** | **Quarto colocado significativo** |\n| 5º | X16 (Ordering & Billing) | 17.664 | < 0.001 | *** | **Quinto em importância** |\n\n**Variáveis Significativas (p < 0.05):** X6, X9, X11, X13, X16, X17, X18 (7 de 13 variáveis)\n\n**Comparação: Poder Individual vs. Poder Combinado:**\n\n1. **X18 (Delivery Speed)**: \n   - Individual: 1º lugar (F = 24.425)\n   - Combinado: 4º lugar (Índice = 0.176)\n   - **Interpretação**: Excelente discriminador individual, mas com alguma redundância no modelo conjunto\n\n2. **X6 (Product Quality)**:\n   - Individual: 2º lugar (F = 22.885)  \n   - Combinado: 1º lugar (Índice = 0.835)\n   - **Interpretação**: Forte individual e dominante no modelo conjunto\n\n**Insights sobre Seleção de Variáveis:**\n\n- **Critério Hair et al.**: Usar X6 + X18 é justificado pelo alto poder discriminante individual de ambas\n- **Potencial de otimização**: X9 (Complaint Resolution) tem poder individual muito alto e poderia ser considerada\n- **Redundância**: Várias variáveis significativas sugerem multicolinearidade (confirmada pelos VIF altos)\n\n**Recomendações Gerenciais:**\n1. **Foco primário**: Delivery Speed e Product Quality (variáveis do modelo)\n2. **Foco secundário**: Complaint Resolution (alto poder discriminante individual)  \n3. **Monitoramento**: Product Line e Ordering & Billing (significativas e importantes)\n4. **Revisão**: Considerar modelo expandido incluindo X9 para melhor discriminação\n\n#### 5.5 Gráfico de Vetores de Atribuição no Espaço Discriminante\n\n```{r}\n# Gráfico dos valores F univariados com descrições\nf_df <- data.frame(\n  Variavel = names(f_univariados),\n  F_Value = f_univariados,\n  P_Value = p_univariados,\n  Significativo = p_univariados < 0.05\n) %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\np_f_values <- ggplot2::ggplot(f_df, ggplot2::aes(x = reorder(Variavel_Desc, F_Value), \n                                                 y = F_Value, fill = Significativo)) +\n  ggplot2::geom_col(alpha = 0.8) +\n  ggplot2::geom_text(ggplot2::aes(label = round(F_Value, 1)), hjust = -0.1, size = 3) +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"TRUE\" = \"steelblue\", \"FALSE\" = \"gray70\"),\n                            labels = c(\"FALSE\" = \"Não Significativo\", \"TRUE\" = \"Significativo\")) +\n  ggplot2::labs(title = \"Valores F Univariados para Seleção de Variáveis\",\n                subtitle = \"Poder discriminante individual de cada variável\",\n                x = \"Variáveis\", y = \"Estatística F\",\n                fill = \"Significância\\n(p < 0.05)\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.y = ggplot2::element_text(size = 9))\n\nprint(p_f_values)\n\n# Criando gráfico de vetores de atribuição (variáveis no espaço discriminante)\nescores_todos <- predict(modelo_final, amostra_analise)$x\ndf_escores <- data.frame(\n  Funcao1 = escores_todos[, 1],\n  Funcao2 = escores_todos[, 2],\n  Grupo = amostra_analise$X1,\n  Probabilidades = apply(predict(modelo_final, amostra_analise)$posterior, 1, max)\n)\n\n# Adicionando centróides\ndf_centroides <- data.frame(\n  Funcao1 = centroides_discriminantes[, 1],\n  Funcao2 = centroides_discriminantes[, 2],\n  Grupo = factor(rownames(centroides_discriminantes), \n                levels = levels(amostra_analise$X1))\n)\n\n# Escalonando as cargas para melhor visualização\nescala_vetor <- 3  # Fator de escala para os vetores\ncargas_escalonadas <- cargas_discriminantes * escala_vetor\n\n# Preparando dados dos vetores com descrições\nvetores_df <- data.frame(\n  Variavel = rownames(cargas_discriminantes),\n  LD1_start = 0,\n  LD2_start = 0,\n  LD1_end = cargas_escalonadas[, 1],\n  LD2_end = cargas_escalonadas[, 2],\n  Magnitude = sqrt(cargas_discriminantes[, 1]^2 + cargas_discriminantes[, 2]^2),\n  Significativa = rownames(cargas_discriminantes) %in% vars_significativas\n) %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\n# Gráfico de vetores de atribuição expandidos\np_vetores <- ggplot2::ggplot() +\n  # Pontos dos grupos (mais transparentes para não ofuscar os vetores)\n  ggplot2::geom_point(data = df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo), \n                      alpha = 0.3, size = 1) +\n  # Centróides dos grupos\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 6, shape = 17, color = \"black\") +\n  # LABELS DOS CENTRÓIDES - NOVO\n  ggplot2::geom_text(data = df_centroides, \n                     ggplot2::aes(x = Funcao1, y = Funcao2, label = Grupo),\n                     vjust = -1.5, hjust = 0.5, color = \"black\", \n                     fontface = \"bold\", size = 3.5,\n                     box.padding = 0.5) +\n  # Vetores das variáveis\n  ggplot2::geom_segment(data = vetores_df,\n                        ggplot2::aes(x = LD1_start, y = LD2_start, \n                                     xend = LD1_end, yend = LD2_end,\n                                     color = Significativa, size = Magnitude),\n                        arrow = ggplot2::arrow(length = ggplot2::unit(0.3, \"cm\")),\n                        alpha = 0.8) +\n  # Labels das variáveis com descrições\n  ggplot2::geom_text(data = vetores_df,\n                     ggplot2::aes(x = LD1_end * 1.1, y = LD2_end * 1.1, \n                                  label = Variavel_Desc, color = Significativa),\n                     size = 2.5, fontface = \"bold\") +\n  # Eixos de referência\n  ggplot2::geom_hline(yintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  ggplot2::geom_vline(xintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  # Escalas e temas\n  ggplot2::scale_color_manual(values = c(\"FALSE\" = \"gray50\", \"TRUE\" = \"red\")) +\n  ggplot2::scale_size_continuous(range = c(0.5, 2), guide = \"none\") +\n  ggplot2::labs(title = \"Vetores de Atribuição das Variáveis no Espaço Discriminante\",\n                subtitle = paste(\"Vetores mostram contribuição das variáveis para as funções discriminantes\\n\",\n                                \"Triângulos pretos = centróides dos grupos | Escala dos vetores: \", escala_vetor, \"x\"),\n                x = paste(\"Função Discriminante 1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"Função Discriminante 2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Variável\\nSignificativa\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 plot.subtitle = ggplot2::element_text(size = 10))\n\nprint(p_vetores)\n\n# IDENTIFICAÇÃO DOS GRUPOS DA VARIÁVEL DEPENDENTE\ncat(\"\\n=== IDENTIFICAÇÃO DOS GRUPOS DA VARIÁVEL DEPENDENTE ===\\n\")\ncat(\"Variável Dependente: X1 (Customer Type)\\n\")\ncat(\"Descrição: Tempo de relacionamento com a empresa HBAT\\n\\n\")\n\n# Grupos identificados no gráfico\ngrupos_identificados <- levels(amostra_analise$X1)\nfreq_grupos <- table(amostra_analise$X1)\ncentroides_info <- centroides_discriminantes\n\ncat(\"GRUPOS REPRESENTADOS NO GRÁFICO:\\n\")\nfor(i in 1:length(grupos_identificados)) {\n  grupo_nome <- grupos_identificados[i]\n  freq <- freq_grupos[i]\n  ld1_pos <- round(centroides_info[grupo_nome, \"LD1\"], 2)\n  ld2_pos <- round(centroides_info[grupo_nome, \"LD2\"], 2)\n  \n  cat(sprintf(\"🔺 GRUPO %d: %s\\n\", i, grupo_nome))\n  cat(sprintf(\"   - Frequência: %d casos (%.1f%%)\\n\", \n              freq, (freq/sum(freq_grupos))*100))\n  cat(sprintf(\"   - Posição no gráfico: LD1 = %.2f, LD2 = %.2f\\n\", ld1_pos, ld2_pos))\n  cat(sprintf(\"   - Característica: %s\\n\", \n              switch(i,\n                     \"Clientes com relacionamento recente - percepções iniciais\",\n                     \"Clientes com relacionamento estabelecido - percepções moderadas\", \n                     \"Clientes com relacionamento consolidado - percepções elevadas\")))\n  cat(\"\\n\")\n}\n\n# Interpretação dos centróides no espaço discriminante\ncat(\"INTERPRETAÇÃO DOS CENTRÓIDES (TRIÂNGULOS PRETOS):\\n\")\ncat(\"- Os triângulos pretos representam o 'centro' de cada grupo no espaço discriminante\\n\")\ncat(\"- Sua posição indica as características médias de cada grupo\\n\")\ncat(\"- A distância entre centróides mostra o grau de separação entre grupos\\n\")\n\n# Análise das posições dos centróides\ncat(\"\\nANÁLISE DAS POSIÇÕES:\\n\")\nfor(i in 1:nrow(centroides_info)) {\n  grupo_nome <- rownames(centroides_info)[i]\n  ld1_val <- centroides_info[i, \"LD1\"]\n  ld2_val <- centroides_info[i, \"LD2\"]\n  \n  # Interpretação baseada na posição\n  interpretacao_ld1 <- ifelse(ld1_val > 0, \"valores altos em LD1\", \"valores baixos em LD1\")\n  interpretacao_ld2 <- ifelse(ld2_val > 0, \"valores altos em LD2\", \"valores baixos em LD2\")\n  \n  cat(sprintf(\"- %s: Caracterizado por %s e %s\\n\", \n              grupo_nome, interpretacao_ld1, interpretacao_ld2))\n}\n\ncat(\"\\nLEGENDA DO GRÁFICO:\\n\")\ncat(\"🔺 Triângulos pretos = Centróides dos grupos\\n\")\ncat(\"● Pontos coloridos = Observações individuais por grupo\\n\")\ncat(\"→ Vetores vermelhos = Variáveis significativas (p < 0.05)\\n\")\ncat(\"→ Vetores cinza = Variáveis não significativas\\n\")\ncat(\"📏 Comprimento do vetor = Magnitude da contribuição discriminante\\n\")\n\n# Interpretação dos vetores\ncat(\"\\n=== INTERPRETAÇÃO DOS VETORES DE ATRIBUIÇÃO ===\\n\")\n```\n\n#### 6.4 Análise das Distâncias entre Grupos\n\n```{r}\n# Calculando distâncias Mahalanobis entre centróides\ncentroides_matriz <- as.matrix(centroides_discriminantes)\n\n# Matriz de distâncias entre centróides\nn_grupos <- nrow(centroides_matriz)\ndist_centroides <- matrix(0, n_grupos, n_grupos)\nrownames(dist_centroides) <- rownames(centroides_matriz)\ncolnames(dist_centroides) <- rownames(centroides_matriz)\n\nfor(i in 1:n_grupos) {\n  for(j in 1:n_grupos) {\n    dist_centroides[i, j] <- sqrt(sum((centroides_matriz[i, ] - centroides_matriz[j, ])^2))\n  }\n}\n\nprint(\"Matriz de Distâncias Euclidianas entre Centróides:\")\nprint(round(dist_centroides, 3))\n\n# Visualização das distâncias como heatmap\ndist_df <- reshape2::melt(dist_centroides)\nnames(dist_df) <- c(\"Grupo1\", \"Grupo2\", \"Distancia\")\n\np_distancias <- ggplot2::ggplot(dist_df, ggplot2::aes(x = Grupo1, y = Grupo2, fill = Distancia)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = round(Distancia, 2)), \n                     color = \"white\", fontface = \"bold\", size = 5) +\n  ggplot2::scale_fill_viridis_c(name = \"Distância\\nEuclidiana\") +\n  ggplot2::labs(title = \"Matriz de Distâncias entre Centróides dos Grupos\",\n                subtitle = \"Distâncias calculadas no espaço discriminante\",\n                x = \"Grupo\", y = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\nprint(p_distancias)\n\n# Análise de separação\ndist_matrix_upper <- dist_centroides[upper.tri(dist_centroides)]\n\n# Identificando grupos mais próximos e mais distantes\ndist_indices <- which(dist_centroides == min(dist_matrix_upper), arr.ind = TRUE)[1, ]\ngrupos_proximos <- c(rownames(dist_centroides)[dist_indices[1]], \n                    colnames(dist_centroides)[dist_indices[2]])\n\ndist_indices_max <- which(dist_centroides == max(dist_matrix_upper), arr.ind = TRUE)[1, ]\ngrupos_distantes <- c(rownames(dist_centroides)[dist_indices_max[1]], \n                     colnames(dist_centroides)[dist_indices_max[2]])\n```\n\n**Interpretação da Análise de Distâncias:**\n\n**Matriz de Distâncias Euclidianas:**\n- **Menor distância**: \"De 1 a 5 anos\" ↔ \"Mais de 5 anos\" (1.737)\n- **Maior distância**: \"Menos de 1 ano\" ↔ \"Mais de 5 anos\" (3.084)\n- **Distância intermediária**: \"Menos de 1 ano\" ↔ \"De 1 a 5 anos\" (2.127)\n\n**Padrões de Similaridade:**\n\n1. **Grupos Intermediário e Maduro são mais próximos**: \n   - Distância de apenas 1.737 unidades\n   - **Interpretação**: Após 1 ano, as percepções começam a convergir\n   - **Implicação**: O primeiro ano é crítico para formar percepções duradouras\n\n2. **Clientes Novos são mais distantes de todos**:\n   - Maior distância dos clientes maduros (3.084)\n   - **Interpretação**: Período inicial tem características muito distintas\n   - **Implicação**: Estratégias específicas necessárias para novos clientes\n\n3. **Progressão Não-Linear**:\n   - A evolução \"Novo → Intermediário → Maduro\" não é uniforme\n   - Maior salto entre \"Novo\" e \"Intermediário\" (2.127)\n   - Menor progressão entre \"Intermediário\" e \"Maduro\" (1.737)\n\n**Insights Gerenciais:**\n\n- **Período Crítico**: Os primeiros 12 meses são fundamentais para retenção\n- **Convergência**: Após 1 ano, clientes tendem a desenvolver percepções similares\n- **Segmentação**: Dois grandes segmentos emergem: \"Novos\" vs. \"Estabelecidos\" (intermediários + maduros)\n\n#### 6.5 Comparação Visual: Espaço Original vs. Espaço Discriminante\n\n```{r}\n# Comparando visualização no espaço original (X6, X18) vs. espaço discriminante\np_original <- ggplot2::ggplot(amostra_analise, ggplot2::aes(x = X6, y = X18, color = X1)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = centroides, ggplot2::aes(x = X6, y = X18), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Espaço Original\",\n                subtitle = \"Variáveis originais do modelo discriminante\",\n                x = descricoes_variaveis[\"X6\"], \n                y = descricoes_variaveis[\"X18\"],\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 12, face = \"bold\"))\n\np_discriminante <- ggplot2::ggplot(df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Espaço Discriminante (LD1 vs LD2)\",\n                subtitle = \"Funções discriminantes otimizadas para separação\",\n                x = paste(\"LD1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"LD2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 12, face = \"bold\"))\n\n# Combinando os gráficos\ncomparacao <- gridExtra::grid.arrange(\n  p_original, p_discriminante, \n  ncol = 2,\n  top = grid::textGrob(\"Comparação: Espaço Original vs. Espaço Discriminante\", \n                       gp = grid::gpar(fontsize = 16, fontface = \"bold\"))\n)\n\nprint(comparacao)\n\n# Interpretação da comparação\ncat(\"\\n=== INTERPRETAÇÃO DA COMPARAÇÃO ===\\n\")\ncat(\"- Espaço Original: mostra sobreposição entre grupos\\n\")\ncat(\"- Espaço Discriminante: maximiza separação entre grupos\\n\")\ncat(\"- A transformação discriminante melhora a separabilidade\\n\")\ncat(\"- LD1 e LD2 são combinações lineares que maximizam discriminação\\n\")\n```\n\n### Estágio 6: Validação dos Resultados\n\n#### 6.6 Matriz de Classificação e Validação\n\n```{r}\n# Classificação da amostra de análise\npredicoes_analise <- predict(modelo_final, amostra_analise)\nmatriz_confusao_analise <- table(Predito = predicoes_analise$class, \n                                Real = amostra_analise$X1)\n\nprint(\"Matriz de Classificação - Amostra de Análise:\")\nprint(matriz_confusao_analise)\n\n# Taxa de acerto geral\nacerto_geral_analise <- sum(diag(matriz_confusao_analise)) / sum(matriz_confusao_analise)\n\n# Taxa de acerto por grupo\nacerto_por_grupo_analise <- diag(matriz_confusao_analise) / rowSums(matriz_confusao_analise)\nprint(\"Taxa de Acerto por Grupo (Análise):\")\nprint(round(acerto_por_grupo_analise * 100, 1))\n\n# Visualização da matriz de confusão\nmatriz_conf_df <- as.data.frame(matriz_confusao_analise)\nnames(matriz_conf_df) <- c(\"Predito\", \"Real\", \"Freq\")\n\np_matriz_conf <- ggplot2::ggplot(matriz_conf_df, ggplot2::aes(x = Real, y = Predito, fill = Freq)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = Freq), color = \"white\", size = 6, fontface = \"bold\") +\n  ggplot2::scale_fill_viridis_c(name = \"Frequência\") +\n  ggplot2::labs(title = \"Matriz de Confusão - Amostra de Análise\",\n                subtitle = paste(\"Taxa de Acerto Geral:\", round(acerto_geral_analise * 100, 1), \"%\"),\n                x = \"Grupo Real\", y = \"Grupo Predito\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\nprint(p_matriz_conf)\n```\n\n**Taxa de Acerto Geral (Análise)**: `r round(acerto_geral_analise * 100, 1)`%\n\n**Taxa de Acerto por Grupo (Análise)**:\n```{r}\n#| echo: false\nknitr::kable(data.frame(\n  Grupo = names(acerto_por_grupo_analise),\n  `Taxa de Acerto (%)` = round(acerto_por_grupo_analise * 100, 1)\n), row.names = FALSE)\n```\n\n#### 6.7 Validação Cruzada\n\n```{r}\n# Função para validação cruzada\nvalidacao_cruzada <- function(dados, formula) {\n  n <- nrow(dados)\n  predicoes <- character(n)\n  \n  for(i in 1:n) {\n    # Treina modelo sem a observação i\n    dados_treino <- dados[-i, ]\n    modelo_temp <- MASS::lda(formula, data = dados_treino)\n    \n    # Prediz a observação i\n    predicao_temp <- predict(modelo_temp, dados[i, ])\n    predicoes[i] <- as.character(predicao_temp$class)\n  }\n  \n  return(factor(predicoes, levels = levels(dados$X1)))\n}\n\n# Aplicando validação cruzada\npredicoes_cv <- validacao_cruzada(amostra_analise, X1 ~ X6 + X18)\nmatriz_confusao_cv <- table(Predito = predicoes_cv, Real = amostra_analise$X1)\n\nprint(\"Matriz de Classificação - Validação Cruzada:\")\nprint(matriz_confusao_cv)\n\n# Taxa de acerto validação cruzada\nacerto_geral_cv <- sum(diag(matriz_confusao_cv)) / sum(matriz_confusao_cv)\n```\n\n**Taxa de Acerto Geral (Validação Cruzada)**: `r round(acerto_geral_cv * 100, 1)`%\n\n#### 6.8 Validação Externa\n\n```{r}\n# Classificação da amostra de validação\npredicoes_validacao <- predict(modelo_final, amostra_validacao)\nmatriz_confusao_validacao <- table(Predito = predicoes_validacao$class, \n                                  Real = amostra_validacao$X1)\n\nprint(\"Matriz de Classificação - Amostra de Validação:\")\nprint(matriz_confusao_validacao)\n\n# Taxa de acerto amostra de validação\nacerto_geral_validacao <- sum(diag(matriz_confusao_validacao)) / sum(matriz_confusao_validacao)\n\n# Taxa de acerto por grupo\nacerto_por_grupo_validacao <- diag(matriz_confusao_validacao) / rowSums(matriz_confusao_validacao)\nprint(\"Taxa de Acerto por Grupo (Validação):\")\nprint(round(acerto_por_grupo_validacao * 100, 1))\n```\n\n**Taxa de Acerto Geral (Validação)**: `r round(acerto_geral_validacao * 100, 1)`%\n\n#### 6.9 Critérios de Chance\n\n```{r}\n# Calculando critérios de chance\ntamanhos_grupos <- table(amostra_analise$X1)\nproporcoes_grupos <- tamanhos_grupos / sum(tamanhos_grupos)\n\n# Critério de chance proporcional\ncriterio_chance_proporcional <- sum(proporcoes_grupos^2) * 100\n\n# Critério de chance máxima\ncriterio_chance_maxima <- max(proporcoes_grupos) * 100\n\n# Gráfico de comparação das taxas de acerto\ntaxas_acerto <- data.frame(\n  Metodo = c(\"Análise\", \"Validação Cruzada\", \"Validação Externa\", \n             \"Critério Proporcional\", \"Critério Máximo\"),\n  Taxa = c(acerto_geral_analise * 100, \n           acerto_geral_cv * 100,\n           acerto_geral_validacao * 100,\n           criterio_chance_proporcional,\n           criterio_chance_maxima),\n  Tipo = c(\"Modelo\", \"Modelo\", \"Modelo\", \"Referência\", \"Referência\")\n)\n\np_performance <- ggplot2::ggplot(taxas_acerto, ggplot2::aes(x = reorder(Metodo, Taxa), y = Taxa, fill = Tipo)) +\n  ggplot2::geom_col(alpha = 0.8, width = 0.7) +\n  ggplot2::geom_text(ggplot2::aes(label = paste0(round(Taxa, 1), \"%\")), \n                     hjust = -0.1, size = 4, fontface = \"bold\") +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"Modelo\" = \"steelblue\", \"Referência\" = \"coral\")) +\n  ggplot2::labs(title = \"Comparação das Taxas de Acerto\",\n                subtitle = \"Modelo vs. Critérios de Chance\",\n                x = \"Método de Validação\", \n                y = \"Taxa de Acerto (%)\",\n                fill = \"Tipo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"))\n\nprint(p_performance)\n```\n\n**Critérios de Chance:**\n\n- **Critério de Chance Proporcional**: `r round(criterio_chance_proporcional, 1)`%\n- **Critério de Chance Máxima**: `r round(criterio_chance_maxima, 1)`%\n\n**Comparação com Resultados Obtidos:**\n\n- Taxa de Acerto Análise: `r round(acerto_geral_analise * 100, 1)`% vs Critério Proporcional: `r round(criterio_chance_proporcional, 1)`%\n- Taxa de Acerto Validação Cruzada: `r round(acerto_geral_cv * 100, 1)`% vs Critério Proporcional: `r round(criterio_chance_proporcional, 1)`%  \n- Taxa de Acerto Validação: `r round(acerto_geral_validacao * 100, 1)`% vs Critério Proporcional: `r round(criterio_chance_proporcional, 1)`%\n\n### Resumo da Interpretação Gerencial\n\nOs resultados da análise discriminante revelam insights importantes sobre a diferenciação de clientes baseada no tempo de relacionamento. Com o dataset completo analisado, identificamos que de 13 variáveis independentes testadas, apenas 2 foram suficientes para uma discriminação efetiva.\n\n#### Principais Descobertas:\n\n1. **Variáveis Discriminantes**: X6 (Product Quality) e X18 (Delivery Speed) são os principais diferenciadores, representando aproximadamente 100% da variância discriminante total.\n\n2. **Precisão do Modelo**: O modelo alcança alta taxa de acertos na amostra de análise, superando significativamente os critérios de chance.\n\n3. **Diferenças entre Grupos**: \n   - **Clientes novos** (< 1 ano): Menores percepções de qualidade e velocidade\n   - **Clientes intermediários** (1-5 anos): Percepções moderadas\n   - **Clientes estabelecidos** (> 5 anos): Maiores percepções de qualidade e velocidade\n\n#### Implicações Gerenciais:\n\n- **Foco na Qualidade**: Investir na melhoria da qualidade do produto é fundamental para reter clientes\n- **Otimização de Entregas**: A velocidade de entrega é um diferencial competitivo crítico\n- **Segmentação**: Os 3 grupos identificados requerem estratégias diferenciadas\n\n```{r}\n# Médias dos grupos para interpretação\nmedias_grupos <- aggregate(amostra_analise[, variaveis_independentes], \n                          by = list(amostra_analise$X1), FUN = mean)\nnames(medias_grupos)[1] <- \"Grupo\"\n\n# Corrigindo erro na impressão das médias dos grupos\nmedias_grupos_numericas <- medias_grupos[, -1]  # Remove coluna 'Grupo'\nrownames(medias_grupos_numericas) <- medias_grupos$Grupo\n\nprint(\"Médias dos Grupos nas Variáveis Independentes:\")\nprint(round(medias_grupos_numericas, 2))\n\ncat(\"\\n=== INTERPRETAÇÃO DAS FUNÇÕES DISCRIMINANTES ===\\n\")\ncat(\"Função 1: Diferencia principalmente entre Grupo 1 e Grupos 2-3\\n\")\ncat(\"Função 2: Diferencia principalmente entre Grupo 3 e Grupos 1-2\\n\")\n\ncat(\"\\n=== VARIÁVEIS MAIS IMPORTANTES ===\\n\")\nif(exists(\"indice_potencia_ordenado\")) {\n  cat(\"Por Índice de Potência:\\n\")\n  print(names(indice_potencia_ordenado)[1:min(5, length(indice_potencia_ordenado))])\n}\n\ncat(\"\\nPor Razão F Univariada:\\n\")\nprint(names(razoes_f_ordenadas)[1:min(5, length(razoes_f_ordenadas))])\n\ncat(\"\\n=== RESUMO FINAL ===\\n\")\ncat(\"Modelo discriminante final: X1 ~ X6 + X18\\n\")\ncat(\"Variáveis selecionadas:\\n\")\ncat(\"- X6: Qualidade do produto\\n\")\ncat(\"- X18: Velocidade de entrega\\n\")\n\nif(exists(\"modelo_stepwise\")) {\n  cat(\"\\nVariáveis selecionadas pelo procedimento stepwise:\\n\")\n  print(modelo_stepwise$formula)\n}\n\ncat(\"\\n=== CONCLUSÕES GERENCIAIS ===\\n\")\ncat(\"1. A qualidade do produto (X6) e velocidade de entrega (X18) são os principais diferenciadores entre os grupos de clientes.\\n\")\ncat(\"2. O modelo consegue discriminar bem entre os três grupos de tempo de relacionamento.\\n\")\ncat(\"3. Clientes de longo prazo valorizam mais qualidade e velocidade de entrega.\\n\")\ncat(\"4. Ações de melhoria devem focar nestas duas dimensões para reter clientes.\\n\")\n```\n\n**Análise das Médias por Grupo:**\n\nOs resultados mostram um padrão claro de evolução das percepções com o tempo de relacionamento, com melhorias progressivas nas percepções de qualidade e velocidade de entrega conforme aumenta o tempo de relacionamento com a empresa.\n\n### Apêndice: Informações Técnicas do Dataset\n\n#### Características do Dataset HBAT\n\n```{r}\n# Informações sobre o dataset após limpeza\ncat(\"=== CARACTERÍSTICAS DO DATASET FINAL ===\\n\")\ncat(\"Total de observações:\", nrow(hbat_clean), \"\\n\")\ncat(\"Variáveis independentes analisadas:\", length(variaveis_independentes), \"\\n\")\ncat(\"Grupos da variável dependente:\", nlevels(hbat_clean$X1), \"\\n\")\n\n# Distribuição dos grupos\ndist_grupos <- table(hbat_clean$X1)\nprop_grupos <- prop.table(dist_grupos) * 100\n\ncat(\"\\nDistribuição dos grupos:\\n\")\nfor(i in 1:length(dist_grupos)) {\n  cat(\"- \", names(dist_grupos)[i], \": \", dist_grupos[i], \" casos (\", \n      round(prop_grupos[i], 1), \"%)\\n\", sep = \"\")\n}\n```\n\n#### Qualidade dos Dados\n\n- **Missing values**: Removidos através de listwise deletion\n- **Balanceamento**: Dataset relativamente balanceado entre os grupos\n- **Escala das variáveis**: Todas as variáveis independentes estão na escala de 0-10\n\n```{r}\n# Informações detalhadas sobre o dataset HBAT\ncat(\"=== INFORMAÇÕES DO DATASET HBAT ===\\n\")\ncat(\"Total de observações:\", nrow(hbat_clean), \"\\n\")\ncat(\"Variáveis independentes:\", length(variaveis_independentes), \"\\n\")\ncat(\"Grupos da variável dependente:\", nlevels(hbat_clean$X1), \"\\n\")\n\n# Descrição das variáveis (baseado nos labels originais) - ATUALIZADO\ncat(\"\\n=== DESCRIÇÃO COMPLETA DAS VARIÁVEIS ===\\n\")\nfor(var in names(descricoes_variaveis)) {\n  cat(var, \"-\", descricoes_variaveis[var], \"\\n\")\n}\n\n# Estatísticas descritivas finais\ncat(\"\\n=== ESTATÍSTICAS DESCRITIVAS FINAIS ===\\n\")\nprint(summary(hbat_clean))\n```\n\n","srcMarkdownNoYaml":"\n\n```{r}\n#| include: false\n#| echo: true\n#| message: false\n#| warning: false\n\n# Carregando os pacotes necessários\nif (!require(\"MASS\")) install.packages(\"MASS\")\nif (!require(\"klaR\")) install.packages(\"klaR\")\nif (!require(\"car\")) install.packages(\"car\")\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nif (!require(\"corrplot\")) install.packages(\"corrplot\")\nif (!require(\"caret\")) install.packages(\"caret\")\nif (!require(\"skimr\")) install.packages(\"skimr\")\nif (!require(\"MVN\")) install.packages(\"MVN\")\nif (!require(\"biotools\")) install.packages(\"biotools\")\nif (!require(\"GGally\")) install.packages(\"GGally\")\nif (!require(\"nnet\")) install.packages(\"nnet\")\nif (!require(\"pROC\")) install.packages(\"pROC\")\nif (!require(\"tidyr\")) install.packages(\"tidyr\")\nif (!require(\"readr\")) install.packages(\"readr\")\nif (!require(\"haven\")) install.packages(\"haven\")\nif (!require(\"gridExtra\")) install.packages(\"gridExtra\")\nif (!require(\"reshape2\")) install.packages(\"reshape2\")\nif (!require(\"viridis\")) install.packages(\"viridis\")\nif (!require(\"plotly\")) install.packages(\"plotly\")\nif (!require(\"RColorBrewer\")) install.packages(\"RColorBrewer\")\n\n```\n\n```{r}\n#| echo: true\n#| message: false\n#| warning: false\n\nlibrary(MASS)\nlibrary(klaR)\nlibrary(car)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(corrplot)\nlibrary(caret)\nlibrary(skimr)\nlibrary(MVN)\nlibrary(biotools)\nlibrary(GGally)\nlibrary(nnet)\nlibrary(pROC)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(haven)\nlibrary(gridExtra)\nlibrary(reshape2)\nlibrary(viridis)\nlibrary(plotly)\nlibrary(RColorBrewer)\n```\n\n## Análise Discriminante - Exemplo HBAT\n\n\n### Reprodução do Exemplo de Hair et al. - Dataset HBAT\n\nNesta seção, reproduziremos a análise discriminante apresentada no livro Hair et al., utilizando o dataset HBAT para classificar clientes em três grupos baseados no tempo de relacionamento com a empresa.\n\n\nO **HBAT** é um dataset educacional fictício amplamente utilizado no livro clássico \"Multivariate Data Analysis\" de Joseph Hair et al., representando uma empresa de distribuição industrial. O dataset contém **100 observações** de clientes classificados em três grupos baseados no tempo de relacionamento: **Grupo 1** (menos de 1 ano), **Grupo 2** (1 a 5 anos) e **Grupo 3** (mais de 5 anos). As variáveis incluem a **variável dependente X1** (Customer Type) e **13 variáveis independentes** (X6-X18) que medem percepções dos clientes sobre diferentes aspectos da empresa, como qualidade do produto (X6), atividades de e-commerce (X7), suporte técnico (X8), resolução de reclamações (X9), propaganda (X10), linha de produtos (X11), imagem da força de vendas (X12), preços competitivos (X13), garantia e reclamações (X14), novos produtos (X15), pedidos e faturamento (X16), flexibilidade de preços (X17) e velocidade de entrega (X18). Todas as variáveis independentes utilizam uma **escala de 0-10**, facilitando comparações e interpretações. Este dataset é ideal para demonstrar técnicas de análise multivariada, especialmente análise discriminante, pois oferece um contexto empresarial realista com dados limpos e estruturados, permitindo focar na aplicação das técnicas estatísticas sem se preocupar com problemas complexos de qualidade de dados típicos de datasets reais.\n\n### Estágio 1: Objetivos da Análise Discriminante\n\nO objetivo é identificar as características perceptuais que distinguem clientes baseados no tempo de relacionamento:\n- **Grupo 1**: Menos de 1 ano\n- **Grupo 2**: De 1 a 5 anos  \n- **Grupo 3**: Mais de 5 anos\n\n#### Carregamento e Inspeção dos Dados do arquivo spss\n\n```{r}\n# Carregando os dados HBAT\nhbat <- haven::read_sav(\"data/hbat.sav\")\n\nglimpse(hbat)\n\n```\n\n\n```{r}\n#| include: false\n#| echo: false\n\n\n# Gráfico da distribuição da variável dependente\np_dist_grupos <- ggplot2::ggplot(data.frame(x1 = hbat$x1), ggplot2::aes(x = factor(x1))) +\n  ggplot2::geom_bar(fill = \"steelblue\", alpha = 0.7) +\n  ggplot2::geom_text(stat = \"count\", ggplot2::aes(label = after_stat(count)), \n                     vjust = -0.5, size = 4) +\n  ggplot2::labs(title = \"Distribuição dos Grupos por Tempo de Relacionamento\",\n                x = \"Grupo (1=<1 ano, 2=1-5 anos, 3=>5 anos)\",\n                y = \"Frequência\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"))\n\nprint(p_dist_grupos)\n```\n\n\n\n```{r}\n#| include: false\n#| echo: false\n\n# Identificando as variáveis corretas baseado na estrutura real do dataset\n# Primeiro vamos ver quais variáveis existem realmente\nprint(\"Variáveis disponíveis no dataset:\")\nprint(colnames(hbat))\n\n# Verificando se existem variáveis que correspondem às do exemplo Hair\n# Procurando por padrões de nomes que possam corresponder a X1, X6-X18\npossiveis_vars <- grep(\"^[Xx][0-9]+\", names(hbat), value = TRUE)\nprint(\"Possíveis variáveis X encontradas:\")\nprint(possiveis_vars)\n\n# Se não encontrar, vamos procurar por outras variáveis categóricas e numéricas\ncat(\"\\nEstrutura das primeiras 10 variáveis:\\n\")\nstr(hbat[,1:min(10, ncol(hbat))])\n```\n\n\n\n```{r}\n#| include: false\n#| echo: false\n\n\n# Preparando os dados baseado na estrutura real encontrada\n# Vamos adaptar baseado nas variáveis que realmente existem\n\n# Primeiro, identificar a variável dependente (tempo de relacionamento)\n# Procurar por variáveis categóricas que possam representar grupos de tempo\n\n# Listar variáveis categóricas\nvars_categoricas <- sapply(hbat, function(x) is.factor(x) || length(unique(x)) <= 10)\nprint(\"Variáveis categóricas ou com poucos valores únicos:\")\nprint(names(hbat)[vars_categoricas])\n\n# Examinar algumas variáveis categóricas potenciais\nfor(var in names(hbat)[vars_categoricas][1:min(5, sum(vars_categoricas))]) {\n  cat(\"\\nVariável:\", var, \"\\n\")\n  print(table(hbat[[var]], useNA = \"ifany\"))\n}\n```\n\n#### Definição das Variáveis do Modelo\n\nCom base na inspeção dos dados, identificamos que o dataset HBAT possui exatamente as variáveis necessárias:\n- **x1**: Variável dependente (Customer Type: 1=Menos de 1 ano, 2=De 1 a 5 anos, 3=Mais de 5 anos)\n- **x6-x18**: Variáveis independentes (percepções sobre a HBAT)\n\n```{r}\n#| include: false\n#| echo: false\n# Agora que sabemos a estrutura, vamos usar as variáveis corretas\nvariavel_dependente <- \"x1\"  # Customer Type - exatamente o que precisamos\nvariaveis_independentes <- paste0(\"x\", 6:18)  # x6 a x18 - percepções\n\n# Verificando se x1 tem os valores corretos\nprint(table(hbat$x1, useNA = \"ifany\"))\n\n# Verificando os labels da variável x1\nif(haven::is.labelled(hbat$x1)) {\n  print(haven::as_factor(hbat$x1))\n  print(table(haven::as_factor(hbat$x1)))\n}\n```\n\n**Configuração das Variáveis:**\n\n- **Variável dependente**: `r variavel_dependente`\n- **Variáveis independentes**: `r paste(variaveis_independentes, collapse = \", \")`\n- **Total de variáveis independentes**: `r length(variaveis_independentes)`\n\n#### Preparação do Dataset Final\n\n```{r}\n#| include: false\n# Criando dataset limpo com as variáveis corretas identificadas\nhbat_clean <- hbat %>%\n  dplyr::select(dplyr::all_of(c(variavel_dependente, variaveis_independentes))) %>%\n  na.omit()\n\n# Converter x1 para fator com os labels corretos do exemplo Hair\nhbat_clean <- hbat_clean %>%\n  dplyr::mutate(\n    X1 = factor(x1, \n                levels = 1:3,\n                labels = c(\"Menos de 1 ano\", \"De 1 a 5 anos\", \"Mais de 5 anos\"))\n  ) %>%\n  dplyr::select(-x1)\n\n# Renomear variáveis independentes para seguir padrão X6-X18 (maiúsculas)\nnomes_independentes <- paste0(\"X\", 6:18)\nnames(hbat_clean)[names(hbat_clean) != \"X1\"] <- nomes_independentes\n\n# Reordenar colunas para X1 ficar primeiro\nhbat_clean <- hbat_clean %>%\n  dplyr::select(X1, dplyr::everything())\n\n# Atualizar lista de variáveis independentes\nvariaveis_independentes <- nomes_independentes\n\n# Criando dicionário de descrições das variáveis\ndescricoes_variaveis <- c(\n  \"X1\" = \"Customer Type\",\n  \"X6\" = \"Product Quality\",\n  \"X7\" = \"E-Commerce Activities\",\n  \"X8\" = \"Technical Support\",\n  \"X9\" = \"Complaint Resolution\",\n  \"X10\" = \"Advertising\",\n  \"X11\" = \"Product Line\",\n  \"X12\" = \"Salesforce Image\",\n  \"X13\" = \"Competitive Pricing\",\n  \"X14\" = \"Warranty & Claims\",\n  \"X15\" = \"New Products\",\n  \"X16\" = \"Ordering & Billing\",\n  \"X17\" = \"Price Flexibility\",\n  \"X18\" = \"Delivery Speed\"\n)\n\n# Função para obter descrição completa da variável\nobter_descricao <- function(var) {\n  if(var %in% names(descricoes_variaveis)) {\n    return(descricoes_variaveis[var])\n  } else {\n    return(var)\n  }\n}\n```\n\n**Resumo da Preparação dos Dados:**\n\n- **Total de observações**: `r nrow(hbat_clean)`\n- **Variáveis independentes**: `r length(variaveis_independentes)`\n- **Grupos identificados**: `r nlevels(hbat_clean$X1)`\n\n**Distribuição da Variável Dependente (X1):**\n```{r}\n#| echo: false\nknitr::kable(table(hbat_clean$X1), col.names = c(\"Grupo\", \"Frequência\"))\n```\n\n**Descrições das Variáveis:**\n\n| Código | Descrição |\n|--------|-----------|\n| X1 | Customer Type |\n| X6 | Product Quality |\n| X7 | E-Commerce Activities |\n| X8 | Technical Support |\n| X9 | Complaint Resolution |\n| X10 | Advertising |\n| X11 | Product Line |\n| X12 | Salesforce Image |\n| X13 | Competitive Pricing |\n| X14 | Warranty & Claims |\n| X15 | New Products |\n| X16 | Ordering & Billing |\n| X17 | Price Flexibility |\n| X18 | Delivery Speed |\n\n### Estágio 2: Delineamento da Pesquisa de Análise Discriminante\n\n```{r}\n# Divisão em amostras de análise e validação\nset.seed(123)\nn_total <- nrow(hbat_clean)\nindices_analise <- sample(1:n_total, size = floor(0.6 * n_total))\n\namostra_analise <- hbat_clean[indices_analise, ]\namostra_validacao <- hbat_clean[-indices_analise, ]\n\n# Verificar balanceamento dos grupos\nprop_analise <- table(amostra_analise$X1) / nrow(amostra_analise)\nprop_validacao <- table(amostra_validacao$X1) / nrow(amostra_validacao)\n```\n\nA análise discriminante requer a divisão dos dados em amostras de estimação e validação para avaliar adequadamente o desempenho do modelo. Utilizamos uma divisão de 60% para análise e 40% para validação.\n\n**Características das Amostras:**\n\n- **Amostra de análise**: `r nrow(amostra_analise)` casos\n- **Amostra de validação**: `r nrow(amostra_validacao)` casos\n\n**Distribuição dos Grupos por Amostra:**\n\n| Grupo | Análise (n) | Análise (%) | Validação (n) | Validação (%) |\n|-------|-------------|-------------|---------------|---------------|\n| Menos de 1 ano | `r table(amostra_analise$X1)[1]` | `r round(prop_analise[1] * 100, 1)`% | `r table(amostra_validacao$X1)[1]` | `r round(prop_validacao[1] * 100, 1)`% |\n| De 1 a 5 anos | `r table(amostra_analise$X1)[2]` | `r round(prop_analise[2] * 100, 1)`% | `r table(amostra_validacao$X1)[2]` | `r round(prop_validacao[2] * 100, 1)`% |\n| Mais de 5 anos | `r table(amostra_analise$X1)[3]` | `r round(prop_analise[3] * 100, 1)`% | `r table(amostra_validacao$X1)[3]` | `r round(prop_validacao[3] * 100, 1)`% |\n\n### Estágio 3: Pressupostos da Análise Discriminante\n\n#### 3.1 Normalidade Multivariada\n\nO teste de normalidade multivariada é fundamental para verificar se os dados seguem uma distribuição normal multivariada, pressuposto da análise discriminante linear. Testamos cada um dos três grupos separadamente usando o teste de Henze-Zirkler.\n\n\n```{r}\nlibrary(MVN)\n\n# Armazenar resultados dos testes de normalidade\nresultados_normalidade <- list()\n\nfor(grupo in levels(amostra_analise$X1)) {\n  dados_grupo <- amostra_analise[amostra_analise$X1 == grupo, variaveis_independentes]\n  \n  # Usando parâmetros corretos da função mvn\n  resultado_mvn <- mvn(dados_grupo, mvn_test = \"hz\", univariate_test = \"SW\")\n  resultados_normalidade[[grupo]] <- resultado_mvn$multivariate_normality\n  \n  # Teste alternativo se o primeiro falhar\n  if(is.null(resultado_mvn$multivariate_normality)) {\n    resultado_mardia <- mvn(dados_grupo, mvn_test = \"mardia\")\n    resultados_normalidade[[grupo]] <- resultado_mardia$multivariate_normality\n  }\n}\n\n# Mostrar resultados\nprint(resultados_normalidade)\n```\n\n**Resumo dos Testes de Normalidade:**\n\nCom base nos resultados obtidos, 2 dos 3 grupos atendem ao pressuposto de normalidade multivariada ao nível de significância de 5%. O grupo que apresentou desvio (p = 0.035) está próximo do limite aceitável, e a análise discriminante pode prosseguir com confiança.\n\n#### 3.2 Homogeneidade das Matrizes de Covariância\n\nO teste M de Box verifica se as matrizes de covariância dos grupos são homogêneas, outro pressuposto importante da análise discriminante. Este teste avalia se as 13 variáveis independentes apresentam estruturas de covariância similares entre os grupos.\n\n**Interpretação dos Resultados do Teste M de Box:**\n\n**Conclusão**: Com p-valor = 0.01122 < 0.05, rejeitamos a hipótese nula de homogeneidade das matrizes de covariância. Isso indica que **há diferenças significativas** entre as estruturas de covariância dos grupos.\n\n**Implicações Práticas:**\n- A violação da homogeneidade das covariâncias sugere que a **Análise Discriminante Quadrática (QDA)** poderia ser mais apropriada que a Linear (LDA)\n- No entanto, a LDA é robusta a violações moderadas deste pressuposto, especialmente quando os tamanhos das amostras são similares\n- Como os grupos estão relativamente balanceados (conforme mostrado acima), podemos prosseguir com cautela usando LDA\n- Os resultados devem ser interpretados considerando esta limitação\n\n```{r}\nlibrary(biotools)\n\ndados_teste <- amostra_analise[, variaveis_independentes]\ngrupos_teste <- amostra_analise$X1\n\n# Teste M de Box com tratamento de erro\ntryCatch({\n  teste_box <- boxM(dados_teste, grupos_teste)\n  print(teste_box)\n}, error = function(e) {\n  message(\"Teste M de Box não pôde ser executado: \", e$message)\n  \n  for(grupo in levels(amostra_analise$X1)) {\n    dados_grupo <- amostra_analise[amostra_analise$X1 == grupo, variaveis_independentes]\n    cov_grupo <- cov(dados_grupo)\n    message(\"\\nMatriz de Covariância - Grupo: \", grupo)\n    print(round(cov_grupo, 3))\n  }\n})\n```\n\n#### 3.3 Multicolinearidade\n\nA presença de multicolinearidade pode afetar a estabilidade dos resultados da análise discriminante. O determinante da matriz de correlação e os valores VIF nos ajudam a identificar possíveis problemas de multicolinearidade entre as variáveis.\n\n**Interpretação dos Valores VIF:**\n\nOs Fatores de Inflação da Variância (VIF) revelam problemas significativos de multicolinearidade:\n\n- **VIF < 5**: Multicolinearidade baixa (aceitável)\n  - X6 (1.90), X7 (4.56), X8 (4.71), X10 (1.65), X13 (1.76), X14 (4.16), X15 (1.23), X16 (4.33)\n\n- **VIF entre 5-10**: Multicolinearidade moderada (preocupante)\n  - X9 (5.33), X12 (5.78)\n\n- **VIF > 10**: Multicolinearidade alta (problemática)\n  - **X11 (Product Line)**: VIF = 52.77\n  - **X17 (Price Flexibility)**: VIF = 41.49  \n  - **X18 (Delivery Speed)**: VIF = 56.34\n\n**Implicações:**\n- As variáveis X11, X17 e X18 apresentam alta correlação com outras variáveis independentes\n- Isso pode causar instabilidade nos coeficientes discriminantes\n- O determinante da matriz de correlação confirma a presença de multicolinearidade\n- Apesar disso, seguimos o exemplo de Hair et al. usando X6 e X18, reconhecendo esta limitação\n\n```{r}\n# Matriz de correlação com visualização aprimorada\nmatriz_cor <- cor(amostra_analise[, variaveis_independentes])\n\n# Gráfico de correlação personalizado\ncorrplot::corrplot(matriz_cor, method = \"color\", type = \"upper\", \n                   order = \"hclust\", tl.cex = 0.8, tl.col = \"black\",\n                   col = RColorBrewer::brewer.pal(n = 8, name = \"RdYlBu\"),\n                   title = \"Matriz de Correlação das Variáveis Independentes\",\n                   mar = c(0,0,2,0))\n\n# Determinante da matriz de correlação\ndet_cor <- det(matriz_cor)\n\n# VIF para identificar multicolinearidade\nmodelo_temp <- lm(as.numeric(X1) ~ ., data = amostra_analise[, c(\"X1\", variaveis_independentes)])\nvif_valores <- car::vif(modelo_temp)\n```\n\n**Análise de Multicolinearidade:**\n\n- **Determinante da matriz de correlação**: `r round(det_cor, 6)`\n\n**Classificação dos Valores VIF:**\n\n| Categoria | Critério | Variáveis |\n|-----------|----------|-----------|\n| **Baixa** (< 5) | Aceitável | `r paste(names(vif_valores[vif_valores < 5]), collapse = \", \")` |\n| **Moderada** (5-10) | Preocupante | `r paste(names(vif_valores[vif_valores >= 5 & vif_valores < 10]), collapse = \", \")` |\n| **Alta** (≥ 10) | Problemática | `r paste(names(vif_valores[vif_valores >= 10]), collapse = \", \")` |\n\n**Variáveis com Multicolinearidade Severa:**\n```{r}\n#| echo: false\nvif_altos <- vif_valores[vif_valores >= 10]\nknitr::kable(data.frame(\n  Variável = names(vif_altos),\n  Descrição = sapply(names(vif_altos), obter_descricao),\n  VIF = round(vif_altos, 2)\n), row.names = FALSE)\n```\n\n### Estágio 4: Estimação do Modelo Discriminante e Avaliação do Ajuste Geral\n\n#### 4.1 Método Stepwise\n\n```{r}\nlibrary(klaR)\nlibrary(MASS)\n\n# Implementando stepwise manual baseado em critérios estatísticos\nf_univariados <- numeric(length(variaveis_independentes))\np_univariados <- numeric(length(variaveis_independentes))\nnames(f_univariados) <- variaveis_independentes\nnames(p_univariados) <- variaveis_independentes\n\nfor(i in seq_along(variaveis_independentes)) {\n  var <- variaveis_independentes[i]\n  formula_temp <- as.formula(paste(var, \"~ X1\"))\n  \n  tryCatch({\n    anova_temp <- aov(formula_temp, data = amostra_analise)\n    anova_summary <- summary(anova_temp)\n    f_univariados[i] <- anova_summary[[1]][\"X1\", \"F value\"]\n    p_univariados[i] <- anova_summary[[1]][\"X1\", \"Pr(>F)\"]\n  }, error = function(e) {\n    f_univariados[i] <- 0\n    p_univariados[i] <- 1\n  })\n}\n\n# Ordenando variáveis por poder discriminante\nordem_importancia <- order(f_univariados, decreasing = TRUE)\nvars_ordenadas <- variaveis_independentes[ordem_importancia]\nvars_significativas <- names(p_univariados[p_univariados < 0.05])\n\n# Testando modelo Hair et al.: X6 + X18\nformula_hair <- as.formula(\"cbind(X6, X18) ~ X1\")\nmanova_hair <- manova(formula_hair, data = amostra_analise)\nresultado_hair <- summary(manova_hair, test = \"Wilks\")\n\nmodelo_stepwise <- list(\n  formula = \"X1 ~ X6 + X18\",\n  selected_vars = c(\"X6\", \"X18\"),\n  wilks_lambda = resultado_hair$stats[\"X1\", \"Wilks\"],\n  f_statistic = resultado_hair$stats[\"X1\", \"approx F\"],\n  p_value = resultado_hair$stats[\"X1\", \"Pr(>F)\"]\n)\n```\n\n**Análise Univariada de Variáveis:**\n\n**Ranking por Poder Discriminante (Top 5):**\n```{r}\n#| echo: false\ntop5 <- data.frame(\n  Posição = 1:5,\n  Variável = vars_ordenadas[1:5],\n  Descrição = sapply(vars_ordenadas[1:5], obter_descricao),\n  `F-value` = round(f_univariados[vars_ordenadas[1:5]], 3),\n  `p-valor` = round(p_univariados[vars_ordenadas[1:5]], 4),\n  Significância = ifelse(p_univariados[vars_ordenadas[1:5]] < 0.001, \"***\",\n                        ifelse(p_univariados[vars_ordenadas[1:5]] < 0.01, \"**\",\n                              ifelse(p_univariados[vars_ordenadas[1:5]] < 0.05, \"*\", \"\")))\n)\nknitr::kable(top5, row.names = FALSE)\n```\n\n**Modelo Stepwise Final:**\n\n- **Fórmula selecionada**: `r modelo_stepwise$formula`\n- **Variáveis incluídas**: `r paste(modelo_stepwise$selected_vars, collapse = \" + \")`\n- **Lambda de Wilks**: `r round(modelo_stepwise$wilks_lambda, 4)`\n- **Estatística F**: `r round(modelo_stepwise$f_statistic, 3)`\n- **p-valor**: `r formatC(modelo_stepwise$p_value, format = \"e\", digits = 3)`\n- **Total de variáveis significativas**: `r length(vars_significativas)` de `r length(variaveis_independentes)`\n\n**Justificativa da Seleção:**\nEmbora `r vars_ordenadas[1]` seja a variável mais discriminante univariadamente, seguimos o exemplo de Hair et al. usando X6 (Product Quality) + X18 (Delivery Speed) por razões teóricas e interpretabilidade gerencial.\n\n#### 4.2 Análise Discriminante Linear\n\n```{r}\n# Modelo final conforme Hair et al. (X6 e X18)\nmodelo_final <- lda(X1 ~ X6 + X18, data = amostra_analise)\n\n# Autovalores e variância explicada\neigenvalues <- modelo_final$svd^2\nvariancia_explicada <- eigenvalues / sum(eigenvalues) * 100\n```\n\nO modelo discriminante final utiliza as variáveis X6 (Product Quality) e X18 (Delivery Speed), seguindo o exemplo de Hair et al.\n\n**Características do Modelo:**\n\n- **Número de funções discriminantes**: `r length(eigenvalues)`\n- **Variância explicada pela Função 1**: `r round(variancia_explicada[1], 1)`%\n- **Variância explicada pela Função 2**: `r round(variancia_explicada[2], 1)`%\n- **Variância total explicada**: `r round(sum(variancia_explicada), 1)`%\n\n**Autovalores:**\n```{r}\n#| echo: false\nknitr::kable(data.frame(\n  Função = paste(\"LD\", 1:length(eigenvalues)),\n  Autovalor = round(eigenvalues, 4),\n  `Variância Explicada (%)` = round(variancia_explicada, 1)\n), row.names = FALSE)\n```\n\n#### 4.3 Significância Estatística\n\nO teste de significância avalia se o modelo discriminante é estatisticamente significativo.\n\n```{r}\nmodelo_manova <- manova(cbind(X6, X18) ~ X1, data = amostra_analise)\nsummary(modelo_manova, test = \"Wilks\")\n\nsummary.aov(modelo_manova)\n```\n\n**Interpretação dos Resultados de Significância:**\n\n**Teste MANOVA (Multivariado):**\n- **Lambda de Wilks = 0.29005**: Valor baixo indica boa discriminação entre grupos\n- **F aproximado = 23.99**: Estatística F alta sugere diferenças significativas\n- **p-valor = 2.388e-14**: Altamente significativo (p < 0.001)\n- **Conclusão**: O modelo discriminante é estatisticamente significativo\n\n**Análises Univariadas por Variável:**\n\n**X6 (Product Quality):**\n- **F = 22.885**: Alta capacidade discriminante individual\n- **p-valor = 5.062e-08**: Altamente significativo\n- **Interpretação**: A qualidade do produto varia significativamente entre os grupos de tempo de relacionamento\n\n**X18 (Delivery Speed):**\n- **F = 24.425**: Maior capacidade discriminante individual entre as duas variáveis\n- **p-valor = 2.182e-08**: Altamente significativo  \n- **Interpretação**: A percepção da velocidade de entrega é o melhor discriminador individual entre os grupos\n\n**Implicações Gerenciais:**\n1. Ambas as variáveis contribuem significativamente para distinguir os grupos\n2. Velocidade de entrega (X18) é ligeiramente mais discriminante que qualidade (X6)\n3. O modelo como um todo tem poder discriminante muito forte\n4. As percepções evoluem significativamente com o tempo de relacionamento\n\n#### 4.4 Centróides dos Grupos\n\nOs centróides representam o \"centro\" de cada grupo no espaço discriminante.\n\n```{r}\ncentroides <- aggregate(amostra_analise[, c(\"X6\", \"X18\")], \n                       by = list(amostra_analise$X1), FUN = mean)\nnames(centroides)[1] <- \"Grupo\"\n\npredict_centroides <- predict(modelo_final, centroides[, c(\"X6\", \"X18\")])\ncentroides_discriminantes <- predict_centroides$x\nrownames(centroides_discriminantes) <- centroides$Grupo\nprint(\"\\nCentróides no Espaço Discriminante:\")\nprint(centroides_discriminantes)\n```\n\n**Análise dos Centróides no Espaço Discriminante:**\n\n**Posicionamento dos Grupos:**\n\n| Grupo | LD1 | LD2 | Interpretação |\n|-------|-----|-----|---------------|\n| Menos de 1 ano | -1.61 | 0.31 | Percepções mais baixas, posicionamento único |\n| De 1 a 5 anos | 0.26 | -0.71 | Percepções intermediárias, diferenciação moderada |\n| Mais de 5 anos | 1.47 | 0.53 | Percepções mais elevadas, alta satisfação |\n\n**Padrões Identificados:**\n\n1. **Evolução Linear em LD1**: Os valores de LD1 crescem progressivamente (-1.61 → 0.26 → 1.47), indicando melhoria das percepções com o tempo de relacionamento\n\n2. **Separação Clara**: A distância entre centróides confirma que os grupos são bem diferenciados no espaço discriminante\n\n3. **Trajetória de Relacionamento**: \n   - **Clientes novos** (< 1 ano): Expectativas em formação, percepções iniciais mais críticas\n   - **Clientes intermediários** (1-5 anos): Período de consolidação das percepções\n   - **Clientes estabelecidos** (> 5 anos): Relacionamento maduro, percepções mais positivas\n\n**Interpretação das Funções Discriminantes:**\n\n- **LD1**: Representa principalmente a **evolução temporal** das percepções (experiência acumulada)\n- **LD2**: Representa **diferenças qualitativas** específicas entre os grupos intermediários e extremos\n\n**Implicações Estratégicas:**\n- Foco na **retenção inicial**: Clientes novos precisam de atenção especial\n- **Gestão da jornada**: Processo gradual de melhoria das percepções\n- **Fidelização**: Clientes de longo prazo são verdadeiros advogados da marca\n\n### Estágio 5: Interpretação dos Resultados\n\n#### 5.1 Cargas Discriminantes (Matriz Estrutural)\n\nAs cargas discriminantes mostram a correlação entre cada variável independente e as funções discriminantes.\n\n```{r}\n# Calculando cargas discriminantes (correlações entre variáveis e funções)\n# Escores discriminantes para todas as observações\nescores_discriminantes <- predict(modelo_final, amostra_analise)$x\n\n# Matriz de cargas (correlações)\nvariaveis_completas <- amostra_analise[, variaveis_independentes]\ncargas_discriminantes <- cor(variaveis_completas, escores_discriminantes)\n\nprint(\"Matriz de Cargas Discriminantes (não-rotacionadas):\")\nprint(round(cargas_discriminantes, 3))\n\n# Identificando variáveis descritivas (|carga| >= 0.40)\ncargas_importantes <- abs(cargas_discriminantes) >= 0.40\nprint(\"\\nVariáveis Descritivas por Função (|carga| >= 0.40):\")\nfor(i in 1:ncol(cargas_discriminantes)) {\n  cat(\"Função\", i, \":\", names(which(cargas_importantes[, i])), \"\\n\")\n}\n```\n\n**Interpretação da Matriz de Cargas Discriminantes:**\n\n**Análise da Função Discriminante 1 (LD1):**\n\n**Variáveis com Cargas Altas (|carga| ≥ 0.40):**\n- **X11 (Product Line)**: 0.773 - Maior contribuição para LD1\n- **X18 (Delivery Speed)**: 0.765 - Forte correlação positiva\n- **X6 (Product Quality)**: 0.736 - Alta correlação positiva  \n- **X9 (Complaint Resolution)**: 0.728 - Contribuição significativa\n- **X16 (Ordering & Billing)**: 0.699 - Forte correlação\n\n**Interpretação de LD1**: Representa a **dimensão geral de satisfação** com aspectos operacionais e de qualidade da HBAT. Valores altos indicam percepções positivas em qualidade, entrega, linha de produtos e resolução de problemas.\n\n**Análise da Função Discriminante 2 (LD2):**\n\n**Variáveis com Cargas Altas (|carga| ≥ 0.40):**\n- **X17 (Price Flexibility)**: -0.699 - Maior magnitude (negativa)\n- **X6 (Product Quality)**: 0.677 - Correlação positiva forte\n- **X18 (Delivery Speed)**: -0.644 - Correlação negativa significativa\n- **X9 (Complaint Resolution)**: -0.467 - Contribuição moderada negativa\n- **X16 (Ordering & Billing)**: -0.416 - Correlação negativa\n- **X12 (Salesforce Image)**: -0.418 - Contribuição moderada negativa\n\n**Interpretação de LD2**: Representa um **contraste entre qualidade percebida** versus **flexibilidade operacional**. Separa grupos com diferentes prioridades: qualidade versus agilidade/flexibilidade.\n\n#### 5.2 Rotação VARIMAX\n\n```{r}\n# Aplicando rotação VARIMAX às cargas discriminantes\nlibrary(stats)\n\nif(ncol(cargas_discriminantes) > 1) {\n  rotacao_varimax <- varimax(cargas_discriminantes)\n  cargas_rotacionadas <- rotacao_varimax$loadings[]\n  \n  print(\"Matriz de Cargas Discriminantes (rotacionadas - VARIMAX):\")\n  print(round(cargas_rotacionadas, 3))\n  \n  # Variáveis descritivas após rotação\n  cargas_rot_importantes <- abs(cargas_rotacionadas) >= 0.40\n  print(\"\\nVariáveis Descritivas por Função Rotacionada (|carga| >= 0.40):\")\n  for(i in 1:ncol(cargas_rotacionadas)) {\n    cat(\"Função\", i, \":\", names(which(cargas_rot_importantes[, i])), \"\\n\")\n  }\n} else {\n  cargas_rotacionadas <- cargas_discriminantes\n  print(\"Apenas uma função discriminante - rotação não aplicável\")\n}\n```\n\n**Interpretação das Cargas Rotacionadas (VARIMAX):**\n\nA rotação VARIMAX simplifica a estrutura, criando fatores mais interpretáveis:\n\n**Função 1 Rotacionada:**\n- **X6 (Product Quality)**: 1.000 - Carga perfeitamente concentrada\n- **X11 (Product Line)**: 0.538 - Contribuição moderada\n- **X17 (Price Flexibility)**: -0.462 - Contribuição negativa moderada\n\n**Interpretação**: LD1 rotacionada representa essencialmente a **\"Dimensão de Qualidade\"**, contrastando qualidade percebida com flexibilidade de preços.\n\n**Função 2 Rotacionada:**\n- **X18 (Delivery Speed)**: -0.992 - Concentração quase perfeita (negativa)\n- **X9 (Complaint Resolution)**: -0.836 - Alta correlação negativa  \n- **X16 (Ordering & Billing)**: -0.779 - Correlação negativa forte\n- **X11 (Product Line)**: -0.558 - Contribuição moderada\n- **X17 (Price Flexibility)**: -0.524 - Contribuição moderada\n\n**Interpretação**: LD2 rotacionada representa a **\"Dimensão Operacional\"**, focando em velocidade, eficiência e aspectos transacionais.\n\n**Vantagem da Rotação:**\n- **Simplifica interpretação**: Cada função tem foco mais claro\n- **Reduz ambiguidade**: Menos variáveis com cargas altas em múltiplas funções\n- **Facilita comunicação gerencial**: Dimensões mais intuitivas\n\n#### 5.3 Índice de Potência\n\n```{r}\n# Calculando índice de potência conforme Hair et al.\nif(ncol(cargas_discriminantes) > 1) {\n  # Autovalores relativos\n  autovalores_relativos <- eigenvalues / sum(eigenvalues)\n  \n  # Índice de potência para cada variável\n  indice_potencia <- numeric(nrow(cargas_rotacionadas))\n  names(indice_potencia) <- rownames(cargas_rotacionadas)\n  \n  for(i in 1:nrow(cargas_rotacionadas)) {\n    potencia_total <- 0\n    for(j in 1:ncol(cargas_rotacionadas)) {\n      potencia_total <- potencia_total + (cargas_rotacionadas[i, j]^2 * autovalores_relativos[j])\n    }\n    indice_potencia[i] <- potencia_total\n  }\n  \n  # Ordenando por índice de potência\n  indice_potencia_ordenado <- sort(indice_potencia, decreasing = TRUE)\n  \n  print(\"Índice de Potência das Variáveis:\")\n  print(round(indice_potencia_ordenado, 3))\n}\n```\n\n**Interpretação do Índice de Potência:**\n\nO índice de potência combina a contribuição de cada variável em todas as funções, ponderada pela importância relativa de cada função:\n\n**Ranking por Poder Discriminante Total:**\n\n| Posição | Variável | Descrição | Índice | Interpretação |\n|---------|----------|-----------|--------|---------------|\n| 1º | X6 | Product Quality | 0.835 | **Discriminador principal** - fundamental para diferenciação |\n| 2º | X11 | Product Line | 0.293 | **Segundo mais importante** - variedade de produtos relevante |\n| 3º | X17 | Price Flexibility | 0.224 | **Terceiro lugar** - flexibilidade de preços diferencia grupos |\n| 4º | X18 | Delivery Speed | 0.176 | **Quarto lugar** - velocidade importante apesar de estar no modelo |\n| 5º | X9 | Complaint Resolution | 0.157 | **Moderadamente importante** - resolução de problemas diferencia |\n\n**Insights Principais:**\n\n1. **X6 (Product Quality)** é o discriminador dominante, responsável por mais de 83% do poder discriminante total\n2. **X18 (Delivery Speed)**, apesar de estar no modelo final, ocupa apenas a 4ª posição no índice de potência\n3. **X11 (Product Line)** aparece como segundo mais importante, sugerindo que variedade de produtos é crucial\n4. A **concentração de poder** nas primeiras variáveis indica que poucas dimensões explicam a maior parte da discriminação\n\n**Implicações Gerenciais:**\n- **Prioridade máxima**: Investir em qualidade do produto\n- **Segunda prioridade**: Expandir e melhorar linha de produtos\n- **Terceira prioridade**: Desenvolver flexibilidade de preços\n- **Monitoramento**: Acompanhar velocidade de entrega e resolução de reclamações\n\n#### 5.4 Razões F Univariadas\n\n```{r}\n# Calculando razões F univariadas para cada variável\nrazoes_f <- numeric(length(variaveis_independentes))\nnames(razoes_f) <- variaveis_independentes\n\nfor(var in variaveis_independentes) {\n  formula_temp <- as.formula(paste(var, \"~ X1\"))\n  anova_temp <- aov(formula_temp, data = amostra_analise)\n  razoes_f[var] <- summary(anova_temp)[[1]][\"X1\", \"F value\"]\n}\n\n# Ordenando por valor F\nrazoes_f_ordenadas <- sort(razoes_f, decreasing = TRUE)\n\nprint(\"Razões F Univariadas:\")\nprint(round(razoes_f_ordenadas, 3))\n\n# Teste de significância (α = 0.05)\np_valores <- numeric(length(variaveis_independentes))\nnames(p_valores) <- variaveis_independentes\n\nfor(var in variaveis_independentes) {\n  formula_temp <- as.formula(paste(var, \"~ X1\"))\n  anova_temp <- aov(formula_temp, data = amostra_analise)\n  p_valores[var] <- summary(anova_temp)[[1]][\"X1\", \"Pr(>F)\"]\n}\n\nprint(\"\\nVariáveis Significativas (p < 0.05):\")\nprint(names(p_valores[p_valores < 0.05]))\n```\n\n**Interpretação das Razões F Univariadas:**\n\n**Ranking de Poder Discriminante Individual:**\n\n| Posição | Variável | F-value | p-valor | Status | Interpretação |\n|---------|----------|---------|---------|--------|---------------|\n| 1º | X18 (Delivery Speed) | 24.425 | < 0.001 | *** | **Melhor discriminador individual** |\n| 2º | X6 (Product Quality) | 22.885 | < 0.001 | *** | **Segundo melhor discriminador** |\n| 3º | X9 (Complaint Resolution) | 22.739 | < 0.001 | *** | **Terceiro em poder discriminante** |\n| 4º | X11 (Product Line) | 20.721 | < 0.001 | *** | **Quarto colocado significativo** |\n| 5º | X16 (Ordering & Billing) | 17.664 | < 0.001 | *** | **Quinto em importância** |\n\n**Variáveis Significativas (p < 0.05):** X6, X9, X11, X13, X16, X17, X18 (7 de 13 variáveis)\n\n**Comparação: Poder Individual vs. Poder Combinado:**\n\n1. **X18 (Delivery Speed)**: \n   - Individual: 1º lugar (F = 24.425)\n   - Combinado: 4º lugar (Índice = 0.176)\n   - **Interpretação**: Excelente discriminador individual, mas com alguma redundância no modelo conjunto\n\n2. **X6 (Product Quality)**:\n   - Individual: 2º lugar (F = 22.885)  \n   - Combinado: 1º lugar (Índice = 0.835)\n   - **Interpretação**: Forte individual e dominante no modelo conjunto\n\n**Insights sobre Seleção de Variáveis:**\n\n- **Critério Hair et al.**: Usar X6 + X18 é justificado pelo alto poder discriminante individual de ambas\n- **Potencial de otimização**: X9 (Complaint Resolution) tem poder individual muito alto e poderia ser considerada\n- **Redundância**: Várias variáveis significativas sugerem multicolinearidade (confirmada pelos VIF altos)\n\n**Recomendações Gerenciais:**\n1. **Foco primário**: Delivery Speed e Product Quality (variáveis do modelo)\n2. **Foco secundário**: Complaint Resolution (alto poder discriminante individual)  \n3. **Monitoramento**: Product Line e Ordering & Billing (significativas e importantes)\n4. **Revisão**: Considerar modelo expandido incluindo X9 para melhor discriminação\n\n#### 5.5 Gráfico de Vetores de Atribuição no Espaço Discriminante\n\n```{r}\n# Gráfico dos valores F univariados com descrições\nf_df <- data.frame(\n  Variavel = names(f_univariados),\n  F_Value = f_univariados,\n  P_Value = p_univariados,\n  Significativo = p_univariados < 0.05\n) %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\np_f_values <- ggplot2::ggplot(f_df, ggplot2::aes(x = reorder(Variavel_Desc, F_Value), \n                                                 y = F_Value, fill = Significativo)) +\n  ggplot2::geom_col(alpha = 0.8) +\n  ggplot2::geom_text(ggplot2::aes(label = round(F_Value, 1)), hjust = -0.1, size = 3) +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"TRUE\" = \"steelblue\", \"FALSE\" = \"gray70\"),\n                            labels = c(\"FALSE\" = \"Não Significativo\", \"TRUE\" = \"Significativo\")) +\n  ggplot2::labs(title = \"Valores F Univariados para Seleção de Variáveis\",\n                subtitle = \"Poder discriminante individual de cada variável\",\n                x = \"Variáveis\", y = \"Estatística F\",\n                fill = \"Significância\\n(p < 0.05)\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.y = ggplot2::element_text(size = 9))\n\nprint(p_f_values)\n\n# Criando gráfico de vetores de atribuição (variáveis no espaço discriminante)\nescores_todos <- predict(modelo_final, amostra_analise)$x\ndf_escores <- data.frame(\n  Funcao1 = escores_todos[, 1],\n  Funcao2 = escores_todos[, 2],\n  Grupo = amostra_analise$X1,\n  Probabilidades = apply(predict(modelo_final, amostra_analise)$posterior, 1, max)\n)\n\n# Adicionando centróides\ndf_centroides <- data.frame(\n  Funcao1 = centroides_discriminantes[, 1],\n  Funcao2 = centroides_discriminantes[, 2],\n  Grupo = factor(rownames(centroides_discriminantes), \n                levels = levels(amostra_analise$X1))\n)\n\n# Escalonando as cargas para melhor visualização\nescala_vetor <- 3  # Fator de escala para os vetores\ncargas_escalonadas <- cargas_discriminantes * escala_vetor\n\n# Preparando dados dos vetores com descrições\nvetores_df <- data.frame(\n  Variavel = rownames(cargas_discriminantes),\n  LD1_start = 0,\n  LD2_start = 0,\n  LD1_end = cargas_escalonadas[, 1],\n  LD2_end = cargas_escalonadas[, 2],\n  Magnitude = sqrt(cargas_discriminantes[, 1]^2 + cargas_discriminantes[, 2]^2),\n  Significativa = rownames(cargas_discriminantes) %in% vars_significativas\n) %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\n# Gráfico de vetores de atribuição expandidos\np_vetores <- ggplot2::ggplot() +\n  # Pontos dos grupos (mais transparentes para não ofuscar os vetores)\n  ggplot2::geom_point(data = df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo), \n                      alpha = 0.3, size = 1) +\n  # Centróides dos grupos\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 6, shape = 17, color = \"black\") +\n  # LABELS DOS CENTRÓIDES - NOVO\n  ggplot2::geom_text(data = df_centroides, \n                     ggplot2::aes(x = Funcao1, y = Funcao2, label = Grupo),\n                     vjust = -1.5, hjust = 0.5, color = \"black\", \n                     fontface = \"bold\", size = 3.5,\n                     box.padding = 0.5) +\n  # Vetores das variáveis\n  ggplot2::geom_segment(data = vetores_df,\n                        ggplot2::aes(x = LD1_start, y = LD2_start, \n                                     xend = LD1_end, yend = LD2_end,\n                                     color = Significativa, size = Magnitude),\n                        arrow = ggplot2::arrow(length = ggplot2::unit(0.3, \"cm\")),\n                        alpha = 0.8) +\n  # Labels das variáveis com descrições\n  ggplot2::geom_text(data = vetores_df,\n                     ggplot2::aes(x = LD1_end * 1.1, y = LD2_end * 1.1, \n                                  label = Variavel_Desc, color = Significativa),\n                     size = 2.5, fontface = \"bold\") +\n  # Eixos de referência\n  ggplot2::geom_hline(yintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  ggplot2::geom_vline(xintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  # Escalas e temas\n  ggplot2::scale_color_manual(values = c(\"FALSE\" = \"gray50\", \"TRUE\" = \"red\")) +\n  ggplot2::scale_size_continuous(range = c(0.5, 2), guide = \"none\") +\n  ggplot2::labs(title = \"Vetores de Atribuição das Variáveis no Espaço Discriminante\",\n                subtitle = paste(\"Vetores mostram contribuição das variáveis para as funções discriminantes\\n\",\n                                \"Triângulos pretos = centróides dos grupos | Escala dos vetores: \", escala_vetor, \"x\"),\n                x = paste(\"Função Discriminante 1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"Função Discriminante 2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Variável\\nSignificativa\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 plot.subtitle = ggplot2::element_text(size = 10))\n\nprint(p_vetores)\n\n# IDENTIFICAÇÃO DOS GRUPOS DA VARIÁVEL DEPENDENTE\ncat(\"\\n=== IDENTIFICAÇÃO DOS GRUPOS DA VARIÁVEL DEPENDENTE ===\\n\")\ncat(\"Variável Dependente: X1 (Customer Type)\\n\")\ncat(\"Descrição: Tempo de relacionamento com a empresa HBAT\\n\\n\")\n\n# Grupos identificados no gráfico\ngrupos_identificados <- levels(amostra_analise$X1)\nfreq_grupos <- table(amostra_analise$X1)\ncentroides_info <- centroides_discriminantes\n\ncat(\"GRUPOS REPRESENTADOS NO GRÁFICO:\\n\")\nfor(i in 1:length(grupos_identificados)) {\n  grupo_nome <- grupos_identificados[i]\n  freq <- freq_grupos[i]\n  ld1_pos <- round(centroides_info[grupo_nome, \"LD1\"], 2)\n  ld2_pos <- round(centroides_info[grupo_nome, \"LD2\"], 2)\n  \n  cat(sprintf(\"🔺 GRUPO %d: %s\\n\", i, grupo_nome))\n  cat(sprintf(\"   - Frequência: %d casos (%.1f%%)\\n\", \n              freq, (freq/sum(freq_grupos))*100))\n  cat(sprintf(\"   - Posição no gráfico: LD1 = %.2f, LD2 = %.2f\\n\", ld1_pos, ld2_pos))\n  cat(sprintf(\"   - Característica: %s\\n\", \n              switch(i,\n                     \"Clientes com relacionamento recente - percepções iniciais\",\n                     \"Clientes com relacionamento estabelecido - percepções moderadas\", \n                     \"Clientes com relacionamento consolidado - percepções elevadas\")))\n  cat(\"\\n\")\n}\n\n# Interpretação dos centróides no espaço discriminante\ncat(\"INTERPRETAÇÃO DOS CENTRÓIDES (TRIÂNGULOS PRETOS):\\n\")\ncat(\"- Os triângulos pretos representam o 'centro' de cada grupo no espaço discriminante\\n\")\ncat(\"- Sua posição indica as características médias de cada grupo\\n\")\ncat(\"- A distância entre centróides mostra o grau de separação entre grupos\\n\")\n\n# Análise das posições dos centróides\ncat(\"\\nANÁLISE DAS POSIÇÕES:\\n\")\nfor(i in 1:nrow(centroides_info)) {\n  grupo_nome <- rownames(centroides_info)[i]\n  ld1_val <- centroides_info[i, \"LD1\"]\n  ld2_val <- centroides_info[i, \"LD2\"]\n  \n  # Interpretação baseada na posição\n  interpretacao_ld1 <- ifelse(ld1_val > 0, \"valores altos em LD1\", \"valores baixos em LD1\")\n  interpretacao_ld2 <- ifelse(ld2_val > 0, \"valores altos em LD2\", \"valores baixos em LD2\")\n  \n  cat(sprintf(\"- %s: Caracterizado por %s e %s\\n\", \n              grupo_nome, interpretacao_ld1, interpretacao_ld2))\n}\n\ncat(\"\\nLEGENDA DO GRÁFICO:\\n\")\ncat(\"🔺 Triângulos pretos = Centróides dos grupos\\n\")\ncat(\"● Pontos coloridos = Observações individuais por grupo\\n\")\ncat(\"→ Vetores vermelhos = Variáveis significativas (p < 0.05)\\n\")\ncat(\"→ Vetores cinza = Variáveis não significativas\\n\")\ncat(\"📏 Comprimento do vetor = Magnitude da contribuição discriminante\\n\")\n\n# Interpretação dos vetores\ncat(\"\\n=== INTERPRETAÇÃO DOS VETORES DE ATRIBUIÇÃO ===\\n\")\n```\n\n#### 6.4 Análise das Distâncias entre Grupos\n\n```{r}\n# Calculando distâncias Mahalanobis entre centróides\ncentroides_matriz <- as.matrix(centroides_discriminantes)\n\n# Matriz de distâncias entre centróides\nn_grupos <- nrow(centroides_matriz)\ndist_centroides <- matrix(0, n_grupos, n_grupos)\nrownames(dist_centroides) <- rownames(centroides_matriz)\ncolnames(dist_centroides) <- rownames(centroides_matriz)\n\nfor(i in 1:n_grupos) {\n  for(j in 1:n_grupos) {\n    dist_centroides[i, j] <- sqrt(sum((centroides_matriz[i, ] - centroides_matriz[j, ])^2))\n  }\n}\n\nprint(\"Matriz de Distâncias Euclidianas entre Centróides:\")\nprint(round(dist_centroides, 3))\n\n# Visualização das distâncias como heatmap\ndist_df <- reshape2::melt(dist_centroides)\nnames(dist_df) <- c(\"Grupo1\", \"Grupo2\", \"Distancia\")\n\np_distancias <- ggplot2::ggplot(dist_df, ggplot2::aes(x = Grupo1, y = Grupo2, fill = Distancia)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = round(Distancia, 2)), \n                     color = \"white\", fontface = \"bold\", size = 5) +\n  ggplot2::scale_fill_viridis_c(name = \"Distância\\nEuclidiana\") +\n  ggplot2::labs(title = \"Matriz de Distâncias entre Centróides dos Grupos\",\n                subtitle = \"Distâncias calculadas no espaço discriminante\",\n                x = \"Grupo\", y = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\nprint(p_distancias)\n\n# Análise de separação\ndist_matrix_upper <- dist_centroides[upper.tri(dist_centroides)]\n\n# Identificando grupos mais próximos e mais distantes\ndist_indices <- which(dist_centroides == min(dist_matrix_upper), arr.ind = TRUE)[1, ]\ngrupos_proximos <- c(rownames(dist_centroides)[dist_indices[1]], \n                    colnames(dist_centroides)[dist_indices[2]])\n\ndist_indices_max <- which(dist_centroides == max(dist_matrix_upper), arr.ind = TRUE)[1, ]\ngrupos_distantes <- c(rownames(dist_centroides)[dist_indices_max[1]], \n                     colnames(dist_centroides)[dist_indices_max[2]])\n```\n\n**Interpretação da Análise de Distâncias:**\n\n**Matriz de Distâncias Euclidianas:**\n- **Menor distância**: \"De 1 a 5 anos\" ↔ \"Mais de 5 anos\" (1.737)\n- **Maior distância**: \"Menos de 1 ano\" ↔ \"Mais de 5 anos\" (3.084)\n- **Distância intermediária**: \"Menos de 1 ano\" ↔ \"De 1 a 5 anos\" (2.127)\n\n**Padrões de Similaridade:**\n\n1. **Grupos Intermediário e Maduro são mais próximos**: \n   - Distância de apenas 1.737 unidades\n   - **Interpretação**: Após 1 ano, as percepções começam a convergir\n   - **Implicação**: O primeiro ano é crítico para formar percepções duradouras\n\n2. **Clientes Novos são mais distantes de todos**:\n   - Maior distância dos clientes maduros (3.084)\n   - **Interpretação**: Período inicial tem características muito distintas\n   - **Implicação**: Estratégias específicas necessárias para novos clientes\n\n3. **Progressão Não-Linear**:\n   - A evolução \"Novo → Intermediário → Maduro\" não é uniforme\n   - Maior salto entre \"Novo\" e \"Intermediário\" (2.127)\n   - Menor progressão entre \"Intermediário\" e \"Maduro\" (1.737)\n\n**Insights Gerenciais:**\n\n- **Período Crítico**: Os primeiros 12 meses são fundamentais para retenção\n- **Convergência**: Após 1 ano, clientes tendem a desenvolver percepções similares\n- **Segmentação**: Dois grandes segmentos emergem: \"Novos\" vs. \"Estabelecidos\" (intermediários + maduros)\n\n#### 6.5 Comparação Visual: Espaço Original vs. Espaço Discriminante\n\n```{r}\n# Comparando visualização no espaço original (X6, X18) vs. espaço discriminante\np_original <- ggplot2::ggplot(amostra_analise, ggplot2::aes(x = X6, y = X18, color = X1)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = centroides, ggplot2::aes(x = X6, y = X18), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Espaço Original\",\n                subtitle = \"Variáveis originais do modelo discriminante\",\n                x = descricoes_variaveis[\"X6\"], \n                y = descricoes_variaveis[\"X18\"],\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 12, face = \"bold\"))\n\np_discriminante <- ggplot2::ggplot(df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Espaço Discriminante (LD1 vs LD2)\",\n                subtitle = \"Funções discriminantes otimizadas para separação\",\n                x = paste(\"LD1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"LD2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 12, face = \"bold\"))\n\n# Combinando os gráficos\ncomparacao <- gridExtra::grid.arrange(\n  p_original, p_discriminante, \n  ncol = 2,\n  top = grid::textGrob(\"Comparação: Espaço Original vs. Espaço Discriminante\", \n                       gp = grid::gpar(fontsize = 16, fontface = \"bold\"))\n)\n\nprint(comparacao)\n\n# Interpretação da comparação\ncat(\"\\n=== INTERPRETAÇÃO DA COMPARAÇÃO ===\\n\")\ncat(\"- Espaço Original: mostra sobreposição entre grupos\\n\")\ncat(\"- Espaço Discriminante: maximiza separação entre grupos\\n\")\ncat(\"- A transformação discriminante melhora a separabilidade\\n\")\ncat(\"- LD1 e LD2 são combinações lineares que maximizam discriminação\\n\")\n```\n\n### Estágio 6: Validação dos Resultados\n\n#### 6.6 Matriz de Classificação e Validação\n\n```{r}\n# Classificação da amostra de análise\npredicoes_analise <- predict(modelo_final, amostra_analise)\nmatriz_confusao_analise <- table(Predito = predicoes_analise$class, \n                                Real = amostra_analise$X1)\n\nprint(\"Matriz de Classificação - Amostra de Análise:\")\nprint(matriz_confusao_analise)\n\n# Taxa de acerto geral\nacerto_geral_analise <- sum(diag(matriz_confusao_analise)) / sum(matriz_confusao_analise)\n\n# Taxa de acerto por grupo\nacerto_por_grupo_analise <- diag(matriz_confusao_analise) / rowSums(matriz_confusao_analise)\nprint(\"Taxa de Acerto por Grupo (Análise):\")\nprint(round(acerto_por_grupo_analise * 100, 1))\n\n# Visualização da matriz de confusão\nmatriz_conf_df <- as.data.frame(matriz_confusao_analise)\nnames(matriz_conf_df) <- c(\"Predito\", \"Real\", \"Freq\")\n\np_matriz_conf <- ggplot2::ggplot(matriz_conf_df, ggplot2::aes(x = Real, y = Predito, fill = Freq)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = Freq), color = \"white\", size = 6, fontface = \"bold\") +\n  ggplot2::scale_fill_viridis_c(name = \"Frequência\") +\n  ggplot2::labs(title = \"Matriz de Confusão - Amostra de Análise\",\n                subtitle = paste(\"Taxa de Acerto Geral:\", round(acerto_geral_analise * 100, 1), \"%\"),\n                x = \"Grupo Real\", y = \"Grupo Predito\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\nprint(p_matriz_conf)\n```\n\n**Taxa de Acerto Geral (Análise)**: `r round(acerto_geral_analise * 100, 1)`%\n\n**Taxa de Acerto por Grupo (Análise)**:\n```{r}\n#| echo: false\nknitr::kable(data.frame(\n  Grupo = names(acerto_por_grupo_analise),\n  `Taxa de Acerto (%)` = round(acerto_por_grupo_analise * 100, 1)\n), row.names = FALSE)\n```\n\n#### 6.7 Validação Cruzada\n\n```{r}\n# Função para validação cruzada\nvalidacao_cruzada <- function(dados, formula) {\n  n <- nrow(dados)\n  predicoes <- character(n)\n  \n  for(i in 1:n) {\n    # Treina modelo sem a observação i\n    dados_treino <- dados[-i, ]\n    modelo_temp <- MASS::lda(formula, data = dados_treino)\n    \n    # Prediz a observação i\n    predicao_temp <- predict(modelo_temp, dados[i, ])\n    predicoes[i] <- as.character(predicao_temp$class)\n  }\n  \n  return(factor(predicoes, levels = levels(dados$X1)))\n}\n\n# Aplicando validação cruzada\npredicoes_cv <- validacao_cruzada(amostra_analise, X1 ~ X6 + X18)\nmatriz_confusao_cv <- table(Predito = predicoes_cv, Real = amostra_analise$X1)\n\nprint(\"Matriz de Classificação - Validação Cruzada:\")\nprint(matriz_confusao_cv)\n\n# Taxa de acerto validação cruzada\nacerto_geral_cv <- sum(diag(matriz_confusao_cv)) / sum(matriz_confusao_cv)\n```\n\n**Taxa de Acerto Geral (Validação Cruzada)**: `r round(acerto_geral_cv * 100, 1)`%\n\n#### 6.8 Validação Externa\n\n```{r}\n# Classificação da amostra de validação\npredicoes_validacao <- predict(modelo_final, amostra_validacao)\nmatriz_confusao_validacao <- table(Predito = predicoes_validacao$class, \n                                  Real = amostra_validacao$X1)\n\nprint(\"Matriz de Classificação - Amostra de Validação:\")\nprint(matriz_confusao_validacao)\n\n# Taxa de acerto amostra de validação\nacerto_geral_validacao <- sum(diag(matriz_confusao_validacao)) / sum(matriz_confusao_validacao)\n\n# Taxa de acerto por grupo\nacerto_por_grupo_validacao <- diag(matriz_confusao_validacao) / rowSums(matriz_confusao_validacao)\nprint(\"Taxa de Acerto por Grupo (Validação):\")\nprint(round(acerto_por_grupo_validacao * 100, 1))\n```\n\n**Taxa de Acerto Geral (Validação)**: `r round(acerto_geral_validacao * 100, 1)`%\n\n#### 6.9 Critérios de Chance\n\n```{r}\n# Calculando critérios de chance\ntamanhos_grupos <- table(amostra_analise$X1)\nproporcoes_grupos <- tamanhos_grupos / sum(tamanhos_grupos)\n\n# Critério de chance proporcional\ncriterio_chance_proporcional <- sum(proporcoes_grupos^2) * 100\n\n# Critério de chance máxima\ncriterio_chance_maxima <- max(proporcoes_grupos) * 100\n\n# Gráfico de comparação das taxas de acerto\ntaxas_acerto <- data.frame(\n  Metodo = c(\"Análise\", \"Validação Cruzada\", \"Validação Externa\", \n             \"Critério Proporcional\", \"Critério Máximo\"),\n  Taxa = c(acerto_geral_analise * 100, \n           acerto_geral_cv * 100,\n           acerto_geral_validacao * 100,\n           criterio_chance_proporcional,\n           criterio_chance_maxima),\n  Tipo = c(\"Modelo\", \"Modelo\", \"Modelo\", \"Referência\", \"Referência\")\n)\n\np_performance <- ggplot2::ggplot(taxas_acerto, ggplot2::aes(x = reorder(Metodo, Taxa), y = Taxa, fill = Tipo)) +\n  ggplot2::geom_col(alpha = 0.8, width = 0.7) +\n  ggplot2::geom_text(ggplot2::aes(label = paste0(round(Taxa, 1), \"%\")), \n                     hjust = -0.1, size = 4, fontface = \"bold\") +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"Modelo\" = \"steelblue\", \"Referência\" = \"coral\")) +\n  ggplot2::labs(title = \"Comparação das Taxas de Acerto\",\n                subtitle = \"Modelo vs. Critérios de Chance\",\n                x = \"Método de Validação\", \n                y = \"Taxa de Acerto (%)\",\n                fill = \"Tipo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"))\n\nprint(p_performance)\n```\n\n**Critérios de Chance:**\n\n- **Critério de Chance Proporcional**: `r round(criterio_chance_proporcional, 1)`%\n- **Critério de Chance Máxima**: `r round(criterio_chance_maxima, 1)`%\n\n**Comparação com Resultados Obtidos:**\n\n- Taxa de Acerto Análise: `r round(acerto_geral_analise * 100, 1)`% vs Critério Proporcional: `r round(criterio_chance_proporcional, 1)`%\n- Taxa de Acerto Validação Cruzada: `r round(acerto_geral_cv * 100, 1)`% vs Critério Proporcional: `r round(criterio_chance_proporcional, 1)`%  \n- Taxa de Acerto Validação: `r round(acerto_geral_validacao * 100, 1)`% vs Critério Proporcional: `r round(criterio_chance_proporcional, 1)`%\n\n### Resumo da Interpretação Gerencial\n\nOs resultados da análise discriminante revelam insights importantes sobre a diferenciação de clientes baseada no tempo de relacionamento. Com o dataset completo analisado, identificamos que de 13 variáveis independentes testadas, apenas 2 foram suficientes para uma discriminação efetiva.\n\n#### Principais Descobertas:\n\n1. **Variáveis Discriminantes**: X6 (Product Quality) e X18 (Delivery Speed) são os principais diferenciadores, representando aproximadamente 100% da variância discriminante total.\n\n2. **Precisão do Modelo**: O modelo alcança alta taxa de acertos na amostra de análise, superando significativamente os critérios de chance.\n\n3. **Diferenças entre Grupos**: \n   - **Clientes novos** (< 1 ano): Menores percepções de qualidade e velocidade\n   - **Clientes intermediários** (1-5 anos): Percepções moderadas\n   - **Clientes estabelecidos** (> 5 anos): Maiores percepções de qualidade e velocidade\n\n#### Implicações Gerenciais:\n\n- **Foco na Qualidade**: Investir na melhoria da qualidade do produto é fundamental para reter clientes\n- **Otimização de Entregas**: A velocidade de entrega é um diferencial competitivo crítico\n- **Segmentação**: Os 3 grupos identificados requerem estratégias diferenciadas\n\n```{r}\n# Médias dos grupos para interpretação\nmedias_grupos <- aggregate(amostra_analise[, variaveis_independentes], \n                          by = list(amostra_analise$X1), FUN = mean)\nnames(medias_grupos)[1] <- \"Grupo\"\n\n# Corrigindo erro na impressão das médias dos grupos\nmedias_grupos_numericas <- medias_grupos[, -1]  # Remove coluna 'Grupo'\nrownames(medias_grupos_numericas) <- medias_grupos$Grupo\n\nprint(\"Médias dos Grupos nas Variáveis Independentes:\")\nprint(round(medias_grupos_numericas, 2))\n\ncat(\"\\n=== INTERPRETAÇÃO DAS FUNÇÕES DISCRIMINANTES ===\\n\")\ncat(\"Função 1: Diferencia principalmente entre Grupo 1 e Grupos 2-3\\n\")\ncat(\"Função 2: Diferencia principalmente entre Grupo 3 e Grupos 1-2\\n\")\n\ncat(\"\\n=== VARIÁVEIS MAIS IMPORTANTES ===\\n\")\nif(exists(\"indice_potencia_ordenado\")) {\n  cat(\"Por Índice de Potência:\\n\")\n  print(names(indice_potencia_ordenado)[1:min(5, length(indice_potencia_ordenado))])\n}\n\ncat(\"\\nPor Razão F Univariada:\\n\")\nprint(names(razoes_f_ordenadas)[1:min(5, length(razoes_f_ordenadas))])\n\ncat(\"\\n=== RESUMO FINAL ===\\n\")\ncat(\"Modelo discriminante final: X1 ~ X6 + X18\\n\")\ncat(\"Variáveis selecionadas:\\n\")\ncat(\"- X6: Qualidade do produto\\n\")\ncat(\"- X18: Velocidade de entrega\\n\")\n\nif(exists(\"modelo_stepwise\")) {\n  cat(\"\\nVariáveis selecionadas pelo procedimento stepwise:\\n\")\n  print(modelo_stepwise$formula)\n}\n\ncat(\"\\n=== CONCLUSÕES GERENCIAIS ===\\n\")\ncat(\"1. A qualidade do produto (X6) e velocidade de entrega (X18) são os principais diferenciadores entre os grupos de clientes.\\n\")\ncat(\"2. O modelo consegue discriminar bem entre os três grupos de tempo de relacionamento.\\n\")\ncat(\"3. Clientes de longo prazo valorizam mais qualidade e velocidade de entrega.\\n\")\ncat(\"4. Ações de melhoria devem focar nestas duas dimensões para reter clientes.\\n\")\n```\n\n**Análise das Médias por Grupo:**\n\nOs resultados mostram um padrão claro de evolução das percepções com o tempo de relacionamento, com melhorias progressivas nas percepções de qualidade e velocidade de entrega conforme aumenta o tempo de relacionamento com a empresa.\n\n### Apêndice: Informações Técnicas do Dataset\n\n#### Características do Dataset HBAT\n\n```{r}\n# Informações sobre o dataset após limpeza\ncat(\"=== CARACTERÍSTICAS DO DATASET FINAL ===\\n\")\ncat(\"Total de observações:\", nrow(hbat_clean), \"\\n\")\ncat(\"Variáveis independentes analisadas:\", length(variaveis_independentes), \"\\n\")\ncat(\"Grupos da variável dependente:\", nlevels(hbat_clean$X1), \"\\n\")\n\n# Distribuição dos grupos\ndist_grupos <- table(hbat_clean$X1)\nprop_grupos <- prop.table(dist_grupos) * 100\n\ncat(\"\\nDistribuição dos grupos:\\n\")\nfor(i in 1:length(dist_grupos)) {\n  cat(\"- \", names(dist_grupos)[i], \": \", dist_grupos[i], \" casos (\", \n      round(prop_grupos[i], 1), \"%)\\n\", sep = \"\")\n}\n```\n\n#### Qualidade dos Dados\n\n- **Missing values**: Removidos através de listwise deletion\n- **Balanceamento**: Dataset relativamente balanceado entre os grupos\n- **Escala das variáveis**: Todas as variáveis independentes estão na escala de 0-10\n\n```{r}\n# Informações detalhadas sobre o dataset HBAT\ncat(\"=== INFORMAÇÕES DO DATASET HBAT ===\\n\")\ncat(\"Total de observações:\", nrow(hbat_clean), \"\\n\")\ncat(\"Variáveis independentes:\", length(variaveis_independentes), \"\\n\")\ncat(\"Grupos da variável dependente:\", nlevels(hbat_clean$X1), \"\\n\")\n\n# Descrição das variáveis (baseado nos labels originais) - ATUALIZADO\ncat(\"\\n=== DESCRIÇÃO COMPLETA DAS VARIÁVEIS ===\\n\")\nfor(var in names(descricoes_variaveis)) {\n  cat(var, \"-\", descricoes_variaveis[var], \"\\n\")\n}\n\n# Estatísticas descritivas finais\ncat(\"\\n=== ESTATÍSTICAS DESCRITIVAS FINAIS ===\\n\")\nprint(summary(hbat_clean))\n```\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Índice","toc-title-website":"Nesta página","related-formats-title":"Outros formatos","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Fonte","other-links-title":"Outros Links","code-links-title":"Links de código","launch-dev-container-title":"Iniciar Dev Container","launch-binder-title":"Iniciar Binder","article-notebook-label":"Caderno de Artigo","notebook-preview-download":"Baixar Caderno","notebook-preview-download-src":"Baixar código-fonte","notebook-preview-back":"Voltar ao Artigo","manuscript-meca-bundle":"Arquivo MECA","section-title-abstract":"Resumo","section-title-appendices":"Apêndices","section-title-footnotes":"Notas de rodapé","section-title-references":"Referências","section-title-reuse":"Reuso","section-title-copyright":"Direito autoral","section-title-citation":"Citação","appendix-attribution-cite-as":"Por favor, cite este trabalho como:","appendix-attribution-bibtex":"BibTeX","appendix-view-license":"Visualizar Licença","title-block-author-single":"Autor","title-block-author-plural":"Autores","title-block-affiliation-single":"Afiliação","title-block-affiliation-plural":"Afiliações","title-block-published":"Data de Publicação","title-block-modified":"Data de Modificação","title-block-keywords":"Palavras-chave","callout-tip-title":"Dica","callout-note-title":"Nota","callout-warning-title":"Aviso","callout-important-title":"Importante","callout-caution-title":"Cuidado","code-summary":"Código","code-tools-menu-caption":"Código","code-tools-show-all-code":"Mostrar o código","code-tools-hide-all-code":"Esconder o código","code-tools-view-source":"Ver o código fonte","code-tools-source-code":"Código fonte","tools-share":"Compartilhar","tools-download":"Baixar","code-line":"Linha","code-lines":"Linhas","copy-button-tooltip":"Copiar para a área de transferência","copy-button-tooltip-success":"Copiada","repo-action-links-edit":"Editar essa página","repo-action-links-source":"Ver o código fonte","repo-action-links-issue":"Criar uma issue","back-to-top":"De volta ao topo","search-no-results-text":"Nenhum resultado","search-matching-documents-text":"documentos correspondentes","search-copy-link-title":"Copiar link para a busca","search-hide-matches-text":"Esconder correspondências adicionais","search-more-match-text":"mais correspondência neste documento","search-more-matches-text":"mais correspondências neste documento","search-clear-button-title":"Limpar","search-text-placeholder":"","search-detached-cancel-button-title":"Cancelar","search-submit-button-title":"Enviar","search-label":"Procurar","toggle-section":"Alternar seção","toggle-sidebar":"Alternar barra lateral","toggle-dark-mode":"Alternar modo escuro","toggle-reader-mode":"Alternar modo de leitor","toggle-navigation":"Alternar de navegação","crossref-fig-title":"Figura","crossref-tbl-title":"Tabela","crossref-lst-title":"Listagem","crossref-thm-title":"Teorema","crossref-lem-title":"Lema","crossref-cor-title":"Corolário","crossref-prp-title":"Proposição","crossref-cnj-title":"Conjectura","crossref-def-title":"Definição","crossref-exm-title":"Exemplo","crossref-exr-title":"Exercício","crossref-ch-prefix":"Capítulo","crossref-apx-prefix":"Apêndice","crossref-sec-prefix":"Seção","crossref-eq-prefix":"Equação","crossref-lof-title":"Lista de Figuras","crossref-lot-title":"Lista de Tabelas","crossref-lol-title":"Lista de Listagens","environment-proof-title":"Comprovação","environment-remark-title":"Comentário","environment-solution-title":"Solução","listing-page-order-by":"Ordenar por","listing-page-order-by-default":"Padrão","listing-page-order-by-date-asc":"Mais antigo","listing-page-order-by-date-desc":"O mais novo","listing-page-order-by-number-desc":"Decrescente","listing-page-order-by-number-asc":"Baixo para alto","listing-page-field-date":"Data","listing-page-field-title":"Título","listing-page-field-description":"Descrição","listing-page-field-author":"Autor","listing-page-field-filename":"Nome do arquivo","listing-page-field-filemodified":"Modificada","listing-page-field-subtitle":"Legenda","listing-page-field-readingtime":"Tempo de leitura","listing-page-field-wordcount":"Contagem de palavras","listing-page-field-categories":"Categorias","listing-page-minutes-compact":"{0}Min","listing-page-category-all":"Todos","listing-page-no-matches":"Sem itens correspondentes","listing-page-words":"{0} palavras","listing-page-filter":"Filtro","draft":"Rascunho"},"metadata":{"lang":"pt-BR","fig-responsive":true,"quarto-version":"1.6.40","theme":["cosmo","brand"],"title":"ANÁLISE DISCRIMINANTE","author":[{"name":"Marcus Antonio Cardoso Ramalho","email":"marcus.ramalho@coppead.ufrj.br","affiliations":[{"name":"COPPEAD - UNIVERSIDADE FEDERAL DO RIO DE JANEIRO","address":"Rua Pascoal Lemme, 355","city":"Rio de Janeiro","state":"RJ","postal-code":"21941-918"}]},{"name":"Claudia Regina da Costa de Souza"},{"name":"Ben Hur Correia"}],"date":"today"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}