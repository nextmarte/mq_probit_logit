{"title":"ANÁLISE DISCRIMINANTE, PROBIT E LOGIT - Aplicações na Classificação de Vinhos","markdown":{"yaml":{"title":"ANÁLISE DISCRIMINANTE, PROBIT E LOGIT - Aplicações na Classificação de Vinhos","lang":"pt-BR","author":[{"name":"Marcus Antonio Cardoso Ramalho","email":"marcus.ramalho@coppead.ufrj.br","affiliations":[{"name":"COPPEAD - UNIVERSIDADE FEDERAL DO RIO DE JANEIRO","address":"Rua Pascoal Lemme, 355","city":"Rio de Janeiro","state":"RJ","postal-code":"21941-918"}]},{"name":"Claudia Regina da Costa de Souza"},{"name":"Ben Hur Correia"}],"date":"today","filters":["webr"]},"headingText":"Carregando os pacotes necessários","containsRefs":false,"markdown":"\n\n```{r}\n#| include: false\n\nif (!require(\"MASS\")) install.packages(\"MASS\")\nif (!require(\"klaR\")) install.packages(\"klaR\")\nif (!require(\"car\")) install.packages(\"car\")\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nif (!require(\"corrplot\")) install.packages(\"corrplot\")\nif (!require(\"caret\")) install.packages(\"caret\")\nif (!require(\"skimr\")) install.packages(\"skimr\")\nif (!require(\"MVN\")) install.packages(\"MVN\")\nif (!require(\"biotools\")) install.packages(\"biotools\")\nif (!require(\"GGally\")) install.packages(\"GGally\")\nif (!require(\"nnet\")) install.packages(\"nnet\")\nif (!require(\"pROC\")) install.packages(\"pROC\")\nif (!require(\"tidyr\")) install.packages(\"tidyr\")\nif (!require(\"readr\")) install.packages(\"readr\")\nif (!require(\"haven\")) install.packages(\"haven\")\nif (!require(\"gridExtra\")) install.packages(\"gridExtra\")\nif (!require(\"reshape2\")) install.packages(\"reshape2\")\nif (!require(\"viridis\")) install.packages(\"viridis\")\nif (!require(\"plotly\")) install.packages(\"plotly\")\nif (!require(\"RColorBrewer\")) install.packages(\"RColorBrewer\")\n\nlibrary(MASS)\nlibrary(klaR)\nlibrary(car)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(corrplot)\nlibrary(caret)\nlibrary(skimr)\nlibrary(MVN)\nlibrary(biotools)\nlibrary(GGally)\nlibrary(nnet)\nlibrary(pROC)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(haven)\nlibrary(gridExtra)\nlibrary(reshape2)\nlibrary(viridis)\nlibrary(plotly)\nlibrary(RColorBrewer)\n```\n\n## Análise Discriminante - Exemplo HBAT\n\n### Reprodução do Exemplo de Hair et al. - Dataset HBAT\n\nNesta seção, reproduziremos a análise discriminante apresentada no livro Hair et al., utilizando o dataset HBAT para classificar clientes em três grupos baseados no tempo de relacionamento com a empresa.\n\n### Estágio 1: Objetivos da Análise Discriminante\n\nO objetivo é identificar as características perceptuais que distinguem clientes baseados no tempo de relacionamento:\n- **Grupo 1**: Menos de 1 ano\n- **Grupo 2**: De 1 a 5 anos  \n- **Grupo 3**: Mais de 5 anos\n\n#### Carregamento e Inspeção dos Dados\n\n```{r}\n# Carregando os dados HBAT\nhbat <- haven::read_sav(\"data/hbat.sav\")\n\n# Examinando a estrutura dos dados\nstr(hbat)\nhead(hbat)\n\n# Verificando as variáveis disponíveis\nnames(hbat)\n\n# Examinando as primeiras linhas para entender a estrutura\ndplyr::glimpse(hbat)\n```\n\n#### Visualização Inicial dos Dados\n\n```{r}\n# Gráfico da distribuição da variável dependente\np_dist_grupos <- ggplot2::ggplot(data.frame(x1 = hbat$x1), ggplot2::aes(x = factor(x1))) +\n  ggplot2::geom_bar(fill = \"steelblue\", alpha = 0.7) +\n  ggplot2::geom_text(stat = \"count\", ggplot2::aes(label = after_stat(count)), \n                     vjust = -0.5, size = 4) +\n  ggplot2::labs(title = \"Distribuição dos Grupos por Tempo de Relacionamento\",\n                x = \"Grupo (1=<1 ano, 2=1-5 anos, 3=>5 anos)\",\n                y = \"Frequência\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"))\n\nprint(p_dist_grupos)\n```\n\n#### Identificação das Variáveis Disponíveis\n\n```{r}\n# Identificando as variáveis corretas baseado na estrutura real do dataset\n# Primeiro vamos ver quais variáveis existem realmente\nprint(\"Variáveis disponíveis no dataset:\")\nprint(colnames(hbat))\n\n# Verificando se existem variáveis que correspondem às do exemplo Hair\n# Procurando por padrões de nomes que possam corresponder a X1, X6-X18\npossiveis_vars <- grep(\"^[Xx][0-9]+\", names(hbat), value = TRUE)\nprint(\"Possíveis variáveis X encontradas:\")\nprint(possiveis_vars)\n\n# Se não encontrar, vamos procurar por outras variáveis categóricas e numéricas\ncat(\"\\nEstrutura das primeiras 10 variáveis:\\n\")\nstr(hbat[,1:min(10, ncol(hbat))])\n```\n\n#### Análise das Variáveis Categóricas\n\n```{r}\n# Preparando os dados baseado na estrutura real encontrada\n# Vamos adaptar baseado nas variáveis que realmente existem\n\n# Primeiro, identificar a variável dependente (tempo de relacionamento)\n# Procurar por variáveis categóricas que possam representar grupos de tempo\n\n# Listar variáveis categóricas\nvars_categoricas <- sapply(hbat, function(x) is.factor(x) || length(unique(x)) <= 10)\nprint(\"Variáveis categóricas ou com poucos valores únicos:\")\nprint(names(hbat)[vars_categoricas])\n\n# Examinar algumas variáveis categóricas potenciais\nfor(var in names(hbat)[vars_categoricas][1:min(5, sum(vars_categoricas))]) {\n  cat(\"\\nVariável:\", var, \"\\n\")\n  print(table(hbat[[var]], useNA = \"ifany\"))\n}\n```\n\n#### Definição das Variáveis do Modelo\n\nCom base na inspeção dos dados, identificamos que o dataset HBAT possui exatamente as variáveis necessárias:\n- **x1**: Variável dependente (Customer Type: 1=Menos de 1 ano, 2=De 1 a 5 anos, 3=Mais de 5 anos)\n- **x6-x18**: Variáveis independentes (percepções sobre a HBAT)\n\n```{r}\n# Baseado na inspeção, vamos definir as variáveis corretas\n# O dataset HBAT tem exatamente as variáveis que precisamos!\n# x1 = variável dependente (Customer Type: 1=Less than 1 year, 2=1 to 5 years, 3=Over 5 years)\n# x6-x18 = variáveis independentes (percepções sobre HBAT)\n\n# Agora que sabemos a estrutura, vamos usar as variáveis corretas\nvariavel_dependente <- \"x1\"  # Customer Type - exatamente o que precisamos\nvariaveis_independentes <- paste0(\"x\", 6:18)  # x6 a x18 - percepções\n\ncat(\"Usando variável dependente:\", variavel_dependente, \"\\n\")\ncat(\"Usando variáveis independentes:\", paste(variaveis_independentes, collapse = \", \"), \"\\n\")\n\n# Verificando se x1 tem os valores corretos\ncat(\"\\nValores únicos em x1 (Customer Type):\\n\")\nprint(table(hbat$x1, useNA = \"ifany\"))\n\n# Verificando os labels da variável x1\nif(haven::is.labelled(hbat$x1)) {\n  cat(\"\\nLabels da variável x1:\\n\")\n  print(haven::as_factor(hbat$x1))\n  print(table(haven::as_factor(hbat$x1)))\n}\n```\n\n#### Preparação do Dataset Final\n\n```{r}\n# Criando dataset limpo com as variáveis corretas identificadas\nhbat_clean <- hbat %>%\n  dplyr::select(dplyr::all_of(c(variavel_dependente, variaveis_independentes))) %>%\n  na.omit()\n\n# Converter x1 para fator com os labels corretos do exemplo Hair\nhbat_clean <- hbat_clean %>%\n  dplyr::mutate(\n    X1 = factor(x1, \n                levels = 1:3,\n                labels = c(\"Menos de 1 ano\", \"De 1 a 5 anos\", \"Mais de 5 anos\"))\n  ) %>%\n  dplyr::select(-x1)\n\n# Renomear variáveis independentes para seguir padrão X6-X18 (maiúsculas)\nnomes_independentes <- paste0(\"X\", 6:18)\nnames(hbat_clean)[names(hbat_clean) != \"X1\"] <- nomes_independentes\n\n# Reordenar colunas para X1 ficar primeiro\nhbat_clean <- hbat_clean %>%\n  dplyr::select(X1, dplyr::everything())\n\n# Atualizar lista de variáveis independentes\nvariaveis_independentes <- nomes_independentes\n\n# Criando dicionário de descrições das variáveis\ndescricoes_variaveis <- c(\n  \"X1\" = \"Customer Type\",\n  \"X6\" = \"Product Quality\",\n  \"X7\" = \"E-Commerce Activities\",\n  \"X8\" = \"Technical Support\",\n  \"X9\" = \"Complaint Resolution\",\n  \"X10\" = \"Advertising\",\n  \"X11\" = \"Product Line\",\n  \"X12\" = \"Salesforce Image\",\n  \"X13\" = \"Competitive Pricing\",\n  \"X14\" = \"Warranty & Claims\",\n  \"X15\" = \"New Products\",\n  \"X16\" = \"Ordering & Billing\",\n  \"X17\" = \"Price Flexibility\",\n  \"X18\" = \"Delivery Speed\"\n)\n\n# Função para obter descrição completa da variável\nobter_descricao <- function(var) {\n  if(var %in% names(descricoes_variaveis)) {\n    return(descricoes_variaveis[var])\n  } else {\n    return(var)\n  }\n}\n\n# Verificar se a variável X1 foi criada corretamente\ncat(\"Verificando variável X1:\\n\")\nstr(hbat_clean$X1)\ncat(\"\\nDistribuição da variável X1:\\n\")\nprint(table(hbat_clean$X1))\n\n# Resumo dos dados limpos\ncat(\"\\nEstrutura do dataset limpo:\\n\")\nstr(hbat_clean)\n\ncat(\"\\nResumo dos dados:\\n\")\nsummary(hbat_clean)\n\ncat(\"\\nPrimeiras linhas do dataset limpo:\\n\")\nprint(head(hbat_clean))\n\n# Verificar nomes das colunas finais\ncat(\"\\nNomes das colunas finais:\\n\")\nprint(names(hbat_clean))\n\n# Mostrando descrições das variáveis\ncat(\"\\n=== DESCRIÇÕES DAS VARIÁVEIS ===\\n\")\nfor(var in names(descricoes_variaveis)) {\n  cat(var, \"-\", descricoes_variaveis[var], \"\\n\")\n}\n```\n\n#### Análise Exploratória com Visualizações\n\n```{r}\n# 1. Distribuição final dos grupos\np_grupos_final <- ggplot2::ggplot(hbat_clean, ggplot2::aes(x = X1, fill = X1)) +\n  ggplot2::geom_bar(alpha = 0.8) +\n  ggplot2::geom_text(stat = \"count\", ggplot2::aes(label = after_stat(count)), \n                     vjust = -0.5, size = 4, fontface = \"bold\") +\n  ggplot2::scale_fill_brewer(type = \"qual\", palette = \"Set2\") +\n  ggplot2::labs(title = \"Distribuição Final dos Grupos\",\n                subtitle = paste(\"Total de observações:\", nrow(hbat_clean)),\n                x = descricoes_variaveis[\"X1\"], \n                y = \"Número de Observações\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"none\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\n# 2. Boxplot de todas as variáveis por grupo com descrições\ndados_long <- hbat_clean %>%\n  tidyr::pivot_longer(cols = -X1, names_to = \"Variavel\", values_to = \"Valor\") %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\np_boxplot_all <- ggplot2::ggplot(dados_long, ggplot2::aes(x = X1, y = Valor, fill = X1)) +\n  ggplot2::geom_boxplot(alpha = 0.7) +\n  ggplot2::facet_wrap(~ Variavel_Desc, scales = \"free_y\", ncol = 4) +\n  ggplot2::scale_fill_brewer(type = \"qual\", palette = \"Set2\") +\n  ggplot2::labs(title = \"Distribuição de Todas as Variáveis por Grupo\",\n                x = descricoes_variaveis[\"X1\"], \n                y = \"Valor da Variável\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1),\n                 strip.text = ggplot2::element_text(size = 7))\n\n# 3. Heatmap de médias por grupo com descrições\nmedias_heatmap <- aggregate(hbat_clean[, variaveis_independentes], \n                           by = list(hbat_clean$X1), FUN = mean)\nnames(medias_heatmap)[1] <- \"Grupo\"\n\nmedias_heatmap_long <- medias_heatmap %>%\n  tidyr::pivot_longer(cols = -Grupo, names_to = \"Variavel\", values_to = \"Media\") %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\np_heatmap_medias <- ggplot2::ggplot(medias_heatmap_long, \n                                   ggplot2::aes(x = Variavel_Desc, y = Grupo, fill = Media)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = round(Media, 1)), \n                     color = \"white\", fontface = \"bold\", size = 3) +\n  ggplot2::scale_fill_viridis_c(name = \"Média\") +\n  ggplot2::labs(title = \"Heatmap das Médias das Variáveis por Grupo\",\n                x = \"Variáveis\", y = \"Grupos\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1, size = 8),\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"))\n\n# Exibindo os gráficos\nprint(p_grupos_final)\nprint(p_boxplot_all)\nprint(p_heatmap_medias)\n```\n\n### Estágio 2: Delineamento da Pesquisa de Análise Discriminante\n\nA análise discriminante requer a divisão dos dados em amostras de estimação e validação para avaliar adequadamente o desempenho do modelo. Utilizamos uma divisão de 60% para análise e 40% para validação, resultando em `r nrow(amostra_analise)` casos na amostra de análise e `r nrow(amostra_validacao)` casos na amostra de validação.\n\n```{r}\n# Divisão em amostras de análise e validação\nset.seed(123)\nn_total <- nrow(hbat_clean)\nindices_analise <- sample(1:n_total, size = floor(0.6 * n_total))\n\namostra_analise <- hbat_clean[indices_analise, ]\namostra_validacao <- hbat_clean[-indices_analise, ]\n\ncat(\"Amostra de análise:\", nrow(amostra_analise), \"casos\\n\")\ncat(\"Amostra de validação:\", nrow(amostra_validacao), \"casos\\n\")\n\n# Verificar se X1 existe nas amostras\ncat(\"\\nVerificando X1 na amostra de análise:\\n\")\nif(\"X1\" %in% names(amostra_analise)) {\n  print(table(amostra_analise$X1))\n} else {\n  cat(\"Erro: Variável X1 não encontrada na amostra de análise\\n\")\n  print(names(amostra_analise))\n}\n\ncat(\"\\nDistribuição dos grupos na amostra de validação:\\n\")\nif(\"X1\" %in% names(amostra_validacao)) {\n  print(table(amostra_validacao$X1))\n} else {\n  cat(\"Erro: Variável X1 não encontrada na amostra de validação\\n\")\n  print(names(amostra_validacao))\n}\n\n# Verificar balanceamento dos grupos\nprop_analise <- table(amostra_analise$X1) / nrow(amostra_analise)\nprop_validacao <- table(amostra_validacao$X1) / nrow(amostra_validacao)\n\ncat(\"\\nProporções na amostra de análise:\\n\")\nprint(round(prop_analise, 3))\ncat(\"\\nProporções na amostra de validação:\\n\")\nprint(round(prop_validacao, 3))\n```\n\n### Estágio 3: Pressupostos da Análise Discriminante\n\n#### 3.1 Normalidade Multivariada\n\nO teste de normalidade multivariada é fundamental para verificar se os dados seguem uma distribuição normal multivariada, pressuposto da análise discriminante linear. Testamos cada um dos `r nlevels(amostra_analise$X1)` grupos separadamente usando o teste de Henze-Zirkler.\n\n**Interpretação dos Resultados:**\n\nOs resultados do teste de Henze-Zirkler mostram que:\n- **Grupo \"Menos de 1 ano\"**: p-valor = 0.113 (> 0.05) → ✓ **Normal** - Dados seguem distribuição normal multivariada\n- **Grupo \"De 1 a 5 anos\"**: p-valor = 0.063 (> 0.05) → ✓ **Normal** - Dados seguem distribuição normal multivariada  \n- **Grupo \"Mais de 5 anos\"**: p-valor = 0.035 (< 0.05) → ✗ **Não Normal** - Violação da normalidade multivariada\n\n**Implicações:**\n- Dois dos três grupos atendem ao pressuposto de normalidade multivariada\n- O grupo \"Mais de 5 anos\" apresenta desvio da normalidade, mas este é considerado aceitável na prática\n- A análise discriminante linear suporta pequenos desvios da normalidade, especialmente com amostras de tamanho adequado\n\n```{r}\nlibrary(MVN)\n\nfor(grupo in levels(amostra_analise$X1)) {\n  dados_grupo <- amostra_analise[amostra_analise$X1 == grupo, variaveis_independentes]\n  cat(\"\\n=== Grupo:\", grupo, \"===\\n\")\n  \n  # Usando parâmetros corretos da função mvn\n  resultado_mvn <- mvn(dados_grupo, mvn_test = \"hz\", univariate_test = \"SW\")\n  print(resultado_mvn$multivariate_normality)\n  \n  # Teste alternativo se o primeiro falhar\n  if(is.null(resultado_mvn$multivariate_normality)) {\n    cat(\"Tentando teste alternativo de normalidade...\\n\")\n    resultado_mardia <- mvn(dados_grupo, mvn_test = \"mardia\")\n    print(resultado_mardia$multivariate_normality)\n  }\n}\n```\n\n**Resumo dos Testes de Normalidade:**\n\nCom base nos resultados obtidos, `r sum(c(0.113, 0.063, 0.035) > 0.05)` dos `r nlevels(amostra_analise$X1)` grupos atendem ao pressuposto de normalidade multivariada ao nível de significância de 5%. O grupo que apresentou desvio (p = 0.035) está próximo do limite aceitável, e a análise discriminante pode prosseguir com confiança.\n\n#### 3.2 Homogeneidade das Matrizes de Covariância\n\nO teste M de Box verifica se as matrizes de covariância dos grupos são homogêneas, outro pressuposto importante da análise discriminante. Este teste avalia se as `r length(variaveis_independentes)` variáveis independentes apresentam estruturas de covariância similares entre os grupos.\n\n**Interpretação dos Resultados do Teste M de Box:**\n\n**Conclusão**: Com p-valor = 0.01122 < 0.05, rejeitamos a hipótese nula de homogeneidade das matrizes de covariância. Isso indica que **há diferenças significativas** entre as estruturas de covariância dos grupos.\n\n**Implicações Práticas:**\n- A violação da homogeneidade das covariâncias sugere que a **Análise Discriminante Quadrática (QDA)** poderia ser mais apropriada que a Linear (LDA)\n- No entanto, a LDA é robusta a violações moderadas deste pressuposto, especialmente quando os tamanhos das amostras são similares\n- Como os grupos estão relativamente balanceados (`r paste(table(amostra_analise$X1), collapse = \", \")` casos), podemos prosseguir com cautela usando LDA\n- Os resultados devem ser interpretados considerando esta limitação\n\n```{r}\nlibrary(biotools)\n\ndados_teste <- amostra_analise[, variaveis_independentes]\ngrupos_teste <- amostra_analise$X1\n\n# Teste M de Box com tratamento de erro\ntryCatch({\n  teste_box <- boxM(dados_teste, grupos_teste)\n  print(teste_box)\n}, error = function(e) {\n  cat(\"Teste M de Box não pôde ser executado:\", e$message, \"\\n\")\n  cat(\"Verificando homogeneidade via inspeção visual das matrizes de covariância\\n\")\n  \n  for(grupo in levels(amostra_analise$X1)) {\n    dados_grupo <- amostra_analise[amostra_analise$X1 == grupo, variaveis_independentes]\n    cov_grupo <- cov(dados_grupo)\n    cat(\"\\nMatriz de Covariância - Grupo:\", grupo, \"\\n\")\n    print(round(cov_grupo, 3))\n  }\n})\n```\n\n**Estratégias para Lidar com a Violação:**\n\n1. **Continuar com LDA**: Aceitável dado o balanceamento dos grupos\n2. **Considerar QDA**: Permitiria matrizes de covariância diferentes por grupo\n3. **Validação cruzada rigorosa**: Para avaliar a robustez dos resultados\n4. **Interpretação cautelosa**: Especialmente para predições em novos dados\n\n#### 3.3 Multicolinearidade\n\nA presença de multicolinearidade pode afetar a estabilidade dos resultados da análise discriminante. O determinante da matriz de correlação e os valores VIF nos ajudam a identificar possíveis problemas de multicolinearidade entre as variáveis.\n\n**Interpretação dos Valores VIF:**\n\nOs Fatores de Inflação da Variância (VIF) revelam problemas significativos de multicolinearidade:\n\n- **VIF < 5**: Multicolinearidade baixa (aceitável)\n  - X6 (1.90), X7 (4.56), X8 (4.71), X10 (1.65), X13 (1.76), X14 (4.16), X15 (1.23), X16 (4.33)\n\n- **VIF entre 5-10**: Multicolinearidade moderada (preocupante)\n  - X9 (5.33), X12 (5.78)\n\n- **VIF > 10**: Multicolinearidade alta (problemática)\n  - **X11 (52.77)**, **X17 (41.49)**, **X18 (56.34)**\n\n**Variáveis com Multicolinearidade Severa:**\n- **X11 (Linha de Produtos)**: VIF = 52.77\n- **X17 (Flexibilidade de Preços)**: VIF = 41.49  \n- **X18 (Velocidade de Entrega)**: VIF = 56.34\n\n**Implicações:**\n- As variáveis X11, X17 e X18 apresentam alta correlação com outras variáveis independentes\n- Isso pode causar instabilidade nos coeficientes discriminantes\n- O determinante da matriz de correlação (`r round(det_cor, 6)`) confirma a presença de multicolinearidade\n- Apesar disso, seguimos o exemplo de Hair et al. usando X6 e X18, reconhecendo esta limitação\n\n```{r}\n# Matriz de correlação com visualização aprimorada\nmatriz_cor <- cor(amostra_analise[, variaveis_independentes])\n\n# Gráfico de correlação personalizado\ncorrplot::corrplot(matriz_cor, method = \"color\", type = \"upper\", \n                   order = \"hclust\", tl.cex = 0.8, tl.col = \"black\",\n                   col = RColorBrewer::brewer.pal(n = 8, name = \"RdYlBu\"),\n                   title = \"Matriz de Correlação das Variáveis Independentes\",\n                   mar = c(0,0,2,0))\n\n# Determinante da matriz de correlação\ndet_cor <- det(matriz_cor)\ncat(\"Determinante da matriz de correlação:\", det_cor, \"\\n\")\n\n# VIF para identificar multicolinearidade\nmodelo_temp <- lm(as.numeric(X1) ~ ., data = amostra_analise[, c(\"X1\", variaveis_independentes)])\nvif_valores <- car::vif(modelo_temp)\nprint(\"Fatores de Inflação da Variância (VIF):\")\nprint(vif_valores)\n\n# Gráfico dos valores VIF com descrições\nvif_df <- data.frame(\n  Variavel = names(vif_valores),\n  VIF = as.numeric(vif_valores),\n  Categoria = ifelse(vif_valores > 10, \"Alto (>10)\", \n                    ifelse(vif_valores > 5, \"Moderado (5-10)\", \"Baixo (<5)\"))\n) %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\np_vif <- ggplot2::ggplot(vif_df, ggplot2::aes(x = reorder(Variavel_Desc, VIF), y = VIF, fill = Categoria)) +\n  ggplot2::geom_col(alpha = 0.8) +\n  ggplot2::geom_hline(yintercept = c(5, 10), linetype = \"dashed\", color = \"red\") +\n  ggplot2::geom_text(ggplot2::aes(label = round(VIF, 1)), hjust = -0.1, size = 3) +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"Baixo (<5)\" = \"green\", \n                                       \"Moderado (5-10)\" = \"orange\", \n                                       \"Alto (>10)\" = \"red\")) +\n  ggplot2::labs(title = \"Fatores de Inflação da Variância (VIF)\",\n                subtitle = \"Linhas tracejadas em 5 e 10 indicam limites de multicolinearidade\",\n                x = \"Variáveis\", y = \"VIF\",\n                fill = \"Nível de\\nMulticolinearidade\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.y = ggplot2::element_text(size = 9))\n\nprint(p_vif)\n```\n\n#### Estágio 4: Estimação do Modelo Discriminante e Avaliação do Ajuste Geral\n\n#### 4.1 Método Stepwise\n\nO procedimento stepwise automatiza a seleção de variáveis mais relevantes para a discriminação entre grupos. Implementaremos um procedimento stepwise manual baseado em ANOVAs univariadas e critérios de Wilks Lambda.\n\n```{r}\nlibrary(klaR)\nlibrary(MASS)\n\n# Implementando stepwise manual baseado em critérios estatísticos\n# Testando cada variável individualmente usando ANOVA\n\nprint(\"=== ANÁLISE UNIVARIADA DE CADA VARIÁVEL ===\")\nf_univariados <- numeric(length(variaveis_independentes))\np_univariados <- numeric(length(variaveis_independentes))\nnames(f_univariados) <- variaveis_independentes\nnames(p_univariados) <- variaveis_independentes\n\nfor(i in seq_along(variaveis_independentes)) {\n  var <- variaveis_independentes[i]\n  formula_temp <- as.formula(paste(var, \"~ X1\"))\n  \n  tryCatch({\n    anova_temp <- aov(formula_temp, data = amostra_analise)\n    anova_summary <- summary(anova_temp)\n    f_univariados[i] <- anova_summary[[1]][\"X1\", \"F value\"]\n    p_univariados[i] <- anova_summary[[1]][\"X1\", \"Pr(>F)\"]\n    \n    cat(\"\\nVariável:\", var, \"\\n\")\n    cat(\"F univariado:\", round(f_univariados[i], 3), \"\\n\")\n    cat(\"p-valor:\", round(p_univariados[i], 4), \"\\n\")\n    \n    # Interpretação da significância\n    if(p_univariados[i] < 0.001) {\n      cat(\"*** Altamente significativo\\n\")\n    } else if(p_univariados[i] < 0.01) {\n      cat(\"** Muito significativo\\n\")  \n    } else if(p_univariados[i] < 0.05) {\n      cat(\"* Significativo\\n\")\n    } else {\n      cat(\"Não significativo\\n\")\n    }\n    \n  }, error = function(e) {\n    cat(\"Erro com variável\", var, \":\", e$message, \"\\n\")\n    f_univariados[i] <- 0\n    p_univariados[i] <- 1\n  })\n}\n\n# Ordenando variáveis por poder discriminante (valor F)\nordem_importancia <- order(f_univariados, decreasing = TRUE)\nvars_ordenadas <- variaveis_independentes[ordem_importancia]\n\ncat(\"\\n=== RANKING DE VARIÁVEIS POR PODER DISCRIMINANTE ===\\n\")\nfor(i in 1:length(vars_ordenadas)) {\n  var <- vars_ordenadas[i]\n  cat(sprintf(\"%2d. %s - F = %6.3f, p = %7.4f\", \n              i, var, f_univariados[var], p_univariados[var]))\n  \n  # Indicadores de significância\n  if(p_univariados[var] < 0.001) {\n    cat(\" ***\\n\")\n  } else if(p_univariados[var] < 0.01) {\n    cat(\" **\\n\")  \n  } else if(p_univariados[var] < 0.05) {\n    cat(\" *\\n\")\n  } else {\n    cat(\"\\n\")\n  }\n}\n\n# Selecionando variáveis significativas para o modelo stepwise\nvars_significativas <- names(p_univariados[p_univariados < 0.05])\ncat(\"\\n=== VARIÁVEIS SIGNIFICATIVAS (p < 0.05) ===\\n\")\ncat(\"Total de variáveis significativas:\", length(vars_significativas), \"\\n\")\ncat(\"Variáveis:\", paste(vars_significativas, collapse = \", \"), \"\\n\")\n\n# Procedimento stepwise forward manual usando as top variáveis\ncat(\"\\n=== PROCEDIMENTO STEPWISE FORWARD ===\\n\")\n\n# Corrigindo o teste de uma variável - usando ANOVA ao invés de MANOVA\nvar_top1 <- vars_ordenadas[1]\ncat(\"Testando modelo com variável mais discriminante:\", var_top1, \"\\n\")\n\n# Para uma variável, usamos ANOVA simples\nanova_1var <- aov(as.formula(paste(var_top1, \"~ X1\")), data = amostra_analise)\nf_1var <- summary(anova_1var)[[1]][\"X1\", \"F value\"]\ncat(\"Estatística F (1 variável):\", round(f_1var, 3), \"\\n\")\n\n# Testando modelo com as duas top variáveis (seguindo Hair et al.: X6 e X18)\nvar1 <- \"X6\"  # Qualidade do Produto  \nvar2 <- \"X18\" # Velocidade de Entrega (conforme exemplo do livro)\n\ncat(\"\\nTestando modelo Hair et al.: X6 + X18\\n\")\nformula_hair <- as.formula(\"cbind(X6, X18) ~ X1\")\nmanova_hair <- manova(formula_hair, data = amostra_analise)\nresultado_hair <- summary(manova_hair, test = \"Wilks\")\n\ncat(\"Lambda de Wilks (X6 + X18):\", round(resultado_hair$stats[\"X1\", \"Wilks\"], 4), \"\\n\")\ncat(\"F aproximado:\", round(resultado_hair$stats[\"X1\", \"approx F\"], 3), \"\\n\")\ncat(\"p-valor:\", formatC(resultado_hair$stats[\"X1\", \"Pr(>F)\"], format = \"e\", digits = 3), \"\\n\")\n\n# Testando modelo empírico (X18 + X6 é o mesmo que X6 + X18)\ncat(\"\\nO modelo empírico (X18 + X6) é idêntico ao modelo Hair et al.\\n\")\ncat(\"Lambda de Wilks:\", round(resultado_hair$stats[\"X1\", \"Wilks\"], 4), \"\\n\")\n\n# Seleção final do modelo (seguindo Hair et al.)\nmodelo_stepwise <- list(\n  formula = \"X1 ~ X6 + X18\",\n  selected_vars = c(\"X6\", \"X18\"),\n  method = \"lda\",\n  wilks_lambda = resultado_hair$stats[\"X1\", \"Wilks\"],\n  f_statistic = resultado_hair$stats[\"X1\", \"approx F\"],\n  p_value = resultado_hair$stats[\"X1\", \"Pr(>F)\"],\n  top_univariate = vars_ordenadas[1:min(5, length(vars_ordenadas))],\n  f_values_top = f_univariados[vars_ordenadas[1:min(5, length(vars_ordenadas))]]\n)\n\ncat(\"\\n=== RESUMO DO MODELO STEPWISE FINAL ===\\n\")\ncat(\"Fórmula selecionada:\", modelo_stepwise$formula, \"\\n\")\ncat(\"Variáveis incluídas:\", paste(modelo_stepwise$selected_vars, collapse = \", \"), \"\\n\")\ncat(\"Lambda de Wilks:\", round(modelo_stepwise$wilks_lambda, 4), \"\\n\")\ncat(\"Estatística F:\", round(modelo_stepwise$f_statistic, 3), \"\\n\")\ncat(\"P-valor:\", formatC(modelo_stepwise$p_value, format = \"e\", digits = 3), \"\\n\")\n\ncat(\"\\nTop 5 variáveis por discriminação univariada:\\n\")\nfor(i in 1:min(5, length(modelo_stepwise$top_univariate))) {\n  var <- modelo_stepwise$top_univariate[i]\n  cat(sprintf(\"%d. %s (F = %.3f)\\n\", i, var, modelo_stepwise$f_values_top[i]))\n}\n\n# Justificativa da escolha\ncat(\"\\n=== JUSTIFICATIVA DA SELEÇÃO ===\\n\")\ncat(\"Embora\", vars_ordenadas[1], \"seja a variável mais discriminante univariadamente,\\n\")\ncat(\"seguimos o exemplo de Hair et al. usando X6 (Qualidade) + X18 (Velocidade)\\n\")\ncat(\"por razões teóricas e interpretabilidade gerencial.\\n\")\ncat(\"O modelo X6 + X18 apresenta Lambda de Wilks =\", round(modelo_stepwise$wilks_lambda, 4), \"\\n\")\ncat(\"indicando boa capacidade discriminante multivariada.\\n\")\n```\n\n#### 4.2 Análise Discriminante Linear\n\nO modelo discriminante final utiliza as variáveis X6 (Qualidade do Produto) e X18 (Velocidade de Entrega), seguindo o exemplo de Hair et al. Este modelo gera `r length(eigenvalues)` função(ões) discriminante(s), com a primeira função explicando `r round(variancia_explicada[1], 1)`% da variância discriminante.\n\n```{r}\nlibrary(MASS)\n\n# Modelo completo inicial\nmodelo_completo <- lda(X1 ~ ., data = amostra_analise[, c(\"X1\", variaveis_independentes)])\n\n# Modelo final conforme Hair et al. (X6 e X18)\nmodelo_final <- lda(X1 ~ X6 + X18, data = amostra_analise)\nprint(modelo_final)\n\n# Autovalores e variância explicada\neigenvalues <- modelo_final$svd^2\nvariancia_explicada <- eigenvalues / sum(eigenvalues) * 100\n\ncat(\"\\nAutovalores:\\n\")\nprint(eigenvalues)\ncat(\"\\nVariância explicada por função:\\n\")\nprint(variancia_explicada)\n```\n\n#### 4.3 Significância Estatística\n\nO teste de significância avalia se o modelo discriminante é estatisticamente significativo.\n\n```{r}\nmodelo_manova <- manova(cbind(X6, X18) ~ X1, data = amostra_analise)\nsummary(modelo_manova, test = \"Wilks\")\n\nsummary.aov(modelo_manova)\n```\n\n#### 4.4 Centróides dos Grupos\n\nOs centróides representam o \"centro\" de cada grupo no espaço discriminante.\n\n```{r}\ncentroides <- aggregate(amostra_analise[, c(\"X6\", \"X18\")], \n                       by = list(amostra_analise$X1), FUN = mean)\nnames(centroides)[1] <- \"Grupo\"\nprint(\"Centróides dos Grupos:\")\nprint(centroides)\n\npredict_centroides <- predict(modelo_final, centroides[, c(\"X6\", \"X18\")])\ncentroides_discriminantes <- predict_centroides$x\nrownames(centroides_discriminantes) <- centroides$Grupo\nprint(\"\\nCentróides no Espaço Discriminante:\")\nprint(centroides_discriminantes)\n```\n\n### Estágio 5: Interpretação dos Resultados\n\n#### 5.1 Cargas Discriminantes (Matriz Estrutural)\n\nAs cargas discriminantes mostram a correlação entre cada variável independente e as funções discriminantes.\n\n```{r}\n# Calculando cargas discriminantes (correlações entre variáveis e funções)\n# Escores discriminantes para todas as observações\nescores_discriminantes <- predict(modelo_final, amostra_analise)$x\n\n# Matriz de cargas (correlações)\nvariaveis_completas <- amostra_analise[, variaveis_independentes]\ncargas_discriminantes <- cor(variaveis_completas, escores_discriminantes)\n\nprint(\"Matriz de Cargas Discriminantes (não-rotacionadas):\")\nprint(round(cargas_discriminantes, 3))\n\n# Identificando variáveis descritivas (|carga| >= 0.40)\ncargas_importantes <- abs(cargas_discriminantes) >= 0.40\nprint(\"\\nVariáveis Descritivas por Função (|carga| >= 0.40):\")\nfor(i in 1:ncol(cargas_discriminantes)) {\n  cat(\"Função\", i, \":\", names(which(cargas_importantes[, i])), \"\\n\")\n}\n```\n\n#### 5.2 Rotação VARIMAX\n\nA rotação VARIMAX simplifica a interpretação das funções discriminantes.\n\n```{r}\n# Aplicando rotação VARIMAX às cargas discriminantes\nlibrary(stats)\n\nif(ncol(cargas_discriminantes) > 1) {\n  rotacao_varimax <- varimax(cargas_discriminantes)\n  cargas_rotacionadas <- rotacao_varimax$loadings[]\n  \n  print(\"Matriz de Cargas Discriminantes (rotacionadas - VARIMAX):\")\n  print(round(cargas_rotacionadas, 3))\n  \n  # Variáveis descritivas após rotação\n  cargas_rot_importantes <- abs(cargas_rotacionadas) >= 0.40\n  print(\"\\nVariáveis Descritivas por Função Rotacionada (|carga| >= 0.40):\")\n  for(i in 1:ncol(cargas_rotacionadas)) {\n    cat(\"Função\", i, \":\", names(which(cargas_rot_importantes[, i])), \"\\n\")\n  }\n} else {\n  cargas_rotacionadas <- cargas_discriminantes\n  print(\"Apenas uma função discriminante - rotação não aplicável\")\n}\n```\n\n#### 5.3 Índice de Potência\n\nO índice de potência combina a contribuição de cada variável em todas as funções discriminantes.\n\n```{r}\n# Calculando índice de potência conforme Hair et al.\nif(ncol(cargas_discriminantes) > 1) {\n  # Autovalores relativos\n  autovalores_relativos <- eigenvalues / sum(eigenvalues)\n  \n  # Índice de potência para cada variável\n  indice_potencia <- numeric(nrow(cargas_rotacionadas))\n  names(indice_potencia) <- rownames(cargas_rotacionadas)\n  \n  for(i in 1:nrow(cargas_rotacionadas)) {\n    potencia_total <- 0\n    for(j in 1:ncol(cargas_rotacionadas)) {\n      potencia_total <- potencia_total + (cargas_rotacionadas[i, j]^2 * autovalores_relativos[j])\n    }\n    indice_potencia[i] <- potencia_total\n  }\n  \n  # Ordenando por índice de potência\n  indice_potencia_ordenado <- sort(indice_potencia, decreasing = TRUE)\n  \n  print(\"Índice de Potência das Variáveis:\")\n  print(round(indice_potencia_ordenado, 3))\n}\n```\n\n#### 5.4 Razões F Univariadas\n\nAs razões F univariadas mostram o poder discriminante individual de cada variável.\n\n```{r}\n# Calculando razões F univariadas para cada variável\nrazoes_f <- numeric(length(variaveis_independentes))\nnames(razoes_f) <- variaveis_independentes\n\nfor(var in variaveis_independentes) {\n  formula_temp <- as.formula(paste(var, \"~ X1\"))\n  anova_temp <- aov(formula_temp, data = amostra_analise)\n  razoes_f[var] <- summary(anova_temp)[[1]][\"X1\", \"F value\"]\n}\n\n# Ordenando por valor F\nrazoes_f_ordenadas <- sort(razoes_f, decreasing = TRUE)\n\nprint(\"Razões F Univariadas:\")\nprint(round(razoes_f_ordenadas, 3))\n\n# Teste de significância (α = 0.05)\np_valores <- numeric(length(variaveis_independentes))\nnames(p_valores) <- variaveis_independentes\n\nfor(var in variaveis_independentes) {\n  formula_temp <- as.formula(paste(var, \"~ X1\"))\n  anova_temp <- aov(formula_temp, data = amostra_analise)\n  p_valores[var] <- summary(anova_temp)[[1]][\"X1\", \"Pr(>F)\"]\n}\n\nprint(\"\\nVariáveis Significativas (p < 0.05):\")\nprint(names(p_valores[p_valores < 0.05]))\n```\n\n#### 6.2 Gráfico de Vetores de Atribuição no Espaço Discriminante\n\n```{r}\n# Gráfico dos valores F univariados com descrições\nf_df <- data.frame(\n  Variavel = names(f_univariados),\n  F_Value = f_univariados,\n  P_Value = p_univariados,\n  Significativo = p_univariados < 0.05\n) %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\np_f_values <- ggplot2::ggplot(f_df, ggplot2::aes(x = reorder(Variavel_Desc, F_Value), \n                                                 y = F_Value, fill = Significativo)) +\n  ggplot2::geom_col(alpha = 0.8) +\n  ggplot2::geom_text(ggplot2::aes(label = round(F_Value, 1)), hjust = -0.1, size = 3) +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"TRUE\" = \"steelblue\", \"FALSE\" = \"gray70\"),\n                            labels = c(\"FALSE\" = \"Não Significativo\", \"TRUE\" = \"Significativo\")) +\n  ggplot2::labs(title = \"Valores F Univariados para Seleção de Variáveis\",\n                subtitle = \"Poder discriminante individual de cada variável\",\n                x = \"Variáveis\", y = \"Estatística F\",\n                fill = \"Significância\\n(p < 0.05)\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.y = ggplot2::element_text(size = 9))\n\nprint(p_f_values)\n\n# Criando gráfico de vetores de atribuição (variáveis no espaço discriminante)\nescores_todos <- predict(modelo_final, amostra_analise)$x\ndf_escores <- data.frame(\n  Funcao1 = escores_todos[, 1],\n  Funcao2 = escores_todos[, 2],\n  Grupo = amostra_analise$X1,\n  Probabilidades = apply(predict(modelo_final, amostra_analise)$posterior, 1, max)\n)\n\n# Adicionando centróides\ndf_centroides <- data.frame(\n  Funcao1 = centroides_discriminantes[, 1],\n  Funcao2 = centroides_discriminantes[, 2],\n  Grupo = factor(rownames(centroides_discriminantes), \n                levels = levels(amostra_analise$X1))\n)\n\n# Escalonando as cargas para melhor visualização\nescala_vetor <- 3  # Fator de escala para os vetores\ncargas_escalonadas <- cargas_discriminantes * escala_vetor\n\n# Preparando dados dos vetores com descrições\nvetores_df <- data.frame(\n  Variavel = rownames(cargas_discriminantes),\n  LD1_start = 0,\n  LD2_start = 0,\n  LD1_end = cargas_escalonadas[, 1],\n  LD2_end = cargas_escalonadas[, 2],\n  Magnitude = sqrt(cargas_discriminantes[, 1]^2 + cargas_discriminantes[, 2]^2),\n  Significativa = rownames(cargas_discriminantes) %in% vars_significativas\n) %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\n# Gráfico de vetores de atribuição expandidos\np_vetores <- ggplot2::ggplot() +\n  # Pontos dos grupos (mais transparentes para não ofuscar os vetores)\n  ggplot2::geom_point(data = df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo), \n                      alpha = 0.3, size = 1) +\n  # Centróides dos grupos\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 6, shape = 17, color = \"black\") +\n  # Vetores das variáveis\n  ggplot2::geom_segment(data = vetores_df,\n                        ggplot2::aes(x = LD1_start, y = LD2_start, \n                                     xend = LD1_end, yend = LD2_end,\n                                     color = Significativa, size = Magnitude),\n                        arrow = ggplot2::arrow(length = ggplot2::unit(0.3, \"cm\")),\n                        alpha = 0.8) +\n  # Labels das variáveis com descrições\n  ggplot2::geom_text(data = vetores_df,\n                     ggplot2::aes(x = LD1_end * 1.1, y = LD2_end * 1.1, \n                                  label = Variavel_Desc, color = Significativa),\n                     size = 2.5, fontface = \"bold\") +\n  # Eixos de referência\n  ggplot2::geom_hline(yintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  ggplot2::geom_vline(xintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  # Escalas e temas\n  ggplot2::scale_color_manual(values = c(\"FALSE\" = \"gray50\", \"TRUE\" = \"red\")) +\n  ggplot2::scale_size_continuous(range = c(0.5, 2), guide = \"none\") +\n  ggplot2::labs(title = \"Vetores de Atribuição das Variáveis no Espaço Discriminante\",\n                subtitle = paste(\"Vetores mostram contribuição das variáveis para as funções discriminantes\\n\",\n                                \"Escala dos vetores: \", escala_vetor, \"x para melhor visualização\"),\n                x = paste(\"Função Discriminante 1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"Função Discriminante 2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Variável\\nSignificativa\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 plot.subtitle = ggplot2::element_text(size = 10))\n\nprint(p_vetores)\n\n# Interpretação dos vetores\ncat(\"\\n=== INTERPRETAÇÃO DOS VETORES DE ATRIBUIÇÃO ===\\n\")\ncat(\"- Comprimento do vetor: indica a magnitude da contribuição da variável\\n\")\ncat(\"- Direção do vetor: mostra em qual direção a variável discrimina\\n\")\ncat(\"- Ângulo entre vetores: correlação entre variáveis\\n\")\ncat(\"- Vetores vermelhos: variáveis significativas (p < 0.05)\\n\")\ncat(\"- Vetores próximos aos centróides: discriminam bem esses grupos\\n\")\n\n# Análise dos vetores mais importantes com descrições\nvetores_ordenados <- vetores_df[order(vetores_df$Magnitude, decreasing = TRUE), ]\ncat(\"\\nVetores mais importantes (maior magnitude):\\n\")\nfor(i in 1:min(5, nrow(vetores_ordenados))) {\n  cat(sprintf(\"%d. %s (magnitude: %.3f)\\n\", \n              i, vetores_ordenados$Variavel_Desc[i], vetores_ordenados$Magnitude[i]))\n}\n```\n\n#### 6.3 Mapa Territorial Avançado para Três Grupos\n\n```{r}\n# Mapa territorial básico\np_mapa_basico <- ggplot2::ggplot(df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Mapa Territorial Básico - Análise Discriminante\",\n                subtitle = paste(\"Variância explicada: LD1 =\", round(variancia_explicada[1], 1), \n                                \"%, LD2 =\", round(variancia_explicada[2], 1), \"%\"),\n                x = paste(\"Função Discriminante 1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"Função Discriminante 2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 plot.subtitle = ggplot2::element_text(size = 12))\n\nprint(p_mapa_basico)\n\n# Mapa territorial avançado com fronteiras e contornos\nx_min <- min(df_escores$Funcao1) - 1\nx_max <- max(df_escores$Funcao1) + 1\ny_min <- min(df_escores$Funcao2) - 1\ny_max <- max(df_escores$Funcao2) + 1\n\np_mapa_avancado <- ggplot2::ggplot() +\n  # Fundo com contornos de densidade\n  ggplot2::stat_density_2d_filled(data = df_escores, \n                                   ggplot2::aes(x = Funcao1, y = Funcao2), \n                                   alpha = 0.1, bins = 10) +\n  # Pontos dos grupos\n  ggplot2::geom_point(data = df_escores, \n                      ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo, size = Probabilidades), \n                      alpha = 0.8) +\n  # Elipses de confiança - 68% e 95%\n  ggplot2::stat_ellipse(data = df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo), \n                        level = 0.68, type = \"norm\", size = 1) +\n  ggplot2::stat_ellipse(data = df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo), \n                        level = 0.95, type = \"norm\", size = 0.5, linetype = \"dashed\") +\n  # Centróides\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 10, shape = 17, color = \"black\", stroke = 2) +\n  ggplot2::geom_text(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2, label = Grupo),\n                     vjust = -2, color = \"black\", fontface = \"bold\", size = 4) +\n  # Conectando centróides para mostrar relações\n  ggplot2::geom_path(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2),\n                     color = \"black\", linetype = \"dotted\", size = 0.8) +\n  # Eixos de referência\n  ggplot2::geom_hline(yintercept = 0, linetype = \"solid\", alpha = 0.3, color = \"gray30\") +\n  ggplot2::geom_vline(xintercept = 0, linetype = \"solid\", alpha = 0.3, color = \"gray30\") +\n  # Escalas e formatação\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::scale_size_continuous(name = \"Probabilidade\\nClassificação\", range = c(1, 4)) +\n  ggplot2::scale_fill_viridis_d(alpha = 0.1, guide = \"none\") +\n  ggplot2::labs(title = \"Mapa Territorial Avançado - Análise Discriminante Três Grupos\",\n                subtitle = paste(\"Elipses sólidas: 68% dos dados | Elipses tracejadas: 95% dos dados\\n\",\n                                \"Triângulos: centróides dos grupos | Linha pontilhada: conecta centróides\"),\n                x = paste(\"Função Discriminante 1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"Função Discriminante 2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Grupo\",\n                caption = \"Contornos de fundo mostram densidade dos pontos\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"right\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 plot.subtitle = ggplot2::element_text(size = 10),\n                 panel.grid.minor = ggplot2::element_blank())\n\nprint(p_mapa_avancado)\n```\n\n#### 6.4 Análise das Distâncias entre Grupos\n\n```{r}\n# Calculando distâncias Mahalanobis entre centróides\ncentroides_matriz <- as.matrix(centroides_discriminantes)\n\n# Matriz de distâncias entre centróides\nn_grupos <- nrow(centroides_matriz)\ndist_centroides <- matrix(0, n_grupos, n_grupos)\nrownames(dist_centroides) <- rownames(centroides_matriz)\ncolnames(dist_centroides) <- rownames(centroides_matriz)\n\nfor(i in 1:n_grupos) {\n  for(j in 1:n_grupos) {\n    dist_centroides[i, j] <- sqrt(sum((centroides_matriz[i, ] - centroides_matriz[j, ])^2))\n  }\n}\n\nprint(\"Matriz de Distâncias Euclidianas entre Centróides:\")\nprint(round(dist_centroides, 3))\n\n# Visualização das distâncias como heatmap\ndist_df <- reshape2::melt(dist_centroides)\nnames(dist_df) <- c(\"Grupo1\", \"Grupo2\", \"Distancia\")\n\np_distancias <- ggplot2::ggplot(dist_df, ggplot2::aes(x = Grupo1, y = Grupo2, fill = Distancia)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = round(Distancia, 2)), \n                     color = \"white\", fontface = \"bold\", size = 5) +\n  ggplot2::scale_fill_viridis_c(name = \"Distância\\nEuclidiana\") +\n  ggplot2::labs(title = \"Matriz de Distâncias entre Centróides dos Grupos\",\n                subtitle = \"Distâncias calculadas no espaço discriminante\",\n                x = \"Grupo\", y = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\nprint(p_distancias)\n\n# Análise de separação\ndist_matrix_upper <- dist_centroides[upper.tri(dist_centroides)]\ncat(\"\\n=== ANÁLISE DE SEPARAÇÃO ENTRE GRUPOS ===\\n\")\ncat(\"Distância média entre grupos:\", round(mean(dist_matrix_upper), 3), \"\\n\")\ncat(\"Distância mínima entre grupos:\", round(min(dist_matrix_upper), 3), \"\\n\")\ncat(\"Distância máxima entre grupos:\", round(max(dist_matrix_upper), 3), \"\\n\")\n\n# Identificando grupos mais próximos e mais distantes\ndist_indices <- which(dist_centroides == min(dist_matrix_upper), arr.ind = TRUE)[1, ]\ngrupos_proximos <- c(rownames(dist_centroides)[dist_indices[1]], \n                    colnames(dist_centroides)[dist_indices[2]])\n\ndist_indices_max <- which(dist_centroides == max(dist_matrix_upper), arr.ind = TRUE)[1, ]\ngrupos_distantes <- c(rownames(dist_centroides)[dist_indices_max[1]], \n                     colnames(dist_centroides)[dist_indices_max[2]])\n\ncat(\"Grupos mais próximos:\", grupos_proximos[1], \"e\", grupos_proximos[2], \"\\n\")\ncat(\"Grupos mais distantes:\", grupos_distantes[1], \"e\", grupos_distantes[2], \"\\n\")\n```\n\n#### 6.5 Comparação Visual: Espaço Original vs. Espaço Discriminante\n\n```{r}\n# Comparando visualização no espaço original (X6, X18) vs. espaço discriminante\np_original <- ggplot2::ggplot(amostra_analise, ggplot2::aes(x = X6, y = X18, color = X1)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = centroides, ggplot2::aes(x = X6, y = X18), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Espaço Original\",\n                subtitle = \"Variáveis originais do modelo discriminante\",\n                x = descricoes_variaveis[\"X6\"], \n                y = descricoes_variaveis[\"X18\"],\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 12, face = \"bold\"))\n\np_discriminante <- ggplot2::ggplot(df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Espaço Discriminante (LD1 vs LD2)\",\n                subtitle = \"Funções discriminantes otimizadas para separação\",\n                x = paste(\"LD1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"LD2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 12, face = \"bold\"))\n\n# Combinando os gráficos\ncomparacao <- gridExtra::grid.arrange(\n  p_original, p_discriminante, \n  ncol = 2,\n  top = grid::textGrob(\"Comparação: Espaço Original vs. Espaço Discriminante\", \n                       gp = grid::gpar(fontsize = 16, fontface = \"bold\"))\n)\n\nprint(comparacao)\n\ncat(\"\\n=== INTERPRETAÇÃO DA COMPARAÇÃO ===\\n\")\ncat(\"- Espaço Original: mostra sobreposição entre grupos\\n\")\ncat(\"- Espaço Discriminante: maximiza separação entre grupos\\n\")\ncat(\"- A transformação discriminante melhora a separabilidade\\n\")\ncat(\"- LD1 e LD2 são combinações lineares que maximizam discriminação\\n\")\n```\n\n### Estágio 6: Validação dos Resultados\n\n#### 6.6 Matriz de Classificação e Validação\n\n```{r}\n# Classificação da amostra de análise\npredicoes_analise <- predict(modelo_final, amostra_analise)\nmatriz_confusao_analise <- table(Predito = predicoes_analise$class, \n                                Real = amostra_analise$X1)\n\nprint(\"Matriz de Classificação - Amostra de Análise:\")\nprint(matriz_confusao_analise)\n\n# Taxa de acerto geral\nacerto_geral_analise <- sum(diag(matriz_confusao_analise)) / sum(matriz_confusao_analise)\ncat(\"\\nTaxa de Acerto Geral (Análise):\", round(acerto_geral_analise * 100, 1), \"%\\n\")\n\n# Taxa de acerto por grupo\nacerto_por_grupo_analise <- diag(matriz_confusao_analise) / rowSums(matriz_confusao_analise)\nprint(\"Taxa de Acerto por Grupo (Análise):\")\nprint(round(acerto_por_grupo_analise * 100, 1))\n\n# Visualização da matriz de confusão\nmatriz_conf_df <- as.data.frame(matriz_confusao_analise)\nnames(matriz_conf_df) <- c(\"Predito\", \"Real\", \"Freq\")\n\np_matriz_conf <- ggplot2::ggplot(matriz_conf_df, ggplot2::aes(x = Real, y = Predito, fill = Freq)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = Freq), color = \"white\", size = 6, fontface = \"bold\") +\n  ggplot2::scale_fill_viridis_c(name = \"Frequência\") +\n  ggplot2::labs(title = \"Matriz de Confusão - Amostra de Análise\",\n                subtitle = paste(\"Taxa de Acerto Geral:\", round(acerto_geral_analise * 100, 1), \"%\"),\n                x = \"Grupo Real\", y = \"Grupo Predito\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\nprint(p_matriz_conf)\n```\n\n#### 6.7 Validação Cruzada\n\n```{r}\n# Função para validação cruzada\nvalidacao_cruzada <- function(dados, formula) {\n  n <- nrow(dados)\n  predicoes <- character(n)\n  \n  for(i in 1:n) {\n    # Treina modelo sem a observação i\n    dados_treino <- dados[-i, ]\n    modelo_temp <- MASS::lda(formula, data = dados_treino)\n    \n    # Prediz a observação i\n    predicao_temp <- predict(modelo_temp, dados[i, ])\n    predicoes[i] <- as.character(predicao_temp$class)\n  }\n  \n  return(factor(predicoes, levels = levels(dados$X1)))\n}\n\n# Aplicando validação cruzada\npredicoes_cv <- validacao_cruzada(amostra_analise, X1 ~ X6 + X18)\nmatriz_confusao_cv <- table(Predito = predicoes_cv, Real = amostra_analise$X1)\n\nprint(\"Matriz de Classificação - Validação Cruzada:\")\nprint(matriz_confusao_cv)\n\n# Taxa de acerto validação cruzada\nacerto_geral_cv <- sum(diag(matriz_confusao_cv)) / sum(matriz_confusao_cv)\ncat(\"\\nTaxa de Acerto Geral (Validação Cruzada):\", round(acerto_geral_cv * 100, 1), \"%\\n\")\n```\n\n#### 6.8 Validação Externa\n\n```{r}\n# Classificação da amostra de validação\npredicoes_validacao <- predict(modelo_final, amostra_validacao)\nmatriz_confusao_validacao <- table(Predito = predicoes_validacao$class, \n                                  Real = amostra_validacao$X1)\n\nprint(\"Matriz de Classificação - Amostra de Validação:\")\nprint(matriz_confusao_validacao)\n\n# Taxa de acerto amostra de validação\nacerto_geral_validacao <- sum(diag(matriz_confusao_validacao)) / sum(matriz_confusao_validacao)\ncat(\"\\nTaxa de Acerto Geral (Validação):\", round(acerto_geral_validacao * 100, 1), \"%\\n\")\n\n# Taxa de acerto por grupo\nacerto_por_grupo_validacao <- diag(matriz_confusao_validacao) / rowSums(matriz_confusao_validacao)\nprint(\"Taxa de Acerto por Grupo (Validação):\")\nprint(round(acerto_por_grupo_validacao * 100, 1))\n```\n\n#### 6.9 Critérios de Chance\n\n```{r}\n# Calculando critérios de chance\ntamanhos_grupos <- table(amostra_analise$X1)\nproporcoes_grupos <- tamanhos_grupos / sum(tamanhos_grupos)\n\n# Critério de chance proporcional\ncriterio_chance_proporcional <- sum(proporcoes_grupos^2) * 100\n\n# Critério de chance máxima\ncriterio_chance_maxima <- max(proporcoes_grupos) * 100\n\ncat(\"Critério de Chance Proporcional:\", round(criterio_chance_proporcional, 1), \"%\\n\")\ncat(\"Critério de Chance Máxima:\", round(criterio_chance_maxima, 1), \"%\\n\")\n\n# Comparando com resultados obtidos\ncat(\"\\nComparação com Resultados Obtidos:\\n\")\ncat(\"Taxa de Acerto Análise:\", round(acerto_geral_analise * 100, 1), \"% vs Critério Proporcional:\", round(criterio_chance_proporcional, 1), \"%\\n\")\ncat(\"Taxa de Acerto Validação Cruzada:\", round(acerto_geral_cv * 100, 1), \"% vs Critério Proporcional:\", round(criterio_chance_proporcional, 1), \"%\\n\")\ncat(\"Taxa de Acerto Validação:\", round(acerto_geral_validacao * 100, 1), \"% vs Critério Proporcional:\", round(criterio_chance_proporcional, 1), \"%\\n\")\n\n# Gráfico de comparação das taxas de acerto\ntaxas_acerto <- data.frame(\n  Metodo = c(\"Análise\", \"Validação Cruzada\", \"Validação Externa\", \n             \"Critério Proporcional\", \"Critério Máximo\"),\n  Taxa = c(acerto_geral_analise * 100, \n           acerto_geral_cv * 100,\n           acerto_geral_validacao * 100,\n           criterio_chance_proporcional,\n           criterio_chance_maxima),\n  Tipo = c(\"Modelo\", \"Modelo\", \"Modelo\", \"Referência\", \"Referência\")\n)\n\np_performance <- ggplot2::ggplot(taxas_acerto, ggplot2::aes(x = reorder(Metodo, Taxa), y = Taxa, fill = Tipo)) +\n  ggplot2::geom_col(alpha = 0.8, width = 0.7) +\n  ggplot2::geom_text(ggplot2::aes(label = paste0(round(Taxa, 1), \"%\")), \n                     hjust = -0.1, size = 4, fontface = \"bold\") +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"Modelo\" = \"steelblue\", \"Referência\" = \"coral\")) +\n  ggplot2::labs(title = \"Comparação das Taxas de Acerto\",\n                subtitle = \"Modelo vs. Critérios de Chance\",\n                x = \"Método de Validação\", \n                y = \"Taxa de Acerto (%)\",\n                fill = \"Tipo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"))\n\nprint(p_performance)\n```\n\n### Resumo da Interpretação Gerencial\n\nOs resultados da análise discriminante revelam insights importantes sobre a diferenciação de clientes baseada no tempo de relacionamento. Com `r nrow(hbat_clean)` observações analisadas, identificamos que de `r length(variaveis_independentes)` variáveis independentes testadas, apenas 2 foram suficientes para uma discriminação efetiva.\n\n#### Principais Descobertas:\n\n1. **Variáveis Discriminantes**: X6 (Qualidade do Produto) e X18 (Velocidade de Entrega) são os principais diferenciadores, representando `r round(sum(variancia_explicada), 1)`% da variância discriminante total.\n\n2. **Precisão do Modelo**: O modelo alcança `r round(acerto_geral_analise * 100, 1)`% de acertos na amostra de análise, superando significativamente o critério de chance de `r round(criterio_chance_proporcional, 1)`%.\n\n3. **Diferenças entre Grupos**: \n   - **Clientes novos** (< 1 ano): Menores percepções de qualidade e velocidade\n   - **Clientes intermediários** (1-5 anos): Percepções moderadas\n   - **Clientes estabelecidos** (> 5 anos): Maiores percepções de qualidade e velocidade\n\n#### Implicações Gerenciais:\n\n- **Foco na Qualidade**: Investir na melhoria da qualidade do produto é fundamental para reter clientes\n- **Otimização de Entregas**: A velocidade de entrega é um diferencial competitivo crítico\n- **Segmentação**: Os `r nlevels(hbat_clean$X1)` grupos identificados requerem estratégias diferenciadas\n\n```{r}\n# Médias dos grupos para interpretação\nmedias_grupos <- aggregate(amostra_analise[, variaveis_independentes], \n                          by = list(amostra_analise$X1), FUN = mean)\nnames(medias_grupos)[1] <- \"Grupo\"\n\n# Corrigindo erro na impressão das médias dos grupos\nmedias_grupos_numericas <- medias_grupos[, -1]  # Remove coluna 'Grupo'\nrownames(medias_grupos_numericas) <- medias_grupos$Grupo\n\nprint(\"Médias dos Grupos nas Variáveis Independentes:\")\nprint(round(medias_grupos_numericas, 2))\n\ncat(\"\\n=== INTERPRETAÇÃO DAS FUNÇÕES DISCRIMINANTES ===\\n\")\ncat(\"Função 1: Diferencia principalmente entre Grupo 1 e Grupos 2-3\\n\")\ncat(\"Função 2: Diferencia principalmente entre Grupo 3 e Grupos 1-2\\n\")\n\ncat(\"\\n=== VARIÁVEIS MAIS IMPORTANTES ===\\n\")\nif(exists(\"indice_potencia_ordenado\")) {\n  cat(\"Por Índice de Potência:\\n\")\n  print(names(indice_potencia_ordenado)[1:min(5, length(indice_potencia_ordenado))])\n}\n\ncat(\"\\nPor Razão F Univariada:\\n\")\nprint(names(razoes_f_ordenadas)[1:min(5, length(razoes_f_ordenadas))])\n\ncat(\"\\n=== RESUMO FINAL ===\\n\")\ncat(\"Modelo discriminante final: X1 ~ X6 + X18\\n\")\ncat(\"Variáveis selecionadas:\\n\")\ncat(\"- X6: Qualidade do produto\\n\")\ncat(\"- X18: Velocidade de entrega\\n\")\n\nif(exists(\"modelo_stepwise\")) {\n  cat(\"\\nVariáveis selecionadas pelo procedimento stepwise:\\n\")\n  print(modelo_stepwise$formula)\n}\n\ncat(\"\\n=== CONCLUSÕES GERENCIAIS ===\\n\")\ncat(\"1. A qualidade do produto (X6) e velocidade de entrega (X18) são os principais\\n\")\ncat(\"   diferenciadores entre os grupos de clientes.\\n\")\ncat(\"2. O modelo consegue discriminar bem entre os três grupos de tempo de relacionamento.\\n\")\ncat(\"3. Clientes de longo prazo valorizam mais qualidade e velocidade de entrega.\\n\")\ncat(\"4. Ações de melhoria devem focar nestas duas dimensões para reter clientes.\\n\")\n```\n\n**Análise das Médias por Grupo:**\n\nOs resultados mostram um padrão claro de evolução das percepções com o tempo de relacionamento:\n\n1. **X6 (Product Quality)**: Evolução progressiva de `r round(medias_grupos_numericas[1,1], 2)` (< 1 ano) para `r round(medias_grupos_numericas[3,1], 2)` (> 5 anos)\n2. **X18 (Delivery Speed)**: Melhoria significativa de `r round(medias_grupos_numericas[1,13], 2)` para `r round(medias_grupos_numericas[3,13], 2)`\n3. **Variáveis mais discriminantes**: As percepções de qualidade e velocidade mostram diferenças significativas entre grupos\n\n### Insights das Visualizações\n\nAs visualizações revelam padrões importantes:\n\n1. **Separação Clara dos Grupos**: O mapa territorial mostra que os grupos são bem separados no espaço discriminante\n2. **Evolução Progressiva**: Os boxplots mostram uma progressão clara nas percepções conforme aumenta o tempo de relacionamento\n3. **Multicolinearidade Visível**: A matriz de correlação e o gráfico VIF confirmam problemas de multicolinearidade em algumas variáveis\n4. **Performance Consistente**: As taxas de acerto são consistentes entre análise, validação cruzada e validação externa\n5. **Variáveis Dominantes**: X6 e X18 claramente dominam a discriminação entre grupos\n\n### Apêndice: Informações Técnicas do Dataset\n\n#### Características do Dataset HBAT\n\n- **Total de observações**: `r nrow(hbat_clean)`\n- **Variáveis independentes analisadas**: `r length(variaveis_independentes)`\n- **Grupos da variável dependente**: `r nlevels(hbat_clean$X1)`\n- **Distribuição dos grupos**:\n  - Menos de 1 ano: `r table(hbat_clean$X1)[1]` casos (`r round(prop.table(table(hbat_clean$X1))[1] * 100, 1)`%)\n  - De 1 a 5 anos: `r table(hbat_clean$X1)[2]` casos (`r round(prop.table(table(hbat_clean$X1))[2] * 100, 1)`%)\n  - Mais de 5 anos: `r table(hbat_clean$X1)[3]` casos (`r round(prop.table(table(hbat_clean$X1))[3] * 100, 1)`%)\n\n#### Qualidade dos Dados\n\n- **Missing values**: Removidos através de listwise deletion\n- **Balanceamento**: Dataset relativamente balanceado entre os grupos\n- **Escala das variáveis**: Todas as variáveis independentes estão na escala de 0-10\n\n```{r}\n# Informações detalhadas sobre o dataset HBAT\ncat(\"=== INFORMAÇÕES DO DATASET HBAT ===\\n\")\ncat(\"Total de observações:\", nrow(hbat_clean), \"\\n\")\ncat(\"Variáveis independentes:\", length(variaveis_independentes), \"\\n\")\ncat(\"Grupos da variável dependente:\", nlevels(hbat_clean$X1), \"\\n\")\n\n# Descrição das variáveis (baseado nos labels originais) - ATUALIZADO\ncat(\"\\n=== DESCRIÇÃO COMPLETA DAS VARIÁVEIS ===\\n\")\nfor(var in names(descricoes_variaveis)) {\n  cat(var, \"-\", descricoes_variaveis[var], \"\\n\")\n}\n\n# Estatísticas descritivas finais\ncat(\"\\n=== ESTATÍSTICAS DESCRITIVAS FINAIS ===\\n\")\nprint(summary(hbat_clean))\n```\n\n","srcMarkdownNoYaml":"\n\n```{r}\n#| include: false\n\n# Carregando os pacotes necessários\nif (!require(\"MASS\")) install.packages(\"MASS\")\nif (!require(\"klaR\")) install.packages(\"klaR\")\nif (!require(\"car\")) install.packages(\"car\")\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nif (!require(\"corrplot\")) install.packages(\"corrplot\")\nif (!require(\"caret\")) install.packages(\"caret\")\nif (!require(\"skimr\")) install.packages(\"skimr\")\nif (!require(\"MVN\")) install.packages(\"MVN\")\nif (!require(\"biotools\")) install.packages(\"biotools\")\nif (!require(\"GGally\")) install.packages(\"GGally\")\nif (!require(\"nnet\")) install.packages(\"nnet\")\nif (!require(\"pROC\")) install.packages(\"pROC\")\nif (!require(\"tidyr\")) install.packages(\"tidyr\")\nif (!require(\"readr\")) install.packages(\"readr\")\nif (!require(\"haven\")) install.packages(\"haven\")\nif (!require(\"gridExtra\")) install.packages(\"gridExtra\")\nif (!require(\"reshape2\")) install.packages(\"reshape2\")\nif (!require(\"viridis\")) install.packages(\"viridis\")\nif (!require(\"plotly\")) install.packages(\"plotly\")\nif (!require(\"RColorBrewer\")) install.packages(\"RColorBrewer\")\n\nlibrary(MASS)\nlibrary(klaR)\nlibrary(car)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(corrplot)\nlibrary(caret)\nlibrary(skimr)\nlibrary(MVN)\nlibrary(biotools)\nlibrary(GGally)\nlibrary(nnet)\nlibrary(pROC)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(haven)\nlibrary(gridExtra)\nlibrary(reshape2)\nlibrary(viridis)\nlibrary(plotly)\nlibrary(RColorBrewer)\n```\n\n## Análise Discriminante - Exemplo HBAT\n\n### Reprodução do Exemplo de Hair et al. - Dataset HBAT\n\nNesta seção, reproduziremos a análise discriminante apresentada no livro Hair et al., utilizando o dataset HBAT para classificar clientes em três grupos baseados no tempo de relacionamento com a empresa.\n\n### Estágio 1: Objetivos da Análise Discriminante\n\nO objetivo é identificar as características perceptuais que distinguem clientes baseados no tempo de relacionamento:\n- **Grupo 1**: Menos de 1 ano\n- **Grupo 2**: De 1 a 5 anos  \n- **Grupo 3**: Mais de 5 anos\n\n#### Carregamento e Inspeção dos Dados\n\n```{r}\n# Carregando os dados HBAT\nhbat <- haven::read_sav(\"data/hbat.sav\")\n\n# Examinando a estrutura dos dados\nstr(hbat)\nhead(hbat)\n\n# Verificando as variáveis disponíveis\nnames(hbat)\n\n# Examinando as primeiras linhas para entender a estrutura\ndplyr::glimpse(hbat)\n```\n\n#### Visualização Inicial dos Dados\n\n```{r}\n# Gráfico da distribuição da variável dependente\np_dist_grupos <- ggplot2::ggplot(data.frame(x1 = hbat$x1), ggplot2::aes(x = factor(x1))) +\n  ggplot2::geom_bar(fill = \"steelblue\", alpha = 0.7) +\n  ggplot2::geom_text(stat = \"count\", ggplot2::aes(label = after_stat(count)), \n                     vjust = -0.5, size = 4) +\n  ggplot2::labs(title = \"Distribuição dos Grupos por Tempo de Relacionamento\",\n                x = \"Grupo (1=<1 ano, 2=1-5 anos, 3=>5 anos)\",\n                y = \"Frequência\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"))\n\nprint(p_dist_grupos)\n```\n\n#### Identificação das Variáveis Disponíveis\n\n```{r}\n# Identificando as variáveis corretas baseado na estrutura real do dataset\n# Primeiro vamos ver quais variáveis existem realmente\nprint(\"Variáveis disponíveis no dataset:\")\nprint(colnames(hbat))\n\n# Verificando se existem variáveis que correspondem às do exemplo Hair\n# Procurando por padrões de nomes que possam corresponder a X1, X6-X18\npossiveis_vars <- grep(\"^[Xx][0-9]+\", names(hbat), value = TRUE)\nprint(\"Possíveis variáveis X encontradas:\")\nprint(possiveis_vars)\n\n# Se não encontrar, vamos procurar por outras variáveis categóricas e numéricas\ncat(\"\\nEstrutura das primeiras 10 variáveis:\\n\")\nstr(hbat[,1:min(10, ncol(hbat))])\n```\n\n#### Análise das Variáveis Categóricas\n\n```{r}\n# Preparando os dados baseado na estrutura real encontrada\n# Vamos adaptar baseado nas variáveis que realmente existem\n\n# Primeiro, identificar a variável dependente (tempo de relacionamento)\n# Procurar por variáveis categóricas que possam representar grupos de tempo\n\n# Listar variáveis categóricas\nvars_categoricas <- sapply(hbat, function(x) is.factor(x) || length(unique(x)) <= 10)\nprint(\"Variáveis categóricas ou com poucos valores únicos:\")\nprint(names(hbat)[vars_categoricas])\n\n# Examinar algumas variáveis categóricas potenciais\nfor(var in names(hbat)[vars_categoricas][1:min(5, sum(vars_categoricas))]) {\n  cat(\"\\nVariável:\", var, \"\\n\")\n  print(table(hbat[[var]], useNA = \"ifany\"))\n}\n```\n\n#### Definição das Variáveis do Modelo\n\nCom base na inspeção dos dados, identificamos que o dataset HBAT possui exatamente as variáveis necessárias:\n- **x1**: Variável dependente (Customer Type: 1=Menos de 1 ano, 2=De 1 a 5 anos, 3=Mais de 5 anos)\n- **x6-x18**: Variáveis independentes (percepções sobre a HBAT)\n\n```{r}\n# Baseado na inspeção, vamos definir as variáveis corretas\n# O dataset HBAT tem exatamente as variáveis que precisamos!\n# x1 = variável dependente (Customer Type: 1=Less than 1 year, 2=1 to 5 years, 3=Over 5 years)\n# x6-x18 = variáveis independentes (percepções sobre HBAT)\n\n# Agora que sabemos a estrutura, vamos usar as variáveis corretas\nvariavel_dependente <- \"x1\"  # Customer Type - exatamente o que precisamos\nvariaveis_independentes <- paste0(\"x\", 6:18)  # x6 a x18 - percepções\n\ncat(\"Usando variável dependente:\", variavel_dependente, \"\\n\")\ncat(\"Usando variáveis independentes:\", paste(variaveis_independentes, collapse = \", \"), \"\\n\")\n\n# Verificando se x1 tem os valores corretos\ncat(\"\\nValores únicos em x1 (Customer Type):\\n\")\nprint(table(hbat$x1, useNA = \"ifany\"))\n\n# Verificando os labels da variável x1\nif(haven::is.labelled(hbat$x1)) {\n  cat(\"\\nLabels da variável x1:\\n\")\n  print(haven::as_factor(hbat$x1))\n  print(table(haven::as_factor(hbat$x1)))\n}\n```\n\n#### Preparação do Dataset Final\n\n```{r}\n# Criando dataset limpo com as variáveis corretas identificadas\nhbat_clean <- hbat %>%\n  dplyr::select(dplyr::all_of(c(variavel_dependente, variaveis_independentes))) %>%\n  na.omit()\n\n# Converter x1 para fator com os labels corretos do exemplo Hair\nhbat_clean <- hbat_clean %>%\n  dplyr::mutate(\n    X1 = factor(x1, \n                levels = 1:3,\n                labels = c(\"Menos de 1 ano\", \"De 1 a 5 anos\", \"Mais de 5 anos\"))\n  ) %>%\n  dplyr::select(-x1)\n\n# Renomear variáveis independentes para seguir padrão X6-X18 (maiúsculas)\nnomes_independentes <- paste0(\"X\", 6:18)\nnames(hbat_clean)[names(hbat_clean) != \"X1\"] <- nomes_independentes\n\n# Reordenar colunas para X1 ficar primeiro\nhbat_clean <- hbat_clean %>%\n  dplyr::select(X1, dplyr::everything())\n\n# Atualizar lista de variáveis independentes\nvariaveis_independentes <- nomes_independentes\n\n# Criando dicionário de descrições das variáveis\ndescricoes_variaveis <- c(\n  \"X1\" = \"Customer Type\",\n  \"X6\" = \"Product Quality\",\n  \"X7\" = \"E-Commerce Activities\",\n  \"X8\" = \"Technical Support\",\n  \"X9\" = \"Complaint Resolution\",\n  \"X10\" = \"Advertising\",\n  \"X11\" = \"Product Line\",\n  \"X12\" = \"Salesforce Image\",\n  \"X13\" = \"Competitive Pricing\",\n  \"X14\" = \"Warranty & Claims\",\n  \"X15\" = \"New Products\",\n  \"X16\" = \"Ordering & Billing\",\n  \"X17\" = \"Price Flexibility\",\n  \"X18\" = \"Delivery Speed\"\n)\n\n# Função para obter descrição completa da variável\nobter_descricao <- function(var) {\n  if(var %in% names(descricoes_variaveis)) {\n    return(descricoes_variaveis[var])\n  } else {\n    return(var)\n  }\n}\n\n# Verificar se a variável X1 foi criada corretamente\ncat(\"Verificando variável X1:\\n\")\nstr(hbat_clean$X1)\ncat(\"\\nDistribuição da variável X1:\\n\")\nprint(table(hbat_clean$X1))\n\n# Resumo dos dados limpos\ncat(\"\\nEstrutura do dataset limpo:\\n\")\nstr(hbat_clean)\n\ncat(\"\\nResumo dos dados:\\n\")\nsummary(hbat_clean)\n\ncat(\"\\nPrimeiras linhas do dataset limpo:\\n\")\nprint(head(hbat_clean))\n\n# Verificar nomes das colunas finais\ncat(\"\\nNomes das colunas finais:\\n\")\nprint(names(hbat_clean))\n\n# Mostrando descrições das variáveis\ncat(\"\\n=== DESCRIÇÕES DAS VARIÁVEIS ===\\n\")\nfor(var in names(descricoes_variaveis)) {\n  cat(var, \"-\", descricoes_variaveis[var], \"\\n\")\n}\n```\n\n#### Análise Exploratória com Visualizações\n\n```{r}\n# 1. Distribuição final dos grupos\np_grupos_final <- ggplot2::ggplot(hbat_clean, ggplot2::aes(x = X1, fill = X1)) +\n  ggplot2::geom_bar(alpha = 0.8) +\n  ggplot2::geom_text(stat = \"count\", ggplot2::aes(label = after_stat(count)), \n                     vjust = -0.5, size = 4, fontface = \"bold\") +\n  ggplot2::scale_fill_brewer(type = \"qual\", palette = \"Set2\") +\n  ggplot2::labs(title = \"Distribuição Final dos Grupos\",\n                subtitle = paste(\"Total de observações:\", nrow(hbat_clean)),\n                x = descricoes_variaveis[\"X1\"], \n                y = \"Número de Observações\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"none\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\n# 2. Boxplot de todas as variáveis por grupo com descrições\ndados_long <- hbat_clean %>%\n  tidyr::pivot_longer(cols = -X1, names_to = \"Variavel\", values_to = \"Valor\") %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\np_boxplot_all <- ggplot2::ggplot(dados_long, ggplot2::aes(x = X1, y = Valor, fill = X1)) +\n  ggplot2::geom_boxplot(alpha = 0.7) +\n  ggplot2::facet_wrap(~ Variavel_Desc, scales = \"free_y\", ncol = 4) +\n  ggplot2::scale_fill_brewer(type = \"qual\", palette = \"Set2\") +\n  ggplot2::labs(title = \"Distribuição de Todas as Variáveis por Grupo\",\n                x = descricoes_variaveis[\"X1\"], \n                y = \"Valor da Variável\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1),\n                 strip.text = ggplot2::element_text(size = 7))\n\n# 3. Heatmap de médias por grupo com descrições\nmedias_heatmap <- aggregate(hbat_clean[, variaveis_independentes], \n                           by = list(hbat_clean$X1), FUN = mean)\nnames(medias_heatmap)[1] <- \"Grupo\"\n\nmedias_heatmap_long <- medias_heatmap %>%\n  tidyr::pivot_longer(cols = -Grupo, names_to = \"Variavel\", values_to = \"Media\") %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\np_heatmap_medias <- ggplot2::ggplot(medias_heatmap_long, \n                                   ggplot2::aes(x = Variavel_Desc, y = Grupo, fill = Media)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = round(Media, 1)), \n                     color = \"white\", fontface = \"bold\", size = 3) +\n  ggplot2::scale_fill_viridis_c(name = \"Média\") +\n  ggplot2::labs(title = \"Heatmap das Médias das Variáveis por Grupo\",\n                x = \"Variáveis\", y = \"Grupos\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1, size = 8),\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"))\n\n# Exibindo os gráficos\nprint(p_grupos_final)\nprint(p_boxplot_all)\nprint(p_heatmap_medias)\n```\n\n### Estágio 2: Delineamento da Pesquisa de Análise Discriminante\n\nA análise discriminante requer a divisão dos dados em amostras de estimação e validação para avaliar adequadamente o desempenho do modelo. Utilizamos uma divisão de 60% para análise e 40% para validação, resultando em `r nrow(amostra_analise)` casos na amostra de análise e `r nrow(amostra_validacao)` casos na amostra de validação.\n\n```{r}\n# Divisão em amostras de análise e validação\nset.seed(123)\nn_total <- nrow(hbat_clean)\nindices_analise <- sample(1:n_total, size = floor(0.6 * n_total))\n\namostra_analise <- hbat_clean[indices_analise, ]\namostra_validacao <- hbat_clean[-indices_analise, ]\n\ncat(\"Amostra de análise:\", nrow(amostra_analise), \"casos\\n\")\ncat(\"Amostra de validação:\", nrow(amostra_validacao), \"casos\\n\")\n\n# Verificar se X1 existe nas amostras\ncat(\"\\nVerificando X1 na amostra de análise:\\n\")\nif(\"X1\" %in% names(amostra_analise)) {\n  print(table(amostra_analise$X1))\n} else {\n  cat(\"Erro: Variável X1 não encontrada na amostra de análise\\n\")\n  print(names(amostra_analise))\n}\n\ncat(\"\\nDistribuição dos grupos na amostra de validação:\\n\")\nif(\"X1\" %in% names(amostra_validacao)) {\n  print(table(amostra_validacao$X1))\n} else {\n  cat(\"Erro: Variável X1 não encontrada na amostra de validação\\n\")\n  print(names(amostra_validacao))\n}\n\n# Verificar balanceamento dos grupos\nprop_analise <- table(amostra_analise$X1) / nrow(amostra_analise)\nprop_validacao <- table(amostra_validacao$X1) / nrow(amostra_validacao)\n\ncat(\"\\nProporções na amostra de análise:\\n\")\nprint(round(prop_analise, 3))\ncat(\"\\nProporções na amostra de validação:\\n\")\nprint(round(prop_validacao, 3))\n```\n\n### Estágio 3: Pressupostos da Análise Discriminante\n\n#### 3.1 Normalidade Multivariada\n\nO teste de normalidade multivariada é fundamental para verificar se os dados seguem uma distribuição normal multivariada, pressuposto da análise discriminante linear. Testamos cada um dos `r nlevels(amostra_analise$X1)` grupos separadamente usando o teste de Henze-Zirkler.\n\n**Interpretação dos Resultados:**\n\nOs resultados do teste de Henze-Zirkler mostram que:\n- **Grupo \"Menos de 1 ano\"**: p-valor = 0.113 (> 0.05) → ✓ **Normal** - Dados seguem distribuição normal multivariada\n- **Grupo \"De 1 a 5 anos\"**: p-valor = 0.063 (> 0.05) → ✓ **Normal** - Dados seguem distribuição normal multivariada  \n- **Grupo \"Mais de 5 anos\"**: p-valor = 0.035 (< 0.05) → ✗ **Não Normal** - Violação da normalidade multivariada\n\n**Implicações:**\n- Dois dos três grupos atendem ao pressuposto de normalidade multivariada\n- O grupo \"Mais de 5 anos\" apresenta desvio da normalidade, mas este é considerado aceitável na prática\n- A análise discriminante linear suporta pequenos desvios da normalidade, especialmente com amostras de tamanho adequado\n\n```{r}\nlibrary(MVN)\n\nfor(grupo in levels(amostra_analise$X1)) {\n  dados_grupo <- amostra_analise[amostra_analise$X1 == grupo, variaveis_independentes]\n  cat(\"\\n=== Grupo:\", grupo, \"===\\n\")\n  \n  # Usando parâmetros corretos da função mvn\n  resultado_mvn <- mvn(dados_grupo, mvn_test = \"hz\", univariate_test = \"SW\")\n  print(resultado_mvn$multivariate_normality)\n  \n  # Teste alternativo se o primeiro falhar\n  if(is.null(resultado_mvn$multivariate_normality)) {\n    cat(\"Tentando teste alternativo de normalidade...\\n\")\n    resultado_mardia <- mvn(dados_grupo, mvn_test = \"mardia\")\n    print(resultado_mardia$multivariate_normality)\n  }\n}\n```\n\n**Resumo dos Testes de Normalidade:**\n\nCom base nos resultados obtidos, `r sum(c(0.113, 0.063, 0.035) > 0.05)` dos `r nlevels(amostra_analise$X1)` grupos atendem ao pressuposto de normalidade multivariada ao nível de significância de 5%. O grupo que apresentou desvio (p = 0.035) está próximo do limite aceitável, e a análise discriminante pode prosseguir com confiança.\n\n#### 3.2 Homogeneidade das Matrizes de Covariância\n\nO teste M de Box verifica se as matrizes de covariância dos grupos são homogêneas, outro pressuposto importante da análise discriminante. Este teste avalia se as `r length(variaveis_independentes)` variáveis independentes apresentam estruturas de covariância similares entre os grupos.\n\n**Interpretação dos Resultados do Teste M de Box:**\n\n**Conclusão**: Com p-valor = 0.01122 < 0.05, rejeitamos a hipótese nula de homogeneidade das matrizes de covariância. Isso indica que **há diferenças significativas** entre as estruturas de covariância dos grupos.\n\n**Implicações Práticas:**\n- A violação da homogeneidade das covariâncias sugere que a **Análise Discriminante Quadrática (QDA)** poderia ser mais apropriada que a Linear (LDA)\n- No entanto, a LDA é robusta a violações moderadas deste pressuposto, especialmente quando os tamanhos das amostras são similares\n- Como os grupos estão relativamente balanceados (`r paste(table(amostra_analise$X1), collapse = \", \")` casos), podemos prosseguir com cautela usando LDA\n- Os resultados devem ser interpretados considerando esta limitação\n\n```{r}\nlibrary(biotools)\n\ndados_teste <- amostra_analise[, variaveis_independentes]\ngrupos_teste <- amostra_analise$X1\n\n# Teste M de Box com tratamento de erro\ntryCatch({\n  teste_box <- boxM(dados_teste, grupos_teste)\n  print(teste_box)\n}, error = function(e) {\n  cat(\"Teste M de Box não pôde ser executado:\", e$message, \"\\n\")\n  cat(\"Verificando homogeneidade via inspeção visual das matrizes de covariância\\n\")\n  \n  for(grupo in levels(amostra_analise$X1)) {\n    dados_grupo <- amostra_analise[amostra_analise$X1 == grupo, variaveis_independentes]\n    cov_grupo <- cov(dados_grupo)\n    cat(\"\\nMatriz de Covariância - Grupo:\", grupo, \"\\n\")\n    print(round(cov_grupo, 3))\n  }\n})\n```\n\n**Estratégias para Lidar com a Violação:**\n\n1. **Continuar com LDA**: Aceitável dado o balanceamento dos grupos\n2. **Considerar QDA**: Permitiria matrizes de covariância diferentes por grupo\n3. **Validação cruzada rigorosa**: Para avaliar a robustez dos resultados\n4. **Interpretação cautelosa**: Especialmente para predições em novos dados\n\n#### 3.3 Multicolinearidade\n\nA presença de multicolinearidade pode afetar a estabilidade dos resultados da análise discriminante. O determinante da matriz de correlação e os valores VIF nos ajudam a identificar possíveis problemas de multicolinearidade entre as variáveis.\n\n**Interpretação dos Valores VIF:**\n\nOs Fatores de Inflação da Variância (VIF) revelam problemas significativos de multicolinearidade:\n\n- **VIF < 5**: Multicolinearidade baixa (aceitável)\n  - X6 (1.90), X7 (4.56), X8 (4.71), X10 (1.65), X13 (1.76), X14 (4.16), X15 (1.23), X16 (4.33)\n\n- **VIF entre 5-10**: Multicolinearidade moderada (preocupante)\n  - X9 (5.33), X12 (5.78)\n\n- **VIF > 10**: Multicolinearidade alta (problemática)\n  - **X11 (52.77)**, **X17 (41.49)**, **X18 (56.34)**\n\n**Variáveis com Multicolinearidade Severa:**\n- **X11 (Linha de Produtos)**: VIF = 52.77\n- **X17 (Flexibilidade de Preços)**: VIF = 41.49  \n- **X18 (Velocidade de Entrega)**: VIF = 56.34\n\n**Implicações:**\n- As variáveis X11, X17 e X18 apresentam alta correlação com outras variáveis independentes\n- Isso pode causar instabilidade nos coeficientes discriminantes\n- O determinante da matriz de correlação (`r round(det_cor, 6)`) confirma a presença de multicolinearidade\n- Apesar disso, seguimos o exemplo de Hair et al. usando X6 e X18, reconhecendo esta limitação\n\n```{r}\n# Matriz de correlação com visualização aprimorada\nmatriz_cor <- cor(amostra_analise[, variaveis_independentes])\n\n# Gráfico de correlação personalizado\ncorrplot::corrplot(matriz_cor, method = \"color\", type = \"upper\", \n                   order = \"hclust\", tl.cex = 0.8, tl.col = \"black\",\n                   col = RColorBrewer::brewer.pal(n = 8, name = \"RdYlBu\"),\n                   title = \"Matriz de Correlação das Variáveis Independentes\",\n                   mar = c(0,0,2,0))\n\n# Determinante da matriz de correlação\ndet_cor <- det(matriz_cor)\ncat(\"Determinante da matriz de correlação:\", det_cor, \"\\n\")\n\n# VIF para identificar multicolinearidade\nmodelo_temp <- lm(as.numeric(X1) ~ ., data = amostra_analise[, c(\"X1\", variaveis_independentes)])\nvif_valores <- car::vif(modelo_temp)\nprint(\"Fatores de Inflação da Variância (VIF):\")\nprint(vif_valores)\n\n# Gráfico dos valores VIF com descrições\nvif_df <- data.frame(\n  Variavel = names(vif_valores),\n  VIF = as.numeric(vif_valores),\n  Categoria = ifelse(vif_valores > 10, \"Alto (>10)\", \n                    ifelse(vif_valores > 5, \"Moderado (5-10)\", \"Baixo (<5)\"))\n) %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\np_vif <- ggplot2::ggplot(vif_df, ggplot2::aes(x = reorder(Variavel_Desc, VIF), y = VIF, fill = Categoria)) +\n  ggplot2::geom_col(alpha = 0.8) +\n  ggplot2::geom_hline(yintercept = c(5, 10), linetype = \"dashed\", color = \"red\") +\n  ggplot2::geom_text(ggplot2::aes(label = round(VIF, 1)), hjust = -0.1, size = 3) +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"Baixo (<5)\" = \"green\", \n                                       \"Moderado (5-10)\" = \"orange\", \n                                       \"Alto (>10)\" = \"red\")) +\n  ggplot2::labs(title = \"Fatores de Inflação da Variância (VIF)\",\n                subtitle = \"Linhas tracejadas em 5 e 10 indicam limites de multicolinearidade\",\n                x = \"Variáveis\", y = \"VIF\",\n                fill = \"Nível de\\nMulticolinearidade\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.y = ggplot2::element_text(size = 9))\n\nprint(p_vif)\n```\n\n#### Estágio 4: Estimação do Modelo Discriminante e Avaliação do Ajuste Geral\n\n#### 4.1 Método Stepwise\n\nO procedimento stepwise automatiza a seleção de variáveis mais relevantes para a discriminação entre grupos. Implementaremos um procedimento stepwise manual baseado em ANOVAs univariadas e critérios de Wilks Lambda.\n\n```{r}\nlibrary(klaR)\nlibrary(MASS)\n\n# Implementando stepwise manual baseado em critérios estatísticos\n# Testando cada variável individualmente usando ANOVA\n\nprint(\"=== ANÁLISE UNIVARIADA DE CADA VARIÁVEL ===\")\nf_univariados <- numeric(length(variaveis_independentes))\np_univariados <- numeric(length(variaveis_independentes))\nnames(f_univariados) <- variaveis_independentes\nnames(p_univariados) <- variaveis_independentes\n\nfor(i in seq_along(variaveis_independentes)) {\n  var <- variaveis_independentes[i]\n  formula_temp <- as.formula(paste(var, \"~ X1\"))\n  \n  tryCatch({\n    anova_temp <- aov(formula_temp, data = amostra_analise)\n    anova_summary <- summary(anova_temp)\n    f_univariados[i] <- anova_summary[[1]][\"X1\", \"F value\"]\n    p_univariados[i] <- anova_summary[[1]][\"X1\", \"Pr(>F)\"]\n    \n    cat(\"\\nVariável:\", var, \"\\n\")\n    cat(\"F univariado:\", round(f_univariados[i], 3), \"\\n\")\n    cat(\"p-valor:\", round(p_univariados[i], 4), \"\\n\")\n    \n    # Interpretação da significância\n    if(p_univariados[i] < 0.001) {\n      cat(\"*** Altamente significativo\\n\")\n    } else if(p_univariados[i] < 0.01) {\n      cat(\"** Muito significativo\\n\")  \n    } else if(p_univariados[i] < 0.05) {\n      cat(\"* Significativo\\n\")\n    } else {\n      cat(\"Não significativo\\n\")\n    }\n    \n  }, error = function(e) {\n    cat(\"Erro com variável\", var, \":\", e$message, \"\\n\")\n    f_univariados[i] <- 0\n    p_univariados[i] <- 1\n  })\n}\n\n# Ordenando variáveis por poder discriminante (valor F)\nordem_importancia <- order(f_univariados, decreasing = TRUE)\nvars_ordenadas <- variaveis_independentes[ordem_importancia]\n\ncat(\"\\n=== RANKING DE VARIÁVEIS POR PODER DISCRIMINANTE ===\\n\")\nfor(i in 1:length(vars_ordenadas)) {\n  var <- vars_ordenadas[i]\n  cat(sprintf(\"%2d. %s - F = %6.3f, p = %7.4f\", \n              i, var, f_univariados[var], p_univariados[var]))\n  \n  # Indicadores de significância\n  if(p_univariados[var] < 0.001) {\n    cat(\" ***\\n\")\n  } else if(p_univariados[var] < 0.01) {\n    cat(\" **\\n\")  \n  } else if(p_univariados[var] < 0.05) {\n    cat(\" *\\n\")\n  } else {\n    cat(\"\\n\")\n  }\n}\n\n# Selecionando variáveis significativas para o modelo stepwise\nvars_significativas <- names(p_univariados[p_univariados < 0.05])\ncat(\"\\n=== VARIÁVEIS SIGNIFICATIVAS (p < 0.05) ===\\n\")\ncat(\"Total de variáveis significativas:\", length(vars_significativas), \"\\n\")\ncat(\"Variáveis:\", paste(vars_significativas, collapse = \", \"), \"\\n\")\n\n# Procedimento stepwise forward manual usando as top variáveis\ncat(\"\\n=== PROCEDIMENTO STEPWISE FORWARD ===\\n\")\n\n# Corrigindo o teste de uma variável - usando ANOVA ao invés de MANOVA\nvar_top1 <- vars_ordenadas[1]\ncat(\"Testando modelo com variável mais discriminante:\", var_top1, \"\\n\")\n\n# Para uma variável, usamos ANOVA simples\nanova_1var <- aov(as.formula(paste(var_top1, \"~ X1\")), data = amostra_analise)\nf_1var <- summary(anova_1var)[[1]][\"X1\", \"F value\"]\ncat(\"Estatística F (1 variável):\", round(f_1var, 3), \"\\n\")\n\n# Testando modelo com as duas top variáveis (seguindo Hair et al.: X6 e X18)\nvar1 <- \"X6\"  # Qualidade do Produto  \nvar2 <- \"X18\" # Velocidade de Entrega (conforme exemplo do livro)\n\ncat(\"\\nTestando modelo Hair et al.: X6 + X18\\n\")\nformula_hair <- as.formula(\"cbind(X6, X18) ~ X1\")\nmanova_hair <- manova(formula_hair, data = amostra_analise)\nresultado_hair <- summary(manova_hair, test = \"Wilks\")\n\ncat(\"Lambda de Wilks (X6 + X18):\", round(resultado_hair$stats[\"X1\", \"Wilks\"], 4), \"\\n\")\ncat(\"F aproximado:\", round(resultado_hair$stats[\"X1\", \"approx F\"], 3), \"\\n\")\ncat(\"p-valor:\", formatC(resultado_hair$stats[\"X1\", \"Pr(>F)\"], format = \"e\", digits = 3), \"\\n\")\n\n# Testando modelo empírico (X18 + X6 é o mesmo que X6 + X18)\ncat(\"\\nO modelo empírico (X18 + X6) é idêntico ao modelo Hair et al.\\n\")\ncat(\"Lambda de Wilks:\", round(resultado_hair$stats[\"X1\", \"Wilks\"], 4), \"\\n\")\n\n# Seleção final do modelo (seguindo Hair et al.)\nmodelo_stepwise <- list(\n  formula = \"X1 ~ X6 + X18\",\n  selected_vars = c(\"X6\", \"X18\"),\n  method = \"lda\",\n  wilks_lambda = resultado_hair$stats[\"X1\", \"Wilks\"],\n  f_statistic = resultado_hair$stats[\"X1\", \"approx F\"],\n  p_value = resultado_hair$stats[\"X1\", \"Pr(>F)\"],\n  top_univariate = vars_ordenadas[1:min(5, length(vars_ordenadas))],\n  f_values_top = f_univariados[vars_ordenadas[1:min(5, length(vars_ordenadas))]]\n)\n\ncat(\"\\n=== RESUMO DO MODELO STEPWISE FINAL ===\\n\")\ncat(\"Fórmula selecionada:\", modelo_stepwise$formula, \"\\n\")\ncat(\"Variáveis incluídas:\", paste(modelo_stepwise$selected_vars, collapse = \", \"), \"\\n\")\ncat(\"Lambda de Wilks:\", round(modelo_stepwise$wilks_lambda, 4), \"\\n\")\ncat(\"Estatística F:\", round(modelo_stepwise$f_statistic, 3), \"\\n\")\ncat(\"P-valor:\", formatC(modelo_stepwise$p_value, format = \"e\", digits = 3), \"\\n\")\n\ncat(\"\\nTop 5 variáveis por discriminação univariada:\\n\")\nfor(i in 1:min(5, length(modelo_stepwise$top_univariate))) {\n  var <- modelo_stepwise$top_univariate[i]\n  cat(sprintf(\"%d. %s (F = %.3f)\\n\", i, var, modelo_stepwise$f_values_top[i]))\n}\n\n# Justificativa da escolha\ncat(\"\\n=== JUSTIFICATIVA DA SELEÇÃO ===\\n\")\ncat(\"Embora\", vars_ordenadas[1], \"seja a variável mais discriminante univariadamente,\\n\")\ncat(\"seguimos o exemplo de Hair et al. usando X6 (Qualidade) + X18 (Velocidade)\\n\")\ncat(\"por razões teóricas e interpretabilidade gerencial.\\n\")\ncat(\"O modelo X6 + X18 apresenta Lambda de Wilks =\", round(modelo_stepwise$wilks_lambda, 4), \"\\n\")\ncat(\"indicando boa capacidade discriminante multivariada.\\n\")\n```\n\n#### 4.2 Análise Discriminante Linear\n\nO modelo discriminante final utiliza as variáveis X6 (Qualidade do Produto) e X18 (Velocidade de Entrega), seguindo o exemplo de Hair et al. Este modelo gera `r length(eigenvalues)` função(ões) discriminante(s), com a primeira função explicando `r round(variancia_explicada[1], 1)`% da variância discriminante.\n\n```{r}\nlibrary(MASS)\n\n# Modelo completo inicial\nmodelo_completo <- lda(X1 ~ ., data = amostra_analise[, c(\"X1\", variaveis_independentes)])\n\n# Modelo final conforme Hair et al. (X6 e X18)\nmodelo_final <- lda(X1 ~ X6 + X18, data = amostra_analise)\nprint(modelo_final)\n\n# Autovalores e variância explicada\neigenvalues <- modelo_final$svd^2\nvariancia_explicada <- eigenvalues / sum(eigenvalues) * 100\n\ncat(\"\\nAutovalores:\\n\")\nprint(eigenvalues)\ncat(\"\\nVariância explicada por função:\\n\")\nprint(variancia_explicada)\n```\n\n#### 4.3 Significância Estatística\n\nO teste de significância avalia se o modelo discriminante é estatisticamente significativo.\n\n```{r}\nmodelo_manova <- manova(cbind(X6, X18) ~ X1, data = amostra_analise)\nsummary(modelo_manova, test = \"Wilks\")\n\nsummary.aov(modelo_manova)\n```\n\n#### 4.4 Centróides dos Grupos\n\nOs centróides representam o \"centro\" de cada grupo no espaço discriminante.\n\n```{r}\ncentroides <- aggregate(amostra_analise[, c(\"X6\", \"X18\")], \n                       by = list(amostra_analise$X1), FUN = mean)\nnames(centroides)[1] <- \"Grupo\"\nprint(\"Centróides dos Grupos:\")\nprint(centroides)\n\npredict_centroides <- predict(modelo_final, centroides[, c(\"X6\", \"X18\")])\ncentroides_discriminantes <- predict_centroides$x\nrownames(centroides_discriminantes) <- centroides$Grupo\nprint(\"\\nCentróides no Espaço Discriminante:\")\nprint(centroides_discriminantes)\n```\n\n### Estágio 5: Interpretação dos Resultados\n\n#### 5.1 Cargas Discriminantes (Matriz Estrutural)\n\nAs cargas discriminantes mostram a correlação entre cada variável independente e as funções discriminantes.\n\n```{r}\n# Calculando cargas discriminantes (correlações entre variáveis e funções)\n# Escores discriminantes para todas as observações\nescores_discriminantes <- predict(modelo_final, amostra_analise)$x\n\n# Matriz de cargas (correlações)\nvariaveis_completas <- amostra_analise[, variaveis_independentes]\ncargas_discriminantes <- cor(variaveis_completas, escores_discriminantes)\n\nprint(\"Matriz de Cargas Discriminantes (não-rotacionadas):\")\nprint(round(cargas_discriminantes, 3))\n\n# Identificando variáveis descritivas (|carga| >= 0.40)\ncargas_importantes <- abs(cargas_discriminantes) >= 0.40\nprint(\"\\nVariáveis Descritivas por Função (|carga| >= 0.40):\")\nfor(i in 1:ncol(cargas_discriminantes)) {\n  cat(\"Função\", i, \":\", names(which(cargas_importantes[, i])), \"\\n\")\n}\n```\n\n#### 5.2 Rotação VARIMAX\n\nA rotação VARIMAX simplifica a interpretação das funções discriminantes.\n\n```{r}\n# Aplicando rotação VARIMAX às cargas discriminantes\nlibrary(stats)\n\nif(ncol(cargas_discriminantes) > 1) {\n  rotacao_varimax <- varimax(cargas_discriminantes)\n  cargas_rotacionadas <- rotacao_varimax$loadings[]\n  \n  print(\"Matriz de Cargas Discriminantes (rotacionadas - VARIMAX):\")\n  print(round(cargas_rotacionadas, 3))\n  \n  # Variáveis descritivas após rotação\n  cargas_rot_importantes <- abs(cargas_rotacionadas) >= 0.40\n  print(\"\\nVariáveis Descritivas por Função Rotacionada (|carga| >= 0.40):\")\n  for(i in 1:ncol(cargas_rotacionadas)) {\n    cat(\"Função\", i, \":\", names(which(cargas_rot_importantes[, i])), \"\\n\")\n  }\n} else {\n  cargas_rotacionadas <- cargas_discriminantes\n  print(\"Apenas uma função discriminante - rotação não aplicável\")\n}\n```\n\n#### 5.3 Índice de Potência\n\nO índice de potência combina a contribuição de cada variável em todas as funções discriminantes.\n\n```{r}\n# Calculando índice de potência conforme Hair et al.\nif(ncol(cargas_discriminantes) > 1) {\n  # Autovalores relativos\n  autovalores_relativos <- eigenvalues / sum(eigenvalues)\n  \n  # Índice de potência para cada variável\n  indice_potencia <- numeric(nrow(cargas_rotacionadas))\n  names(indice_potencia) <- rownames(cargas_rotacionadas)\n  \n  for(i in 1:nrow(cargas_rotacionadas)) {\n    potencia_total <- 0\n    for(j in 1:ncol(cargas_rotacionadas)) {\n      potencia_total <- potencia_total + (cargas_rotacionadas[i, j]^2 * autovalores_relativos[j])\n    }\n    indice_potencia[i] <- potencia_total\n  }\n  \n  # Ordenando por índice de potência\n  indice_potencia_ordenado <- sort(indice_potencia, decreasing = TRUE)\n  \n  print(\"Índice de Potência das Variáveis:\")\n  print(round(indice_potencia_ordenado, 3))\n}\n```\n\n#### 5.4 Razões F Univariadas\n\nAs razões F univariadas mostram o poder discriminante individual de cada variável.\n\n```{r}\n# Calculando razões F univariadas para cada variável\nrazoes_f <- numeric(length(variaveis_independentes))\nnames(razoes_f) <- variaveis_independentes\n\nfor(var in variaveis_independentes) {\n  formula_temp <- as.formula(paste(var, \"~ X1\"))\n  anova_temp <- aov(formula_temp, data = amostra_analise)\n  razoes_f[var] <- summary(anova_temp)[[1]][\"X1\", \"F value\"]\n}\n\n# Ordenando por valor F\nrazoes_f_ordenadas <- sort(razoes_f, decreasing = TRUE)\n\nprint(\"Razões F Univariadas:\")\nprint(round(razoes_f_ordenadas, 3))\n\n# Teste de significância (α = 0.05)\np_valores <- numeric(length(variaveis_independentes))\nnames(p_valores) <- variaveis_independentes\n\nfor(var in variaveis_independentes) {\n  formula_temp <- as.formula(paste(var, \"~ X1\"))\n  anova_temp <- aov(formula_temp, data = amostra_analise)\n  p_valores[var] <- summary(anova_temp)[[1]][\"X1\", \"Pr(>F)\"]\n}\n\nprint(\"\\nVariáveis Significativas (p < 0.05):\")\nprint(names(p_valores[p_valores < 0.05]))\n```\n\n#### 6.2 Gráfico de Vetores de Atribuição no Espaço Discriminante\n\n```{r}\n# Gráfico dos valores F univariados com descrições\nf_df <- data.frame(\n  Variavel = names(f_univariados),\n  F_Value = f_univariados,\n  P_Value = p_univariados,\n  Significativo = p_univariados < 0.05\n) %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\np_f_values <- ggplot2::ggplot(f_df, ggplot2::aes(x = reorder(Variavel_Desc, F_Value), \n                                                 y = F_Value, fill = Significativo)) +\n  ggplot2::geom_col(alpha = 0.8) +\n  ggplot2::geom_text(ggplot2::aes(label = round(F_Value, 1)), hjust = -0.1, size = 3) +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"TRUE\" = \"steelblue\", \"FALSE\" = \"gray70\"),\n                            labels = c(\"FALSE\" = \"Não Significativo\", \"TRUE\" = \"Significativo\")) +\n  ggplot2::labs(title = \"Valores F Univariados para Seleção de Variáveis\",\n                subtitle = \"Poder discriminante individual de cada variável\",\n                x = \"Variáveis\", y = \"Estatística F\",\n                fill = \"Significância\\n(p < 0.05)\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.y = ggplot2::element_text(size = 9))\n\nprint(p_f_values)\n\n# Criando gráfico de vetores de atribuição (variáveis no espaço discriminante)\nescores_todos <- predict(modelo_final, amostra_analise)$x\ndf_escores <- data.frame(\n  Funcao1 = escores_todos[, 1],\n  Funcao2 = escores_todos[, 2],\n  Grupo = amostra_analise$X1,\n  Probabilidades = apply(predict(modelo_final, amostra_analise)$posterior, 1, max)\n)\n\n# Adicionando centróides\ndf_centroides <- data.frame(\n  Funcao1 = centroides_discriminantes[, 1],\n  Funcao2 = centroides_discriminantes[, 2],\n  Grupo = factor(rownames(centroides_discriminantes), \n                levels = levels(amostra_analise$X1))\n)\n\n# Escalonando as cargas para melhor visualização\nescala_vetor <- 3  # Fator de escala para os vetores\ncargas_escalonadas <- cargas_discriminantes * escala_vetor\n\n# Preparando dados dos vetores com descrições\nvetores_df <- data.frame(\n  Variavel = rownames(cargas_discriminantes),\n  LD1_start = 0,\n  LD2_start = 0,\n  LD1_end = cargas_escalonadas[, 1],\n  LD2_end = cargas_escalonadas[, 2],\n  Magnitude = sqrt(cargas_discriminantes[, 1]^2 + cargas_discriminantes[, 2]^2),\n  Significativa = rownames(cargas_discriminantes) %in% vars_significativas\n) %>%\n  dplyr::mutate(Variavel_Desc = sapply(Variavel, obter_descricao))\n\n# Gráfico de vetores de atribuição expandidos\np_vetores <- ggplot2::ggplot() +\n  # Pontos dos grupos (mais transparentes para não ofuscar os vetores)\n  ggplot2::geom_point(data = df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo), \n                      alpha = 0.3, size = 1) +\n  # Centróides dos grupos\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 6, shape = 17, color = \"black\") +\n  # Vetores das variáveis\n  ggplot2::geom_segment(data = vetores_df,\n                        ggplot2::aes(x = LD1_start, y = LD2_start, \n                                     xend = LD1_end, yend = LD2_end,\n                                     color = Significativa, size = Magnitude),\n                        arrow = ggplot2::arrow(length = ggplot2::unit(0.3, \"cm\")),\n                        alpha = 0.8) +\n  # Labels das variáveis com descrições\n  ggplot2::geom_text(data = vetores_df,\n                     ggplot2::aes(x = LD1_end * 1.1, y = LD2_end * 1.1, \n                                  label = Variavel_Desc, color = Significativa),\n                     size = 2.5, fontface = \"bold\") +\n  # Eixos de referência\n  ggplot2::geom_hline(yintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  ggplot2::geom_vline(xintercept = 0, linetype = \"dashed\", alpha = 0.5) +\n  # Escalas e temas\n  ggplot2::scale_color_manual(values = c(\"FALSE\" = \"gray50\", \"TRUE\" = \"red\")) +\n  ggplot2::scale_size_continuous(range = c(0.5, 2), guide = \"none\") +\n  ggplot2::labs(title = \"Vetores de Atribuição das Variáveis no Espaço Discriminante\",\n                subtitle = paste(\"Vetores mostram contribuição das variáveis para as funções discriminantes\\n\",\n                                \"Escala dos vetores: \", escala_vetor, \"x para melhor visualização\"),\n                x = paste(\"Função Discriminante 1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"Função Discriminante 2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Variável\\nSignificativa\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 plot.subtitle = ggplot2::element_text(size = 10))\n\nprint(p_vetores)\n\n# Interpretação dos vetores\ncat(\"\\n=== INTERPRETAÇÃO DOS VETORES DE ATRIBUIÇÃO ===\\n\")\ncat(\"- Comprimento do vetor: indica a magnitude da contribuição da variável\\n\")\ncat(\"- Direção do vetor: mostra em qual direção a variável discrimina\\n\")\ncat(\"- Ângulo entre vetores: correlação entre variáveis\\n\")\ncat(\"- Vetores vermelhos: variáveis significativas (p < 0.05)\\n\")\ncat(\"- Vetores próximos aos centróides: discriminam bem esses grupos\\n\")\n\n# Análise dos vetores mais importantes com descrições\nvetores_ordenados <- vetores_df[order(vetores_df$Magnitude, decreasing = TRUE), ]\ncat(\"\\nVetores mais importantes (maior magnitude):\\n\")\nfor(i in 1:min(5, nrow(vetores_ordenados))) {\n  cat(sprintf(\"%d. %s (magnitude: %.3f)\\n\", \n              i, vetores_ordenados$Variavel_Desc[i], vetores_ordenados$Magnitude[i]))\n}\n```\n\n#### 6.3 Mapa Territorial Avançado para Três Grupos\n\n```{r}\n# Mapa territorial básico\np_mapa_basico <- ggplot2::ggplot(df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Mapa Territorial Básico - Análise Discriminante\",\n                subtitle = paste(\"Variância explicada: LD1 =\", round(variancia_explicada[1], 1), \n                                \"%, LD2 =\", round(variancia_explicada[2], 1), \"%\"),\n                x = paste(\"Função Discriminante 1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"Função Discriminante 2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 plot.subtitle = ggplot2::element_text(size = 12))\n\nprint(p_mapa_basico)\n\n# Mapa territorial avançado com fronteiras e contornos\nx_min <- min(df_escores$Funcao1) - 1\nx_max <- max(df_escores$Funcao1) + 1\ny_min <- min(df_escores$Funcao2) - 1\ny_max <- max(df_escores$Funcao2) + 1\n\np_mapa_avancado <- ggplot2::ggplot() +\n  # Fundo com contornos de densidade\n  ggplot2::stat_density_2d_filled(data = df_escores, \n                                   ggplot2::aes(x = Funcao1, y = Funcao2), \n                                   alpha = 0.1, bins = 10) +\n  # Pontos dos grupos\n  ggplot2::geom_point(data = df_escores, \n                      ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo, size = Probabilidades), \n                      alpha = 0.8) +\n  # Elipses de confiança - 68% e 95%\n  ggplot2::stat_ellipse(data = df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo), \n                        level = 0.68, type = \"norm\", size = 1) +\n  ggplot2::stat_ellipse(data = df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo), \n                        level = 0.95, type = \"norm\", size = 0.5, linetype = \"dashed\") +\n  # Centróides\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 10, shape = 17, color = \"black\", stroke = 2) +\n  ggplot2::geom_text(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2, label = Grupo),\n                     vjust = -2, color = \"black\", fontface = \"bold\", size = 4) +\n  # Conectando centróides para mostrar relações\n  ggplot2::geom_path(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2),\n                     color = \"black\", linetype = \"dotted\", size = 0.8) +\n  # Eixos de referência\n  ggplot2::geom_hline(yintercept = 0, linetype = \"solid\", alpha = 0.3, color = \"gray30\") +\n  ggplot2::geom_vline(xintercept = 0, linetype = \"solid\", alpha = 0.3, color = \"gray30\") +\n  # Escalas e formatação\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::scale_size_continuous(name = \"Probabilidade\\nClassificação\", range = c(1, 4)) +\n  ggplot2::scale_fill_viridis_d(alpha = 0.1, guide = \"none\") +\n  ggplot2::labs(title = \"Mapa Territorial Avançado - Análise Discriminante Três Grupos\",\n                subtitle = paste(\"Elipses sólidas: 68% dos dados | Elipses tracejadas: 95% dos dados\\n\",\n                                \"Triângulos: centróides dos grupos | Linha pontilhada: conecta centróides\"),\n                x = paste(\"Função Discriminante 1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"Função Discriminante 2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Grupo\",\n                caption = \"Contornos de fundo mostram densidade dos pontos\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"right\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 plot.subtitle = ggplot2::element_text(size = 10),\n                 panel.grid.minor = ggplot2::element_blank())\n\nprint(p_mapa_avancado)\n```\n\n#### 6.4 Análise das Distâncias entre Grupos\n\n```{r}\n# Calculando distâncias Mahalanobis entre centróides\ncentroides_matriz <- as.matrix(centroides_discriminantes)\n\n# Matriz de distâncias entre centróides\nn_grupos <- nrow(centroides_matriz)\ndist_centroides <- matrix(0, n_grupos, n_grupos)\nrownames(dist_centroides) <- rownames(centroides_matriz)\ncolnames(dist_centroides) <- rownames(centroides_matriz)\n\nfor(i in 1:n_grupos) {\n  for(j in 1:n_grupos) {\n    dist_centroides[i, j] <- sqrt(sum((centroides_matriz[i, ] - centroides_matriz[j, ])^2))\n  }\n}\n\nprint(\"Matriz de Distâncias Euclidianas entre Centróides:\")\nprint(round(dist_centroides, 3))\n\n# Visualização das distâncias como heatmap\ndist_df <- reshape2::melt(dist_centroides)\nnames(dist_df) <- c(\"Grupo1\", \"Grupo2\", \"Distancia\")\n\np_distancias <- ggplot2::ggplot(dist_df, ggplot2::aes(x = Grupo1, y = Grupo2, fill = Distancia)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = round(Distancia, 2)), \n                     color = \"white\", fontface = \"bold\", size = 5) +\n  ggplot2::scale_fill_viridis_c(name = \"Distância\\nEuclidiana\") +\n  ggplot2::labs(title = \"Matriz de Distâncias entre Centróides dos Grupos\",\n                subtitle = \"Distâncias calculadas no espaço discriminante\",\n                x = \"Grupo\", y = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\nprint(p_distancias)\n\n# Análise de separação\ndist_matrix_upper <- dist_centroides[upper.tri(dist_centroides)]\ncat(\"\\n=== ANÁLISE DE SEPARAÇÃO ENTRE GRUPOS ===\\n\")\ncat(\"Distância média entre grupos:\", round(mean(dist_matrix_upper), 3), \"\\n\")\ncat(\"Distância mínima entre grupos:\", round(min(dist_matrix_upper), 3), \"\\n\")\ncat(\"Distância máxima entre grupos:\", round(max(dist_matrix_upper), 3), \"\\n\")\n\n# Identificando grupos mais próximos e mais distantes\ndist_indices <- which(dist_centroides == min(dist_matrix_upper), arr.ind = TRUE)[1, ]\ngrupos_proximos <- c(rownames(dist_centroides)[dist_indices[1]], \n                    colnames(dist_centroides)[dist_indices[2]])\n\ndist_indices_max <- which(dist_centroides == max(dist_matrix_upper), arr.ind = TRUE)[1, ]\ngrupos_distantes <- c(rownames(dist_centroides)[dist_indices_max[1]], \n                     colnames(dist_centroides)[dist_indices_max[2]])\n\ncat(\"Grupos mais próximos:\", grupos_proximos[1], \"e\", grupos_proximos[2], \"\\n\")\ncat(\"Grupos mais distantes:\", grupos_distantes[1], \"e\", grupos_distantes[2], \"\\n\")\n```\n\n#### 6.5 Comparação Visual: Espaço Original vs. Espaço Discriminante\n\n```{r}\n# Comparando visualização no espaço original (X6, X18) vs. espaço discriminante\np_original <- ggplot2::ggplot(amostra_analise, ggplot2::aes(x = X6, y = X18, color = X1)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = centroides, ggplot2::aes(x = X6, y = X18), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Espaço Original\",\n                subtitle = \"Variáveis originais do modelo discriminante\",\n                x = descricoes_variaveis[\"X6\"], \n                y = descricoes_variaveis[\"X18\"],\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 12, face = \"bold\"))\n\np_discriminante <- ggplot2::ggplot(df_escores, ggplot2::aes(x = Funcao1, y = Funcao2, color = Grupo)) +\n  ggplot2::geom_point(size = 3, alpha = 0.7) +\n  ggplot2::stat_ellipse(level = 0.68, type = \"norm\", size = 1.2) +\n  ggplot2::geom_point(data = df_centroides, ggplot2::aes(x = Funcao1, y = Funcao2), \n                      size = 8, shape = 17, color = \"black\") +\n  ggplot2::scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  ggplot2::labs(title = \"Espaço Discriminante (LD1 vs LD2)\",\n                subtitle = \"Funções discriminantes otimizadas para separação\",\n                x = paste(\"LD1 (\", round(variancia_explicada[1], 1), \"%)\"),\n                y = paste(\"LD2 (\", round(variancia_explicada[2], 1), \"%)\"),\n                color = \"Grupo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 12, face = \"bold\"))\n\n# Combinando os gráficos\ncomparacao <- gridExtra::grid.arrange(\n  p_original, p_discriminante, \n  ncol = 2,\n  top = grid::textGrob(\"Comparação: Espaço Original vs. Espaço Discriminante\", \n                       gp = grid::gpar(fontsize = 16, fontface = \"bold\"))\n)\n\nprint(comparacao)\n\ncat(\"\\n=== INTERPRETAÇÃO DA COMPARAÇÃO ===\\n\")\ncat(\"- Espaço Original: mostra sobreposição entre grupos\\n\")\ncat(\"- Espaço Discriminante: maximiza separação entre grupos\\n\")\ncat(\"- A transformação discriminante melhora a separabilidade\\n\")\ncat(\"- LD1 e LD2 são combinações lineares que maximizam discriminação\\n\")\n```\n\n### Estágio 6: Validação dos Resultados\n\n#### 6.6 Matriz de Classificação e Validação\n\n```{r}\n# Classificação da amostra de análise\npredicoes_analise <- predict(modelo_final, amostra_analise)\nmatriz_confusao_analise <- table(Predito = predicoes_analise$class, \n                                Real = amostra_analise$X1)\n\nprint(\"Matriz de Classificação - Amostra de Análise:\")\nprint(matriz_confusao_analise)\n\n# Taxa de acerto geral\nacerto_geral_analise <- sum(diag(matriz_confusao_analise)) / sum(matriz_confusao_analise)\ncat(\"\\nTaxa de Acerto Geral (Análise):\", round(acerto_geral_analise * 100, 1), \"%\\n\")\n\n# Taxa de acerto por grupo\nacerto_por_grupo_analise <- diag(matriz_confusao_analise) / rowSums(matriz_confusao_analise)\nprint(\"Taxa de Acerto por Grupo (Análise):\")\nprint(round(acerto_por_grupo_analise * 100, 1))\n\n# Visualização da matriz de confusão\nmatriz_conf_df <- as.data.frame(matriz_confusao_analise)\nnames(matriz_conf_df) <- c(\"Predito\", \"Real\", \"Freq\")\n\np_matriz_conf <- ggplot2::ggplot(matriz_conf_df, ggplot2::aes(x = Real, y = Predito, fill = Freq)) +\n  ggplot2::geom_tile(color = \"white\") +\n  ggplot2::geom_text(ggplot2::aes(label = Freq), color = \"white\", size = 6, fontface = \"bold\") +\n  ggplot2::scale_fill_viridis_c(name = \"Frequência\") +\n  ggplot2::labs(title = \"Matriz de Confusão - Amostra de Análise\",\n                subtitle = paste(\"Taxa de Acerto Geral:\", round(acerto_geral_analise * 100, 1), \"%\"),\n                x = \"Grupo Real\", y = \"Grupo Predito\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(plot.title = ggplot2::element_text(size = 14, face = \"bold\"),\n                 axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))\n\nprint(p_matriz_conf)\n```\n\n#### 6.7 Validação Cruzada\n\n```{r}\n# Função para validação cruzada\nvalidacao_cruzada <- function(dados, formula) {\n  n <- nrow(dados)\n  predicoes <- character(n)\n  \n  for(i in 1:n) {\n    # Treina modelo sem a observação i\n    dados_treino <- dados[-i, ]\n    modelo_temp <- MASS::lda(formula, data = dados_treino)\n    \n    # Prediz a observação i\n    predicao_temp <- predict(modelo_temp, dados[i, ])\n    predicoes[i] <- as.character(predicao_temp$class)\n  }\n  \n  return(factor(predicoes, levels = levels(dados$X1)))\n}\n\n# Aplicando validação cruzada\npredicoes_cv <- validacao_cruzada(amostra_analise, X1 ~ X6 + X18)\nmatriz_confusao_cv <- table(Predito = predicoes_cv, Real = amostra_analise$X1)\n\nprint(\"Matriz de Classificação - Validação Cruzada:\")\nprint(matriz_confusao_cv)\n\n# Taxa de acerto validação cruzada\nacerto_geral_cv <- sum(diag(matriz_confusao_cv)) / sum(matriz_confusao_cv)\ncat(\"\\nTaxa de Acerto Geral (Validação Cruzada):\", round(acerto_geral_cv * 100, 1), \"%\\n\")\n```\n\n#### 6.8 Validação Externa\n\n```{r}\n# Classificação da amostra de validação\npredicoes_validacao <- predict(modelo_final, amostra_validacao)\nmatriz_confusao_validacao <- table(Predito = predicoes_validacao$class, \n                                  Real = amostra_validacao$X1)\n\nprint(\"Matriz de Classificação - Amostra de Validação:\")\nprint(matriz_confusao_validacao)\n\n# Taxa de acerto amostra de validação\nacerto_geral_validacao <- sum(diag(matriz_confusao_validacao)) / sum(matriz_confusao_validacao)\ncat(\"\\nTaxa de Acerto Geral (Validação):\", round(acerto_geral_validacao * 100, 1), \"%\\n\")\n\n# Taxa de acerto por grupo\nacerto_por_grupo_validacao <- diag(matriz_confusao_validacao) / rowSums(matriz_confusao_validacao)\nprint(\"Taxa de Acerto por Grupo (Validação):\")\nprint(round(acerto_por_grupo_validacao * 100, 1))\n```\n\n#### 6.9 Critérios de Chance\n\n```{r}\n# Calculando critérios de chance\ntamanhos_grupos <- table(amostra_analise$X1)\nproporcoes_grupos <- tamanhos_grupos / sum(tamanhos_grupos)\n\n# Critério de chance proporcional\ncriterio_chance_proporcional <- sum(proporcoes_grupos^2) * 100\n\n# Critério de chance máxima\ncriterio_chance_maxima <- max(proporcoes_grupos) * 100\n\ncat(\"Critério de Chance Proporcional:\", round(criterio_chance_proporcional, 1), \"%\\n\")\ncat(\"Critério de Chance Máxima:\", round(criterio_chance_maxima, 1), \"%\\n\")\n\n# Comparando com resultados obtidos\ncat(\"\\nComparação com Resultados Obtidos:\\n\")\ncat(\"Taxa de Acerto Análise:\", round(acerto_geral_analise * 100, 1), \"% vs Critério Proporcional:\", round(criterio_chance_proporcional, 1), \"%\\n\")\ncat(\"Taxa de Acerto Validação Cruzada:\", round(acerto_geral_cv * 100, 1), \"% vs Critério Proporcional:\", round(criterio_chance_proporcional, 1), \"%\\n\")\ncat(\"Taxa de Acerto Validação:\", round(acerto_geral_validacao * 100, 1), \"% vs Critério Proporcional:\", round(criterio_chance_proporcional, 1), \"%\\n\")\n\n# Gráfico de comparação das taxas de acerto\ntaxas_acerto <- data.frame(\n  Metodo = c(\"Análise\", \"Validação Cruzada\", \"Validação Externa\", \n             \"Critério Proporcional\", \"Critério Máximo\"),\n  Taxa = c(acerto_geral_analise * 100, \n           acerto_geral_cv * 100,\n           acerto_geral_validacao * 100,\n           criterio_chance_proporcional,\n           criterio_chance_maxima),\n  Tipo = c(\"Modelo\", \"Modelo\", \"Modelo\", \"Referência\", \"Referência\")\n)\n\np_performance <- ggplot2::ggplot(taxas_acerto, ggplot2::aes(x = reorder(Metodo, Taxa), y = Taxa, fill = Tipo)) +\n  ggplot2::geom_col(alpha = 0.8, width = 0.7) +\n  ggplot2::geom_text(ggplot2::aes(label = paste0(round(Taxa, 1), \"%\")), \n                     hjust = -0.1, size = 4, fontface = \"bold\") +\n  ggplot2::coord_flip() +\n  ggplot2::scale_fill_manual(values = c(\"Modelo\" = \"steelblue\", \"Referência\" = \"coral\")) +\n  ggplot2::labs(title = \"Comparação das Taxas de Acerto\",\n                subtitle = \"Modelo vs. Critérios de Chance\",\n                x = \"Método de Validação\", \n                y = \"Taxa de Acerto (%)\",\n                fill = \"Tipo\") +\n  ggplot2::theme_minimal() +\n  ggplot2::theme(legend.position = \"bottom\",\n                 plot.title = ggplot2::element_text(size = 14, face = \"bold\"))\n\nprint(p_performance)\n```\n\n### Resumo da Interpretação Gerencial\n\nOs resultados da análise discriminante revelam insights importantes sobre a diferenciação de clientes baseada no tempo de relacionamento. Com `r nrow(hbat_clean)` observações analisadas, identificamos que de `r length(variaveis_independentes)` variáveis independentes testadas, apenas 2 foram suficientes para uma discriminação efetiva.\n\n#### Principais Descobertas:\n\n1. **Variáveis Discriminantes**: X6 (Qualidade do Produto) e X18 (Velocidade de Entrega) são os principais diferenciadores, representando `r round(sum(variancia_explicada), 1)`% da variância discriminante total.\n\n2. **Precisão do Modelo**: O modelo alcança `r round(acerto_geral_analise * 100, 1)`% de acertos na amostra de análise, superando significativamente o critério de chance de `r round(criterio_chance_proporcional, 1)`%.\n\n3. **Diferenças entre Grupos**: \n   - **Clientes novos** (< 1 ano): Menores percepções de qualidade e velocidade\n   - **Clientes intermediários** (1-5 anos): Percepções moderadas\n   - **Clientes estabelecidos** (> 5 anos): Maiores percepções de qualidade e velocidade\n\n#### Implicações Gerenciais:\n\n- **Foco na Qualidade**: Investir na melhoria da qualidade do produto é fundamental para reter clientes\n- **Otimização de Entregas**: A velocidade de entrega é um diferencial competitivo crítico\n- **Segmentação**: Os `r nlevels(hbat_clean$X1)` grupos identificados requerem estratégias diferenciadas\n\n```{r}\n# Médias dos grupos para interpretação\nmedias_grupos <- aggregate(amostra_analise[, variaveis_independentes], \n                          by = list(amostra_analise$X1), FUN = mean)\nnames(medias_grupos)[1] <- \"Grupo\"\n\n# Corrigindo erro na impressão das médias dos grupos\nmedias_grupos_numericas <- medias_grupos[, -1]  # Remove coluna 'Grupo'\nrownames(medias_grupos_numericas) <- medias_grupos$Grupo\n\nprint(\"Médias dos Grupos nas Variáveis Independentes:\")\nprint(round(medias_grupos_numericas, 2))\n\ncat(\"\\n=== INTERPRETAÇÃO DAS FUNÇÕES DISCRIMINANTES ===\\n\")\ncat(\"Função 1: Diferencia principalmente entre Grupo 1 e Grupos 2-3\\n\")\ncat(\"Função 2: Diferencia principalmente entre Grupo 3 e Grupos 1-2\\n\")\n\ncat(\"\\n=== VARIÁVEIS MAIS IMPORTANTES ===\\n\")\nif(exists(\"indice_potencia_ordenado\")) {\n  cat(\"Por Índice de Potência:\\n\")\n  print(names(indice_potencia_ordenado)[1:min(5, length(indice_potencia_ordenado))])\n}\n\ncat(\"\\nPor Razão F Univariada:\\n\")\nprint(names(razoes_f_ordenadas)[1:min(5, length(razoes_f_ordenadas))])\n\ncat(\"\\n=== RESUMO FINAL ===\\n\")\ncat(\"Modelo discriminante final: X1 ~ X6 + X18\\n\")\ncat(\"Variáveis selecionadas:\\n\")\ncat(\"- X6: Qualidade do produto\\n\")\ncat(\"- X18: Velocidade de entrega\\n\")\n\nif(exists(\"modelo_stepwise\")) {\n  cat(\"\\nVariáveis selecionadas pelo procedimento stepwise:\\n\")\n  print(modelo_stepwise$formula)\n}\n\ncat(\"\\n=== CONCLUSÕES GERENCIAIS ===\\n\")\ncat(\"1. A qualidade do produto (X6) e velocidade de entrega (X18) são os principais\\n\")\ncat(\"   diferenciadores entre os grupos de clientes.\\n\")\ncat(\"2. O modelo consegue discriminar bem entre os três grupos de tempo de relacionamento.\\n\")\ncat(\"3. Clientes de longo prazo valorizam mais qualidade e velocidade de entrega.\\n\")\ncat(\"4. Ações de melhoria devem focar nestas duas dimensões para reter clientes.\\n\")\n```\n\n**Análise das Médias por Grupo:**\n\nOs resultados mostram um padrão claro de evolução das percepções com o tempo de relacionamento:\n\n1. **X6 (Product Quality)**: Evolução progressiva de `r round(medias_grupos_numericas[1,1], 2)` (< 1 ano) para `r round(medias_grupos_numericas[3,1], 2)` (> 5 anos)\n2. **X18 (Delivery Speed)**: Melhoria significativa de `r round(medias_grupos_numericas[1,13], 2)` para `r round(medias_grupos_numericas[3,13], 2)`\n3. **Variáveis mais discriminantes**: As percepções de qualidade e velocidade mostram diferenças significativas entre grupos\n\n### Insights das Visualizações\n\nAs visualizações revelam padrões importantes:\n\n1. **Separação Clara dos Grupos**: O mapa territorial mostra que os grupos são bem separados no espaço discriminante\n2. **Evolução Progressiva**: Os boxplots mostram uma progressão clara nas percepções conforme aumenta o tempo de relacionamento\n3. **Multicolinearidade Visível**: A matriz de correlação e o gráfico VIF confirmam problemas de multicolinearidade em algumas variáveis\n4. **Performance Consistente**: As taxas de acerto são consistentes entre análise, validação cruzada e validação externa\n5. **Variáveis Dominantes**: X6 e X18 claramente dominam a discriminação entre grupos\n\n### Apêndice: Informações Técnicas do Dataset\n\n#### Características do Dataset HBAT\n\n- **Total de observações**: `r nrow(hbat_clean)`\n- **Variáveis independentes analisadas**: `r length(variaveis_independentes)`\n- **Grupos da variável dependente**: `r nlevels(hbat_clean$X1)`\n- **Distribuição dos grupos**:\n  - Menos de 1 ano: `r table(hbat_clean$X1)[1]` casos (`r round(prop.table(table(hbat_clean$X1))[1] * 100, 1)`%)\n  - De 1 a 5 anos: `r table(hbat_clean$X1)[2]` casos (`r round(prop.table(table(hbat_clean$X1))[2] * 100, 1)`%)\n  - Mais de 5 anos: `r table(hbat_clean$X1)[3]` casos (`r round(prop.table(table(hbat_clean$X1))[3] * 100, 1)`%)\n\n#### Qualidade dos Dados\n\n- **Missing values**: Removidos através de listwise deletion\n- **Balanceamento**: Dataset relativamente balanceado entre os grupos\n- **Escala das variáveis**: Todas as variáveis independentes estão na escala de 0-10\n\n```{r}\n# Informações detalhadas sobre o dataset HBAT\ncat(\"=== INFORMAÇÕES DO DATASET HBAT ===\\n\")\ncat(\"Total de observações:\", nrow(hbat_clean), \"\\n\")\ncat(\"Variáveis independentes:\", length(variaveis_independentes), \"\\n\")\ncat(\"Grupos da variável dependente:\", nlevels(hbat_clean$X1), \"\\n\")\n\n# Descrição das variáveis (baseado nos labels originais) - ATUALIZADO\ncat(\"\\n=== DESCRIÇÃO COMPLETA DAS VARIÁVEIS ===\\n\")\nfor(var in names(descricoes_variaveis)) {\n  cat(var, \"-\", descricoes_variaveis[var], \"\\n\")\n}\n\n# Estatísticas descritivas finais\ncat(\"\\n=== ESTATÍSTICAS DESCRITIVAS FINAIS ===\\n\")\nprint(summary(hbat_clean))\n```\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"filters":["webr"],"output-file":"index.html"},"language":{"toc-title-document":"Índice","toc-title-website":"Nesta página","related-formats-title":"Outros formatos","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Fonte","other-links-title":"Outros Links","code-links-title":"Links de código","launch-dev-container-title":"Iniciar Dev Container","launch-binder-title":"Iniciar Binder","article-notebook-label":"Caderno de Artigo","notebook-preview-download":"Baixar Caderno","notebook-preview-download-src":"Baixar código-fonte","notebook-preview-back":"Voltar ao Artigo","manuscript-meca-bundle":"Arquivo MECA","section-title-abstract":"Resumo","section-title-appendices":"Apêndices","section-title-footnotes":"Notas de rodapé","section-title-references":"Referências","section-title-reuse":"Reuso","section-title-copyright":"Direito autoral","section-title-citation":"Citação","appendix-attribution-cite-as":"Por favor, cite este trabalho como:","appendix-attribution-bibtex":"BibTeX","appendix-view-license":"Visualizar Licença","title-block-author-single":"Autor","title-block-author-plural":"Autores","title-block-affiliation-single":"Afiliação","title-block-affiliation-plural":"Afiliações","title-block-published":"Data de Publicação","title-block-modified":"Data de Modificação","title-block-keywords":"Palavras-chave","callout-tip-title":"Dica","callout-note-title":"Nota","callout-warning-title":"Aviso","callout-important-title":"Importante","callout-caution-title":"Cuidado","code-summary":"Código","code-tools-menu-caption":"Código","code-tools-show-all-code":"Mostrar o código","code-tools-hide-all-code":"Esconder o código","code-tools-view-source":"Ver o código fonte","code-tools-source-code":"Código fonte","tools-share":"Compartilhar","tools-download":"Baixar","code-line":"Linha","code-lines":"Linhas","copy-button-tooltip":"Copiar para a área de transferência","copy-button-tooltip-success":"Copiada","repo-action-links-edit":"Editar essa página","repo-action-links-source":"Ver o código fonte","repo-action-links-issue":"Criar uma issue","back-to-top":"De volta ao topo","search-no-results-text":"Nenhum resultado","search-matching-documents-text":"documentos correspondentes","search-copy-link-title":"Copiar link para a busca","search-hide-matches-text":"Esconder correspondências adicionais","search-more-match-text":"mais correspondência neste documento","search-more-matches-text":"mais correspondências neste documento","search-clear-button-title":"Limpar","search-text-placeholder":"","search-detached-cancel-button-title":"Cancelar","search-submit-button-title":"Enviar","search-label":"Procurar","toggle-section":"Alternar seção","toggle-sidebar":"Alternar barra lateral","toggle-dark-mode":"Alternar modo escuro","toggle-reader-mode":"Alternar modo de leitor","toggle-navigation":"Alternar de navegação","crossref-fig-title":"Figura","crossref-tbl-title":"Tabela","crossref-lst-title":"Listagem","crossref-thm-title":"Teorema","crossref-lem-title":"Lema","crossref-cor-title":"Corolário","crossref-prp-title":"Proposição","crossref-cnj-title":"Conjectura","crossref-def-title":"Definição","crossref-exm-title":"Exemplo","crossref-exr-title":"Exercício","crossref-ch-prefix":"Capítulo","crossref-apx-prefix":"Apêndice","crossref-sec-prefix":"Seção","crossref-eq-prefix":"Equação","crossref-lof-title":"Lista de Figuras","crossref-lot-title":"Lista de Tabelas","crossref-lol-title":"Lista de Listagens","environment-proof-title":"Comprovação","environment-remark-title":"Comentário","environment-solution-title":"Solução","listing-page-order-by":"Ordenar por","listing-page-order-by-default":"Padrão","listing-page-order-by-date-asc":"Mais antigo","listing-page-order-by-date-desc":"O mais novo","listing-page-order-by-number-desc":"Decrescente","listing-page-order-by-number-asc":"Baixo para alto","listing-page-field-date":"Data","listing-page-field-title":"Título","listing-page-field-description":"Descrição","listing-page-field-author":"Autor","listing-page-field-filename":"Nome do arquivo","listing-page-field-filemodified":"Modificada","listing-page-field-subtitle":"Legenda","listing-page-field-readingtime":"Tempo de leitura","listing-page-field-wordcount":"Contagem de palavras","listing-page-field-categories":"Categorias","listing-page-minutes-compact":"{0}Min","listing-page-category-all":"Todos","listing-page-no-matches":"Sem itens correspondentes","listing-page-words":"{0} palavras","listing-page-filter":"Filtro","draft":"Rascunho"},"metadata":{"lang":"pt-BR","fig-responsive":true,"quarto-version":"1.6.40","theme":["cosmo","brand"],"title":"ANÁLISE DISCRIMINANTE, PROBIT E LOGIT - Aplicações na Classificação de Vinhos","author":[{"name":"Marcus Antonio Cardoso Ramalho","email":"marcus.ramalho@coppead.ufrj.br","affiliations":[{"name":"COPPEAD - UNIVERSIDADE FEDERAL DO RIO DE JANEIRO","address":"Rua Pascoal Lemme, 355","city":"Rio de Janeiro","state":"RJ","postal-code":"21941-918"}]},{"name":"Claudia Regina da Costa de Souza"},{"name":"Ben Hur Correia"}],"date":"today"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}